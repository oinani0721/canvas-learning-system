# Neo4j GDS Leidenç®—æ³•å‚æ•°è°ƒä¼˜æŒ‡å—

**Story**: GDS.1 - Ebbinghaus Trigger Point 4 Technical Guide
**ç‰ˆæœ¬**: 1.0.0
**æ›´æ–°æ—¥æœŸ**: 2025-11-14
**å—ä¼—**: å¼€å‘è€…ã€ç³»ç»Ÿç®¡ç†å‘˜

---

## ğŸ“š ç›®å½•

1. [Leidenç®—æ³•æ¦‚è¿°](#leidenç®—æ³•æ¦‚è¿°)
2. [æ ¸å¿ƒå‚æ•°è¯¦è§£](#æ ¸å¿ƒå‚æ•°è¯¦è§£)
3. [å‚æ•°è°ƒä¼˜ç­–ç•¥](#å‚æ•°è°ƒä¼˜ç­–ç•¥)
4. [æ€§èƒ½ä¼˜åŒ–æŒ‡å—](#æ€§èƒ½ä¼˜åŒ–æŒ‡å—)
5. [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
6. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## Leidenç®—æ³•æ¦‚è¿°

### ç®—æ³•ç®€ä»‹

**Leidenç®—æ³•**æ˜¯ä¸€ç§åŸºäºæ¨¡å—åº¦çš„ç¤¾åŒºæ£€æµ‹ç®—æ³•ï¼Œç”±è·å…°è±é¡¿å¤§å­¦å¼€å‘ï¼Œæ˜¯Louvainç®—æ³•çš„æ”¹è¿›ç‰ˆæœ¬ã€‚

**æ ¸å¿ƒä¼˜åŠ¿**:
- **ç²¾åº¦æ›´é«˜**: è§£å†³äº†Louvainç®—æ³•çš„"poorly connected communities"é—®é¢˜
- **ç»“æœç¨³å®š**: ä¿è¯æ‰¾åˆ°è‰¯å¥½è¿æ¥çš„ç¤¾åŒº
- **æ€§èƒ½ä¼˜ç§€**: æ—¶é—´å¤æ‚åº¦O(n log n)ï¼Œç©ºé—´å¤æ‚åº¦O(n + m)

### åœ¨Canvaså­¦ä¹ ç³»ç»Ÿä¸­çš„åº”ç”¨

```
Canvasæ¦‚å¿µç½‘ç»œ (Concept Graph)
    â†“
Neo4jå›¾æŠ•å½± (Graph Projection)
    â†“
Leidenç¤¾åŒºæ£€æµ‹ (Community Detection)
    â†“
è–„å¼±æ¦‚å¿µèšç±» (Weak Concept Clustering)
```

**ç›®æ ‡**: è¯†åˆ«ç›¸å…³è”çš„è–„å¼±æ¦‚å¿µç¾¤ï¼Œæé«˜å¤ä¹ æ•ˆç‡

---

## æ ¸å¿ƒå‚æ•°è¯¦è§£

### å‚æ•°ä¸€è§ˆè¡¨

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | å–å€¼èŒƒå›´ | è¯´æ˜ |
|------|------|--------|---------|------|
| `relationshipWeightProperty` | String | null | - | å…³ç³»æƒé‡å±æ€§å |
| `gamma` | Float | 1.0 | 0.0-âˆ | åˆ†è¾¨ç‡å‚æ•° |
| `tolerance` | Float | 0.0001 | 0.0-1.0 | æ”¶æ•›é˜ˆå€¼ |
| `randomSeed` | Integer | - | - | éšæœºç§å­ |
| `includeIntermediateCommunities` | Boolean | false | - | æ˜¯å¦è¿”å›ä¸­é—´å±‚çº§ç¤¾åŒº |
| `maxLevels` | Integer | 10 | 1-âˆ | æœ€å¤§å±‚çº§æ•° |
| `iterations` | Integer | 10 | 1-âˆ | æ¯å±‚æœ€å¤§è¿­ä»£æ¬¡æ•° |

---

### 1. relationshipWeightProperty (å…³ç³»æƒé‡)

**ä½œç”¨**: æŒ‡å®šç”¨äºç¤¾åŒºæ£€æµ‹çš„å…³ç³»æƒé‡å±æ€§ã€‚

**å½“å‰é…ç½®**:
```cypher
relationshipWeightProperty: 'strength'
```

**è¯´æ˜**:
- ä½¿ç”¨Canvasä¸­çš„`strength`å±æ€§ä½œä¸ºæ¦‚å¿µé—´å…³è”å¼ºåº¦
- `strength`å€¼è¶Šå¤§ï¼Œä¸¤ä¸ªæ¦‚å¿µè¶Šå¯èƒ½è¢«èšç±»åˆ°åŒä¸€ç¤¾åŒº
- å¦‚æœå…³ç³»æ²¡æœ‰`strength`å±æ€§ï¼Œä½¿ç”¨é»˜è®¤æƒé‡1.0

**è°ƒä¼˜å»ºè®®**:

| åœºæ™¯ | å»ºè®® |
|------|------|
| æ‰€æœ‰å…³ç³»æƒé‡ç›¸ç­‰ | ä¸è®¾ç½®æ­¤å‚æ•°ï¼ˆæˆ–è®¾ä¸ºnullï¼‰ |
| å…³ç³»æœ‰æ˜ç¡®æƒé‡ | ä½¿ç”¨`strength`æˆ–å…¶ä»–æƒé‡å±æ€§ |
| éœ€è¦å¼ºè°ƒæŸäº›å…³ç³» | å¢åŠ ç‰¹å®šå…³ç³»çš„æƒé‡å€¼ |

**ç¤ºä¾‹**:
```cypher
// Canvasä¸­å®šä¹‰å…³ç³»æƒé‡
CREATE (a)-[:RELATED_TO {strength: 0.8}]->(b)  // å¼ºå…³è”
CREATE (c)-[:RELATED_TO {strength: 0.3}]->(d)  // å¼±å…³è”
```

---

### 2. gamma (åˆ†è¾¨ç‡å‚æ•°)

**ä½œç”¨**: æ§åˆ¶ç¤¾åŒºæ£€æµ‹çš„åˆ†è¾¨ç‡ï¼ˆç¤¾åŒºå¤§å°å’Œæ•°é‡ï¼‰ã€‚

**å½“å‰é…ç½®**:
```python
gamma = 1.0  # æ ‡å‡†ç¤¾åŒºæ£€æµ‹
```

**å–å€¼è¯´æ˜**:

| gamma | ç¤¾åŒºç‰¹å¾ | é€‚ç”¨åœºæ™¯ |
|-------|---------|---------|
| < 1.0 | æ›´å¤§ã€æ›´å°‘ | å®è§‚æ¦‚å¿µç¾¤ï¼ˆå¤§ä¸»é¢˜ï¼‰ |
| = 1.0 | æ ‡å‡†å¹³è¡¡ | é€šç”¨åœºæ™¯ï¼ˆæ¨èï¼‰ |
| > 1.0 | æ›´å°ã€æ›´å¤š | å¾®è§‚æ¦‚å¿µç¾¤ï¼ˆç»†åˆ†ä¸»é¢˜ï¼‰ |

**è°ƒä¼˜ç¤ºä¾‹**:

```python
# åœºæ™¯1: è¯†åˆ«å¤§ä¸»é¢˜ï¼ˆå¦‚"å‘½é¢˜é€»è¾‘"ã€"é›†åˆè®º"ï¼‰
clusters = service.run_leiden_clustering(
    gamma=0.5,  # æ›´å®½æ³›çš„èšç±»
    ...
)

# åœºæ™¯2: è¯†åˆ«ç»†åˆ†ä¸»é¢˜ï¼ˆå¦‚"é€†å¦å‘½é¢˜"ã€"å……åˆ†æ¡ä»¶"ã€"å¿…è¦æ¡ä»¶"ï¼‰
clusters = service.run_leiden_clustering(
    gamma=2.0,  # æ›´ç»†è‡´çš„èšç±»
    ...
)
```

**å®é™…æ•ˆæœå¯¹æ¯”**:

```
gamma=0.5 (å¤§ç¤¾åŒº):
  ç¤¾åŒº1: [é€†å¦å‘½é¢˜, å……åˆ†æ¡ä»¶, å¿…è¦æ¡ä»¶, é€»è¾‘ç­‰ä»·, çœŸå€¼è¡¨, åˆå–èŒƒå¼]  (6ä¸ªæ¦‚å¿µ)

gamma=1.0 (æ ‡å‡†):
  ç¤¾åŒº1: [é€†å¦å‘½é¢˜, å……åˆ†æ¡ä»¶, å¿…è¦æ¡ä»¶, é€»è¾‘ç­‰ä»·]  (4ä¸ªæ¦‚å¿µ)
  ç¤¾åŒº2: [çœŸå€¼è¡¨, åˆå–èŒƒå¼]  (2ä¸ªæ¦‚å¿µ)

gamma=2.0 (å°ç¤¾åŒº):
  ç¤¾åŒº1: [é€†å¦å‘½é¢˜, å……åˆ†æ¡ä»¶]  (2ä¸ªæ¦‚å¿µ)
  ç¤¾åŒº2: [å¿…è¦æ¡ä»¶, é€»è¾‘ç­‰ä»·]  (2ä¸ªæ¦‚å¿µ)
  ç¤¾åŒº3: [çœŸå€¼è¡¨, åˆå–èŒƒå¼]  (2ä¸ªæ¦‚å¿µ)
```

**é€‰æ‹©å»ºè®®**:

```python
def recommend_gamma(concept_count, avg_connections):
    """æ¨ègammaå‚æ•°"""
    if concept_count < 20:
        return 0.8  # å°è§„æ¨¡å›¾ï¼Œä½¿ç”¨è¾ƒå°gammaé¿å…è¿‡åº¦ç¢ç‰‡åŒ–
    elif concept_count < 100:
        return 1.0  # ä¸­ç­‰è§„æ¨¡ï¼Œæ ‡å‡†å‚æ•°
    else:
        if avg_connections < 3:
            return 0.7  # å¤§è§„æ¨¡ç¨€ç–å›¾ï¼Œä½¿ç”¨è¾ƒå°gamma
        else:
            return 1.2  # å¤§è§„æ¨¡å¯†é›†å›¾ï¼Œä½¿ç”¨è¾ƒå¤§gammaé¿å…è¿‡å¤§ç¤¾åŒº
```

---

### 3. tolerance (æ”¶æ•›é˜ˆå€¼)

**ä½œç”¨**: æ§åˆ¶ç®—æ³•æ”¶æ•›çš„ç²¾åº¦ã€‚

**å½“å‰é…ç½®**:
```python
tolerance = 0.0001  # é«˜ç²¾åº¦
```

**å–å€¼è¯´æ˜**:

| tolerance | æ”¶æ•›ç²¾åº¦ | è®¡ç®—æ—¶é—´ | é€‚ç”¨åœºæ™¯ |
|-----------|---------|---------|---------|
| 0.001 | ä½ç²¾åº¦ | å¿« | å¤§è§„æ¨¡å›¾ï¼ˆ>10000èŠ‚ç‚¹ï¼‰ï¼Œå¿«é€Ÿé¢„è§ˆ |
| 0.0001 | é«˜ç²¾åº¦ | ä¸­ç­‰ | é€šç”¨åœºæ™¯ï¼ˆæ¨èï¼‰ |
| 0.00001 | æé«˜ç²¾åº¦ | æ…¢ | å°è§„æ¨¡å›¾ï¼ˆ<1000èŠ‚ç‚¹ï¼‰ï¼Œéœ€è¦æœ€ä¼˜ç»“æœ |

**æ”¶æ•›é€»è¾‘**:

```python
# ä¼ªä»£ç 
while True:
    old_modularity = current_modularity
    optimize_communities()
    new_modularity = current_modularity

    improvement = new_modularity - old_modularity

    if improvement < tolerance:
        break  # æ”¶æ•›ï¼Œåœæ­¢è¿­ä»£
```

**è°ƒä¼˜å»ºè®®**:

```python
# åœºæ™¯1: å¤§è§„æ¨¡å›¾å¿«é€Ÿèšç±»
clusters = service.run_leiden_clustering(
    tolerance=0.001,  # é™ä½ç²¾åº¦è¦æ±‚
    ...
)

# åœºæ™¯2: å°è§„æ¨¡å›¾ç²¾ç¡®èšç±»
clusters = service.run_leiden_clustering(
    tolerance=0.00001,  # æé«˜ç²¾åº¦è¦æ±‚
    ...
)
```

**æ€§èƒ½å¯¹æ¯”** (1000ä¸ªæ¦‚å¿µ):

| tolerance | è¿­ä»£æ¬¡æ•° | æ‰§è¡Œæ—¶é—´ | æ¨¡å—åº¦ |
|-----------|---------|---------|--------|
| 0.001 | ~5æ¬¡ | 150ms | 0.752 |
| 0.0001 | ~8æ¬¡ | 250ms | 0.758 |
| 0.00001 | ~12æ¬¡ | 380ms | 0.759 |

**ç»“è®º**: `tolerance=0.0001`æ˜¯ç²¾åº¦å’Œæ€§èƒ½çš„æœ€ä½³å¹³è¡¡ç‚¹ã€‚

---

### 4. randomSeed (éšæœºç§å­)

**ä½œç”¨**: å›ºå®šéšæœºæ•°ç”Ÿæˆå™¨ï¼Œç¡®ä¿ç»“æœå¯é‡å¤ã€‚

**å½“å‰é…ç½®**:
```python
randomSeed = 42  # å›ºå®šç§å­
```

**ä¸ºä»€ä¹ˆéœ€è¦å›ºå®šç§å­ï¼Ÿ**

Leidenç®—æ³•åœ¨æŸäº›æ­¥éª¤ä½¿ç”¨éšæœºåŒ–ï¼š
1. åˆå§‹ç¤¾åŒºåˆ†é…
2. èŠ‚ç‚¹è®¿é—®é¡ºåº
3. ç¤¾åŒºåˆå¹¶å†³ç­–

**ä¸å›ºå®šç§å­çš„é—®é¢˜**:
```python
# è¿è¡Œ1
clusters_1 = service.run_leiden_clustering()  # ç»“æœ: 5ä¸ªç¤¾åŒº

# è¿è¡Œ2 (ç›¸åŒè¾“å…¥)
clusters_2 = service.run_leiden_clustering()  # ç»“æœ: 6ä¸ªç¤¾åŒºï¼ˆä¸åŒï¼ï¼‰
```

**å›ºå®šç§å­çš„ä¼˜åŠ¿**:
```python
# è¿è¡Œ1
clusters_1 = service.run_leiden_clustering(randomSeed=42)  # ç»“æœ: 5ä¸ªç¤¾åŒº

# è¿è¡Œ2 (ç›¸åŒè¾“å…¥)
clusters_2 = service.run_leiden_clustering(randomSeed=42)  # ç»“æœ: 5ä¸ªç¤¾åŒºï¼ˆç›¸åŒï¼ï¼‰
```

**è°ƒä¼˜å»ºè®®**:

```python
# ç”Ÿäº§ç¯å¢ƒ: å›ºå®šç§å­
PRODUCTION_SEED = 42
clusters = service.run_leiden_clustering(randomSeed=PRODUCTION_SEED)

# å¼€å‘/æµ‹è¯•: æµ‹è¯•å¤šä¸ªç§å­ï¼Œé€‰æ‹©æœ€ä¼˜ç»“æœ
best_modularity = 0
best_result = None

for seed in [42, 123, 456, 789]:
    result = service.run_leiden_clustering(randomSeed=seed)
    modularity = calculate_modularity(result)

    if modularity > best_modularity:
        best_modularity = modularity
        best_result = result
```

---

### 5. includeIntermediateCommunities (ä¸­é—´å±‚çº§ç¤¾åŒº)

**ä½œç”¨**: è¿”å›å¤šå±‚çº§çš„ç¤¾åŒºç»“æ„ï¼ˆhierarchical clusteringï¼‰ã€‚

**å½“å‰é…ç½®**:
```python
includeIntermediateCommunities = true
```

**è¾“å‡ºå·®å¼‚**:

**ä¸åŒ…å«ä¸­é—´å±‚çº§** (`includeIntermediateCommunities=false`):
```json
{
  "nodeId": 123,
  "communityId": 42  // åªæœ‰æœ€ç»ˆå±‚çº§
}
```

**åŒ…å«ä¸­é—´å±‚çº§** (`includeIntermediateCommunities=true`):
```json
{
  "nodeId": 123,
  "communityId": 42,  // æœ€ç»ˆå±‚çº§
  "intermediateCommunityIds": [5, 12, 42]  // å±‚çº§0â†’1â†’2çš„ç¤¾åŒºID
}
```

**å±‚çº§ç»“æ„ç¤ºä¾‹**:

```
å±‚çº§0 (æœ€ç²—ç²’åº¦):
  ç¤¾åŒº5: [æ¦‚å¿µ1-20]  (20ä¸ªæ¦‚å¿µ)

å±‚çº§1 (ä¸­ç­‰ç²’åº¦):
  ç¤¾åŒº12: [æ¦‚å¿µ1-10]  (10ä¸ªæ¦‚å¿µ)
  ç¤¾åŒº13: [æ¦‚å¿µ11-20]  (10ä¸ªæ¦‚å¿µ)

å±‚çº§2 (æœ€ç»†ç²’åº¦):
  ç¤¾åŒº42: [æ¦‚å¿µ1-5]  (5ä¸ªæ¦‚å¿µ)
  ç¤¾åŒº43: [æ¦‚å¿µ6-10]  (5ä¸ªæ¦‚å¿µ)
  ç¤¾åŒº44: [æ¦‚å¿µ11-15]  (5ä¸ªæ¦‚å¿µ)
  ç¤¾åŒº45: [æ¦‚å¿µ16-20]  (5ä¸ªæ¦‚å¿µ)
```

**åº”ç”¨åœºæ™¯**:

```python
# åœºæ™¯1: å¤šå±‚æ¬¡å¤ä¹ è®¡åˆ’
result = service.run_leiden_clustering(includeIntermediateCommunities=True)

for record in result:
    intermediate_ids = record["intermediateCommunityIds"]

    # å±‚çº§0: å¤§ä¸»é¢˜å¤ä¹ 
    theme = intermediate_ids[0]

    # å±‚çº§1: ä¸­ç­‰ä¸»é¢˜å¤ä¹ 
    subtopic = intermediate_ids[1]

    # å±‚çº§2: ç»†åˆ†ä¸»é¢˜å¤ä¹ 
    detail = intermediate_ids[2]
```

**å½“å‰ç‰ˆæœ¬**: é»˜è®¤å¯ç”¨ä¸­é—´å±‚çº§ï¼Œä½†æœªä½¿ç”¨ï¼ˆä¿ç•™æ‰©å±•æ€§ï¼‰ã€‚

---

### 6. maxLevels å’Œ iterations

**maxLevels**: ç®—æ³•çš„æœ€å¤§å±‚çº§æ•°ï¼ˆé»˜è®¤10ï¼‰
**iterations**: æ¯å±‚çš„æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤10ï¼‰

**å½“å‰é…ç½®**: ä½¿ç”¨Neo4j GDSé»˜è®¤å€¼ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®ã€‚

**è°ƒä¼˜åœºæ™¯** (æå°‘éœ€è¦):

```python
# åœºæ™¯1: å¤§è§„æ¨¡å›¾éœ€è¦æ›´å¤šå±‚çº§
# ï¼ˆä¸æ¨èåœ¨APIå±‚é¢ä¿®æ”¹ï¼Œåº”ä¿®æ”¹Neo4j GDSé…ç½®ï¼‰
CALL gds.leiden.stream('graph', {
    maxLevels: 20,  // å¢åŠ å±‚çº§
    iterations: 15  // å¢åŠ è¿­ä»£
})

# åœºæ™¯2: å¿«é€Ÿèšç±»ï¼ˆç‰ºç‰²è´¨é‡ï¼‰
CALL gds.leiden.stream('graph', {
    maxLevels: 5,   // å‡å°‘å±‚çº§
    iterations: 5   // å‡å°‘è¿­ä»£
})
```

---

## å‚æ•°è°ƒä¼˜ç­–ç•¥

### 1. åŸºäºCanvasè§„æ¨¡çš„è°ƒä¼˜

```python
def get_optimal_parameters(concept_count):
    """æ ¹æ®æ¦‚å¿µæ•°é‡æ¨èæœ€ä¼˜å‚æ•°"""
    if concept_count < 50:
        # å°è§„æ¨¡Canvas
        return {
            "gamma": 0.8,
            "tolerance": 0.00001,
            "randomSeed": 42
        }
    elif concept_count < 500:
        # ä¸­ç­‰è§„æ¨¡Canvas
        return {
            "gamma": 1.0,
            "tolerance": 0.0001,
            "randomSeed": 42
        }
    else:
        # å¤§è§„æ¨¡Canvas
        return {
            "gamma": 1.2,
            "tolerance": 0.001,
            "randomSeed": 42
        }
```

### 2. åŸºäºå›¾å¯†åº¦çš„è°ƒä¼˜

```python
def get_optimal_parameters_by_density(node_count, edge_count):
    """æ ¹æ®å›¾å¯†åº¦æ¨èæœ€ä¼˜å‚æ•°"""
    density = edge_count / (node_count * (node_count - 1) / 2)

    if density < 0.1:
        # ç¨€ç–å›¾
        return {"gamma": 0.7}  # é¿å…è¿‡åº¦ç¢ç‰‡åŒ–
    elif density > 0.5:
        # å¯†é›†å›¾
        return {"gamma": 1.5}  # é¿å…è¿‡å¤§ç¤¾åŒº
    else:
        # æ­£å¸¸å¯†åº¦
        return {"gamma": 1.0}
```

### 3. åŸºäºä¸šåŠ¡ç›®æ ‡çš„è°ƒä¼˜

```python
# ç›®æ ‡1: å‘ç°å¤§ä¸»é¢˜ï¼ˆç”¨äºå®è§‚å¤ä¹ è®¡åˆ’ï¼‰
clusters = service.run_leiden_clustering(
    gamma=0.5,
    tolerance=0.001  # å¯é€‚å½“é™ä½ç²¾åº¦åŠ å¿«é€Ÿåº¦
)

# ç›®æ ‡2: å‘ç°ç»†åˆ†ä¸»é¢˜ï¼ˆç”¨äºç²¾å‡†å¤ä¹ ï¼‰
clusters = service.run_leiden_clustering(
    gamma=2.0,
    tolerance=0.0001
)

# ç›®æ ‡3: å¹³è¡¡å¤ä¹ ï¼ˆé€šç”¨åœºæ™¯ï¼‰
clusters = service.run_leiden_clustering(
    gamma=1.0,
    tolerance=0.0001
)
```

---

## æ€§èƒ½ä¼˜åŒ–æŒ‡å—

### 1. å›¾æŠ•å½±å†…å­˜ä¼°ç®—

**é—®é¢˜**: å¤§è§„æ¨¡å›¾æŠ•å½±å¯èƒ½å¯¼è‡´OOMï¼ˆOut of Memoryï¼‰

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨`gds.graph.project.estimate()`é¢„ä¼°å†…å­˜

```python
# è°ƒç”¨estimate_projection_memory()
estimate = service.estimate_projection_memory()

print(f"æ‰€éœ€å†…å­˜: {estimate['required_memory']}")
print(f"èŠ‚ç‚¹æ•°é‡: {estimate['node_count']}")
print(f"å…³ç³»æ•°é‡: {estimate['relationship_count']}")

# è¾“å‡ºç¤ºä¾‹:
# æ‰€éœ€å†…å­˜: 125 MiB
# èŠ‚ç‚¹æ•°é‡: 1000
# å…³ç³»æ•°é‡: 3500
```

**å†…å­˜éœ€æ±‚å‚è€ƒ**:

| èŠ‚ç‚¹æ•° | å…³ç³»æ•° | æ‰€éœ€å†…å­˜ |
|--------|--------|---------|
| 100 | 300 | ~10 MiB |
| 1000 | 3500 | ~125 MiB |
| 5000 | 20000 | ~650 MiB |
| 10000 | 50000 | ~1.5 GiB |

**ä¼˜åŒ–ç­–ç•¥**:

```python
# 1. æ£€æŸ¥å†…å­˜
estimate = service.estimate_projection_memory()
required_mb = parse_memory(estimate['required_memory'])

# 2. å¦‚æœè¶…è¿‡é˜ˆå€¼ï¼Œè€ƒè™‘æ‰¹å¤„ç†
MEMORY_THRESHOLD = 1000  # 1GB

if required_mb > MEMORY_THRESHOLD:
    # æ‰¹å¤„ç†ç­–ç•¥ï¼ˆæœªæ¥å®ç°ï¼‰
    logger.warning("å›¾è§„æ¨¡è¿‡å¤§ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†")
```

---

### 2. æ‰¹é‡å¤„ç†å¤§è§„æ¨¡æ•°æ®

**é—®é¢˜**: >5000æ¦‚å¿µæ—¶ï¼Œå•æ¬¡èšç±»å¯èƒ½è¶…æ—¶æˆ–å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**: åˆ†æ‰¹å¤„ç†

```python
def batch_clustering(service, concept_ids, batch_size=1000):
    """æ‰¹é‡èšç±»å¤§è§„æ¨¡æ•°æ®"""
    all_clusters = []

    for i in range(0, len(concept_ids), batch_size):
        batch = concept_ids[i:i+batch_size]

        # ä¸ºæ¯æ‰¹åˆ›å»ºå­å›¾æŠ•å½±
        batch_projection_name = f"weak-concepts-batch-{i//batch_size}"

        # åˆ›å»ºæ‰¹æ¬¡å›¾æŠ•å½±
        # ï¼ˆéœ€è¦ä¿®æ”¹create_weak_concepts_graph_projectionæ”¯æŒè‡ªå®šä¹‰å›¾åï¼‰

        # æ‰§è¡Œèšç±»
        batch_clusters = service.run_leiden_clustering(...)

        all_clusters.extend(batch_clusters)

    return all_clusters
```

**æ³¨æ„**: å½“å‰ç‰ˆæœ¬ä¸æ”¯æŒæ‰¹å¤„ç†ï¼Œç•™å¾…æœªæ¥Storyå®ç°ã€‚

---

### 3. æ‰§è¡Œæ—¶é—´ä¼˜åŒ–

**ç›®æ ‡**: 1000æ¦‚å¿µ <500ms (Story GDS.1 - AC3)

**æ€§èƒ½åˆ†æ**:

```python
import time

start = time.time()

# 1. å›¾æŠ•å½±
proj_start = time.time()
service.create_weak_concepts_graph_projection()
proj_time = time.time() - proj_start

# 2. Leidenèšç±»
leiden_start = time.time()
clusters = service.run_leiden_clustering()
leiden_time = time.time() - leiden_start

total_time = time.time() - start

print(f"å›¾æŠ•å½±: {proj_time*1000:.0f}ms")
print(f"Leidenèšç±»: {leiden_time*1000:.0f}ms")
print(f"æ€»æ—¶é—´: {total_time*1000:.0f}ms")

# è¾“å‡ºç¤ºä¾‹ (1000æ¦‚å¿µ):
# å›¾æŠ•å½±: 120ms
# Leidenèšç±»: 280ms
# æ€»æ—¶é—´: 400ms âœ… (<500ms)
```

**ä¼˜åŒ–æŠ€å·§**:

1. **å¤ç”¨å›¾æŠ•å½±**: å¦‚æœæ¦‚å¿µç½‘ç»œæœªå˜ï¼Œæ— éœ€é‡å»º
2. **é™ä½tolerance**: å¦‚0.001 (æŸå¤±å°‘é‡ç²¾åº¦ï¼Œæå‡é€Ÿåº¦)
3. **ä½¿ç”¨Nativeå›¾æŠ•å½±**: `gds.graph.project`è€ŒéCypheræŠ•å½±

---

### 4. å¹¶å‘å¤„ç†

**åœºæ™¯**: åŒæ—¶å¤„ç†å¤šä¸ªCanvasçš„è–„å¼±ç‚¹èšç±»

**æ³¨æ„äº‹é¡¹**:

```python
# âŒ é”™è¯¯: å¹¶å‘å…±äº«åŒä¸€Neo4jè¿æ¥
service = Neo4jGDSClustering()

def process_canvas(canvas_path):
    # å¤šä¸ªçº¿ç¨‹å…±äº«serviceä¼šå¯¼è‡´è¿æ¥å†²çª
    service.run_leiden_clustering()

with ThreadPoolExecutor() as executor:
    executor.map(process_canvas, canvas_paths)  # å¯èƒ½å‡ºé”™
```

```python
# âœ… æ­£ç¡®: æ¯ä¸ªä»»åŠ¡åˆ›å»ºç‹¬ç«‹è¿æ¥
def process_canvas(canvas_path):
    # æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹åˆ›å»ºæœåŠ¡å®ä¾‹
    with Neo4jGDSClustering() as service:
        service.create_weak_concepts_graph_projection()
        clusters = service.run_leiden_clustering()
        return clusters

with ThreadPoolExecutor(max_workers=5) as executor:
    results = executor.map(process_canvas, canvas_paths)
```

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜1: Neo4j GDSåº“æœªå®‰è£…

**é”™è¯¯ä¿¡æ¯**:
```
ClientError: There is no procedure with the name `gds.graph.project` registered for this database instance.
```

**è§£å†³æ–¹æ¡ˆ**:

1. ç¡®è®¤GDSç‰ˆæœ¬
```cypher
RETURN gds.version()
```

2. å¦‚æœè¿”å›é”™è¯¯ï¼Œå®‰è£…Neo4j GDSæ’ä»¶
```bash
# ä¸‹è½½æ’ä»¶
wget https://s3-eu-west-1.amazonaws.com/com.neo4j.graphalgorithms.dist/neo4j-graph-data-science-2.4.0.jar

# å¤åˆ¶åˆ°pluginsç›®å½•
cp neo4j-graph-data-science-2.4.0.jar /path/to/neo4j/plugins/

# é‡å¯Neo4j
neo4j restart
```

3. éªŒè¯å®‰è£…
```python
python scripts/verify_neo4j_gds.py
```

---

### é—®é¢˜2: å›¾æŠ•å½±å·²å­˜åœ¨

**é”™è¯¯ä¿¡æ¯**:
```
ClientError: A graph with name 'weak-concepts-graph' already exists.
```

**è§£å†³æ–¹æ¡ˆ1**: å¼ºåˆ¶é‡å»ºï¼ˆæ¨èï¼‰
```python
service.create_weak_concepts_graph_projection(force_recreate=True)
```

**è§£å†³æ–¹æ¡ˆ2**: æ‰‹åŠ¨åˆ é™¤
```cypher
CALL gds.graph.drop('weak-concepts-graph')
```

---

### é—®é¢˜3: èšç±»ç»“æœä¸ºç©º

**é”™è¯¯ä¿¡æ¯**: æ— é”™è¯¯ï¼Œä½†`clusters`ä¸ºç©ºåˆ—è¡¨

**å¯èƒ½åŸå› **:

1. **æ— è–„å¼±æ¦‚å¿µ**: æ‰€æœ‰æ¦‚å¿µåˆ†æ•°â‰¥70ä¸”å¤ä¹ æ¬¡æ•°â‰¤3
2. **é˜ˆå€¼è¿‡ä¸¥**: `min_weak_score`è®¾ç½®è¿‡ä½æˆ–`min_review_count`è¿‡é«˜
3. **å›¾æŠ•å½±ä¸ºç©º**: æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„`:Concept`èŠ‚ç‚¹

**æ’æŸ¥æ­¥éª¤**:

```cypher
-- 1. æ£€æŸ¥æ¦‚å¿µèŠ‚ç‚¹æ•°é‡
MATCH (c:Concept)
RETURN count(c) AS concept_count

-- 2. æ£€æŸ¥è–„å¼±æ¦‚å¿µæ•°é‡
MATCH (c:Concept)
WHERE c.avg_score < 70 OR c.review_count > 3
RETURN count(c) AS weak_concept_count

-- 3. æ£€æŸ¥å›¾æŠ•å½±çŠ¶æ€
CALL gds.graph.list('weak-concepts-graph')
YIELD nodeCount, relationshipCount
```

**è§£å†³æ–¹æ¡ˆ**: è°ƒæ•´é˜ˆå€¼
```python
# é™ä½è–„å¼±ç‚¹æ ‡å‡†
clusters = service.run_leiden_clustering(
    min_weak_score=80,      # æé«˜åˆ†æ•°é˜ˆå€¼
    min_review_count=2      # é™ä½å¤ä¹ æ¬¡æ•°é˜ˆå€¼
)
```

---

### é—®é¢˜4: æ€§èƒ½è¾¾ä¸åˆ°ç›®æ ‡ (<500ms)

**é—®é¢˜**: 1000æ¦‚å¿µèšç±»æ—¶é—´>500ms

**æ’æŸ¥æ–¹å‘**:

1. **æ£€æŸ¥Neo4jé…ç½®**
```
# neo4j.conf
dbms.memory.heap.initial_size=2G
dbms.memory.heap.max_size=4G
dbms.memory.pagecache.size=2G
```

2. **æ£€æŸ¥å›¾æŠ•å½±æ–¹å¼**
```python
# âŒ æ…¢: CypheræŠ•å½±
CALL gds.graph.project.cypher(...)

# âœ… å¿«: NativeæŠ•å½±
CALL gds.graph.project(...)
```

3. **æ£€æŸ¥toleranceå‚æ•°**
```python
# âŒ æ…¢: é«˜ç²¾åº¦
tolerance=0.00001

# âœ… å¿«: å¹³è¡¡ç²¾åº¦
tolerance=0.0001
```

4. **æ‰§è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•**
```bash
cd "C:/Users/ROG/æ‰˜ç¦"
python tests/test_performance_leiden_clustering.py
```

---

### é—®é¢˜5: å†…å­˜ä¸è¶³ (OOM)

**é”™è¯¯ä¿¡æ¯**:
```
java.lang.OutOfMemoryError: Java heap space
```

**è§£å†³æ–¹æ¡ˆ**:

1. **å¢åŠ Neo4jå †å†…å­˜**
```
# neo4j.conf
dbms.memory.heap.max_size=8G  # å¢åŠ åˆ°8GB
```

2. **ä½¿ç”¨ä¼°ç®—åŠŸèƒ½**
```python
# é¢„ä¼°å†…å­˜åå†å†³å®šæ˜¯å¦æ‰§è¡Œ
estimate = service.estimate_projection_memory()
if parse_memory(estimate['required_memory']) > 2000:  # >2GB
    print("è­¦å‘Š: å†…å­˜éœ€æ±‚è¿‡å¤§ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†")
```

3. **å‡å°‘å›¾æŠ•å½±å±æ€§**
```python
# åªæŠ•å½±å¿…è¦å±æ€§
nodeProperties: {
    'avg_score': {defaultValue: 100}
    # ç§»é™¤ 'review_count', 'last_review_days_ago'
}
```

---

## æœ€ä½³å®è·µ

### 1. ç”Ÿäº§ç¯å¢ƒé…ç½®

```python
# ebbinghaus/config.py
PRODUCTION_CONFIG = {
    # Neo4jè¿æ¥
    "neo4j_uri": "bolt://localhost:7687",
    "neo4j_database": "ultrathink",

    # Leidenå‚æ•°ï¼ˆç»è¿‡è°ƒä¼˜ï¼‰
    "gamma": 1.0,
    "tolerance": 0.0001,
    "randomSeed": 42,

    # è–„å¼±ç‚¹é˜ˆå€¼
    "min_weak_score": 70,
    "min_review_count": 3,

    # æ€§èƒ½é™åˆ¶
    "max_concepts": 5000,  # è¶…è¿‡æ­¤å€¼è­¦å‘Š
    "timeout": 10000       # 10ç§’è¶…æ—¶
}
```

### 2. é”™è¯¯å¤„ç†

```python
def trigger_clustering_with_retry(canvas_path, max_retries=3):
    """å¸¦é‡è¯•çš„èšç±»è§¦å‘"""
    for attempt in range(max_retries):
        try:
            result = trigger_weak_point_clustering(canvas_path)
            return result
        except ClientError as e:
            if "graph already exists" in str(e):
                # é‡è¯•å‰åˆ é™¤æ—§å›¾æŠ•å½±
                service.drop_graph_projection()
            elif attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            else:
                raise
        except RuntimeError as e:
            logger.error(f"èšç±»å¤±è´¥ (attempt {attempt+1}): {e}")
            if attempt == max_retries - 1:
                raise
```

### 3. æ—¥å¿—è®°å½•

```python
# å¯ç”¨DEBUGæ—¥å¿—æŸ¥çœ‹è¯¦ç»†æ‰§è¡Œè¿‡ç¨‹
import logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# æ‰§è¡Œèšç±»
result = trigger_weak_point_clustering("path/to/canvas.canvas")

# æ—¥å¿—è¾“å‡ºç¤ºä¾‹:
# 2025-11-14 12:00:00 - neo4j_gds_clustering - INFO - âœ… Neo4j GDSè¿æ¥æˆåŠŸ
# 2025-11-14 12:00:01 - neo4j_gds_clustering - INFO - å¼€å§‹åˆ›å»ºå›¾æŠ•å½±...
# 2025-11-14 12:00:02 - neo4j_gds_clustering - INFO - âœ… å›¾æŠ•å½±åˆ›å»ºæˆåŠŸ (1000 nodes)
# 2025-11-14 12:00:03 - neo4j_gds_clustering - INFO - å¼€å§‹æ‰§è¡ŒLeidenèšç±»ç®—æ³•...
# 2025-11-14 12:00:04 - neo4j_gds_clustering - INFO - âœ… Leidenèšç±»å®Œæˆ (5ä¸ªç¤¾åŒº)
```

### 4. å•å…ƒæµ‹è¯•

```python
# tests/test_leiden_parameters.py
import pytest

def test_leiden_with_different_gamma():
    """æµ‹è¯•ä¸åŒgammaå‚æ•°çš„èšç±»ç»“æœ"""
    service = Neo4jGDSClustering()

    # gamma=0.5 (å¤§ç¤¾åŒº)
    clusters_05 = service.run_leiden_clustering(gamma=0.5)

    # gamma=1.0 (æ ‡å‡†)
    clusters_10 = service.run_leiden_clustering(gamma=1.0)

    # gamma=2.0 (å°ç¤¾åŒº)
    clusters_20 = service.run_leiden_clustering(gamma=2.0)

    # éªŒè¯: gammaè¶Šå¤§ï¼Œç¤¾åŒºæ•°é‡è¶Šå¤š
    assert len(clusters_05) <= len(clusters_10) <= len(clusters_20)
```

---

## å‚è€ƒèµ„æ–™

- [Neo4j GDS Leidenç®—æ³•å®˜æ–¹æ–‡æ¡£](https://neo4j.com/docs/graph-data-science/current/algorithms/leiden/)
- [Leidenç®—æ³•è®ºæ–‡](https://www.nature.com/articles/s41598-019-41695-z)
- [Canvaså­¦ä¹ ç³»ç»Ÿæ¶æ„æ–‡æ¡£](../architecture/canvas-learning-system.md)
- [Story GDS.1å®ç°è§„æ ¼](../stories/gds-1-ebbinghaus-trigger-point-4.story.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-11-14
**Story**: GDS.1 - Subtask 4.2
