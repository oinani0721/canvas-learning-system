# Epic: GraphRAG集成 - 四层混合检索架构

---
**Epic ID**: EPIC-GraphRAG
**Epic类型**: 新功能 + 架构升级 (Greenfield + Enhancement)
**状态**: ⏸️ **Postponed (Over-Engineering)** 🚫
**暂停日期**: 2025-11-14
**暂停原因**: 技术评估发现过度设计
**替代方案**: EPIC-Neo4j-GDS-Integration
**决策记录**: ADR-004-GRAPHRAG-INTEGRATION-EVALUATION.md
**变更提案**: SCP-005
**原优先级**: ~~🟡 Medium (P1)~~
**创建日期**: 2025-11-14
**负责团队**: Backend Team + AI/ML Team
---

## ⚠️ Epic状态：已暂停

**暂停日期**: 2025-11-14
**暂停原因**: 技术评估发现过度设计（Over-Engineering）

**关键发现**:
1. **功能重叠严重**: 与现有Graphiti系统功能重叠60%（Local Search重叠86%）
2. **成本过高**: 首年成本$9,784 vs Neo4j GDS方案$1,200（**10倍差异**）
3. **架构冲突**: Parquet存储与现有Neo4j架构不兼容
4. **ROI不足**: 收益不足以证明额外复杂度和成本

**替代方案**: EPIC-Neo4j-GDS-Integration
- 使用Neo4j GDS Leiden算法实现社区检测
- 满足Epic 14触发点4的所有需求
- 成本节省88%（$8,584首年）
- 开发时间缩短75%（11-16天）

**重启条件**:
仅当满足以下**所有**条件时，才考虑重启此Epic：
1. ✅ Graphiti + Neo4j GDS方案已部署并证明**无法满足需求**
2. ✅ 出现GraphRAG**独有的必需功能**（当前未识别到）
3. ✅ GraphRAG成本降低至与Neo4j GDS相当水平（<$2,000/年）
4. ✅ 架构演进计划已明确如何整合Parquet存储层

**决策文档**:
- ADR-004: GraphRAG Integration Evaluation (✅ Accepted - Do Not Integrate)
- SCP-005: GraphRAG过度设计纠偏提案 (✅ Approved, 2025-11-14)
- GRAPHRAG-NECESSITY-ASSESSMENT.md (技术评估报告)

**历史价值**:
此Epic文档保留作为技术评估的参考案例，展示了如何识别和避免过度设计。

---

## 📄 原始Epic定义（以下内容为历史记录，不代表当前计划）

---

## 📋 目录

1. [Epic概述](#epic概述)
2. [业务背景](#业务背景)
3. [Epic目标](#epic目标)
4. [Story概览](#story概览)
5. [验收标准](#验收标准)
6. [技术约束](#技术约束)
7. [风险与缓解](#风险与缓解)
8. [成功指标](#成功指标)
9. [依赖关系](#依赖关系)
10. [参考文档](#参考文档)

---

## Epic概述

### 简述

集成**Microsoft GraphRAG**到Canvas学习系统，作为第四层记忆（Strategic Memory），补充现有的Graphiti/LanceDB/Temporal三层记忆系统，实现数据集级全局分析和社区检测能力。采用**本地模型优先架构**（Qwen2.5-14B），将月成本从$570降至$57（节省90%）。

### 问题陈述

**PRD需求缺失**（v1.1.6 Line 1495-1496）:

当前3层记忆系统已实现：
- ✅ **Temporal Memory** (Neo4j) - 学习行为时序数据
- ✅ **Graphiti Knowledge Graph** (Neo4j) - 概念关系网络
- ✅ **Semantic Memory** (LanceDB) - 文档语义检索

但缺失第5个数据源：
- ❌ **GraphRAG** (Microsoft) - 概念社区检测、数据集级趋势分析、跨主题学习模式

**具体影响**:

1. **艾宾浩斯复习系统不完整**:
   - PRD触发点4（行为监控触发，Line 1572-1579）无法实现
   - 无法识别薄弱点聚集模式（如"线性代数基础"社区有3个红色节点）
   - 复习推荐缺少全局视角（只能看到单个概念，看不到概念社区）

2. **检验白板生成质量受限**:
   - 无法回答"哪些概念最容易混淆？"（数据集级分析）
   - 无法生成"跨主题学习路径"（如从微积分到机器学习）
   - 历史关联功能（PRD v1.1.8）缺少全局知识结构支持

3. **API成本风险**:
   - 原设计使用GPT-4o，Level 3查询单次$0.19
   - 假设每天100次查询 → 月成本$570（不可接受）
   - 缺少成本控制机制

### 解决方案（修正版）

**核心策略**: 本地模型优先 + API降级 + 智能路由

```
┌─────────────────────────────────────────────────────────────┐
│  GraphRAG四层混合检索架构（本地模型优先）                    │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  LangGraph智能路由层                                   │  │
│  │  - Question Router (LLM分类: local/global/hybrid)     │  │
│  │  - Fusion Reranker (RRF算法融合4源)                   │  │
│  └───────────────────────────────────────────────────────┘  │
│                          │                                    │
│                          ▼                                    │
│  ┌────────────┬────────────┬────────────┬────────────────┐  │
│  │ Graphiti   │ LanceDB    │ Temporal   │ GraphRAG       │  │
│  │ (Local)    │ (Local)    │ (Local)    │ (Global)       │  │
│  ├────────────┼────────────┼────────────┼────────────────┤  │
│  │ 图遍历     │ 向量检索   │ 时序查询   │ 社区检测       │  │
│  │ <200ms     │ <150ms     │ <100ms     │ 2-8秒          │  │
│  └────────────┴────────────┴────────────┴────────────────┘  │
│                                              │                │
│                                              ▼                │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  本地模型优先LLM层（成本节省90%）                     │   │
│  │  ┌─────────────────┐  ┌─────────────────┐            │   │
│  │  │ Qwen2.5-14B     │  │ GPT-4o-mini     │            │   │
│  │  │ (Ollama本地)    │  │ (API降级)       │            │   │
│  │  │ 成本: $0        │  │ 成本: $0.02/次  │            │   │
│  │  │ 质量: 85%       │  │ 质量: 90%       │            │   │
│  │  │ 延迟: 3-8秒     │  │ 延迟: 2-5秒     │            │   │
│  │  └─────────────────┘  └─────────────────┘            │   │
│  │  使用率: 90%              使用率: 10%                  │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                               │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  混合策略（智能成本控制）                             │   │
│  │  - Level 0-1 (概念组): 100%本地模型                  │   │
│  │  - Level 2 (主题域): 80%本地 + 20%API（复杂查询）    │   │
│  │  - Level 3 (全局): 50%本地 + 50%API（复杂度判断）    │   │
│  └──────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘

月成本: $570 (原设计GPT-4o) → $57 (本地模型优先) 💰 节省90%
```

**关键技术决策**（详见ADR-001）:

| 决策点 | 选择 | 理由 |
|--------|------|------|
| **LLM提供商** | Qwen2.5-14B (Ollama) | 中文能力顶级，成本$0，硬件友好 |
| **API降级** | gpt-4o-mini | 成本低（$0.02 vs $0.19），质量可接受（90%） |
| **推理引擎** | Ollama（推荐）/vLLM/LM Studio | 易用性、性能、社区支持综合最优 |
| **混合策略** | 90%本地 + 10%API | 成本-质量最佳平衡点 |

### 预期影响

**成本优化**:
- 月API成本: $570 → $57 (**节省90%**)
- 单次Global Search (Level 3): $0.19 → $0 (本地) 或 $0.02 (API降级)
- ROI: 首月硬件投入（RTX 4090 ~$1600）2.8个月回本

**功能增强**:
- ✅ 完整实现PRD v1.1.6第5个数据源
- ✅ 支持艾宾浩斯触发点4（行为监控自动触发）
- ✅ 支持检验白板历史关联功能（PRD v1.1.8）
- ✅ 支持数据集级分析查询（"哪些概念最容易混淆？"）

**性能指标**:
- Local路径（3工具）: <5秒
- Global路径（GraphRAG本地）: <8秒（Level 2）
- Hybrid路径（4工具并行）: <12秒
- 本地模型推理: 3秒（Level 1），6秒（Level 2），10秒（Level 3）

**质量保证**:
- 中文概念分析准确率: ≥85%（vs GPT-4o 100%基线）
- 实体提取准确率: ≥80%（人工抽样验证）
- API降级成功率: 100%（5秒超时自动切换）

---

## 业务背景

### 当前状态

**Canvas学习系统**已完成核心架构：
- ✅ Epic 1-5: 核心Canvas操作、拆解、解释、检验、智能化（100%完成）
- ✅ Epic 10: 智能并行处理系统（90%完成，记忆存储待完善）
- ✅ 3层记忆系统: Graphiti + LanceDB + Temporal（已运行）
- ✅ 12个学习型Sub-agents + 2个系统级Agents

**PRD状态**:
- 版本: v1.1.6（Obsidian Native Migration PRD）
- 关键需求: Line 1495-1496定义5个数据源，GraphRAG为第5个
- 触发点4: Line 1572-1579定义3层记忆系统行为监控触发

**技术债务**:
1. GraphRAG集成方案已设计（GRAPHRAG-INTEGRATION-DESIGN.md + LANGGRAPH Section 10）
2. 但未实现数据采集Pipeline（无法从Canvas内容提取实体/关系）
3. 成本控制机制缺失（原设计月成本$570不可接受）
4. 艾宾浩斯触发点4缺失实现

### 用户痛点

**场景1: 艾宾浩斯复习推荐不智能**

**当前体验** ❌:
- 用户在"线性代数"Canvas中3个概念（特征向量、特征值、对角化）都是红色节点
- 复习系统只能单独推荐这3个概念，无法识别"线性代数基础"社区整体薄弱
- 用户收到碎片化推荐，缺少系统化学习路径

**理想体验** ✅（GraphRAG支持后）:
- 系统识别"线性代数基础"社区有3个红色节点（薄弱点聚集）
- 触发GraphRAG社区分析："线性代数基础的核心概念和学习路径是什么？"
- 推荐系统化复习路径：矩阵乘法 → 线性变换 → 特征向量/特征值 → 对角化
- 用户获得结构化的学习建议

**场景2: 检验白板生成缺少全局视角**

**当前体验** ❌:
- 用户想复习"离散数学"，检验白板只包含历史薄弱点（70%）+ 已掌握概念（30%）
- 但无法回答"哪些概念最容易混淆？"（需要数据集级分析）
- 无法生成跨主题学习路径（如"从集合论到图论的依赖关系"）

**理想体验** ✅（GraphRAG支持后）:
- 检验白板生成时自动查询："离散数学中哪些概念最容易混淆？"
- GraphRAG分析社区结构，返回：逆否命题 vs 逆命题（混淆度87%），排列 vs 组合（混淆度79%）
- 检验白板包含这些高混淆概念，提升复习针对性

**场景3: 成本失控风险**

**原设计问题** ❌:
- 使用GPT-4o作为GraphRAG的LLM
- Level 3查询单次成本$0.19，假设每天100次 → 月成本$570
- 无成本控制机制，可能导致预算超支

**本地模型方案** ✅:
- 使用Qwen2.5-14B本地模型，成本$0
- 仅在复杂查询或本地失败时使用API（gpt-4o-mini，$0.02/次）
- 月成本控制在$57以内（90%本地 + 10%API）

### 业务价值

**战略价值**:
1. **完成PRD承诺**: 实现5个数据源整合，兑现v1.1.6功能规划
2. **成本可控**: 本地模型方案使GraphRAG成为可持续的功能，而非预算黑洞
3. **智能升级**: 从"单点查询"升级到"全局分析"，提升学习系统智能化水平
4. **开源友好**: Qwen2.5开源模型，降低对商业API的依赖，符合长期战略

**量化价值**:
- **成本节省**: $570/月 → $57/月（年节省$6156）
- **功能完整性**: PRD需求覆盖度 95% → 100%
- **用户体验**: 复习推荐相关性 +30%（估算，基于社区检测）
- **系统能力**: 支持数据集级查询（0 → 100%覆盖）

**风险降低**:
- **硬件投入**: RTX 4090 ~$1600，2.8个月回本
- **技术风险**: 本地模型质量验证（≥85%准确率）
- **实施风险**: 5个P0/P1 Story，15-20个工作日可完成

---

## Epic目标

### 主要目标

**目标1: 实现GraphRAG数据采集Pipeline** ⭐ P0
- 从Canvas内容自动提取实体和关系（LLM powered）
- 存储到Neo4j（:GraphRAGNode标签，与Graphiti隔离）
- 支持增量索引（每日）和全量索引（每周）
- 提取准确率≥80%

**目标2: 集成本地模型优先架构** ⭐ P0
- 默认使用Qwen2.5-14B本地模型（Ollama）
- API自动降级（5秒超时或失败切换gpt-4o-mini）
- 混合策略（Level 0-1本地，Level 3根据复杂度选择）
- 月API成本<$100

**目标3: 实现智能问题路由与融合重排序** P1
- question_router节点（LLM分类：local/global/hybrid）
- composite_search节点（4工具并行，asyncio.gather）
- fusion_rerank节点（RRF算法融合4源结果）
- 端到端延迟<12秒（Hybrid路径）

**目标4: 集成艾宾浩斯触发点4** ⭐ P0
- MemoryBehaviorMonitor后台任务（每6小时运行）
- 检测薄弱点聚集（同一社区≥3个红色节点）
- 触发GraphRAG社区分析并生成复习推荐
- 触发失败不阻塞主流程（非关键路径）

**目标5: 性能优化与成本监控** P1
- Neo4j资源隔离（避免与Graphiti冲突）
- 批量索引时间窗口（每日凌晨2-3点）
- API调用监控和成本告警（月成本>$80告警）
- 性能指标：Local<5秒，Global<8秒，Hybrid<12秒

### 非目标 (Out of Scope)

❌ **不包括**:
- **分布式GraphRAG架构**: 单机部署足够，暂不考虑多节点集群
- **实时索引**: 仅支持批量索引（增量每日，全量每周），不支持实时
- **多语言支持**: 仅优化中文场景，英文作为次要支持
- **GraphRAG UI**: 无独立管理界面，仅通过CLI命令调用
- **自定义社区检测算法**: 使用GraphRAG默认Leiden算法，不自研
- **GraphRAG Local Search**: 仅实现Global Search，Local Search由Graphiti覆盖

---

## Story概览

### Story优先级和依赖

```
Timeline (15-20工作日):

Sprint 1 (Week 1-2): P0基础设施
├─ Story GraphRAG.1: 数据采集Pipeline ⭐ P0 [5天]
│  └─ 依赖: Neo4j, Qwen2.5-14B已部署
├─ Story GraphRAG.2: 本地模型集成 ⭐ P0 [3天]
│  └─ 依赖: Ollama安装, GraphRAG框架
└─ Story GraphRAG.4: 艾宾浩斯触发点4 ⭐ P0 [3天]
   └─ 依赖: Story GraphRAG.1, GraphRAG.2

Sprint 2 (Week 3): P1优化和集成
├─ Story GraphRAG.3: 智能路由与融合 P1 [4天]
│  └─ 依赖: Story GraphRAG.2
└─ Story GraphRAG.5: 性能优化与成本监控 P1 [3天]
   └─ 依赖: Story GraphRAG.1-4全部完成

Sprint 3 (Week 4): 测试和文档
└─ 端到端测试、性能验证、文档补充 [2天]
```

### Story列表

| Story ID | 标题 | 优先级 | 工作量估算 | 依赖 |
|----------|------|--------|----------|------|
| **GraphRAG.1** | GraphRAG数据采集Pipeline | 🔴 P0 | 5天 | Neo4j, Qwen2.5 |
| **GraphRAG.2** | 本地模型集成与混合策略 | 🔴 P0 | 3天 | Ollama |
| **GraphRAG.3** | 智能问题路由与融合重排序 | 🟡 P1 | 4天 | GraphRAG.2 |
| **GraphRAG.4** | 艾宾浩斯触发点4集成 | 🔴 P0 | 3天 | GraphRAG.1, GraphRAG.2 |
| **GraphRAG.5** | 性能优化与成本监控 | 🟡 P1 | 3天 | GraphRAG.1-4 |

### Story详细描述（概要）

**Story GraphRAG.1: GraphRAG数据采集Pipeline** ⭐ P0
- 实现从Canvas内容自动提取实体/关系
- 使用Qwen2.5-14B设计few-shot提取Prompt
- 存储到Neo4j（:GraphRAGNode标签）
- 增量索引（每日凌晨2-3点）+ 全量索引（每周日凌晨2-4点）
- 验收: 提取准确率≥80%，索引不阻塞Graphiti

**Story GraphRAG.2: 本地模型集成与混合策略** ⭐ P0
- 安装Ollama并下载qwen2.5:14b模型
- 创建GraphRAGConfig模块（本地优先，API降级）
- 实现混合策略（Level 0-1本地，Level 3自动选择）
- 质量验证（中文概念分析≥85%）
- 验收: 月API成本<$100，API降级成功率100%

**Story GraphRAG.3: 智能问题路由与融合重排序** 🟡 P1
- 实现question_router节点（LLM分类查询类型）
- 实现composite_search节点（4工具并行）
- 实现fusion_rerank节点（RRF算法）
- 验收: Hybrid路径端到端<12秒

**Story GraphRAG.4: 艾宾浩斯触发点4集成** ⭐ P0
- 实现MemoryBehaviorMonitor（每6小时运行）
- 检测薄弱点聚集（同一社区≥3红色节点）
- 触发GraphRAG社区分析
- 验收: 触发准确率≥90%，失败不阻塞主流程

**Story GraphRAG.5: 性能优化与成本监控** 🟡 P1
- Neo4j连接池配置（避免与Graphiti冲突）
- 批量索引锁机制
- API调用监控和成本告警
- 验收: 所有路径满足延迟目标，月成本<$100

---

## 验收标准

### Epic级别验收标准

**功能完整性**:
1. ✅ GraphRAG数据采集Pipeline可正常运行（增量+全量索引）
2. ✅ 本地模型（Qwen2.5-14B）作为默认LLM，API降级机制有效
3. ✅ 支持3种查询路径（Local/Global/Hybrid）
4. ✅ 艾宾浩斯触发点4可自动触发GraphRAG分析
5. ✅ 所有5个Story验收标准全部通过

**性能指标**:
1. ✅ Local路径端到端<5秒
2. ✅ Global路径端到端<8秒（Level 2本地模型）
3. ✅ Hybrid路径端到端<12秒
4. ✅ 本地模型推理: Level 1 <3秒, Level 2 <6秒, Level 3 <10秒

**质量指标**:
1. ✅ 实体提取准确率≥80%（人工抽样100个样本）
2. ✅ 中文概念分析准确率≥85%（vs GPT-4o基线）
3. ✅ API降级成功率=100%（5秒超时自动切换）
4. ✅ 触发点4准确率≥90%（薄弱点聚集检测）

**成本控制**:
1. ✅ 月API成本<$100（vs 原设计$570）
2. ✅ 本地模型使用率≥90%
3. ✅ API调用仅在必要时触发（超时/失败/复杂查询）
4. ✅ 成本告警机制有效（月成本>$80时发送告警）

**系统兼容性**:
1. ✅ 不影响现有3层记忆系统（Graphiti/LanceDB/Temporal）
2. ✅ Neo4j共享实例无资源竞争（Graphiti写入延迟<100ms）
3. ✅ 所有Epic 1-5功能正常运行
4. ✅ 357个现有测试用例全部通过

**文档完整性**:
1. ✅ 5个Story文档包含验收标准和任务分解
2. ✅ ADR-001记录本地模型vs API决策
3. ✅ LANGGRAPH-MEMORY-INTEGRATION-DESIGN.md Section 10更新
4. ✅ 本地模型部署指南（安装Ollama、配置环境）

---

## 技术约束

### 硬件约束

**GPU要求**:
- **推荐**: RTX 4090 24GB VRAM（~$1600，2.8个月回本）
- **最低**: RTX 3090 24GB VRAM（量化模型INT4，~9GB显存）
- **不支持**: CPU推理（速度太慢，Level 2 >60秒）

**存储要求**:
- 模型文件: ~9GB（qwen2.5:14b-q4_k_m量化版）
- Neo4j数据库: 预留50GB（GraphRAG索引 + Graphiti数据）
- 日志和缓存: 10GB

### 软件依赖

**必需组件**:
- Neo4j 5.x（已安装，共享实例）
- Ollama 0.1.x（新安装）
- Python 3.9+（已安装）
- LangChain 0.1.x（已安装）
- Microsoft GraphRAG SDK 0.2.x（新安装）

**可选组件**:
- vLLM（高性能推理引擎，可替代Ollama）
- LM Studio（图形界面，开发友好）
- Grafana（成本监控仪表盘，可选）

### 技术栈约束

**LLM提供商**:
- 默认: Qwen2.5-14B（Ollama本地）
- 降级: gpt-4o-mini（OpenAI API）
- **不支持**: Claude、Gemini（GraphRAG SDK暂不支持）

**Neo4j命名空间隔离**:
- Graphiti: Label `:GraphitiNode`, properties `valid_at`, `invalid_at`
- GraphRAG: Label `:GraphRAGNode`, properties `extracted_at`, `community_level`
- **禁止**: 跨命名空间关系（Graphiti ↔ GraphRAG）

**GraphRAG索引策略**:
- 增量索引: 每日凌晨2-3点（仅新增Canvas内容）
- 全量索引: 每周日凌晨2-4点（全量重建）
- **禁止**: 实时索引（会阻塞Graphiti写入）

### 集成约束

**与现有系统协调**:
1. **Graphiti**: 共享Neo4j，但使用不同Label和Property，无冲突
2. **LanceDB**: 独立存储，无交互
3. **Temporal**: 独立Neo4j database，无交互
4. **艾宾浩斯系统**: 读取GraphRAG结果，单向依赖

**API限流**:
- OpenAI API: 每分钟最多60次请求（Tier 1账户）
- 混合策略下，API调用率<6次/分钟（10%总请求）
- 需配置Exponential Backoff重试机制

---

## 风险与缓解

### 高风险 🔴

**风险1: 本地模型质量不达标**
- **描述**: Qwen2.5中文概念分析准确率<85%，影响用户体验
- **概率**: 中（30%）
- **影响**: 高（用户不信任GraphRAG结果）
- **缓解**:
  1. 在Story GraphRAG.2中进行质量验证（10个测试案例）
  2. 低于85%时立即切换API降级策略（Level 0-2也用API）
  3. 持续优化Prompt工程（few-shot示例）
- **应急预案**: 全部切换到gpt-4o-mini（成本$60/月，仍可接受）

**风险2: Neo4j资源竞争导致Graphiti性能下降**
- **描述**: GraphRAG批量索引时锁定Neo4j，Graphiti写入延迟>100ms
- **概率**: 中（40%）
- **影响**: 高（影响实时学习体验）
- **缓解**:
  1. 使用独立事务（READ COMMITTED隔离级别）
  2. 批量索引限制在凌晨2-4点（低峰时段）
  3. 监控Graphiti写入延迟，超过100ms自动暂停索引
- **应急预案**: 部署独立Neo4j实例（增加$20/月云服务成本）

**风险3: GPU硬件不可用**
- **描述**: 本地GPU故障或被其他任务占用，本地模型无法运行
- **概率**: 低（10%）
- **影响**: 高（GraphRAG功能完全依赖API，成本暴增）
- **缓解**:
  1. 配置API自动降级（5秒超时）
  2. GPU健康监控（每小时检查一次）
  3. 告警机制（GPU不可用时发送邮件）
- **应急预案**: 临时切换到100% API模式（成本$570/月，需申请预算）

### 中风险 🟡

**风险4: GraphRAG索引速度慢于预期**
- **描述**: 100个Canvas内容提取实体需要>1小时（预期30分钟）
- **概率**: 中（30%）
- **影响**: 中（延迟复习推荐，但不阻塞学习）
- **缓解**:
  1. 使用vLLM替代Ollama（推理速度提升2-3倍）
  2. 批量处理（一次提取10个Canvas，而非逐个）
  3. 降低提取频率（每2日增量索引，而非每日）
- **应急预案**: 接受更长索引时间，调整用户预期

**风险5: API成本超过$100/月预算**
- **描述**: 实际API使用率>10%，导致月成本>$100
- **概率**: 低（20%）
- **影响**: 中（预算超支，但在可接受范围）
- **缓解**:
  1. 实时成本监控（每日报表）
  2. API调用限流（每用户每天最多10次Global查询）
  3. 成本告警（月成本>$80时发送告警）
- **应急预案**: 临时禁用API降级，100%使用本地模型（质量略降）

### 低风险 🟢

**风险6: Qwen2.5模型更新导致不兼容**
- **概率**: 低（10%）
- **影响**: 低（锁定模型版本即可避免）
- **缓解**: 使用固定版本 `qwen2.5:14b` 而非 `qwen2.5:latest`

**风险7: 用户不理解本地模型vs API差异**
- **概率**: 低（15%）
- **影响**: 低（混淆但不影响功能）
- **缓解**: 在文档中明确说明质量-成本权衡

---

## 成功指标

### 业务指标

**功能采用率**:
- 目标: 艾宾浩斯触发点4触发率≥80%（有薄弱点聚集时）
- 基线: 0%（功能不存在）
- 测量: 统计每周触发次数 / 薄弱点聚集检测次数

**复习推荐质量**:
- 目标: 用户接受复习推荐率≥70%（点击"生成检验白板"）
- 基线: 50%（当前基于单点推荐）
- 测量: 用户行为日志分析

**检验白板相关性**:
- 目标: 包含数据集级混淆概念的检验白板占比≥30%
- 基线: 0%（功能不存在）
- 测量: 抽样分析100个检验白板

### 技术指标

**成本节省**:
- 目标: 月API成本<$100
- 基线: $570（原设计GPT-4o）
- 测量: 每月汇总OpenAI API账单

**本地模型使用率**:
- 目标: ≥90%
- 基线: 0%
- 测量: 本地LLM调用次数 / 总LLM调用次数

**性能达标率**:
- 目标: 95%查询满足延迟目标（Local<5s, Global<8s, Hybrid<12s）
- 基线: N/A
- 测量: Prometheus监控，P95延迟

**质量达标率**:
- 目标: 中文概念分析准确率≥85%
- 基线: 100%（GPT-4o基线）
- 测量: 每周人工抽样10个结果评分

### 系统健康指标

**Neo4j性能影响**:
- 目标: Graphiti平均写入延迟<100ms（不因GraphRAG增加）
- 基线: ~50ms（当前）
- 测量: Neo4j metrics，Graphiti写入延迟

**API降级成功率**:
- 目标: 100%（本地模型失败时立即切换API）
- 基线: N/A
- 测量: 错误日志分析，降级触发次数 / 降级成功次数

**索引成功率**:
- 目标: 增量索引成功率≥99%，全量索引成功率≥95%
- 基线: N/A
- 测量: 索引任务日志，成功次数 / 总任务次数

---

## 依赖关系

### 技术依赖

**硬件依赖**:
- ✅ RTX 4090 24GB GPU（或等效）- **必须在开发前准备**
- ✅ Neo4j服务器（已运行）
- ✅ 50GB+ 存储空间

**软件依赖**:
- ✅ Python 3.9+ (已安装)
- ✅ Neo4j 5.x (已安装)
- ❌ Ollama 0.1.x (需安装) - **阻塞Story GraphRAG.2**
- ❌ Microsoft GraphRAG SDK (需安装) - **阻塞Story GraphRAG.1**

**数据依赖**:
- ✅ Canvas文件内容（已有）
- ✅ Graphiti概念关系数据（已有）
- ❌ GraphRAG实体/关系数据（Story GraphRAG.1生成）

### Epic依赖

**上游Epic（已完成）**:
- ✅ Epic 1-5: 核心Canvas操作和3层架构
- ✅ Epic 10: 智能并行处理系统（90%完成）
- ✅ Epic 12: 3层记忆系统集成（Graphiti/LanceDB/Temporal）

**下游Epic（被阻塞）**:
- ⏸️ Epic 14: 艾宾浩斯复习系统（需要触发点4，依赖Story GraphRAG.4）
- ⏸️ 检验白板历史关联功能（PRD v1.1.8，需要GraphRAG全局分析）

### 团队依赖

**所需技能**:
- Backend开发: Python, FastAPI, Neo4j（已有）
- AI/ML工程: LLM Prompt工程, Ollama, GraphRAG（需培训）
- DevOps: GPU服务器运维, Ollama部署（需支持）

**外部依赖**:
- OpenAI API密钥（已有，用于降级）
- Hugging Face账户（下载Qwen2.5模型）
- Neo4j社区支持（技术问题咨询）

---

## 参考文档

### 技术设计文档

1. **架构设计**:
   - `docs/architecture/GRAPHRAG-INTEGRATION-DESIGN.md` - GraphRAG集成架构全景
   - `docs/architecture/LANGGRAPH-MEMORY-INTEGRATION-DESIGN.md` Section 10 - Agentic RAG实现

2. **PRD需求**:
   - `docs/prd/CANVAS-LEARNING-SYSTEM-OBSIDIAN-NATIVE-MIGRATION-PRD.md`
     - Line 50: GraphRAG集成说明
     - Line 1495-1496: 5个数据源定义
     - Line 1572-1579: 触发点4设计

3. **技术决策**:
   - `docs/architecture/ADR-001-local-model-vs-api.md` - 本地模型vs API决策记录（待创建）

### PM审查报告

- `docs/pm-reviews/graphrag-integration-pm-review-2025-11-14.md` - PM审查报告（本文档基础）
  - P0/P1问题清单
  - 成本优化方案
  - 风险分析

### 外部参考

1. **Microsoft GraphRAG**:
   - GitHub: https://github.com/microsoft/graphrag
   - 文档: https://microsoft.github.io/graphrag/

2. **Qwen2.5模型**:
   - Hugging Face: https://huggingface.co/Qwen/Qwen2.5-14B-Instruct
   - Ollama: https://ollama.com/library/qwen2.5

3. **LangGraph框架**:
   - 文档: `.claude/skills/langgraph/SKILL.md`
   - Pattern: Agent with Tools, StateGraph

---

**Epic创建时间**: 2025-11-14
**最后更新**: 2025-11-14
**负责PM**: Claude (PM Agent)
**审查状态**: ✅ PM审查通过，进入Story分解阶段
