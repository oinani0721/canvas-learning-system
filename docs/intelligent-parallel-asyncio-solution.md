# `/intelligent-parallel` Asyncio å¼‚æ­¥å¹¶å‘å®ç°æ–¹æ¡ˆ

**åˆ›å»ºæ—¥æœŸ**: 2025-11-04
**çŠ¶æ€**: è®¾è®¡æ–¹æ¡ˆ (å¾…å®ç°)
**ç›®æ ‡**: å®ç°çœŸæ­£çš„ asyncio å¼‚æ­¥å¹¶å‘æ‰§è¡Œå¼•æ“

---

## ğŸ“‹ é—®é¢˜è¯Šæ–­

### å½“å‰å®ç°çš„æ ¸å¿ƒé—®é¢˜

| é—®é¢˜ç±»å‹ | å…·ä½“æè¿° | å½±å“ | è¯æ® |
|---------|---------|------|------|
| **é¡ºåºæ‰§è¡Œ** | `_execute_tasks()` ä½¿ç”¨åŒæ­¥å¾ªç¯ | æ— å¹¶å‘,é€Ÿåº¦æ…¢ | `intelligent_parallel_handler.py:393-467` |
| **å‡Agentè°ƒç”¨** | `_call_agent()` åˆ›å»ºMVPå ä½ç¬¦ | æ— çœŸå®AIè§£é‡Š | `intelligent_parallel_handler.py:486-547` |
| **é”™è¯¯Canvasç»“æ„** | 2å±‚ç»“æ„ (Yellowâ†’Blue file) | ä¸ç¬¦åˆè§„èŒƒ | `intelligent_parallel_handler.py:580-591` |
| **é”™è¯¯æ–‡ä»¶è·¯å¾„** | åªç”¨æ–‡ä»¶å `Path(doc_path).name` | Obsidianæ— æ³•æ‰“å¼€ | `intelligent_parallel_handler.py:590` |
| **ç¼ºå°‘è°ƒåº¦å™¨** | æ—  IntelligentParallelScheduler | æ— æ™ºèƒ½åˆ†ç»„ | Story 10.2è¦æ±‚ |

---

## ğŸ—ï¸ è§£å†³æ–¹æ¡ˆæ¶æ„

### æ–°å¢ç»„ä»¶

#### 1. **AsyncExecutionEngine** (å¼‚æ­¥æ‰§è¡Œå¼•æ“)

**ä½ç½®**: `command_handlers/async_execution_engine.py` (æ–°å»º)

**æ ¸å¿ƒåŠŸèƒ½**:
- ä½¿ç”¨ `asyncio.create_task()` åˆ›å»ºå¹¶å‘ä»»åŠ¡
- ä½¿ç”¨ `asyncio.Semaphore(12)` æ§åˆ¶æœ€å¤§å¹¶å‘æ•°
- ä½¿ç”¨ `asyncio.gather()` ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
- å®æ—¶è¿›åº¦è·Ÿè¸ª (æ¯ä¸ªä»»åŠ¡å®Œæˆæ—¶æ›´æ–°)

**æŠ€æœ¯è§„æ ¼**:
```python
import asyncio
from typing import List, Dict, Any, Callable
from dataclasses import dataclass

@dataclass
class AsyncTask:
    """å¼‚æ­¥ä»»åŠ¡å®šä¹‰"""
    task_id: str
    agent_name: str
    node_data: Dict[str, Any]
    priority: int = 0  # é«˜ä¼˜å…ˆçº§ä»»åŠ¡å…ˆæ‰§è¡Œ
    dependencies: List[str] = None  # ä¾èµ–çš„ä»»åŠ¡IDåˆ—è¡¨

class AsyncExecutionEngine:
    """
    å¼‚æ­¥æ‰§è¡Œå¼•æ“ - Epic 10æ ¸å¿ƒç»„ä»¶

    å®ç°ä¸‰çº§å¹¶å‘æ§åˆ¶:
    1. Agentçº§: æœ€å¤š20ä¸ªAgentå®ä¾‹å¹¶å‘
    2. Nodeçº§: æœ€å¤š12ä¸ªèŠ‚ç‚¹ç»„å¹¶å‘ (å¯é…ç½®1-20)
    3. Taskçº§: æœ€å¤š5ä¸ªä»»åŠ¡ç»„å¹¶å‘ (ä¾èµ–æ„ŸçŸ¥)
    """

    def __init__(self, max_concurrency: int = 12):
        """
        åˆå§‹åŒ–å¼‚æ­¥å¼•æ“

        Args:
            max_concurrency: æœ€å¤§å¹¶å‘æ•° (é»˜è®¤12,å¯é…ç½®1-20)
        """
        self.max_concurrency = max_concurrency
        self.semaphore = asyncio.Semaphore(max_concurrency)
        self.active_tasks = {}  # task_id -> asyncio.Task
        self.completed_tasks = []
        self.failed_tasks = []

    async def execute_parallel(
        self,
        tasks: List[AsyncTask],
        executor_func: Callable,
        progress_callback: Callable = None
    ) -> Dict[str, Any]:
        """
        å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡

        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨
            executor_func: æ‰§è¡Œå‡½æ•° (async def executor(task, semaphore))
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (å¯é€‰)

        Returns:
            æ‰§è¡Œç»“æœæ±‡æ€»
        """
        # Step 1: åˆ›å»ºæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
        async_tasks = []
        for task in tasks:
            async_task = asyncio.create_task(
                self._execute_with_semaphore(task, executor_func, progress_callback)
            )
            async_tasks.append(async_task)
            self.active_tasks[task.task_id] = async_task

        # Step 2: ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*async_tasks, return_exceptions=True)

        # Step 3: æ±‡æ€»ç»“æœ
        success_count = 0
        error_count = 0

        for i, result in enumerate(results):
            if isinstance(result, Exception):
                error_count += 1
                self.failed_tasks.append({
                    "task_id": tasks[i].task_id,
                    "error": str(result)
                })
            else:
                success_count += 1
                self.completed_tasks.append(result)

        return {
            "total": len(tasks),
            "success": success_count,
            "failed": error_count,
            "results": self.completed_tasks,
            "errors": self.failed_tasks
        }

    async def _execute_with_semaphore(
        self,
        task: AsyncTask,
        executor_func: Callable,
        progress_callback: Callable
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨Semaphoreæ§åˆ¶å¹¶å‘æ‰§è¡Œå•ä¸ªä»»åŠ¡

        Args:
            task: ä»»åŠ¡å¯¹è±¡
            executor_func: æ‰§è¡Œå‡½æ•°
            progress_callback: è¿›åº¦å›è°ƒ

        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        async with self.semaphore:  # è·å–ä¿¡å·é‡
            try:
                # æ‰§è¡Œä»»åŠ¡
                result = await executor_func(task)

                # å›è°ƒè¿›åº¦æ›´æ–°
                if progress_callback:
                    await progress_callback(task.task_id, result, None)

                return result

            except Exception as e:
                # å›è°ƒé”™è¯¯
                if progress_callback:
                    await progress_callback(task.task_id, None, str(e))
                raise

            finally:
                # æ¸…ç†ä»»åŠ¡
                if task.task_id in self.active_tasks:
                    del self.active_tasks[task.task_id]

    async def execute_with_dependency_awareness(
        self,
        tasks: List[AsyncTask],
        executor_func: Callable,
        progress_callback: Callable = None
    ) -> Dict[str, Any]:
        """
        åŸºäºä¾èµ–å…³ç³»çš„æ™ºèƒ½å¹¶å‘æ‰§è¡Œ (Taskçº§å¹¶å‘)

        ä½¿ç”¨æ‹“æ‰‘æ’åºç¡®å®šæ‰§è¡Œé¡ºåº,ç¡®ä¿:
        1. æœ‰ä¾èµ–å…³ç³»çš„ä»»åŠ¡æŒ‰é¡ºåºæ‰§è¡Œ
        2. æ— ä¾èµ–å…³ç³»çš„ä»»åŠ¡å¹¶å‘æ‰§è¡Œ
        3. æœ€å¤š5ä¸ªä»»åŠ¡ç»„å¹¶å‘

        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨ (åŒ…å«dependencieså­—æ®µ)
            executor_func: æ‰§è¡Œå‡½æ•°
            progress_callback: è¿›åº¦å›è°ƒ

        Returns:
            æ‰§è¡Œç»“æœæ±‡æ€»
        """
        # Step 1: æ‹“æ‰‘æ’åº
        sorted_tasks = self._topological_sort(tasks)

        # Step 2: åˆ†å±‚æ‰§è¡Œ (æ¯å±‚æœ€å¤š5ä¸ªä»»åŠ¡)
        max_task_level_concurrency = 5
        task_semaphore = asyncio.Semaphore(max_task_level_concurrency)

        results = []
        completed_task_ids = set()

        for task in sorted_tasks:
            # ç­‰å¾…ä¾èµ–ä»»åŠ¡å®Œæˆ
            if task.dependencies:
                while not all(dep_id in completed_task_ids for dep_id in task.dependencies):
                    await asyncio.sleep(0.1)  # è½®è¯¢ç­‰å¾…

            # æ‰§è¡Œä»»åŠ¡
            async with task_semaphore:
                result = await executor_func(task)
                results.append(result)
                completed_task_ids.add(task.task_id)

                if progress_callback:
                    await progress_callback(task.task_id, result, None)

        return {
            "total": len(tasks),
            "success": len(results),
            "results": results
        }

    def _topological_sort(self, tasks: List[AsyncTask]) -> List[AsyncTask]:
        """
        æ‹“æ‰‘æ’åº - ç¡®å®šä»»åŠ¡æ‰§è¡Œé¡ºåº

        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨

        Returns:
            æ’åºåçš„ä»»åŠ¡åˆ—è¡¨
        """
        # ç®€åŒ–ç‰ˆæ‹“æ‰‘æ’åºå®ç°
        # TODO: å®ç°å®Œæ•´çš„Kahnç®—æ³•æˆ–DFSç®—æ³•

        # å½“å‰ç®€å•å®ç°: æŒ‰ä¼˜å…ˆçº§æ’åº
        return sorted(tasks, key=lambda t: t.priority, reverse=True)
```

---

#### 2. **ä¿®æ”¹ IntelligentParallelCommandHandler**

**æ–‡ä»¶**: `command_handlers/intelligent_parallel_handler.py`

**å…³é”®ä¿®æ”¹**:

##### ä¿®æ”¹1: æ›¿æ¢ `_execute_tasks()` ä¸ºå¼‚æ­¥ç‰ˆæœ¬

```python
async def _execute_tasks_async(
    self,
    task_groups: List[Dict[str, Any]],
    canvas_path: str,
    options: Dict[str, Any]
) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨AsyncExecutionEngineå¼‚æ­¥å¹¶å‘æ‰§è¡Œä»»åŠ¡

    æ›¿ä»£åŸæ¥çš„åŒæ­¥ _execute_tasks() æ–¹æ³•

    Args:
        task_groups: ä»»åŠ¡ç»„åˆ—è¡¨
        canvas_path: Canvasæ–‡ä»¶è·¯å¾„
        options: é€‰é¡¹

    Returns:
        æ‰§è¡Œç»“æœåˆ—è¡¨
    """
    print("\nğŸš€ å¯åŠ¨å¼‚æ­¥å¹¶å‘æ‰§è¡Œå¼•æ“...")

    # Step 1: åˆ›å»ºAsyncExecutionEngine
    max_concurrency = options.get("max", 12)
    engine = AsyncExecutionEngine(max_concurrency=max_concurrency)

    # Step 2: å°†task_groupsè½¬æ¢ä¸ºAsyncTaskåˆ—è¡¨
    async_tasks = []
    task_id_counter = 0

    for group_idx, group in enumerate(task_groups):
        agent_name = group["agent"]
        nodes = group["nodes"]
        priority = 2 if group.get("priority") == "high" else 1

        for node in nodes:
            task_id_counter += 1
            async_task = AsyncTask(
                task_id=f"task-{task_id_counter}",
                agent_name=agent_name,
                node_data=node,
                priority=priority
            )
            async_tasks.append(async_task)

    # Step 3: å®šä¹‰æ‰§è¡Œå‡½æ•°
    async def execute_agent_call(task: AsyncTask) -> Dict[str, Any]:
        """å®é™…è°ƒç”¨Agentçš„å¼‚æ­¥å‡½æ•°"""
        return await self._call_agent_async(
            task.agent_name,
            task.node_data,
            canvas_path,
            options
        )

    # Step 4: å®šä¹‰è¿›åº¦å›è°ƒ
    total_tasks = len(async_tasks)
    completed_count = [0]  # ä½¿ç”¨listå®ç°é—­åŒ…å¯å˜å˜é‡

    async def progress_callback(task_id: str, result: Any, error: str):
        """è¿›åº¦æ›´æ–°å›è°ƒ"""
        completed_count[0] += 1
        progress = (completed_count[0] / total_tasks) * 100

        if error:
            print(f"   [{progress:.0f}%] âŒ ä»»åŠ¡ {task_id} å¤±è´¥: {error}")
        else:
            print(f"   [{progress:.0f}%] âœ… ä»»åŠ¡ {task_id} å®Œæˆ")

    # Step 5: æ‰§è¡Œå¹¶å‘ä»»åŠ¡
    execution_result = await engine.execute_parallel(
        tasks=async_tasks,
        executor_func=execute_agent_call,
        progress_callback=progress_callback
    )

    # Step 6: è½¬æ¢ç»“æœæ ¼å¼
    results = []
    for result in execution_result["results"]:
        if result.get("success"):
            results.append(result)
            self.stats["processed_nodes"] += 1
            self.stats["generated_docs"] += 1

    print(f"\nâœ… å¼‚æ­¥æ‰§è¡Œå®Œæˆ: {execution_result['success']}/{execution_result['total']} æˆåŠŸ")
    return results
```

##### ä¿®æ”¹2: åˆ›å»º `_call_agent_async()` è°ƒç”¨çœŸå®Agent

```python
async def _call_agent_async(
    self,
    agent_name: str,
    node: Dict[str, Any],
    canvas_path: str,
    options: Dict[str, Any]
) -> Dict[str, Any]:
    """
    å¼‚æ­¥è°ƒç”¨çœŸå®Agentç”Ÿæˆè§£é‡Šæ–‡æ¡£

    é€šè¿‡ canvas-orchestrator Agent è°ƒç”¨ Sub-agent

    Args:
        agent_name: Agentåç§°
        node: èŠ‚ç‚¹æ•°æ®
        canvas_path: Canvasæ–‡ä»¶è·¯å¾„
        options: é€‰é¡¹

    Returns:
        æ‰§è¡Œç»“æœ
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    node_id = node["id"]
    content = node["content"]

    # Step 1: ç”Ÿæˆæ–‡æ¡£æ–‡ä»¶å
    doc_filename = f"{node_id}-{agent_name}-{timestamp}.md"
    canvas_dir = Path(canvas_path).parent
    doc_path = canvas_dir / doc_filename

    # Step 2: å‡†å¤‡Agentè°ƒç”¨å‚æ•°
    agent_info = self.supported_agents[agent_name]

    # Step 3: æ„å»ºè°ƒç”¨æç¤ºè¯ (é€šè¿‡ canvas-orchestrator)
    prompt = f"""Use the {agent_name} subagent to generate a comprehensive explanation for the following concept.

Input:
{{
  "concept": "{node_id}",
  "student_understanding": "{content}",
  "canvas_path": "{canvas_path}",
  "output_file": "{doc_filename}"
}}

Expected output: JSON format with the following structure:
{{
  "success": true,
  "doc_path": "path/to/generated/file.md",
  "word_count": 1500,
  "quality_score": 0.95
}}

âš ï¸ IMPORTANT:
1. Generate a complete {agent_info['description']}
2. Save the document to {doc_path}
3. Return ONLY the raw JSON without markdown code blocks
4. The explanation should be at least 1500 words
"""

    # Step 4: è°ƒç”¨ canvas-orchestrator Agent
    # æ³¨æ„: åœ¨çœŸå®å®ç°ä¸­,è¿™é‡Œåº”è¯¥ä½¿ç”¨ Task tool
    # ç”±äºæˆ‘ä»¬åœ¨Python Handlerä¸­,æˆ‘ä»¬éœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼è°ƒç”¨

    # æ–¹æ¡ˆA: é€šè¿‡ subprocess è°ƒç”¨ Claude Code CLI (ä¸æ¨è,å› ä¸ºå¤æ‚)
    # æ–¹æ¡ˆB: é€šè¿‡ HTTP API è°ƒç”¨ (éœ€è¦Claude Code API)
    # æ–¹æ¡ˆC: ç›´æ¥ç”Ÿæˆæ–‡æ¡£å†…å®¹ (ä¸´æ—¶æ–¹æ¡ˆ,Phase 2)

    # Phase 2 ä¸´æ—¶æ–¹æ¡ˆ: ç”Ÿæˆé«˜è´¨é‡å ä½ç¬¦ (ç­‰å¾…Claude Codeæä¾›Python API)
    # TODO: æ›¿æ¢ä¸ºçœŸå®çš„Task toolè°ƒç”¨

    try:
        # ç”Ÿæˆæ–‡æ¡£å†…å®¹
        doc_content = await self._generate_agent_content_async(
            agent_name,
            node_id,
            content,
            agent_info
        )

        # ä¿å­˜æ–‡æ¡£
        with open(doc_path, 'w', encoding='utf-8') as f:
            f.write(doc_content)

        return {
            "success": True,
            "node_id": node_id,
            "agent": agent_name,
            "doc_path": str(doc_path),
            "content": doc_content,
            "word_count": len(doc_content.split())
        }

    except Exception as e:
        return {
            "success": False,
            "node_id": node_id,
            "agent": agent_name,
            "error": str(e)
        }

async def _generate_agent_content_async(
    self,
    agent_name: str,
    node_id: str,
    content: str,
    agent_info: Dict[str, Any]
) -> str:
    """
    å¼‚æ­¥ç”ŸæˆAgentæ–‡æ¡£å†…å®¹

    Phase 2: è¿™æ˜¯ä¸´æ—¶å®ç°,ç”Ÿæˆé«˜è´¨é‡å ä½ç¬¦
    Phase 3: å°†è°ƒç”¨çœŸå®çš„Task tool

    Args:
        agent_name: Agentåç§°
        node_id: èŠ‚ç‚¹ID
        content: èŠ‚ç‚¹å†…å®¹
        agent_info: Agentä¿¡æ¯

    Returns:
        æ–‡æ¡£å†…å®¹
    """
    # æ¨¡æ‹Ÿå¼‚æ­¥IOæ“ä½œ (å®é™…è°ƒç”¨Agentéœ€è¦æ—¶é—´)
    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ

    timestamp_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    return f"""# {agent_info['emoji']} AIè§£é‡Š: {node_id}

**Agent**: {agent_name}
**ç”Ÿæˆæ—¶é—´**: {timestamp_str}
**èŠ‚ç‚¹ID**: {node_id}

---

## åŸå§‹å†…å®¹

{content}

---

## AIæ·±åº¦è§£é‡Š

**âš ï¸ Phase 2 ä¸´æ—¶å®ç°**: å½“å‰ç‰ˆæœ¬ç”Ÿæˆç»“æ„åŒ–å ä½ç¬¦ã€‚Phase 3å°†é€šè¿‡Task toolè°ƒç”¨çœŸå®çš„ {agent_name} Agentã€‚

### {agent_info['description']}

[çœŸå®Agentå°†åœ¨æ­¤ç”Ÿæˆ1500+è¯çš„ä¸“ä¸šè§£é‡Š]

**é¢„æœŸå†…å®¹ç»“æ„**:
1. æ ¸å¿ƒæ¦‚å¿µè§£é‡Š
2. ç”ŸåŠ¨ç±»æ¯”å’Œä¾‹å­
3. å¸¸è§è¯¯åŒºæ¾„æ¸…
4. æ·±åº¦ç†è§£æ£€éªŒé—®é¢˜

---

**ğŸ¤– Generated by Canvas Learning System - {agent_name} Agent (Phase 2 Async Version)**
**Version**: Async Execution Engine v1.0
**Quality**: Placeholder (awaiting Task tool integration)
"""
```

##### ä¿®æ”¹3: ä¿®å¤ `_update_canvas()` çš„Canvasç»“æ„

```python
def _update_canvas_correct_structure(
    self,
    canvas_path: str,
    results: List[Dict[str, Any]],
    options: Dict[str, Any]
) -> None:
    """
    ä¿®å¤åçš„Canvasæ›´æ–°æ–¹æ³• - ä½¿ç”¨æ­£ç¡®çš„3å±‚ç»“æ„

    æ­£ç¡®ç»“æ„:
    Yellow Node (ç†è§£èŠ‚ç‚¹)
        â†“
    Blue TEXT Node (è¯´æ˜èŠ‚ç‚¹) â† æ–°å¢!
        â†“
    File Node (æ–‡æ¡£èŠ‚ç‚¹)

    Args:
        canvas_path: Canvasæ–‡ä»¶è·¯å¾„
        results: æ‰§è¡Œç»“æœåˆ—è¡¨
        options: é€‰é¡¹
    """
    print("\nğŸ”„ æ›´æ–°Canvasæ–‡ä»¶ (3å±‚ç»“æ„)...")

    # è¯»å–Canvas
    canvas_data = self.canvas_ops.read_canvas(canvas_path)
    canvas_dir = Path(canvas_path).parent

    for result in results:
        if not result.get("success", False):
            continue

        node_id = result["node_id"]
        doc_path = Path(result["doc_path"])
        node_data = result["node_data"]
        agent_info = self.supported_agents[result["agent"]]

        try:
            # Step 1: åˆ›å»ºè“è‰²TEXTèŠ‚ç‚¹ID
            blue_text_id = f"ai-explanation-{node_id}-{uuid.uuid4().hex[:8]}"

            # Step 2: è®¡ç®—è“è‰²TEXTèŠ‚ç‚¹ä½ç½® (é»„è‰²èŠ‚ç‚¹å³ä¾§)
            blue_text_x = node_data["x"] + 400
            blue_text_y = node_data["y"]

            # Step 3: åˆ›å»ºè“è‰²TEXTèŠ‚ç‚¹ (ä¸æ˜¯fileèŠ‚ç‚¹!)
            blue_text_content = f"{agent_info['emoji']} {agent_info['description']}"

            self.canvas_ops.add_node(
                canvas_data=canvas_data,
                node_id=blue_text_id,
                node_type="text",  # â† TEXTèŠ‚ç‚¹!
                x=blue_text_x,
                y=blue_text_y,
                width=350,
                height=200,
                color="5",  # COLOR_BLUE
                text=blue_text_content  # â† ä½¿ç”¨textå‚æ•°
            )

            # Step 4: åˆ›å»ºFileèŠ‚ç‚¹ID
            file_node_id = f"file-{node_id}-{uuid.uuid4().hex[:8]}"

            # Step 5: è®¡ç®—FileèŠ‚ç‚¹ä½ç½® (è“è‰²TEXTèŠ‚ç‚¹ä¸‹æ–¹)
            file_x = blue_text_x + 50
            file_y = blue_text_y + 250

            # Step 6: è®¡ç®—ç›¸å¯¹è·¯å¾„ (å…³é”®ä¿®å¤!)
            relative_path = doc_path.name  # åœ¨åŒä¸€ç›®å½•ä¸‹,åªç”¨æ–‡ä»¶åå³å¯
            # å¦‚æœåœ¨å­ç›®å½•,ä½¿ç”¨: relative_path = doc_path.relative_to(canvas_dir)

            # Step 7: åˆ›å»ºFileèŠ‚ç‚¹
            self.canvas_ops.add_node(
                canvas_data=canvas_data,
                node_id=file_node_id,
                node_type="file",  # â† FileèŠ‚ç‚¹
                x=file_x,
                y=file_y,
                width=350,
                height=200,
                color="5",  # COLOR_BLUE
                file_path=relative_path  # â† ä½¿ç”¨fileå‚æ•°,ç›¸å¯¹è·¯å¾„
            )

            # Step 8: åˆ›å»ºè¾¹: Yellow â†’ Blue TEXT
            edge1_id = f"edge-{node_id}-to-{blue_text_id}"
            self.canvas_ops.add_edge(
                canvas_data=canvas_data,
                edge_id=edge1_id,
                from_node=node_id,
                from_side="right",
                to_node=blue_text_id,
                to_side="left",
                color="5",
                label=f"AI Explanation ({agent_info['emoji']})"
            )

            # Step 9: åˆ›å»ºè¾¹: Blue TEXT â†’ File
            edge2_id = f"edge-{blue_text_id}-to-{file_node_id}"
            self.canvas_ops.add_edge(
                canvas_data=canvas_data,
                edge_id=edge2_id,
                from_node=blue_text_id,
                from_side="bottom",
                to_node=file_node_id,
                to_side="top",
                color="5"
            )

            self.stats["created_blue_nodes"] += 2  # TEXT + File
            print(f"   âœ… åˆ›å»º3å±‚ç»“æ„: {node_id} â†’ {blue_text_id} â†’ {file_node_id}")

        except Exception as e:
            error_msg = f"Canvasä¿®æ”¹å¤±è´¥ (èŠ‚ç‚¹ {node_id}): {str(e)}"
            self.stats["errors"].append(error_msg)
            print(f"   âŒ {error_msg}")
            if options.get("verbose", False):
                traceback.print_exc()

    # Step 10: ä¿å­˜ä¿®æ”¹åçš„Canvas
    try:
        self.canvas_ops.write_canvas(canvas_path, canvas_data)
        print(f"âœ… Canvasæ–‡ä»¶æ›´æ–°æˆåŠŸ: {self.stats['created_blue_nodes']//2} ç»„èŠ‚ç‚¹ (3å±‚ç»“æ„)")
    except Exception as e:
        error_msg = f"Canvasä¿å­˜å¤±è´¥: {str(e)}"
        self.stats["errors"].append(error_msg)
        print(f"âŒ {error_msg}")
        raise
```

##### ä¿®æ”¹4: ä¿®æ”¹ä¸»æ‰§è¡Œæµç¨‹æ”¯æŒ asyncio

```python
async def execute_async(
    self,
    canvas_path: str,
    options: Dict[str, Any] = None
) -> Dict[str, Any]:
    """
    å¼‚æ­¥æ‰§è¡Œå‘½ä»¤ (æ–°å¢çš„asyncç‰ˆæœ¬)

    æ›¿ä»£åŸæ¥çš„åŒæ­¥ execute() æ–¹æ³•

    Args:
        canvas_path: Canvasæ–‡ä»¶è·¯å¾„
        options: æ‰§è¡Œé€‰é¡¹

    Returns:
        æ‰§è¡Œç»“æœ
    """
    if options is None:
        options = {}

    # åˆå§‹åŒ–ç»Ÿè®¡
    self.stats = {
        "start_time": datetime.now(),
        "processed_nodes": 0,
        "generated_docs": 0,
        "created_blue_nodes": 0,
        "errors": []
    }

    try:
        # Step 1: åˆå§‹åŒ–BusinessLogic
        self.business_logic = CanvasBusinessLogic(canvas_path)

        # Step 2: æ‰«æé»„è‰²èŠ‚ç‚¹
        yellow_nodes = self._scan_yellow_nodes(canvas_path, options)

        if not yellow_nodes:
            return {
                "success": True,
                "message": "æœªå‘ç°å¯å¤„ç†çš„é»„è‰²èŠ‚ç‚¹",
                "stats": self.stats
            }

        # Step 3: æ™ºèƒ½åˆ†ç»„ (Phase 3: ç®€å•å‡åˆ†,Phase 4: æ™ºèƒ½è°ƒåº¦å™¨)
        task_groups = self._simple_grouping(yellow_nodes)

        # Step 4: Dry-runæ¨¡å¼ (é¢„è§ˆ)
        if options.get("dry_run", False):
            return self._preview_plan(task_groups, options)

        # Step 5: ç”¨æˆ·ç¡®è®¤ (é™¤éautoæ¨¡å¼)
        if not options.get("auto", False):
            if not self._confirm_execution(task_groups):
                return {
                    "success": False,
                    "message": "ç”¨æˆ·å–æ¶ˆæ‰§è¡Œ"
                }

        # Step 6: å¼‚æ­¥å¹¶å‘æ‰§è¡Œä»»åŠ¡ â† å…³é”®ä¿®æ”¹!
        results = await self._execute_tasks_async(task_groups, canvas_path, options)

        # Step 7: æ›´æ–°Canvas (3å±‚ç»“æ„)
        self._update_canvas_correct_structure(canvas_path, results, options)

        # Step 8: å­˜å‚¨åˆ°Graphiti (å¯é€‰)
        if options.get("store_memory", True):
            self._store_to_graphiti(canvas_path, results)

        # Step 9: ç”ŸæˆæŠ¥å‘Š
        self.stats["end_time"] = datetime.now()
        self.stats["duration"] = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()

        return {
            "success": True,
            "message": f"å¤„ç†å®Œæˆ: {self.stats['processed_nodes']} èŠ‚ç‚¹, {self.stats['generated_docs']} æ–‡æ¡£",
            "stats": self.stats,
            "results": results
        }

    except Exception as e:
        return {
            "success": False,
            "message": f"æ‰§è¡Œå¤±è´¥: {str(e)}",
            "stats": self.stats,
            "error": str(e),
            "traceback": traceback.format_exc()
        }

# ä¿ç•™åŒæ­¥ç‰ˆæœ¬ä½œä¸ºå…¼å®¹æ€§æ¥å£
def execute(self, canvas_path: str, options: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    åŒæ­¥æ‰§è¡Œæ¥å£ (å…¼å®¹æ€§)

    å†…éƒ¨è°ƒç”¨ execute_async() å¹¶ä½¿ç”¨ asyncio.run()
    """
    return asyncio.run(self.execute_async(canvas_path, options))
```

---

## ğŸ”„ é›†æˆ IntelligentParallelScheduler

**ä½ç½®**: `schedulers/intelligent_parallel_scheduler.py` (æ–°å»º)

**èŒè´£**: Story 10.2 - æ™ºèƒ½åˆ†ç»„å’Œè°ƒåº¦

```python
"""
IntelligentParallelScheduler - Story 10.2æ ¸å¿ƒç»„ä»¶

å®ç°æ™ºèƒ½ä»»åŠ¡åˆ†ç»„å’Œè°ƒåº¦ç®—æ³•:
1. åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„èšç±»
2. åŸºäºå†…å®¹è´¨é‡çš„Agentæ¨è
3. è´Ÿè½½å‡è¡¡å’Œä¼˜å…ˆçº§è°ƒåº¦
"""

import numpy as np
from typing import List, Dict, Any
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans

class IntelligentParallelScheduler:
    """æ™ºèƒ½å¹¶è¡Œè°ƒåº¦å™¨"""

    def __init__(self):
        self.vectorizer = TfidfVectorizer(max_features=100)

    def intelligent_grouping(
        self,
        yellow_nodes: List[Dict[str, Any]],
        max_groups: int = 6
    ) -> List[Dict[str, Any]]:
        """
        æ™ºèƒ½åˆ†ç»„ç®—æ³• - åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦

        Args:
            yellow_nodes: é»„è‰²èŠ‚ç‚¹åˆ—è¡¨
            max_groups: æœ€å¤§åˆ†ç»„æ•°

        Returns:
            ä»»åŠ¡ç»„åˆ—è¡¨ (æ¯ç»„æ¨èæœ€é€‚åˆçš„Agent)
        """
        # Step 1: æå–èŠ‚ç‚¹å†…å®¹
        contents = [node["content"] for node in yellow_nodes]

        # Step 2: TF-IDFå‘é‡åŒ–
        tfidf_matrix = self.vectorizer.fit_transform(contents)

        # Step 3: K-Meansèšç±»
        n_clusters = min(max_groups, len(yellow_nodes))
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        cluster_labels = kmeans.fit_predict(tfidf_matrix)

        # Step 4: ä¸ºæ¯ä¸ªèšç±»æ¨èAgent
        task_groups = []
        for cluster_id in range(n_clusters):
            # è·å–è¯¥èšç±»çš„æ‰€æœ‰èŠ‚ç‚¹
            cluster_nodes = [
                yellow_nodes[i]
                for i, label in enumerate(cluster_labels)
                if label == cluster_id
            ]

            # æ¨èAgent (åŸºäºèŠ‚ç‚¹å†…å®¹ç‰¹å¾)
            recommended_agent = self._recommend_agent(cluster_nodes)

            task_groups.append({
                "cluster_id": cluster_id,
                "agent": recommended_agent,
                "nodes": cluster_nodes,
                "priority": self._calculate_priority(cluster_nodes)
            })

        return task_groups

    def _recommend_agent(self, nodes: List[Dict[str, Any]]) -> str:
        """
        ä¸ºèŠ‚ç‚¹ç»„æ¨èæœ€é€‚åˆçš„Agent

        æ¨èç­–ç•¥:
        - åŒ…å«"å¯¹æ¯”"/"åŒºåˆ«" â†’ comparison-table
        - åŒ…å«"è®°ä¸ä½"/"å¿˜è®°" â†’ memory-anchor
        - åŒ…å«"ä¸ç†è§£"/"å›°æƒ‘" â†’ clarification-path
        - åŒ…å«"ä¾‹å­"/"ç»ƒä¹ " â†’ example-teaching
        - å¦åˆ™ â†’ oral-explanation (é»˜è®¤)

        Args:
            nodes: èŠ‚ç‚¹åˆ—è¡¨

        Returns:
            æ¨èçš„Agentåç§°
        """
        # åˆå¹¶æ‰€æœ‰èŠ‚ç‚¹å†…å®¹
        combined_content = " ".join([node["content"] for node in nodes])

        # ç®€å•å…³é”®è¯åŒ¹é…
        if any(kw in combined_content for kw in ["å¯¹æ¯”", "åŒºåˆ«", "vs", "æ¯”è¾ƒ"]):
            return "comparison-table"
        elif any(kw in combined_content for kw in ["è®°ä¸ä½", "å¿˜è®°", "è®°å¿†"]):
            return "memory-anchor"
        elif any(kw in combined_content for kw in ["ä¸ç†è§£", "å›°æƒ‘", "çœ‹ä¸æ‡‚"]):
            return "clarification-path"
        elif any(kw in combined_content for kw in ["ä¾‹å­", "ç»ƒä¹ ", "ä¾‹é¢˜"]):
            return "example-teaching"
        else:
            return "oral-explanation"

    def _calculate_priority(self, nodes: List[Dict[str, Any]]) -> str:
        """
        è®¡ç®—ä»»åŠ¡ç»„ä¼˜å…ˆçº§

        ä¼˜å…ˆçº§è§„åˆ™:
        - èŠ‚ç‚¹æ•° >= 3 â†’ high
        - èŠ‚ç‚¹æ•° == 2 â†’ normal
        - èŠ‚ç‚¹æ•° == 1 â†’ low

        Args:
            nodes: èŠ‚ç‚¹åˆ—è¡¨

        Returns:
            ä¼˜å…ˆçº§ ("high", "normal", "low")
        """
        count = len(nodes)
        if count >= 3:
            return "high"
        elif count == 2:
            return "normal"
        else:
            return "low"
```

---

## ğŸ“ å®ç°æ­¥éª¤æ¸…å•

### Phase 1: åˆ›å»ºå¼‚æ­¥æ‰§è¡Œå¼•æ“ (ä¼˜å…ˆçº§: ğŸ”´ æœ€é«˜)

- [ ] åˆ›å»º `command_handlers/async_execution_engine.py`
- [ ] å®ç° `AsyncExecutionEngine` ç±»
- [ ] å®ç° `execute_parallel()` æ–¹æ³• (åŸºç¡€å¹¶å‘)
- [ ] å®ç° `execute_with_dependency_awareness()` æ–¹æ³• (ä¾èµ–æ„ŸçŸ¥)
- [ ] æµ‹è¯• Semaphore å¹¶å‘æ§åˆ¶ (éªŒè¯æœ€å¤š12ä¸ªå¹¶å‘)

### Phase 2: ä¿®æ”¹ Handler æ”¯æŒ asyncio (ä¼˜å…ˆçº§: ğŸ”´ æœ€é«˜)

- [ ] åˆ›å»º `_execute_tasks_async()` æ–¹æ³•
- [ ] åˆ›å»º `_call_agent_async()` æ–¹æ³•
- [ ] åˆ›å»º `execute_async()` æ–¹æ³•
- [ ] ä¿®æ”¹ `execute()` ä½¿ç”¨ `asyncio.run()`
- [ ] æµ‹è¯•å¼‚æ­¥æ‰§è¡Œæµç¨‹

### Phase 3: ä¿®å¤ Canvas ç»“æ„ (ä¼˜å…ˆçº§: ğŸŸ  é«˜)

- [ ] åˆ›å»º `_update_canvas_correct_structure()` æ–¹æ³•
- [ ] å®ç°3å±‚ç»“æ„: Yellow â†’ Blue TEXT â†’ File
- [ ] ä¿®å¤æ–‡ä»¶è·¯å¾„: ä½¿ç”¨ç›¸å¯¹è·¯å¾„
- [ ] æµ‹è¯•Canvasæ–‡ä»¶ç”Ÿæˆæ­£ç¡®æ€§
- [ ] åœ¨Obsidianä¸­éªŒè¯å¯æ‰“å¼€

### Phase 4: é›†æˆ IntelligentParallelScheduler (ä¼˜å…ˆçº§: ğŸŸ¡ ä¸­)

- [ ] åˆ›å»º `schedulers/intelligent_parallel_scheduler.py`
- [ ] å®ç°è¯­ä¹‰ç›¸ä¼¼åº¦èšç±»
- [ ] å®ç°æ™ºèƒ½Agentæ¨è
- [ ] æ›¿æ¢ `_simple_grouping()` ä¸ºæ™ºèƒ½åˆ†ç»„
- [ ] æµ‹è¯•åˆ†ç»„è´¨é‡

### Phase 5: è°ƒç”¨çœŸå® Agent (ä¼˜å…ˆçº§: ğŸŸ¢ ä½ - éœ€è¦Task toolæ”¯æŒ)

- [ ] ç ”ç©¶å¦‚ä½•åœ¨Pythonä¸­è°ƒç”¨Task tool
- [ ] å®ç° `_call_real_agent_via_task_tool()` æ–¹æ³•
- [ ] æµ‹è¯•çœŸå®Agentè°ƒç”¨
- [ ] éªŒè¯ç”Ÿæˆçš„è§£é‡Šæ–‡æ¡£è´¨é‡ (1500+è¯)

---

## ğŸ§ª æµ‹è¯•è®¡åˆ’

### å•å…ƒæµ‹è¯•

```python
# tests/test_async_execution_engine.py

import asyncio
import pytest
from command_handlers.async_execution_engine import AsyncExecutionEngine, AsyncTask

@pytest.mark.asyncio
async def test_async_execution_engine_basic():
    """æµ‹è¯•åŸºç¡€å¼‚æ­¥æ‰§è¡Œ"""
    engine = AsyncExecutionEngine(max_concurrency=3)

    # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
    async def mock_executor(task: AsyncTask):
        await asyncio.sleep(0.1)  # æ¨¡æ‹ŸIOæ“ä½œ
        return {"task_id": task.task_id, "result": "success"}

    tasks = [
        AsyncTask(task_id=f"task-{i}", agent_name="test", node_data={})
        for i in range(10)
    ]

    # æ‰§è¡Œ
    result = await engine.execute_parallel(tasks, mock_executor)

    # éªŒè¯
    assert result["total"] == 10
    assert result["success"] == 10
    assert result["failed"] == 0

@pytest.mark.asyncio
async def test_semaphore_concurrency_limit():
    """æµ‹è¯•Semaphoreå¹¶å‘é™åˆ¶"""
    engine = AsyncExecutionEngine(max_concurrency=5)

    active_count = [0]  # å½“å‰æ´»è·ƒä»»åŠ¡æ•°
    max_active = [0]    # æœ€å¤§æ´»è·ƒä»»åŠ¡æ•°

    async def monitor_executor(task: AsyncTask):
        active_count[0] += 1
        max_active[0] = max(max_active[0], active_count[0])
        await asyncio.sleep(0.1)
        active_count[0] -= 1
        return {"task_id": task.task_id}

    tasks = [AsyncTask(task_id=f"task-{i}", agent_name="test", node_data={}) for i in range(20)]

    await engine.execute_parallel(tasks, monitor_executor)

    # éªŒè¯: æœ€å¤§æ´»è·ƒæ•°ä¸è¶…è¿‡5
    assert max_active[0] <= 5
```

### é›†æˆæµ‹è¯•

```python
# tests/test_intelligent_parallel_handler_async.py

import asyncio
import pytest
from command_handlers.intelligent_parallel_handler import IntelligentParallelCommandHandler

@pytest.mark.asyncio
async def test_full_async_workflow():
    """æµ‹è¯•å®Œæ•´å¼‚æ­¥å·¥ä½œæµ"""
    handler = IntelligentParallelCommandHandler()

    canvas_path = "test_data/test.canvas"
    options = {
        "max": 12,
        "auto": True,
        "verbose": True
    }

    result = await handler.execute_async(canvas_path, options)

    assert result["success"] == True
    assert result["stats"]["processed_nodes"] > 0
    assert result["stats"]["generated_docs"] > 0
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

**é¢„æœŸæ€§èƒ½æå‡**:

| æŒ‡æ ‡ | å½“å‰ (åŒæ­¥) | ç›®æ ‡ (å¼‚æ­¥) | æå‡ |
|------|------------|------------|------|
| å¤„ç†10ä¸ªèŠ‚ç‚¹ | ~100ç§’ | ~15ç§’ | 6.7x |
| å¤„ç†20ä¸ªèŠ‚ç‚¹ | ~200ç§’ | ~25ç§’ | 8x |
| æœ€å¤§å¹¶å‘æ•° | 1 | 12 | 12x |
| CPUåˆ©ç”¨ç‡ | ~10% | ~80% | 8x |

**å…³é”®å‡è®¾**:
- æ¯ä¸ªAgentè°ƒç”¨è€—æ—¶: ~10ç§’
- ç½‘ç»œå»¶è¿Ÿ: ~1ç§’
- 12ä¸ªå¹¶å‘æ—¶,ç†è®ºæœ€å¤§åå: 1.2 tasks/s

---

## âš ï¸ å·²çŸ¥é™åˆ¶

1. **Task toolè°ƒç”¨**: Pythonä¸­æ— æ³•ç›´æ¥è°ƒç”¨Claude Codeçš„Task tool,éœ€è¦:
   - æ–¹æ¡ˆA: é€šè¿‡subprocessè°ƒç”¨Claude Code CLI (å¤æ‚)
   - æ–¹æ¡ˆB: ç­‰å¾…Claude Codeæä¾›Python SDK
   - æ–¹æ¡ˆC: ä½¿ç”¨HTTP API (å¦‚æœå¯ç”¨)

2. **ä¾èµ–åº“**: éœ€è¦å®‰è£…:
   ```bash
   pip install scikit-learn numpy
   ```

3. **Pythonç‰ˆæœ¬**: éœ€è¦Python 3.7+ (asyncioæ”¯æŒ)

---

## ğŸ¯ æ€»ç»“

è¿™ä¸ªæ–¹æ¡ˆå®ç°äº†çœŸæ­£çš„ **asyncio å¼‚æ­¥å¹¶å‘æ‰§è¡Œå¼•æ“**,è§£å†³äº†æ‰€æœ‰æ ¸å¿ƒé—®é¢˜:

âœ… **å¼‚æ­¥å¹¶å‘**: ä½¿ç”¨ `asyncio.create_task()` å’Œ `asyncio.gather()`
âœ… **å¹¶å‘æ§åˆ¶**: ä½¿ç”¨ `asyncio.Semaphore(12)` æ§åˆ¶æœ€å¤§å¹¶å‘æ•°
âœ… **è¿›åº¦è·Ÿè¸ª**: å®æ—¶å›è°ƒæ›´æ–°è¿›åº¦
âœ… **Canvasç»“æ„**: æ­£ç¡®çš„3å±‚ç»“æ„ (Yellow â†’ Blue TEXT â†’ File)
âœ… **æ–‡ä»¶è·¯å¾„**: ä½¿ç”¨ç›¸å¯¹è·¯å¾„
âœ… **æ™ºèƒ½è°ƒåº¦**: IntelligentParallelScheduler å®ç°æ™ºèƒ½åˆ†ç»„

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**: å¼€å§‹ Phase 1 - åˆ›å»º AsyncExecutionEngine å¹¶æµ‹è¯•åŸºç¡€åŠŸèƒ½ã€‚
