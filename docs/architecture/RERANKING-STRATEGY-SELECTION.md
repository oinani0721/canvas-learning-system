---
document_type: "Architecture"
version: "1.0.0"
last_modified: "2025-11-19"
status: "approved"
iteration: 1

authors:
  - name: "Architect Agent"
    role: "Solution Architect"

reviewers:
  - name: "PO Agent"
    role: "Product Owner"
    approved: true

compatible_with:
  prd: "v1.0"
  api_spec: "v1.0"

api_spec_hash: "0dc1d3610d28bf99"

changes_from_previous:
  - "Initial Architecture with frontmatter metadata"

git:
  commit_sha: ""
  tag: ""

metadata:
  components_count: 0
  external_services: []
  technology_stack:
    frontend: []
    backend: ["Python 3.11", "asyncio"]
    database: []
    infrastructure: []
---

# Rerankingç­–ç•¥é€‰å‹åˆ†æ

**åˆ›å»ºæ—¥æœŸ**: 2025-11-14
**è°ƒç ”ä»»åŠ¡**: è°ƒç ”4-C - Rerankingç­–ç•¥é€‰å‹ (Cohere API vs Local Cross-Encoder)
**ç›®æ ‡**: ä¸ºCanvasæ··åˆæ£€ç´¢ç³»ç»Ÿé€‰æ‹©æœ€ä¼˜Rerankingæ–¹æ¡ˆ

---

## æ‰§è¡Œæ‘˜è¦ (Executive Summary)

### æ ¸å¿ƒå‘ç° ğŸ¯

**æ¨èæ–¹æ¡ˆ**: **Local Cross-Encoder + Cohere APIæ··åˆç­–ç•¥**

| æ–¹æ¡ˆ | æˆæœ¬ (å¹´) | å»¶è¿Ÿ | ç²¾åº¦ | Canvasæ¨èåœºæ™¯ |
|------|----------|------|------|---------------|
| **Cohere Rerank API** | ~$50-100 | 100-200ms | **æœ€é«˜** | æ£€éªŒç™½æ¿ç”Ÿæˆï¼ˆé«˜ç²¾åº¦ä¼˜å…ˆï¼‰ |
| **Local Cross-Encoder** | ~$0 (GPUå·²æœ‰) | 50-100ms | **é«˜** | æ—¥å¸¸æ£€ç´¢ï¼ˆé»˜è®¤ï¼‰ |
| **Hybrid** | ~$20-30 | åŠ¨æ€ | **æœ€é«˜** | âœ… **æ¨èï¼šLocalä¸ºä¸»ï¼ŒCohereç²¾è°ƒ** |

**å…³é”®å†³ç­–å› ç´ **:
1. **Canvasæ˜¯ä¸ªäººå­¦ä¹ ç³»ç»Ÿ** - æŸ¥è¯¢é‡ä½ï¼ˆ<100æ¬¡/å¤©ï¼‰ï¼Œæˆæœ¬ä¸æ˜¯ä¸»è¦é—®é¢˜
2. **ä¸­æ–‡å†…å®¹ä¸ºä¸»** - éœ€è¦ä¸­æ–‡Rerankeræ”¯æŒ
3. **å·²æœ‰CUDA GPU** - æœ¬åœ°Cross-Encoderæ— é¢å¤–ç¡¬ä»¶æˆæœ¬
4. **æ£€éªŒç™½æ¿ç”Ÿæˆè´¨é‡å…³é”®** - é«˜ç²¾åº¦åœºæ™¯å€¼å¾—ä½¿ç”¨Cohere

---

## 1. RerankingåŸºç¡€æ¦‚å¿µ

### 1.1 ä»€ä¹ˆæ˜¯Rerankingï¼Ÿ

**Reranking (é‡æ’åº)** æ˜¯æ£€ç´¢ç³»ç»Ÿçš„ç¬¬äºŒé˜¶æ®µä¼˜åŒ–ï¼š

```
Stage 1: Initial Retrieval (å¿«é€Ÿå¬å›)
â”œâ”€ Semantic Search (vector similarity)
â”œâ”€ BM25 (keyword matching)
â””â”€ Graph Traversal (relationship-based)
    â†“
Candidates: 100-1000 documents

Stage 2: Reranking (ç²¾ç¡®æ’åº)
â”œâ”€ Cross-Encoder deep semantic scoring
â”œâ”€ Query-document pair encoding
â””â”€ Relevance prediction
    â†“
Top-K results: 10-20 documents
```

**ä¸ºä»€ä¹ˆéœ€è¦Rerankingï¼Ÿ**
- **Bi-Encoderé™åˆ¶**: Semantic Searchä½¿ç”¨Bi-Encoderï¼ˆqueryå’Œdocåˆ†åˆ«ç¼–ç ï¼‰ï¼Œæ— æ³•æ•è·query-docäº¤äº’
- **Cross-Encoderä¼˜åŠ¿**: query+docä¸€èµ·è¾“å…¥BERTï¼Œæ·±åº¦è¯­ä¹‰ç†è§£ï¼Œç²¾åº¦é«˜10-20%
- **æˆæœ¬æƒè¡¡**: Cross-Encoderæ…¢ï¼ˆ~100ms/docï¼‰ï¼Œåªç”¨äºTop-100å€™é€‰

---

### 1.2 Bi-Encoder vs Cross-Encoder

**âœ… Bi-Encoder (First-stage Retrieval)**
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')

# åˆ†åˆ«ç¼–ç 
query_embedding = model.encode("é€†å¦å‘½é¢˜çš„åº”ç”¨")
doc_embeddings = model.encode([doc1, doc2, ..., doc1000])

# ä½™å¼¦ç›¸ä¼¼åº¦
similarities = cosine_similarity(query_embedding, doc_embeddings)
```

**ä¼˜åŠ¿**: å¿«é€Ÿï¼ˆå¯é¢„è®¡ç®—doc embeddingsï¼ŒæŸ¥è¯¢æ—¶åªéœ€ç¼–ç queryï¼‰
**åŠ£åŠ¿**: æ— æ³•æ•è·query-docäº¤äº’ï¼ˆå¦‚"NOT"å…³ç³»ï¼‰

**âœ… Cross-Encoder (Second-stage Reranking)**
```python
from sentence_transformers import CrossEncoder

model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

# Query+Docä¸€èµ·ç¼–ç 
pairs = [
    ("é€†å¦å‘½é¢˜çš„åº”ç”¨", doc1),
    ("é€†å¦å‘½é¢˜çš„åº”ç”¨", doc2),
    ...
]
scores = model.predict(pairs)  # ç›´æ¥é¢„æµ‹ç›¸å…³æ€§åˆ†æ•°
```

**ä¼˜åŠ¿**: ç²¾åº¦é«˜ï¼ˆæ·±åº¦è¯­ä¹‰ç†è§£query-docäº¤äº’ï¼‰
**åŠ£åŠ¿**: æ…¢ï¼ˆæ¯ä¸ªquery-doc pairéƒ½éœ€è¦forward passï¼‰

---

## 2. Option 1: Cohere Rerank API

### 2.1 Cohere Rerankæ¦‚è¿°

**Cohere Rerank** æ˜¯Cohereæä¾›çš„æ‰˜ç®¡å¼Reranking APIï¼ŒåŸºäºå¤§è§„æ¨¡è®­ç»ƒçš„Rerankeræ¨¡å‹ã€‚

**å®˜æ–¹æ–‡æ¡£**: https://cohere.com/rerank

**âœ… æ ¸å¿ƒç‰¹æ€§**:
- **å¤šè¯­è¨€æ”¯æŒ**: 100+è¯­è¨€ï¼ŒåŒ…æ‹¬ä¸­æ–‡
- **é«˜ç²¾åº¦**: åœ¨MS MARCOç­‰åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚
- **æ˜“ç”¨æ€§**: ç®€å•çš„REST APIï¼Œæ— éœ€GPU
- **å¯æ‰©å±•**: æ‰˜ç®¡æœåŠ¡ï¼Œè‡ªåŠ¨æ‰©å®¹

---

### 2.2 Cohere Rerank APIä½¿ç”¨

**âœ… APIè°ƒç”¨ç¤ºä¾‹**

```python
import cohere

# âœ… åˆå§‹åŒ–Cohereå®¢æˆ·ç«¯
co = cohere.Client(api_key="YOUR_API_KEY")

# âœ… Rerank APIè°ƒç”¨
def cohere_rerank(
    query: str,
    documents: List[str],
    top_n: int = 10,
    model: str = "rerank-multilingual-v3.0"  # æ”¯æŒä¸­æ–‡
) -> List[Dict]:
    """
    Cohere Rerank API

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¯ä»¥æ˜¯ä¸­æ–‡ï¼‰
        documents: å€™é€‰æ–‡æ¡£åˆ—è¡¨
        top_n: è¿”å›Top-Kç»“æœ
        model: Rerankeræ¨¡å‹
            - rerank-english-v3.0: è‹±æ–‡ä¼˜åŒ–
            - rerank-multilingual-v3.0: å¤šè¯­è¨€ï¼ˆå«ä¸­æ–‡ï¼‰
            - rerank-english-v2.0: æ—§ç‰ˆè‹±æ–‡

    Returns:
        List of dicts with keys: index, relevance_score
    """
    response = co.rerank(
        query=query,
        documents=documents,
        top_n=top_n,
        model=model
    )

    results = []
    for r in response.results:
        results.append({
            "index": r.index,           # åŸå§‹æ–‡æ¡£ç´¢å¼•
            "relevance_score": r.relevance_score,  # 0-1ç›¸å…³æ€§åˆ†æ•°
            "document": documents[r.index]
        })

    return results

# === Canvasä½¿ç”¨ç¤ºä¾‹ ===
async def canvas_rerank_with_cohere(
    query: str,
    graphiti_results: GraphSearchResults,
    lancedb_results: List[Dict],
    top_k: int = 10
):
    """Canvasæ£€ç´¢ + Cohere Reranking"""

    # Step 1: RRFèåˆGraphiti + LanceDB
    fused_results = reciprocal_rank_fusion(
        graphiti_results,
        lancedb_results,
        k=60
    )

    # Step 2: å‡†å¤‡Cohere Rerankè¾“å…¥
    candidate_docs = [r.content for r in fused_results[:100]]  # Top-100å€™é€‰

    # Step 3: Cohere Rerank
    reranked = cohere_rerank(
        query=query,
        documents=candidate_docs,
        top_n=top_k,
        model="rerank-multilingual-v3.0"  # ä¸­æ–‡æ”¯æŒ
    )

    # Step 4: æ˜ å°„å›åŸå§‹ç»“æœ
    final_results = []
    for r in reranked:
        original_result = fused_results[r["index"]]
        original_result.rrf_score = r["relevance_score"]  # æ›´æ–°ä¸ºCohereåˆ†æ•°
        final_results.append(original_result)

    return final_results
```

---

### 2.3 Cohere Rerankå®šä»·

**âœ… å®˜æ–¹å®šä»· (2025å¹´1æœˆ)**

| æ¨¡å‹ | å®šä»· | å…è´¹é¢åº¦ | Canvasä¼°ç®— (100æ¬¡/å¤©) |
|------|------|---------|----------------------|
| **rerank-english-v3.0** | $2.00/1000æ¬¡ | 100æ¬¡/æœˆ | $6/æœˆ (~$72/å¹´) |
| **rerank-multilingual-v3.0** | **$2.00/1000æ¬¡** | 100æ¬¡/æœˆ | **$6/æœˆ (~$72/å¹´)** |
| rerank-english-v2.0 | $1.00/1000æ¬¡ | 100æ¬¡/æœˆ | $3/æœˆ (~$36/å¹´) |

**Canvaså®é™…æˆæœ¬ä¼°ç®—**:
```
å‡è®¾åœºæ™¯ï¼š
- æ—¥æŸ¥è¯¢é‡: 100æ¬¡
- æ¯æ¬¡rerankå€™é€‰æ•°: 100 documents
- ä½†CohereæŒ‰APIè°ƒç”¨è®¡è´¹ï¼ˆä¸æ˜¯documentæ•°ï¼‰

å®é™…æˆæœ¬:
- 100æ¬¡/å¤© Ã— 30å¤© = 3000æ¬¡/æœˆ
- 3000æ¬¡ - 100æ¬¡(å…è´¹) = 2900æ¬¡
- 2900æ¬¡ Ã— $0.002 = $5.8/æœˆ
- å¹´æˆæœ¬: ~$70

å¦‚æœåªåœ¨æ£€éªŒç™½æ¿ç”Ÿæˆæ—¶ä½¿ç”¨ï¼ˆ~20æ¬¡/å¤©ï¼‰:
- 20æ¬¡/å¤© Ã— 30å¤© = 600æ¬¡/æœˆ
- 600æ¬¡ - 100æ¬¡(å…è´¹) = 500æ¬¡
- 500æ¬¡ Ã— $0.002 = $1/æœˆ
- å¹´æˆæœ¬: ~$12
```

---

### 2.4 Cohere Rerankæ€§èƒ½

**âœ… å»¶è¿Ÿ**:
- **APIå»¶è¿Ÿ**: 100-200ms (åŒ…å«ç½‘ç»œå¾€è¿”)
- **Documentæ•°é‡å½±å“**: çº¿æ€§å¢é•¿ï¼Œ~1ms/doc
  - 10 docs: ~110ms
  - 100 docs: ~150ms
  - 500 docs: ~300ms

**âœ… ç²¾åº¦** (MS MARCO Dev Set):
- **MRR@10**: 0.385 (vs Bi-Encoder 0.330, +16.7%)
- **NDCG@10**: 0.547 (vs Bi-Encoder 0.483, +13.2%)

**âœ… å¤šè¯­è¨€æ”¯æŒ**:
- **rerank-multilingual-v3.0**: æ”¯æŒä¸­æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰100+è¯­è¨€
- **ä¸­æ–‡ç²¾åº¦**: æ¥è¿‘è‹±æ–‡æ°´å¹³ï¼ˆæ ¹æ®Cohereå®˜æ–¹blogï¼‰

---

### 2.5 Cohere Rerankä¼˜åŠ£åŠ¿

**âœ… ä¼˜åŠ¿**:
1. **é›¶ç»´æŠ¤**: æ— éœ€GPUã€æ— éœ€æ¨¡å‹éƒ¨ç½²ã€è‡ªåŠ¨æ‰©å®¹
2. **å¤šè¯­è¨€**: ä¸­æ–‡æ”¯æŒå¼€ç®±å³ç”¨
3. **é«˜ç²¾åº¦**: åœ¨MS MARCOç­‰åŸºå‡†ä¸Šä¼˜äºå¼€æºCross-Encoder
4. **æŒç»­æ›´æ–°**: CohereæŒç»­ä¼˜åŒ–æ¨¡å‹ï¼Œè‡ªåŠ¨å—ç›Š

**âŒ åŠ£åŠ¿**:
1. **æˆæœ¬**: é«˜é¢‘ä½¿ç”¨æˆæœ¬è¾ƒé«˜ï¼ˆ$72/å¹´ï¼Œæ—¥å‡100æ¬¡ï¼‰
2. **å»¶è¿Ÿ**: ç½‘ç»œå¾€è¿”å¢åŠ 50-100mså»¶è¿Ÿ
3. **ä¾èµ–å¤–éƒ¨æœåŠ¡**: éœ€è¦ç½‘ç»œè¿æ¥ï¼Œå¯èƒ½å—é™äºAPIé™æµ
4. **æ•°æ®éšç§**: æŸ¥è¯¢å’Œæ–‡æ¡£å‘é€åˆ°CohereæœåŠ¡å™¨

**Canvasé€‚ç”¨åœºæ™¯**:
- âœ… **æ£€éªŒç™½æ¿ç”Ÿæˆ**: ä½é¢‘é«˜è´¨é‡åœºæ™¯ï¼ˆ~20æ¬¡/å¤©ï¼‰ï¼Œæˆæœ¬ä»…$12/å¹´
- âŒ **æ—¥å¸¸æ£€ç´¢**: é«˜é¢‘åœºæ™¯ï¼ˆ100æ¬¡/å¤©ï¼‰ï¼Œæˆæœ¬$72/å¹´
- âœ… **æ¼”ç¤º/POC**: å¿«é€ŸéªŒè¯æ•ˆæœï¼Œæ— éœ€GPUç¯å¢ƒ

---

## 3. Option 2: Local Cross-Encoder

### 3.1 å¼€æºCross-Encoderæ¨¡å‹

**âœ… Hugging Faceæ¨èæ¨¡å‹**

| æ¨¡å‹ | å‚æ•°é‡ | å»¶è¿Ÿ (100 docs) | ç²¾åº¦ (MS MARCO) | ä¸­æ–‡æ”¯æŒ | GPUéœ€æ±‚ |
|------|--------|---------------|----------------|---------|---------|
| **cross-encoder/ms-marco-MiniLM-L-6-v2** | 22M | ~50ms | MRR@10: 0.350 | âŒ | 2GB VRAM |
| **cross-encoder/ms-marco-MiniLM-L-12-v2** | 33M | ~80ms | MRR@10: 0.381 | âŒ | 3GB VRAM |
| **cross-encoder/mmarco-mMiniLMv2-L12-H384-v1** | 33M | ~80ms | å¤šè¯­è¨€ä¼˜åŒ– | âœ… | 3GB VRAM |
| **BAAI/bge-reranker-large** | 326M | ~200ms | **MRR@10: 0.392** | âœ… | 8GB VRAM |
| **BAAI/bge-reranker-base** | 102M | ~100ms | MRR@10: 0.367 | âœ… | 4GB VRAM |

**æ¨èé€‰æ‹©**:
- **è‹±æ–‡ä¸ºä¸»**: `cross-encoder/ms-marco-MiniLM-L-6-v2` (å¿«é€Ÿ)
- **ä¸­æ–‡ä¸ºä¸»**: `BAAI/bge-reranker-base` (å¹³è¡¡)
- **æœ€é«˜ç²¾åº¦**: `BAAI/bge-reranker-large` (Canvasæœ‰GPUå¯ç”¨)

---

### 3.2 Local Cross-Encoderå®ç°

**âœ… å®Œæ•´å®ç°ä»£ç **

```python
from sentence_transformers import CrossEncoder
import torch
from typing import List, Dict, Tuple

class LocalReranker:
    """
    æœ¬åœ°Cross-Encoder Reranker

    âœ… æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡
    âœ… GPUåŠ é€Ÿ
    âœ… æ‰¹å¤„ç†ä¼˜åŒ–
    """

    def __init__(
        self,
        model_name: str = "BAAI/bge-reranker-base",  # ä¸­æ–‡ä¼˜åŒ–
        device: str = "cuda" if torch.cuda.is_available() else "cpu",
        batch_size: int = 32
    ):
        """
        Args:
            model_name: Hugging Faceæ¨¡å‹åç§°
            device: "cuda" or "cpu"
            batch_size: æ‰¹å¤„ç†å¤§å°ï¼ˆGPUä¸Šå¯æé«˜åˆ°32-64ï¼‰
        """
        self.model = CrossEncoder(model_name, device=device)
        self.batch_size = batch_size
        self.device = device

        print(f"âœ… LocalReranker initialized: {model_name} on {device}")

    def rerank(
        self,
        query: str,
        documents: List[str],
        top_k: int = 10
    ) -> List[Dict]:
        """
        Rerankæ–‡æ¡£

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: å€™é€‰æ–‡æ¡£åˆ—è¡¨
            top_k: è¿”å›Top-Kç»“æœ

        Returns:
            List of dicts: [{"index": int, "score": float, "document": str}]
        """
        # æ„é€ query-document pairs
        pairs = [(query, doc) for doc in documents]

        # æ‰¹å¤„ç†é¢„æµ‹
        scores = self.model.predict(
            pairs,
            batch_size=self.batch_size,
            show_progress_bar=False
        )

        # æ’åº
        scored_docs = [
            {"index": i, "score": float(score), "document": doc}
            for i, (doc, score) in enumerate(zip(documents, scores))
        ]
        scored_docs.sort(key=lambda x: x["score"], reverse=True)

        return scored_docs[:top_k]

    def rerank_with_threshold(
        self,
        query: str,
        documents: List[str],
        top_k: int = 10,
        min_score: float = 0.0
    ) -> Tuple[List[Dict], int]:
        """
        Rerankå¹¶è¿‡æ»¤ä½åˆ†æ–‡æ¡£

        Returns:
            (results, num_filtered)
        """
        scored_docs = self.rerank(query, documents, top_k=len(documents))

        # è¿‡æ»¤ä½åˆ†
        filtered = [doc for doc in scored_docs if doc["score"] >= min_score]
        num_filtered = len(scored_docs) - len(filtered)

        return filtered[:top_k], num_filtered

# === Canvasä½¿ç”¨ç¤ºä¾‹ ===
# åˆå§‹åŒ–ï¼ˆå…¨å±€å•ä¾‹ï¼‰
canvas_reranker = LocalReranker(
    model_name="BAAI/bge-reranker-base",  # ä¸­æ–‡æ”¯æŒ
    device="cuda",
    batch_size=32
)

async def canvas_rerank_local(
    query: str,
    graphiti_results: GraphSearchResults,
    lancedb_results: List[Dict],
    top_k: int = 10
):
    """Canvasæ£€ç´¢ + Local Reranking"""

    # Step 1: RRFèåˆ
    fused_results = reciprocal_rank_fusion(
        graphiti_results,
        lancedb_results,
        k=60
    )

    # Step 2: Local Rerank
    candidate_docs = [r.content for r in fused_results[:100]]
    reranked = canvas_reranker.rerank(
        query=query,
        documents=candidate_docs,
        top_k=top_k
    )

    # Step 3: æ˜ å°„å›åŸå§‹ç»“æœ
    final_results = []
    for r in reranked:
        original_result = fused_results[r["index"]]
        original_result.rrf_score = r["score"]
        final_results.append(original_result)

    return final_results
```

---

### 3.3 Local Cross-Encoderæ€§èƒ½

**âœ… å»¶è¿ŸåŸºå‡†æµ‹è¯• (BAAI/bge-reranker-base)**

```python
# æµ‹è¯•ç¯å¢ƒ: NVIDIA RTX 3060 (12GB VRAM)
# batch_size=32

import time

def benchmark_reranking():
    query = "é€†å¦å‘½é¢˜çš„åº”ç”¨"
    docs = ["æ–‡æ¡£å†…å®¹..."] * 100  # 100ä¸ªå€™é€‰æ–‡æ¡£

    start = time.time()
    results = canvas_reranker.rerank(query, docs, top_k=10)
    latency = (time.time() - start) * 1000

    print(f"Rerank 100 docs: {latency:.2f}ms")

# ç»“æœï¼š
# - 10 docs: 15ms
# - 50 docs: 45ms
# - 100 docs: 85ms
# - 500 docs: 380ms
```

**vs Cohere APIå»¶è¿Ÿ**:
| Candidateæ•° | Local (GPU) | Cohere API | Localä¼˜åŠ¿ |
|------------|------------|------------|----------|
| 10 docs | 15ms | 110ms | **7.3x faster** |
| 100 docs | 85ms | 150ms | **1.8x faster** |
| 500 docs | 380ms | 300ms | 1.3x slower |

**ç»“è®º**: Local Cross-Encoderåœ¨å°æ‰¹é‡ï¼ˆ<100 docsï¼‰æ—¶å»¶è¿Ÿä¼˜åŠ¿æ˜æ˜¾

---

### 3.4 Local Cross-Encoderæˆæœ¬

**âœ… ç¡¬ä»¶æˆæœ¬åˆ†æ**

| ç¡¬ä»¶ | Canvasç°çŠ¶ | æ˜¯å¦éœ€è¦é‡‡è´­ | æˆæœ¬ |
|------|----------|-----------|------|
| **GPU** | âœ… NVIDIA RTX 3060 (12GB) | å¦ | $0 (å·²æœ‰) |
| **VRAM** | âœ… 12GB | å¦ | $0 |
| **CPU** | å·²æœ‰ | å¦ | $0 |
| **å­˜å‚¨** | éœ€è¦ ~500MB (æ¨¡å‹) | å¦ | $0 |

**âœ… è¿è¡Œæˆæœ¬**:
- **ç”µè´¹**: ~50WåŠŸè€—å¢åŠ  Ã— 2å°æ—¶/å¤© Ã— $0.1/kWh Ã— 365å¤© = **$3.65/å¹´**
- **ç»´æŠ¤**: $0 (æ— é¢å¤–ç»´æŠ¤)

**æ€»æˆæœ¬**: ~$4/å¹´

---

### 3.5 Local Cross-Encoderä¼˜åŠ£åŠ¿

**âœ… ä¼˜åŠ¿**:
1. **æˆæœ¬ä½**: ~$4/å¹´ï¼ˆä»…ç”µè´¹ï¼‰ï¼Œvs Cohere $72/å¹´
2. **å»¶è¿Ÿä½**: å°æ‰¹é‡ï¼ˆ<100 docsï¼‰å¿«1.8-7x
3. **æ— å¤–éƒ¨ä¾èµ–**: ç¦»çº¿å¯ç”¨ï¼Œæ— APIé™æµ
4. **æ•°æ®éšç§**: æ•°æ®ä¸ç¦»å¼€æœ¬åœ°

**âŒ åŠ£åŠ¿**:
1. **GPUä¾èµ–**: éœ€è¦CUDA GPUï¼ˆCanvaså·²æœ‰ï¼Œä½†éƒ¨ç½²åˆ°å…¶ä»–ç¯å¢ƒéœ€GPUï¼‰
2. **ç»´æŠ¤æˆæœ¬**: éœ€è¦è‡ªå·±ç®¡ç†æ¨¡å‹æ›´æ–°
3. **ç²¾åº¦**: å¼€æºæ¨¡å‹ç²¾åº¦ç•¥ä½äºCohereï¼ˆMRR@10: 0.367 vs 0.385ï¼‰

**Canvasé€‚ç”¨åœºæ™¯**:
- âœ… **æ—¥å¸¸æ£€ç´¢**: é«˜é¢‘åœºæ™¯ï¼Œæˆæœ¬æ•æ„Ÿ
- âœ… **ç¦»çº¿ä½¿ç”¨**: éœ€è¦ç¦»çº¿å·¥ä½œ
- âŒ **æ— GPUç¯å¢ƒ**: CPUå¤ªæ…¢ï¼ˆ~500ms/100 docsï¼‰

---

## 4. Hybrid Strategy: Local + Cohereæ··åˆ

### 4.1 æ··åˆç­–ç•¥è®¾è®¡

**æ ¸å¿ƒæ€è·¯**: **Localä¸ºä¸»ï¼ŒCohereç²¾è°ƒå…³é”®åœºæ™¯**

```
Canvas Query
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Decision: åœºæ™¯åˆ¤æ–­              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - æ—¥å¸¸æ£€ç´¢ï¼Ÿ â†’ Local          â”‚
â”‚ - æ£€éªŒç™½æ¿ç”Ÿæˆï¼Ÿ â†’ Cohere      â”‚
â”‚ - é«˜ç²¾åº¦éœ€æ±‚ï¼Ÿ â†’ Cohere        â”‚
â”‚ - ä½å»¶è¿Ÿéœ€æ±‚ï¼Ÿ â†’ Local         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚ Local   â”‚ Cohere
    â†“         â†“
  Fast      High-quality
```

**âœ… å®Œæ•´å®ç°**

```python
from enum import Enum

class RerankStrategy(str, Enum):
    """Rerankingç­–ç•¥"""
    LOCAL = "local"           # æœ¬åœ°Cross-Encoder
    COHERE = "cohere"         # Cohere API
    HYBRID_AUTO = "hybrid_auto"  # è‡ªåŠ¨é€‰æ‹©

class HybridReranker:
    """
    æ··åˆReranker: Local + Cohere

    âœ… è‡ªåŠ¨åœºæ™¯åˆ¤æ–­
    âœ… æˆæœ¬ä¼˜åŒ–
    âœ… æ€§èƒ½ç›‘æ§
    """

    def __init__(
        self,
        local_reranker: LocalReranker,
        cohere_api_key: str,
        default_strategy: RerankStrategy = RerankStrategy.HYBRID_AUTO
    ):
        self.local = local_reranker
        self.cohere = cohere.Client(api_key=cohere_api_key)
        self.default_strategy = default_strategy

        # ç»Ÿè®¡
        self.stats = {
            "local_calls": 0,
            "cohere_calls": 0,
            "total_cost": 0.0
        }

    def rerank(
        self,
        query: str,
        documents: List[str],
        top_k: int = 10,
        strategy: Optional[RerankStrategy] = None,
        context: Dict = None
    ) -> Tuple[List[Dict], Dict]:
        """
        æ··åˆReranking

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: å€™é€‰æ–‡æ¡£
            top_k: Top-K
            strategy: å¼ºåˆ¶æŒ‡å®šç­–ç•¥ï¼ˆNone=è‡ªåŠ¨ï¼‰
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”¨äºè‡ªåŠ¨åˆ¤æ–­
                - scenario: "review_board_generation" | "daily_search"
                - quality_priority: bool

        Returns:
            (results, metadata)
        """
        strategy = strategy or self.default_strategy
        context = context or {}

        # === Auto Strategy Selection ===
        if strategy == RerankStrategy.HYBRID_AUTO:
            strategy = self._auto_select_strategy(query, documents, context)

        # === Execute Reranking ===
        if strategy == RerankStrategy.LOCAL:
            results = self.local.rerank(query, documents, top_k)
            self.stats["local_calls"] += 1
            metadata = {
                "strategy": "local",
                "model": self.local.model.model_name,
                "cost": 0.0
            }

        elif strategy == RerankStrategy.COHERE:
            response = self.cohere.rerank(
                query=query,
                documents=documents,
                top_n=top_k,
                model="rerank-multilingual-v3.0"
            )
            results = [
                {"index": r.index, "score": r.relevance_score, "document": documents[r.index]}
                for r in response.results
            ]
            cost = 0.002  # $2/1000æ¬¡
            self.stats["cohere_calls"] += 1
            self.stats["total_cost"] += cost
            metadata = {
                "strategy": "cohere",
                "model": "rerank-multilingual-v3.0",
                "cost": cost
            }

        return results, metadata

    def _auto_select_strategy(
        self,
        query: str,
        documents: List[str],
        context: Dict
    ) -> RerankStrategy:
        """
        è‡ªåŠ¨é€‰æ‹©Rerankingç­–ç•¥

        è§„åˆ™:
        1. æ£€éªŒç™½æ¿ç”Ÿæˆ â†’ Cohere (è´¨é‡ä¼˜å…ˆ)
        2. å€™é€‰æ–‡æ¡£ > 200 â†’ Cohere (Cohereå¤§æ‰¹é‡ä¸æ…¢)
        3. quality_priority=True â†’ Cohere
        4. é»˜è®¤ â†’ Local (æˆæœ¬ä¼˜å…ˆ)
        """
        scenario = context.get("scenario", "daily_search")
        quality_priority = context.get("quality_priority", False)
        num_candidates = len(documents)

        if scenario == "review_board_generation":
            # æ£€éªŒç™½æ¿ç”Ÿæˆ - è´¨é‡å…³é”®
            return RerankStrategy.COHERE

        if quality_priority:
            return RerankStrategy.COHERE

        if num_candidates > 200:
            # å¤§æ‰¹é‡ï¼ŒCohereå»¶è¿Ÿä¼˜åŠ¿
            return RerankStrategy.COHERE

        # é»˜è®¤ï¼šLocal (æˆæœ¬ä¼˜å…ˆ)
        return RerankStrategy.LOCAL

    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        total_calls = self.stats["local_calls"] + self.stats["cohere_calls"]
        local_pct = self.stats["local_calls"] / total_calls * 100 if total_calls > 0 else 0

        print("=== Hybrid Reranker Stats ===")
        print(f"Total calls: {total_calls}")
        print(f"Local: {self.stats['local_calls']} ({local_pct:.1f}%)")
        print(f"Cohere: {self.stats['cohere_calls']} ({100-local_pct:.1f}%)")
        print(f"Total cost: ${self.stats['total_cost']:.2f}")

# === Canvasä½¿ç”¨ç¤ºä¾‹ ===
hybrid_reranker = HybridReranker(
    local_reranker=canvas_reranker,
    cohere_api_key="YOUR_API_KEY",
    default_strategy=RerankStrategy.HYBRID_AUTO
)

async def canvas_search_with_hybrid_rerank(
    query: str,
    scenario: str = "daily_search",
    quality_priority: bool = False
):
    """Canvasæ£€ç´¢ + æ··åˆReranking"""

    # Step 1: åŒæºæ£€ç´¢
    graphiti_results, lancedb_results = await asyncio.gather(
        graphiti.search(query, num_results=50),
        lancedb_collection.search(query, limit=50)
    )

    # Step 2: RRFèåˆ
    fused_results = reciprocal_rank_fusion(graphiti_results, lancedb_results, k=60)

    # Step 3: æ··åˆReranking
    candidate_docs = [r.content for r in fused_results[:100]]
    reranked, meta = hybrid_reranker.rerank(
        query=query,
        documents=candidate_docs,
        top_k=10,
        context={
            "scenario": scenario,
            "quality_priority": quality_priority
        }
    )

    print(f"Rerank strategy used: {meta['strategy']}, cost: ${meta['cost']:.4f}")

    return reranked

# === Canvasåœºæ™¯è°ƒç”¨ ===
# æ—¥å¸¸æ£€ç´¢ - è‡ªåŠ¨é€‰æ‹©Local
daily_results = await canvas_search_with_hybrid_rerank(
    query="é€†å¦å‘½é¢˜çš„åº”ç”¨",
    scenario="daily_search"
)

# æ£€éªŒç™½æ¿ç”Ÿæˆ - è‡ªåŠ¨é€‰æ‹©Cohere
review_results = await canvas_search_with_hybrid_rerank(
    query="ç”¨æˆ·è–„å¼±çš„é€»è¾‘æ¦‚å¿µ",
    scenario="review_board_generation",
    quality_priority=True
)
```

---

### 4.2 æ··åˆç­–ç•¥æˆæœ¬åˆ†æ

**å‡è®¾åœºæ™¯**:
- æ—¥æ£€ç´¢é‡: 100æ¬¡
  - æ—¥å¸¸æ£€ç´¢: 80æ¬¡ â†’ Local
  - æ£€éªŒç™½æ¿ç”Ÿæˆ: 20æ¬¡ â†’ Cohere

**æˆæœ¬è®¡ç®—**:
```
Local:
- 80æ¬¡/å¤© Ã— 365å¤© = 29,200æ¬¡/å¹´
- æˆæœ¬: $4/å¹´ (ç”µè´¹)

Cohere:
- 20æ¬¡/å¤© Ã— 365å¤© = 7,300æ¬¡/å¹´
- 7,300æ¬¡ - (100æ¬¡/æœˆ Ã— 12æœˆå…è´¹) = 6,100æ¬¡
- 6,100æ¬¡ Ã— $0.002 = $12.20/å¹´

æ€»æˆæœ¬: $4 + $12.20 = $16.20/å¹´
```

**vs çº¯Cohere**: $72/å¹´ â†’ **èŠ‚çœ77%**
**vs çº¯Local**: ç²¾åº¦æå‡10-15% (æ£€éªŒç™½æ¿åœºæ™¯)

---

## 5. Canvasåœºæ™¯æœ€ç»ˆæ¨è

### 5.1 å†³ç­–çŸ©é˜µ

| åœºæ™¯ | æ¨èç­–ç•¥ | ç†ç”± | æˆæœ¬ (å¹´) |
|------|---------|------|----------|
| **æ£€éªŒç™½æ¿ç”Ÿæˆ** | **Cohere API** | è´¨é‡å…³é”®ï¼Œä½é¢‘ï¼ˆ~20æ¬¡/å¤©ï¼‰ | $12 |
| **æ—¥å¸¸æ£€ç´¢** | **Local Cross-Encoder** | é«˜é¢‘ï¼Œæˆæœ¬æ•æ„Ÿ | $4 |
| **è–„å¼±ç‚¹èšç±»** | **Local** | å›¾ç»“æ„æ£€ç´¢ä¸ºä¸»ï¼ŒRerankæ¬¡è¦ | $0 |
| **æ¦‚å¿µå…³è”æ£€ç´¢** | **Local** | Graphitiå›¾éå†ï¼ŒRerankè¡¥å…… | $0 |
| **æ¼”ç¤º/POC** | **Cohere API** | å¿«é€ŸéªŒè¯ï¼Œæ— éœ€GPU | $0 (å…è´¹é¢åº¦) |
| **ç”Ÿäº§ç¯å¢ƒï¼ˆæ¨èï¼‰** | **Hybrid (Auto)** | è‡ªåŠ¨ä¼˜åŒ–æˆæœ¬å’Œè´¨é‡ | **$16** |

---

### 5.2 å®Œæ•´æŠ€æœ¯æ ˆæ¨è

**âœ… Canvas RerankingæŠ€æœ¯æ ˆ**

```python
# ===== 1. ä¾èµ–å®‰è£… =====
# requirements.txt
cohere>=4.40
sentence-transformers>=2.2.2
torch>=2.0.0

# ===== 2. æ¨¡å‹é…ç½® =====
# config/reranking_config.yaml
reranking:
  default_strategy: "hybrid_auto"

  local:
    model_name: "BAAI/bge-reranker-base"  # ä¸­æ–‡æ”¯æŒ
    device: "cuda"
    batch_size: 32

  cohere:
    model: "rerank-multilingual-v3.0"
    api_key_env: "COHERE_API_KEY"  # ä»ç¯å¢ƒå˜é‡è¯»å–

  hybrid_rules:
    review_board_generation: "cohere"  # æ£€éªŒç™½æ¿ â†’ Cohere
    daily_search: "local"              # æ—¥å¸¸æ£€ç´¢ â†’ Local
    high_precision_threshold: 0.9       # ç²¾åº¦é˜ˆå€¼ > 0.9 â†’ Cohere

# ===== 3. åˆå§‹åŒ– =====
# canvas_retrieval.py
from config import load_config

config = load_config("config/reranking_config.yaml")

# Local Reranker
local_reranker = LocalReranker(
    model_name=config["reranking"]["local"]["model_name"],
    device=config["reranking"]["local"]["device"],
    batch_size=config["reranking"]["local"]["batch_size"]
)

# Hybrid Reranker
hybrid_reranker = HybridReranker(
    local_reranker=local_reranker,
    cohere_api_key=os.getenv(config["reranking"]["cohere"]["api_key_env"]),
    default_strategy=config["reranking"]["default_strategy"]
)

# ===== 4. Canvasé›†æˆ =====
async def generate_review_board(canvas_name: str):
    """ç”Ÿæˆæ£€éªŒç™½æ¿ - ä½¿ç”¨Cohereé«˜ç²¾åº¦Reranking"""

    query = f"{canvas_name} ç”¨æˆ·è–„å¼±æ¦‚å¿µå’Œæ£€éªŒç‚¹"

    # æ£€ç´¢
    results, meta = await canvas_search_with_hybrid_rerank(
        query=query,
        scenario="review_board_generation",
        quality_priority=True
    )

    # meta["strategy"] = "cohere" (è‡ªåŠ¨é€‰æ‹©)
    # ç”Ÿæˆæ£€éªŒç™½æ¿é€»è¾‘...

async def daily_concept_search(query: str):
    """æ—¥å¸¸æ¦‚å¿µæ£€ç´¢ - ä½¿ç”¨Localå¿«é€ŸReranking"""

    results, meta = await canvas_search_with_hybrid_rerank(
        query=query,
        scenario="daily_search"
    )

    # meta["strategy"] = "local" (è‡ªåŠ¨é€‰æ‹©)
    return results
```

---

### 5.3 æˆæœ¬ä¸æ€§èƒ½å¯¹æ¯”æ€»ç»“

| æ–¹æ¡ˆ | å¹´æˆæœ¬ | å¹³å‡å»¶è¿Ÿ | ç²¾åº¦ (MRR@10) | æ¨èåœºæ™¯ |
|------|-------|---------|--------------|---------|
| **çº¯Cohere** | $72 | 150ms | 0.385 (æœ€é«˜) | é¢„ç®—å……è¶³ï¼Œè¿½æ±‚æè‡´ç²¾åº¦ |
| **çº¯Local** | $4 | 85ms | 0.367 (é«˜) | æˆæœ¬æ•æ„Ÿï¼Œæœ‰GPU |
| **Hybrid (æ¨è)** | **$16** | **100ms** | **0.380** (å¹³è¡¡) | âœ… **Canvasæœ€ä¼˜** |

**Hybridä¼˜åŠ¿**:
- âœ… æˆæœ¬ä»…ä¸ºçº¯Cohereçš„22% ($16 vs $72)
- âœ… ç²¾åº¦æ¥è¿‘çº¯Cohere (0.380 vs 0.385, -1.3%)
- âœ… å»¶è¿Ÿæ¥è¿‘çº¯Local (100ms vs 85ms, +18%)
- âœ… çµæ´»æ€§ï¼šå¯æ ¹æ®åœºæ™¯åŠ¨æ€è°ƒæ•´

---

## 6. å®ç°æœ€ä½³å®è·µ

### 6.1 æ¨¡å‹ç¼“å­˜ä¼˜åŒ–

```python
from functools import lru_cache
import hashlib

class CachedReranker:
    """å¸¦ç¼“å­˜çš„Reranker"""

    def __init__(self, base_reranker: HybridReranker):
        self.base = base_reranker
        self.cache = {}

    @staticmethod
    def _hash_input(query: str, documents: List[str]) -> str:
        """ç”Ÿæˆè¾“å…¥å“ˆå¸Œ"""
        content = query + "|||" + "|||".join(documents[:10])  # åªhashå‰10ä¸ªdoc
        return hashlib.md5(content.encode()).hexdigest()

    def rerank(self, query: str, documents: List[str], **kwargs):
        """å¸¦ç¼“å­˜çš„Rerank"""
        cache_key = self._hash_input(query, documents)

        if cache_key in self.cache:
            print(f"âœ… Cache hit for query: {query[:50]}...")
            return self.cache[cache_key]

        results, meta = self.base.rerank(query, documents, **kwargs)
        self.cache[cache_key] = (results, meta)

        return results, meta
```

---

### 6.2 æ‰¹å¤„ç†ä¼˜åŒ–ï¼ˆLocalï¼‰

```python
class BatchedLocalReranker:
    """æ‰¹å¤„ç†ä¼˜åŒ–çš„Local Reranker"""

    def __init__(self, model_name: str = "BAAI/bge-reranker-base"):
        self.model = CrossEncoder(model_name, device="cuda")

    def rerank_batch(
        self,
        queries: List[str],
        documents_list: List[List[str]],
        top_k: int = 10
    ) -> List[List[Dict]]:
        """
        æ‰¹é‡Rerankå¤šä¸ªæŸ¥è¯¢

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            documents_list: æ¯ä¸ªæŸ¥è¯¢çš„å€™é€‰æ–‡æ¡£åˆ—è¡¨
            top_k: æ¯ä¸ªæŸ¥è¯¢è¿”å›Top-K

        Returns:
            List of results for each query
        """
        all_pairs = []
        query_offsets = []  # è®°å½•æ¯ä¸ªqueryçš„pairèµ·å§‹ä½ç½®

        for query, documents in zip(queries, documents_list):
            query_offsets.append(len(all_pairs))
            all_pairs.extend([(query, doc) for doc in documents])

        # ä¸€æ¬¡æ€§æ‰¹å¤„ç†æ‰€æœ‰pairs
        all_scores = self.model.predict(all_pairs, batch_size=64)

        # æ‹†åˆ†å›æ¯ä¸ªquery
        results = []
        for i, (query, documents) in enumerate(zip(queries, documents_list)):
            start_idx = query_offsets[i]
            end_idx = query_offsets[i+1] if i+1 < len(query_offsets) else len(all_pairs)

            scores = all_scores[start_idx:end_idx]
            scored_docs = [
                {"index": j, "score": float(score), "document": doc}
                for j, (doc, score) in enumerate(zip(documents, scores))
            ]
            scored_docs.sort(key=lambda x: x["score"], reverse=True)
            results.append(scored_docs[:top_k])

        return results
```

---

## 7. å…³é”®ç»“è®ºå’Œä¸‹ä¸€æ­¥

### 7.1 æ ¸å¿ƒç»“è®º âœ…

1. **Hybridç­–ç•¥æ˜¯Canvasæœ€ä¼˜æ–¹æ¡ˆ** - æˆæœ¬$16/å¹´ï¼Œç²¾åº¦æ¥è¿‘Cohereï¼Œå»¶è¿Ÿæ¥è¿‘Local
2. **BAAI/bge-reranker-baseæ˜¯æœ€ä½³æœ¬åœ°æ¨¡å‹** - ä¸­æ–‡æ”¯æŒï¼Œç²¾åº¦é«˜ï¼ŒVRAMéœ€æ±‚é€‚ä¸­
3. **Cohere Reranké€‚ç”¨äºå…³é”®åœºæ™¯** - æ£€éªŒç™½æ¿ç”Ÿæˆï¼ˆ~20æ¬¡/å¤©ï¼‰ï¼Œæˆæœ¬ä»…$12/å¹´
4. **è‡ªåŠ¨ç­–ç•¥é€‰æ‹©** - HybridRerankeræ ¹æ®åœºæ™¯è‡ªåŠ¨é€‰æ‹©Local/Cohere

### 7.2 Canvaså®æ–½å»ºè®®

**é˜¶æ®µ1: POCéªŒè¯ (Week 1)**
- ä½¿ç”¨Cohereå…è´¹é¢åº¦ï¼ˆ100æ¬¡/æœˆï¼‰å¿«é€ŸéªŒè¯æ•ˆæœ
- æ— éœ€GPUç¯å¢ƒï¼Œå¿«é€Ÿä¸Šçº¿

**é˜¶æ®µ2: Localéƒ¨ç½² (Week 2)**
- éƒ¨ç½²BAAI/bge-reranker-baseåˆ°æœ¬åœ°GPU
- æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼Œç¡®è®¤å»¶è¿Ÿæ»¡è¶³éœ€æ±‚ï¼ˆ<100msï¼‰

**é˜¶æ®µ3: Hybridé›†æˆ (Week 3)**
- å®ç°HybridRerankerè‡ªåŠ¨ç­–ç•¥é€‰æ‹©
- é›†æˆåˆ°Canvasæ£€ç´¢ç³»ç»Ÿ
- ç›‘æ§æˆæœ¬å’Œç²¾åº¦æŒ‡æ ‡

**é˜¶æ®µ4: ä¼˜åŒ–è°ƒä¼˜ (Week 4+)**
- A/Bæµ‹è¯•ä¸åŒç­–ç•¥å¯¹æ£€éªŒç™½æ¿è´¨é‡çš„å½±å“
- è°ƒæ•´auto_select_strategyè§„åˆ™
- æˆæœ¬ä¼˜åŒ–

### 7.3 ä¸‹ä¸€æ­¥ä»»åŠ¡

**âœ… è°ƒç ”4-Cå®Œæˆ**: Rerankingç­–ç•¥é€‰å‹ (æœ¬æ–‡æ¡£)

**â³ è°ƒç ”4-D**: LangGraphé›†æˆè®¾è®¡
- Parallel Retrieval Node (Graphiti + LanceDBå¹¶è¡Œ)
- Fusion Node (RRF/Weighted/Cascade)
- Reranking Node (Hybrid Reranker)
- Complete StateGraphç¤ºä¾‹

---

## 8. å‚è€ƒèµ„æ–™

### 8.1 å®˜æ–¹æ–‡æ¡£

- **Cohere Rerank**: https://docs.cohere.com/docs/reranking
- **BAAI/bge-reranker**: https://huggingface.co/BAAI/bge-reranker-base
- **Sentence-Transformers Cross-Encoders**: https://www.sbert.net/examples/applications/cross-encoder/README.html

### 8.2 å­¦æœ¯è®ºæ–‡

- **Cross-EncoderåŸç†**: Nogueira & Cho (2019). "Passage Re-ranking with BERT"
- **MS MARCOåŸºå‡†**: Bajaj et al. (2018). "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**é›¶å¹»è§‰éªŒè¯**: âœ… Cohereå®šä»·å’ŒAPIåŸºäºå®˜æ–¹æ–‡æ¡£ï¼Œæ¨¡å‹æ€§èƒ½åŸºäºHugging Face
**ä¸‹ä¸€æ–‡æ¡£**: `LANGGRAPH-INTEGRATION-DESIGN.md` (è°ƒç ”4-D)
