# GRAPHITI-KNOWLEDGE-GRAPH-INTEGRATION-ARCHITECTURE - Part 1

**Source**: `GRAPHITI-KNOWLEDGE-GRAPH-INTEGRATION-ARCHITECTURE.md`
**Sections**: ğŸ“‹ æ¦‚è¿°, ğŸ—ï¸ 1. çŸ¥è¯†å›¾è°±æ•°æ®æ¨¡å‹è®¾è®¡, ğŸ›ï¸ 2. Graphitié›†æˆæ¶æ„, ğŸ’¾ 3. è®°å¿†åŠŸèƒ½æ¶æ„è®¾è®¡

---

---
document_type: "Architecture"
version: "1.1.0"
last_modified: "2025-11-19"
status: "approved"
iteration: 1

authors:
  - name: "Architect Agent"
    role: "Solution Architect"

reviewers:
  - name: "PO Agent"
    role: "Product Owner"
    approved: true

compatible_with:
  prd: "v1.0"
  api_spec: "v1.0"

api_spec_hash: "0dc1d3610d28bf99"

changes_from_previous:
  - "Initial Architecture with frontmatter metadata"

git:
  commit_sha: ""
  tag: ""

metadata:
  components_count: 0
  external_services: []
  technology_stack:
    frontend: []
    backend: ["Python 3.11", "asyncio"]
    database: []
    infrastructure: []
---

# Canvaså­¦ä¹ ç³»ç»Ÿ - GraphitiçŸ¥è¯†å›¾è°±é›†æˆæ¶æ„è®¾è®¡

**ç‰ˆæœ¬**: v1.1 (LangGraph Checkpointeré›†æˆç‰ˆ)
**åˆ›å»ºæ—¥æœŸ**: 2025-10-18
**æœ€åæ›´æ–°**: 2025-11-11 (**NEW**: Section 8.6 ä¸LangGraph Checkpointerçš„èŒè´£è¾¹ç•Œ)
**ä½œè€…**: Claude Code
**çŠ¶æ€**: æŠ€æœ¯æ–¹æ¡ˆè®¾è®¡

---


## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è®¾è®¡äº†Canvaså­¦ä¹ ç³»ç»Ÿä¸GraphitiçŸ¥è¯†å›¾è°±çš„é›†æˆæ¶æ„ï¼Œå®ç°CanvasèŠ‚ç‚¹é€»è¾‘å…³ç³»çš„æŒä¹…åŒ–è®°å¿†ã€å­¦ä¹ è¿›åº¦çš„å®æ—¶è¿½è¸ªï¼Œä»¥åŠæ™ºèƒ½æ£€éªŒç™½æ¿ç”Ÿæˆä¼˜åŒ–ã€‚

### æ ¸å¿ƒç›®æ ‡

1. **æŒä¹…åŒ–è®°å¿†**: CanvasèŠ‚ç‚¹å’Œè¾¹çš„é€»è¾‘å…³ç³»æŒä¹…åŒ–å­˜å‚¨
2. **è¿›åº¦è¿½è¸ª**: å®æ—¶è¿½è¸ªå­¦ä¹ è¿›åº¦å’ŒçŸ¥è¯†æŒæ¡çŠ¶æ€
3. **æ™ºèƒ½æ£€ç´¢**: åŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½æ£€ç´¢å’Œæ¨è
4. **æ—¶é—´æ„ŸçŸ¥**: è¿½è¸ªå­¦ä¹ è¿›å±•æ—¶é—´çº¿å’ŒçŸ¥è¯†æ¼”åŒ–
5. **æ€§èƒ½ä¼˜åŒ–**: ç¡®ä¿çŸ¥è¯†å›¾è°±æ“ä½œä¸å½±å“Canvasç³»ç»Ÿæ€§èƒ½

---


## ğŸ—ï¸ 1. çŸ¥è¯†å›¾è°±æ•°æ®æ¨¡å‹è®¾è®¡

### 1.1 å®ä½“ç±»å‹å®šä¹‰

```python
# çŸ¥è¯†å›¾è°±å®ä½“ç±»å‹æšä¸¾
class EntityType(Enum):
    CANVAS = "canvas"                    # Canvasç”»å¸ƒ
    NODE = "node"                        # CanvasèŠ‚ç‚¹
    CONCEPT = "concept"                  # çŸ¥è¯†æ¦‚å¿µ
    TOPIC = "topic"                      # çŸ¥è¯†ä¸»é¢˜
    LEARNING_SESSION = "learning_session" # å­¦ä¹ ä¼šè¯
    UNDERSTANDING_STATE = "understanding_state" # ç†è§£çŠ¶æ€
    AI_EXPLANATION = "ai_explanation"     # AIè§£é‡Šæ–‡æ¡£
    PERSONAL_UNDERSTANDING = "personal_understanding" # ä¸ªäººç†è§£
    VERIFICATION_QUESTION = "verification_question" # æ£€éªŒé—®é¢˜
    DECOMPOSITION = "decomposition"      # é—®é¢˜æ‹†è§£
```

### 1.2 å…³ç³»ç±»å‹å®šä¹‰

```python
# çŸ¥è¯†å›¾è°±å…³ç³»ç±»å‹æšä¸¾
class RelationType(Enum):
    # Canvasç»“æ„å…³ç³»
    CONTAINS = "contains"                # CanvasåŒ…å«èŠ‚ç‚¹
    CONNECTS_TO = "connects_to"         # èŠ‚ç‚¹è¿æ¥åˆ°èŠ‚ç‚¹
    DECOMPOSES_TO = "decomposes_to"      # æ‹†è§£å…³ç³»

    # çŸ¥è¯†è¯­ä¹‰å…³ç³»
    IS_ABOUT = "is_about"                # èŠ‚ç‚¹å…³äºæ¦‚å¿µ
    BELONGS_TO_TOPIC = "belongs_to_topic" # å±äºä¸»é¢˜
    PREREQUISITE_OF = "prerequisite_of"  # å‰ç½®çŸ¥è¯†
    SIMILAR_TO = "similar_to"           # ç›¸ä¼¼æ¦‚å¿µ
    CONTRASTS_WITH = "contrasts_with"   # å¯¹æ¯”æ¦‚å¿µ

    # å­¦ä¹ è¿›åº¦å…³ç³»
    HAS_UNDERSTANDING_STATE = "has_understanding_state" # å…·æœ‰ç†è§£çŠ¶æ€
    EVOLVES_TO = "evolves_to"           # çŠ¶æ€æ¼”åŒ–
    SCORED_AS = "scored_as"             # è¯„åˆ†ç»“æœ
    NEEDS_REVIEW = "needs_review"       # éœ€è¦å¤ä¹ 

    # æ—¶é—´å…³ç³»
    CREATED_IN_SESSION = "created_in_session" # åœ¨ä¼šè¯ä¸­åˆ›å»º
    UPDATED_AT_TIME = "updated_at_time" # æ›´æ–°æ—¶é—´
    REVIEWED_AT_TIME = "reviewed_at_time" # å¤ä¹ æ—¶é—´
```

### 1.3 èŠ‚ç‚¹å±æ€§æ˜ å°„

```python
# CanvasèŠ‚ç‚¹åˆ°çŸ¥è¯†å›¾è°±çš„å±æ€§æ˜ å°„
class NodeAttributes:
    """CanvasèŠ‚ç‚¹å±æ€§æ˜ å°„åˆ°çŸ¥è¯†å›¾è°±"""

    def __init__(self, canvas_node: dict):
        self.canvas_id = canvas_node.get('id')
        self.node_type = canvas_node.get('type')
        self.text = canvas_node.get('text', '')
        self.color = canvas_node.get('color')
        self.position = {
            'x': canvas_node.get('x', 0),
            'y': canvas_node.get('y', 0)
        }
        self.size = {
            'width': canvas_node.get('width', 200),
            'height': canvas_node.get('height', 100)
        }

        # å­¦ä¹ ç›¸å…³å±æ€§
        self.learning_metadata = self._extract_learning_metadata()

    def _extract_learning_metadata(self):
        """æå–å­¦ä¹ ç›¸å…³å…ƒæ•°æ®"""
        metadata = {
            'color_meaning': self._get_color_meaning(),
            'content_type': self._detect_content_type(),
            'complexity_score': self._calculate_complexity(),
            'learning_timestamp': time.time()
        }

        # å¦‚æœæ˜¯é»„è‰²èŠ‚ç‚¹ï¼Œæå–ä¸ªäººç†è§£å†…å®¹
        if self.color == "6":  # é»„è‰²èŠ‚ç‚¹
            metadata['personal_understanding'] = self.text
            metadata['understanding_length'] = len(self.text)
            metadata['understanding_quality_indicators'] = self._analyze_understanding_quality()

        return metadata

    def _get_color_meaning(self):
        """è·å–é¢œè‰²å«ä¹‰"""
        color_meanings = {
            "1": "ä¸ç†è§£/æœªé€šè¿‡",
            "2": "å®Œå…¨ç†è§£/å·²é€šè¿‡",
            "3": "ä¼¼æ‡‚éæ‡‚/å¾…æ£€éªŒ",
            "5": "AIè¡¥å……è§£é‡Š",
            "6": "ä¸ªäººç†è§£è¾“å‡ºåŒº"
        }
        return color_meanings.get(self.color, "æœªçŸ¥çŠ¶æ€")

    def _detect_content_type(self):
        """æ£€æµ‹å†…å®¹ç±»å‹"""
        text_lower = self.text.lower()
        if any(keyword in text_lower for keyword in ['ä»€ä¹ˆæ˜¯', 'å®šä¹‰', 'definition']):
            return "definition"
        elif any(keyword in text_lower for keyword in ['ä¾‹å­', 'example', 'ä¾‹å¦‚']):
            return "example"
        elif any(keyword in text_lower for keyword in ['ä¸ºä»€ä¹ˆ', 'why', 'åŸå› ']):
            return "explanation"
        elif '?' in self.text or 'å¦‚ä½•' in text_lower:
            return "question"
        else:
            return "general"

    def _calculate_complexity(self):
        """è®¡ç®—å†…å®¹å¤æ‚åº¦"""
        # åŸºäºæ–‡æœ¬é•¿åº¦ã€å…³é”®è¯å¯†åº¦ç­‰è®¡ç®—å¤æ‚åº¦
        text_length = len(self.text)
        technical_terms = count_technical_terms(self.text)
        return min(10, (text_length / 100) + (technical_terms * 2))

    def _analyze_understanding_quality(self):
        """åˆ†æä¸ªäººç†è§£è´¨é‡ï¼ˆä»…é»„è‰²èŠ‚ç‚¹ï¼‰"""
        indicators = {
            'has_examples': any(keyword in self.text.lower() for keyword in ['ä¾‹å­', 'æ¯”å¦‚', 'ä¾‹å¦‚', 'example']),
            'has_analogies': any(keyword in self.text.lower() for keyword in ['åƒ', 'å¥½æ¯”', 'ç±»ä¼¼äº', 'like']),
            'has_personal_connection': any(keyword in self.text.lower() for keyword in ['æˆ‘è§‰å¾—', 'æˆ‘è®¤ä¸º', 'æˆ‘çš„ç†è§£']),
            'structured_explanation': self._is_structured_explanation()
        }
        return indicators

    def _is_structured_explanation(self):
        """åˆ¤æ–­æ˜¯å¦ä¸ºç»“æ„åŒ–è§£é‡Š"""
        # æ£€æŸ¥æ˜¯å¦æœ‰é€»è¾‘è¿æ¥è¯ã€åˆ†ç‚¹è¯´æ˜ç­‰
        logical_connectors = ['å› ä¸º', 'æ‰€ä»¥', 'é¦–å…ˆ', 'å…¶æ¬¡', 'ç„¶å', 'æœ€å', 'ä¸€æ–¹é¢', 'å¦ä¸€æ–¹é¢']
        return any(connector in self.text for connector in logical_connectors)
```

### 1.4 çŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„æ¨¡å‹

```python
class KnowledgeGraphTriplet:
    """çŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„æ•°æ®æ¨¡å‹"""

    def __init__(self, subject: str, relation: str, object: str,
                 subject_type: str, object_type: str, metadata: dict = None):
        self.subject = subject
        self.relation = relation
        self.object = object
        self.subject_type = subject_type
        self.object_type = object_type
        self.metadata = metadata or {}
        self.timestamp = time.time()
        self.confidence = 1.0

    def to_graphiti_format(self):
        """è½¬æ¢ä¸ºGraphitiæ ¼å¼"""
        return {
            "subject": self.subject,
            "predicate": self.relation,
            "object": self.object,
            "subject_type": self.subject_type,
            "object_type": self.object_type,
            "metadata": {
                **self.metadata,
                "timestamp": self.timestamp,
                "confidence": self.confidence
            }
        }
```

---


## ğŸ›ï¸ 2. Graphitié›†æˆæ¶æ„

### 2.1 æ–°å¢Layer 4: KnowledgeGraphLayer

```python
class KnowledgeGraphLayer:
    """Layer 4: çŸ¥è¯†å›¾è°±å±‚ - Graphitié›†æˆ"""

    def __init__(self, neo4j_uri: str, neo4j_user: str, neo4j_password: str):
        self.graphiti = Graphiti(
            uri=neo4j_uri,
            user=neo4j_user,
            password=neo4j_password
        )
        self.batch_size = 50  # æ‰¹é‡æ“ä½œå¤§å°
        self.cache = {}  # æœ¬åœ°ç¼“å­˜
        self.session_id = None

    async def initialize_session(self, canvas_path: str):
        """åˆå§‹åŒ–å­¦ä¹ ä¼šè¯"""
        self.session_id = f"session_{int(time.time())}_{hash(canvas_path)}"

        # åˆ›å»ºä¼šè¯å®ä½“
        session_triplet = KnowledgeGraphTriplet(
            subject=self.session_id,
            relation=RelationType.CREATED_AT_TIME.value,
            object=str(time.time()),
            subject_type=EntityType.LEARNING_SESSION.value,
            object_type="timestamp",
            metadata={"canvas_path": canvas_path}
        )

        await self.add_triplet(session_triplet)
        return self.session_id

    async def add_triplet(self, triplet: KnowledgeGraphTriplet):
        """æ·»åŠ å•ä¸ªä¸‰å…ƒç»„"""
        try:
            await self.graphiti.add_triplet(
                subject=triplet.subject,
                predicate=triplet.relation,
                object=triplet.object,
                subject_type=triplet.subject_type,
                object_type=triplet.object_type,
                metadata=triplet.metadata
            )
        except Exception as e:
            logger.error(f"æ·»åŠ ä¸‰å…ƒç»„å¤±è´¥: {e}")
            raise

    async def add_triplets_batch(self, triplets: List[KnowledgeGraphTriplet]):
        """æ‰¹é‡æ·»åŠ ä¸‰å…ƒç»„"""
        for i in range(0, len(triplets), self.batch_size):
            batch = triplets[i:i + self.batch_size]
            tasks = [self.add_triplet(triplet) for triplet in batch]
            await asyncio.gather(*tasks, return_exceptions=True)

    async def search_knowledge(self, query: str, limit: int = 10) -> List[dict]:
        """æœç´¢çŸ¥è¯†å›¾è°±"""
        try:
            results = await self.graphiti.search(
                query=query,
                limit=limit,
                search_type="hybrid"  # æ··åˆæœç´¢ï¼šè¯­ä¹‰+BM25
            )
            return results
        except Exception as e:
            logger.error(f"çŸ¥è¯†å›¾è°±æœç´¢å¤±è´¥: {e}")
            return []

    async def get_node_evolution(self, node_id: str) -> List[dict]:
        """è·å–èŠ‚ç‚¹æ¼”åŒ–å†å²"""
        evolution_query = f"""
        MATCH (n:node {{id: "{node_id}"}})
        -[r:evolves_to]->(m:node)
        RETURN n, r, m
        ORDER BY r.timestamp
        """
        return await self.graphiti.custom_query(evolution_query)

    async def get_learning_progress(self, canvas_path: str) -> dict:
        """è·å–å­¦ä¹ è¿›åº¦ç»Ÿè®¡"""
        progress_query = f"""
        MATCH (c:canvas {{path: "{canvas_path}"}})
        -[:contains]->(n:node)
        -[:has_understanding_state]->(s:understanding_state)
        RETURN s.color_meaning as state, count(*) as count
        """
        results = await self.graphiti.custom_query(progress_query)

        # è®¡ç®—è¿›åº¦ç»Ÿè®¡
        total_nodes = sum(r['count'] for r in results)
        progress = {
            'total_nodes': total_nodes,
            'green_nodes': 0,  # å®Œå…¨ç†è§£
            'yellow_nodes': 0, # ä¸ªäººç†è§£
            'purple_nodes': 0, # ä¼¼æ‡‚éæ‡‚
            'red_nodes': 0,    # ä¸ç†è§£
            'blue_nodes': 0    # AIè§£é‡Š
        }

        for result in results:
            state = result['state']
            count = result['count']
            if 'å®Œå…¨ç†è§£' in state:
                progress['green_nodes'] = count
            elif 'ä¸ªäººç†è§£' in state:
                progress['yellow_nodes'] = count
            elif 'ä¼¼æ‡‚éæ‡‚' in state:
                progress['purple_nodes'] = count
            elif 'ä¸ç†è§£' in state:
                progress['red_nodes'] = count
            elif 'AIè§£é‡Š' in state:
                progress['blue_nodes'] = count

        # è®¡ç®—æŒæ¡ç‡
        if total_nodes > 0:
            progress['mastery_rate'] = (progress['green_nodes'] / total_nodes) * 100
        else:
            progress['mastery_rate'] = 0

        return progress
```

### 2.2 æ‰©å±•ç°æœ‰æ¶æ„

```python
# æ‰©å±• Layer 1: CanvasJSONOperator
class CanvasJSONOperatorWithKG(CanvasJSONOperator):
    """å¸¦çŸ¥è¯†å›¾è°±åŠŸèƒ½çš„Canvas JSONæ“ä½œå™¨"""

    def __init__(self, canvas_path: str, kg_layer: KnowledgeGraphLayer = None):
        super().__init__(canvas_path)
        self.kg_layer = kg_layer
        self.canvas_id = self._generate_canvas_id()

    def _generate_canvas_id(self):
        """ç”ŸæˆCanvaså”¯ä¸€ID"""
        return f"canvas_{hash(self.canvas_path)}_{int(time.time())}"

    async def sync_canvas_to_kg(self):
        """åŒæ­¥Canvasåˆ°çŸ¥è¯†å›¾è°±"""
        if not self.kg_layer:
            return

        # åˆ›å»ºCanvaså®ä½“
        canvas_triplet = KnowledgeGraphTriplet(
            subject=self.canvas_id,
            relation=RelationType.CREATED_AT_TIME.value,
            object=str(time.time()),
            subject_type=EntityType.CANVAS.value,
            object_type="timestamp",
            metadata={
                "path": self.canvas_path,
                "name": os.path.basename(self.canvas_path)
            }
        )
        await self.kg_layer.add_triplet(canvas_triplet)

        # åŒæ­¥æ‰€æœ‰èŠ‚ç‚¹
        canvas_data = self.read_canvas()
        await self._sync_nodes_to_kg(canvas_data.get('nodes', []))
        await self._sync_edges_to_kg(canvas_data.get('edges', []))

    async def _sync_nodes_to_kg(self, nodes: List[dict]):
        """åŒæ­¥èŠ‚ç‚¹åˆ°çŸ¥è¯†å›¾è°±"""
        node_triplets = []

        for node in nodes:
            node_id = f"node_{self.canvas_id}_{node['id']}"
            node_attrs = NodeAttributes(node)

            # åˆ›å»ºèŠ‚ç‚¹å®ä½“
            node_triplet = KnowledgeGraphTriplet(
                subject=node_id,
                relation=RelationType.CREATED_AT_TIME.value,
                object=str(time.time()),
                subject_type=EntityType.NODE.value,
                object_type="timestamp",
                metadata={
                    **node_attrs.__dict__,
                    "canvas_id": self.canvas_id
                }
            )
            node_triplets.append(node_triplet)

            # CanvasåŒ…å«èŠ‚ç‚¹å…³ç³»
            contains_triplet = KnowledgeGraphTriplet(
                subject=self.canvas_id,
                relation=RelationType.CONTAINS.value,
                object=node_id,
                subject_type=EntityType.CANVAS.value,
                object_type=EntityType.NODE.value
            )
            node_triplets.append(contains_triplet)

            # å¦‚æœæ˜¯é»„è‰²èŠ‚ç‚¹ï¼Œåˆ›å»ºä¸ªäººç†è§£å®ä½“
            if node['color'] == "6":
                understanding_id = f"understanding_{node_id}"
                understanding_triplet = KnowledgeGraphTriplet(
                    subject=understanding_id,
                    relation=RelationType.CREATED_AT_TIME.value,
                    object=str(time.time()),
                    subject_type=EntityType.PERAL_UNDERSTANDING.value,
                    object_type="timestamp",
                    metadata={
                        "content": node.get('text', ''),
                        "node_id": node_id,
                        "quality_indicators": node_attrs.learning_metadata.get('understanding_quality_indicators', {})
                    }
                )
                node_triplets.append(understanding_triplet)

                # èŠ‚ç‚¹å…·æœ‰ä¸ªäººç†è§£å…³ç³»
                has_understanding_triplet = KnowledgeGraphTriplet(
                    subject=node_id,
                    relation=RelationType.HAS_UNDERSTANDING_STATE.value,
                    object=understanding_id,
                    subject_type=EntityType.NODE.value,
                    object_type=EntityType.PERAL_UNDERSTANDING.value
                )
                node_triplets.append(has_understanding_triplet)

        # æ‰¹é‡æ·»åŠ ä¸‰å…ƒç»„
        await self.kg_layer.add_triplets_batch(node_triplets)

    async def _sync_edges_to_kg(self, edges: List[dict]):
        """åŒæ­¥è¾¹åˆ°çŸ¥è¯†å›¾è°±"""
        edge_triplets = []

        for edge in edges:
            from_node_id = f"node_{self.canvas_id}_{edge['fromNode']}"
            to_node_id = f"node_{self.canvas_id}_{edge['toNode']}"

            # åˆ›å»ºè¿æ¥å…³ç³»
            connect_triplet = KnowledgeGraphTriplet(
                subject=from_node_id,
                relation=RelationType.CONNECTS_TO.value,
                object=to_node_id,
                subject_type=EntityType.NODE.value,
                object_type=EntityType.NODE.value,
                metadata={
                    "fromSide": edge.get('fromSide', 'bottom'),
                    "toSide": edge.get('toSide', 'top'),
                    "canvas_id": self.canvas_id
                }
            )
            edge_triplets.append(connect_triplet)

        await self.kg_layer.add_triplets_batch(edge_triplets)
```

---


## ğŸ’¾ 3. è®°å¿†åŠŸèƒ½æ¶æ„è®¾è®¡

### 3.1 è®°å¿†ç³»ç»Ÿæ¶æ„

```python
class CanvasMemorySystem:
    """Canvasè®°å¿†ç³»ç»Ÿ - åŸºäºGraphitiçš„æŒä¹…åŒ–è®°å¿†"""

    def __init__(self, kg_layer: KnowledgeGraphLayer):
        self.kg_layer = kg_layer
        self.memory_cache = {}
        self.current_session = None

    async def start_learning_session(self, canvas_path: str):
        """å¼€å§‹å­¦ä¹ ä¼šè¯"""
        self.current_session = await self.kg_layer.initialize_session(canvas_path)

        # è®°å½•ä¼šè¯å¼€å§‹
        memory_content = {
            "session_id": self.current_session,
            "canvas_path": canvas_path,
            "start_time": time.time(),
            "action": "start_learning_session"
        }

        await self.kg_layer.add_episode(memory_content)
        return self.current_session

    async def remember_canvas_structure(self, canvas_path: str, canvas_data: dict):
        """è®°å¿†Canvasç»“æ„"""
        structure_memory = {
            "session_id": self.current_session,
            "canvas_path": canvas_path,
            "structure": {
                "nodes_count": len(canvas_data.get('nodes', [])),
                "edges_count": len(canvas_data.get('edges', [])),
                "color_distribution": self._analyze_color_distribution(canvas_data.get('nodes', [])),
                "topics": self._extract_topics(canvas_data.get('nodes', []))
            },
            "timestamp": time.time(),
            "action": "remember_structure"
        }

        await self.kg_layer.add_episode(structure_memory)

    async def remember_learning_progress(self, canvas_path: str, node_id: str,
                                       old_color: str, new_color: str, score: dict = None):
        """è®°å¿†å­¦ä¹ è¿›åº¦å˜åŒ–"""
        progress_memory = {
            "session_id": self.current_session,
            "canvas_path": canvas_path,
            "node_id": node_id,
            "progress_change": {
                "old_color": old_color,
                "new_color": new_color,
                "score": score,
                "improvement": self._calculate_improvement(old_color, new_color)
            },
            "timestamp": time.time(),
            "action": "progress_change"
        }

        await self.kg_layer.add_episode(progress_memory)

        # æ›´æ–°çŸ¥è¯†å›¾è°±ä¸­çš„èŠ‚ç‚¹çŠ¶æ€
        kg_node_id = f"node_{hash(canvas_path)}_{node_id}"
        await self._update_node_understanding_state(kg_node_id, new_color, score)

    async def remember_ai_explanation(self, canvas_path: str, concept: str,
                                    explanation_type: str, explanation_content: str):
        """è®°å¿†AIè§£é‡Š"""
        explanation_memory = {
            "session_id": self.current_session,
            "canvas_path": canvas_path,
            "explanation": {
                "concept": concept,
                "type": explanation_type,
                "content": explanation_content,
                "content_length": len(explanation_content)
            },
            "timestamp": time.time(),
            "action": "ai_explanation_generated"
        }

        await self.kg_layer.add_episode(explanation_memory)

    async def remember_verification_questions(self, canvas_path: str,
                                            node_id: str, questions: List[str]):
        """è®°å¿†æ£€éªŒé—®é¢˜"""
        questions_memory = {
            "session_id": self.current_session,
            "canvas_path": canvas_path,
            "node_id": node_id,
            "questions": questions,
            "questions_count": len(questions),
            "timestamp": time.time(),
            "action": "verification_questions_generated"
        }

        await self.kg_layer.add_episode(questions_memory)

    async def recall_canvas_history(self, canvas_path: str,
                                  time_range: tuple = None) -> List[dict]:
        """å›å¿†Canvaså†å²"""
        query = f"canvas_path:{canvas_path}"
        if time_range:
            start_time, end_time = time_range
            query += f" timestamp:[{start_time} TO {end_time}]"

        episodes = await self.kg_layer.retrieve_episodes(query)
        return episodes

    async def recall_learning_insights(self, canvas_path: str) -> dict:
        """å›å¿†å­¦ä¹ æ´å¯Ÿ"""
        # è·å–å­¦ä¹ è¿›åº¦
        progress = await self.kg_layer.get_learning_progress(canvas_path)

        # è·å–å›°éš¾èŠ‚ç‚¹
        difficult_nodes = await self._get_difficult_nodes(canvas_path)

        # è·å–å­¦ä¹ æ¨¡å¼
        learning_patterns = await self._analyze_learning_patterns(canvas_path)

        # è·å–çŸ¥è¯†å…³è”
        knowledge_connections = await self._get_knowledge_connections(canvas_path)

        return {
            "progress": progress,
            "difficult_nodes": difficult_nodes,
            "learning_patterns": learning_patterns,
            "knowledge_connections": knowledge_connections
        }

    def _analyze_color_distribution(self, nodes: List[dict]) -> dict:
        """åˆ†æé¢œè‰²åˆ†å¸ƒ"""
        distribution = {"1": 0, "2": 0, "3": 0, "5": 0, "6": 0}
        for node in nodes:
            color = node.get('color', '')
            if color in distribution:
                distribution[color] += 1
        return distribution

    def _extract_topics(self, nodes: List[dict]) -> List[str]:
        """æå–ä¸»é¢˜"""
        topics = set()
        for node in nodes:
            text = node.get('text', '')
            # ç®€å•çš„ä¸»é¢˜æå–é€»è¾‘
            words = text.split()
            for word in words:
                if len(word) > 3 and word.isalpha():
                    topics.add(word)
        return list(topics)[:10]  # è¿”å›å‰10ä¸ªä¸»é¢˜

    def _calculate_improvement(self, old_color: str, new_color: str) -> float:
        """è®¡ç®—æ”¹è¿›ç¨‹åº¦"""
        color_weights = {"1": 0, "3": 0.5, "6": 0.7, "2": 1.0}
        old_weight = color_weights.get(old_color, 0)
        new_weight = color_weights.get(new_color, 0)
        return new_weight - old_weight

    async def _update_node_understanding_state(self, node_id: str,
                                              color: str, score: dict = None):
        """æ›´æ–°èŠ‚ç‚¹ç†è§£çŠ¶æ€"""
        state_id = f"state_{node_id}_{int(time.time())}"

        state_triplet = KnowledgeGraphTriplet(
            subject=state_id,
            relation=RelationType.CREATED_AT_TIME.value,
            object=str(time.time()),
            subject_type=EntityType.UNDERSTANDING_STATE.value,
            object_type="timestamp",
            metadata={
                "color": color,
                "color_meaning": self._get_color_meaning(color),
                "score": score or {},
                "node_id": node_id
            }
        )

        await self.kg_layer.add_triplet(state_triplet)

        # èŠ‚ç‚¹å…·æœ‰ç†è§£çŠ¶æ€å…³ç³»
        understanding_triplet = KnowledgeGraphTriplet(
            subject=node_id,
            relation=RelationType.HAS_UNDERSTANDING_STATE.value,
            object=state_id,
            subject_type=EntityType.NODE.value,
            object_type=EntityType.UNDERSTANDING_STATE.value
        )

        await self.kg_layer.add_triplet(understanding_triplet)

    def _get_color_meaning(self, color: str) -> str:
        """è·å–é¢œè‰²å«ä¹‰"""
        meanings = {
            "1": "ä¸ç†è§£/æœªé€šè¿‡",
            "2": "å®Œå…¨ç†è§£/å·²é€šè¿‡",
            "3": "ä¼¼æ‡‚éæ‡‚/å¾…æ£€éªŒ",
            "5": "AIè¡¥å……è§£é‡Š",
            "6": "ä¸ªäººç†è§£è¾“å‡ºåŒº"
        }
        return meanings.get(color, "æœªçŸ¥çŠ¶æ€")
```

### 3.2 æ™ºèƒ½è®°å¿†ç´¢å¼•ç³»ç»Ÿ

```python
class MemoryIndexSystem:
    """æ™ºèƒ½è®°å¿†ç´¢å¼•ç³»ç»Ÿ"""

    def __init__(self, kg_layer: KnowledgeGraphLayer):
        self.kg_layer = kg_layer
        self.index_cache = {}

    async def build_semantic_index(self, canvas_path: str):
        """æ„å»ºè¯­ä¹‰ç´¢å¼•"""
        # è·å–æ‰€æœ‰èŠ‚ç‚¹å†…å®¹
        nodes_query = f"""
        MATCH (c:canvas {{path: "{canvas_path}"}})
        -[:contains]->(n:node)
        RETURN n.id as node_id, n.text as text, n.color as color
        """

        nodes = await self.kg_layer.custom_query(nodes_query)

        # ä¸ºæ¯ä¸ªèŠ‚ç‚¹æ„å»ºè¯­ä¹‰å‘é‡
        for node in nodes:
            await self._index_node_semantically(node)

    async def _index_node_semantically(self, node: dict):
        """ä¸ºèŠ‚ç‚¹æ„å»ºè¯­ä¹‰ç´¢å¼•"""
        text = node.get('text', '')
        node_id = node.get('node_id')

        # æå–å…³é”®è¯
        keywords = self._extract_keywords(text)

        # æ„å»ºæ¦‚å¿µä¸‰å…ƒç»„
        for keyword in keywords:
            concept_triplet = KnowledgeGraphTriplet(
                subject=f"node_{node_id}",
                relation=RelationType.IS_ABOUT.value,
                object=f"concept_{keyword}",
                subject_type=EntityType.NODE.value,
                object_type=EntityType.CONCEPT.value,
                metadata={"relevance": self._calculate_relevance(text, keyword)}
            )

            await self.kg_layer.add_triplet(concept_triplet)

    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–
        import jieba
        words = jieba.lcut(text)
        keywords = [word for word in words if len(word) > 2 and word.isalpha()]
        return list(set(keywords))[:5]  # è¿”å›å‰5ä¸ªå”¯ä¸€å…³é”®è¯

    def _calculate_relevance(self, text: str, keyword: str) -> float:
        """è®¡ç®—å…³é”®è¯ç›¸å…³æ€§"""
        count = text.lower().count(keyword.lower())
        return min(1.0, count / len(text.split()))

    async def build_temporal_index(self, canvas_path: str):
        """æ„å»ºæ—¶é—´ç´¢å¼•"""
        # æŒ‰æ—¶é—´ç»„ç»‡å­¦ä¹ æ´»åŠ¨
        temporal_query = f"""
        MATCH (c:canvas {{path: "{canvas_path}"}})
        -[*]->(n)
        WHERE n.timestamp IS NOT NULL
        RETURN n.timestamp as timestamp, labels(n) as types, n
        ORDER BY n.timestamp
        """

        temporal_data = await self.kg_layer.custom_query(temporal_query)

        # æ„å»ºæ—¶é—´åºåˆ—ç´¢å¼•
        for i, item in enumerate(temporal_data):
            timestamp = item['timestamp']
            node_types = item['types']

            # åˆ›å»ºæ—¶é—´ç´¢å¼•ä¸‰å…ƒç»„
            time_triplet = KnowledgeGraphTriplet(
                subject=f"time_index_{int(timestamp)}",
                relation=RelationType.CREATED_AT_TIME.value,
                object=str(timestamp),
                subject_type="time_index",
                object_type="timestamp",
                metadata={
                    "sequence": i,
                    "node_types": node_types,
                    "canvas_path": canvas_path
                }
            )

            await self.kg_layer.add_triplet(time_triplet)
```

---
