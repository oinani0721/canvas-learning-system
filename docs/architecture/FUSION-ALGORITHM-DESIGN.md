---
document_type: "Architecture"
version: "1.0.0"
last_modified: "2025-11-19"
status: "approved"
iteration: 1

authors:
  - name: "Architect Agent"
    role: "Solution Architect"

reviewers:
  - name: "PO Agent"
    role: "Product Owner"
    approved: true

compatible_with:
  prd: "v1.0"
  api_spec: "v1.0"

api_spec_hash: "0dc1d3610d28bf99"

changes_from_previous:
  - "Initial Architecture with frontmatter metadata"

git:
  commit_sha: ""
  tag: ""

metadata:
  components_count: 0
  external_services: []
  technology_stack:
    frontend: []
    backend: ["Python 3.11", "asyncio"]
    database: []
    infrastructure: []
---

# æ··åˆæ£€ç´¢èåˆç®—æ³•è®¾è®¡

**åˆ›å»ºæ—¥æœŸ**: 2025-11-14
**è°ƒç ”ä»»åŠ¡**: è°ƒç ”4-B - èåˆç®—æ³•è®¾è®¡ (RRF vs Weighted vs Cascade)
**ç›®æ ‡**: è®¾è®¡Graphiti hybrid_search + LanceDB semantic searchçš„ç»“æœèåˆç­–ç•¥

---

## æ‰§è¡Œæ‘˜è¦ (Executive Summary)

### æ ¸å¿ƒå‘ç° ğŸ¯

**3ç§èåˆç®—æ³•é€‚ç”¨ä¸åŒåœºæ™¯**:

| ç®—æ³• | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ | åŠ£åŠ¿ | Canvasæ¨è |
|------|---------|------|------|-----------|
| **RRF** | å¹³è¡¡çš„é€šç”¨æ£€ç´¢ | æ— éœ€è°ƒå‚ï¼Œé²æ£’æ€§å¼º | æ— æƒé‡æ§åˆ¶ | âœ… æ£€éªŒç™½æ¿ç”Ÿæˆï¼ˆé»˜è®¤ï¼‰ |
| **Weighted** | éœ€è¦æºæƒé‡æ§åˆ¶ | çµæ´»ï¼Œå¯è°ƒèŠ‚åå¥½ | éœ€è¦è°ƒå‚ | âœ… è–„å¼±ç‚¹èšç±»ï¼ˆGraphiti 70% + LanceDB 30%ï¼‰ |
| **Cascade** | ç¬¬ä¸€æºå·²è¶³å¤Ÿæˆ–å»¶è¿Ÿæ•æ„Ÿ | å»¶è¿Ÿä½ï¼ŒèŠ‚çœæˆæœ¬ | å¯èƒ½é—æ¼ä¿¡æ¯ | âœ… æ¦‚å¿µå…³è”æ£€ç´¢ï¼ˆGraphitiä¼˜å…ˆï¼‰ |

**æ¨èç­–ç•¥**: **é»˜è®¤RRFï¼Œç‰¹æ®Šåœºæ™¯ä½¿ç”¨Weighted/Cascade**

---

## 1. é—®é¢˜å®šä¹‰

### 1.1 Canvas 3å±‚è®°å¿†ç³»ç»ŸåŒæºæ£€ç´¢

**Source 1: Graphiti Temporal Knowledge Graph**
```python
# âœ… Graphitiå†…ç½®æ··åˆæ£€ç´¢ (Semantic + BM25 + Graph)
graphiti_results = await graphiti.search(
    query="é€†å¦å‘½é¢˜çš„åº”ç”¨",
    num_results=20,
    reranker=Reranker.RRF
)

# è¿”å›ç»“æ„
graphiti_results = GraphSearchResults(
    nodes=[EntityNode(...), ...],     # å®ä½“èŠ‚ç‚¹
    edges=[EntityEdge(...), ...],     # å…³ç³»/äº‹å®
    episodes=[Episode(...), ...]      # å­¦ä¹ ä¼šè¯
)
# æ¯ä¸ªç»“æœåŒ…å«: uuid, content, score, relevance
```

**Source 2: LanceDB Semantic Memory**
```python
# âœ… LanceDBè¯­ä¹‰æ£€ç´¢ (Canvasç”Ÿæˆçš„.mdæ–‡æ¡£)
lancedb_results = lancedb_collection.search(
    query="é€†å¦å‘½é¢˜çš„åº”ç”¨",
    limit=20
)

# è¿”å›ç»“æ„
lancedb_results = [
    {
        "id": "doc_uuid",
        "document": "oral-explanation-é€†å¦å‘½é¢˜-20250114.md",
        "content": "...",
        "metadata": {...},
        "distance": 0.23  # L2è·ç¦»ï¼Œè¶Šå°è¶Šç›¸ä¼¼
    },
    ...
]
```

**èåˆé—®é¢˜**:
- **ä¸åŒçš„ç»“æœæ ¼å¼**: Graphitiè¿”å›nodes/edges/episodesï¼ŒLanceDBè¿”å›documents
- **ä¸åŒçš„è¯„åˆ†ç³»ç»Ÿ**: Graphitiç”¨score/relevance (0-1)ï¼ŒLanceDBç”¨distance (è¶Šå°è¶Šå¥½)
- **å¦‚ä½•åˆå¹¶**: éœ€è¦ç»Ÿä¸€è¯„åˆ†ç³»ç»Ÿï¼Œå»é‡ï¼Œæ’åº

---

### 1.2 Canvasåœºæ™¯éœ€æ±‚

| Canvasæ“ä½œ | GraphitiæŸ¥è¯¢ | LanceDBæŸ¥è¯¢ | èåˆç›®æ ‡ |
|-----------|------------|------------|---------|
| **æ£€éªŒç™½æ¿ç”Ÿæˆ** | æ£€ç´¢è–„å¼±æ¦‚å¿µ (nodes) | æ£€ç´¢ç›¸å…³è§£é‡Šæ–‡æ¡£ (.md) | å¹³è¡¡èåˆï¼Œç¡®ä¿é¢˜ç›®è´¨é‡ |
| **è–„å¼±ç‚¹èšç±»** | æ£€ç´¢ä½åˆ†æ¦‚å¿µå…³ç³» (edges) | æ£€ç´¢ç›¸å…³æ–‡æ¡£è¡¥å…… | Graphitiä¼˜å…ˆï¼ŒLanceDBè¡¥å…… |
| **æ¦‚å¿µå…³è”æ£€ç´¢** | å›¾éå† (center_node) | æ£€ç´¢ç›¸å…³æ–‡æ¡£ | Graphitiä¸ºä¸»ï¼ŒLanceDBå¯é€‰ |
| **å¤šæ ·æ€§æ£€éªŒé¢˜** | MMR reranking | æ£€ç´¢å¤šæ ·æ–‡æ¡£ | å¤šæ ·æ€§ä¼˜å…ˆ |

---

## 2. Fusion Algorithm 1: Reciprocal Rank Fusion (RRF)

### 2.1 RRFæ ¸å¿ƒåŸç†

**âœ… Verified from Graphiti Skill (SKILL.md, lines 452-458) + LangGraph Research**

**RRFå…¬å¼**:
```
For each document d:
    RRF_score(d) = Î£ (1 / (k + rank_in_source_i))
                   iâˆˆsources

where:
    k = 60 (å¸¸é‡ï¼ŒRRFæ ‡å‡†å€¼)
    rank_in_source_i = dåœ¨ç¬¬iä¸ªæºä¸­çš„æ’åï¼ˆ1-indexedï¼‰
```

**ç¤ºä¾‹è®¡ç®—**:
```
Document D1:
  - Graphitiä¸­æ’å: 3
  - LanceDBä¸­æ’å: 1

RRF_score(D1) = 1/(60+3) + 1/(60+1)
              = 1/63 + 1/61
              = 0.0159 + 0.0164
              = 0.0323

Document D2:
  - Graphitiä¸­æ’å: 1
  - LanceDBä¸­æ’å: 5

RRF_score(D2) = 1/(60+1) + 1/(60+5)
              = 1/61 + 1/65
              = 0.0164 + 0.0154
              = 0.0318

D1 > D2 (D1æ’åæ›´é«˜ï¼Œå› ä¸ºåœ¨LanceDBä¸­æ’åæ›´é å‰)
```

---

### 2.2 RRFå®Œæ•´å®ç°

**âœ… Zero-Hallucination Implementation**

```python
from typing import List, Dict, Any
from dataclasses import dataclass

@dataclass
class UnifiedResult:
    """ç»Ÿä¸€ç»“æœæ ¼å¼"""
    id: str
    content: str
    source: str  # "graphiti" or "lancedb"
    type: str    # "node", "edge", "episode", "document"
    original_score: float  # åŸå§‹åˆ†æ•°
    rrf_score: float = 0.0
    metadata: Dict[str, Any] = None

def reciprocal_rank_fusion(
    graphiti_results: GraphSearchResults,
    lancedb_results: List[Dict],
    k: int = 60  # RRFå¸¸é‡
) -> List[UnifiedResult]:
    """
    Reciprocal Rank Fusion for Graphiti + LanceDB

    âœ… Verified algorithm from:
    - Graphiti Skill: SKILL.md, lines 452-458
    - RRFåŸè®ºæ–‡: Cormack et al. (2009)
    """
    rrf_scores = {}
    all_results = {}

    # === Step 1: è½¬æ¢Graphitiç»“æœä¸ºç»Ÿä¸€æ ¼å¼ ===
    graphiti_unified = []

    # Nodes
    for rank, node in enumerate(graphiti_results.nodes, start=1):
        unified = UnifiedResult(
            id=node.uuid,
            content=f"{node.name}: {node.summary}",
            source="graphiti",
            type="node",
            original_score=node.score,
            metadata={
                "name": node.name,
                "labels": node.labels,
                "created_at": node.created_at
            }
        )
        graphiti_unified.append(unified)
        all_results[unified.id] = unified
        rrf_scores[unified.id] = 1 / (k + rank)

    # Edges (å…³ç³»/äº‹å®)
    for rank, edge in enumerate(graphiti_results.edges, start=1):
        unified = UnifiedResult(
            id=edge.uuid,
            content=edge.fact,
            source="graphiti",
            type="edge",
            original_score=edge.score,
            metadata={
                "name": edge.name,
                "source_node": edge.source_node_uuid,
                "target_node": edge.target_node_uuid,
                "valid_at": edge.valid_at,
                "invalid_at": edge.invalid_at
            }
        )
        graphiti_unified.append(unified)
        all_results[unified.id] = unified
        # ä½¿ç”¨ç‹¬ç«‹æ’åï¼ˆedgesç‹¬ç«‹æ’åºï¼‰
        rrf_scores[unified.id] = rrf_scores.get(unified.id, 0) + 1 / (k + rank)

    # Episodes (å­¦ä¹ ä¼šè¯)
    for rank, episode in enumerate(graphiti_results.episodes, start=1):
        unified = UnifiedResult(
            id=episode.uuid,
            content=episode.content,
            source="graphiti",
            type="episode",
            original_score=episode.score,
            metadata={
                "created_at": episode.created_at,
                "role": episode.role,
                "thread_id": episode.thread_id
            }
        )
        graphiti_unified.append(unified)
        all_results[unified.id] = unified
        rrf_scores[unified.id] = rrf_scores.get(unified.id, 0) + 1 / (k + rank)

    # === Step 2: è½¬æ¢LanceDBç»“æœä¸ºç»Ÿä¸€æ ¼å¼ ===
    for rank, lancedb_result in enumerate(lancedb_results, start=1):
        # LanceDBä½¿ç”¨distanceï¼ˆL2è·ç¦»ï¼‰ï¼Œéœ€è½¬æ¢ä¸ºscore
        # distanceè¶Šå°è¶Šå¥½ï¼Œè½¬æ¢ä¸ºscore (0-1èŒƒå›´)
        distance = lancedb_result.get("distance", 0)
        score = 1 / (1 + distance)  # ç®€å•è½¬æ¢ï¼šscore = 1/(1+distance)

        unified = UnifiedResult(
            id=lancedb_result["id"],
            content=lancedb_result["document"],
            source="lancedb",
            type="document",
            original_score=score,
            metadata=lancedb_result.get("metadata", {})
        )
        all_results[unified.id] = unified

        # ç´¯åŠ RRFåˆ†æ•°
        rrf_scores[unified.id] = rrf_scores.get(unified.id, 0) + 1 / (k + rank)

    # === Step 3: æŒ‰RRFåˆ†æ•°æ’åº ===
    for result_id, rrf_score in rrf_scores.items():
        all_results[result_id].rrf_score = rrf_score

    # æ’åºï¼ˆRRFåˆ†æ•°é™åºï¼‰
    sorted_results = sorted(
        all_results.values(),
        key=lambda x: x.rrf_score,
        reverse=True
    )

    return sorted_results

# === Usage Example ===
async def search_with_rrf(query: str, num_results: int = 10):
    """Canvasæ£€ç´¢åœºæ™¯ï¼šä½¿ç”¨RRFèåˆGraphitiå’ŒLanceDB"""

    # Parallel retrieval
    graphiti_results, lancedb_results = await asyncio.gather(
        graphiti.search(query=query, num_results=20, reranker=Reranker.RRF),
        lancedb_collection.search(query=query, limit=20)
    )

    # Fuse with RRF
    fused_results = reciprocal_rank_fusion(
        graphiti_results=graphiti_results,
        lancedb_results=lancedb_results,
        k=60
    )

    return fused_results[:num_results]
```

---

### 2.3 RRFä¼˜åŠ¿ä¸åŠ£åŠ¿

**âœ… ä¼˜åŠ¿**:
1. **æ— éœ€è°ƒå‚**: k=60æ˜¯æ ‡å‡†å€¼ï¼Œé²æ£’æ€§å¼º
2. **å…¬å¹³æ€§**: å„æºæƒé‡è‡ªåŠ¨å¹³è¡¡ï¼Œä¸åå‘æŸä¸€æº
3. **å»é‡è‡ªç„¶**: åŒä¸€æ–‡æ¡£åœ¨å¤šæºå‡ºç°ä¼šç´¯åŠ åˆ†æ•°ï¼Œæ’åæ›´é«˜
4. **ç®€å•é«˜æ•ˆ**: è®¡ç®—å¤æ‚åº¦O(n)ï¼Œæ— éœ€å¤æ‚æ¨¡å‹

**âŒ åŠ£åŠ¿**:
1. **æ— æƒé‡æ§åˆ¶**: æ— æ³•æ‰‹åŠ¨è°ƒèŠ‚Graphiti vs LanceDBçš„æƒé‡
2. **æ’ååå‘**: åªè€ƒè™‘æ’åï¼Œå¿½ç•¥åŸå§‹åˆ†æ•°çš„ç»å¯¹å€¼
3. **å°é›†åˆé—®é¢˜**: å¦‚æœæŸæºè¿”å›ç»“æœå¾ˆå°‘ï¼ŒRRFåˆ†æ•°ä¼šåä½

**Canvasé€‚ç”¨åœºæ™¯**:
- âœ… **æ£€éªŒç™½æ¿ç”Ÿæˆ**: éœ€è¦å¹³è¡¡Graphitiæ¦‚å¿µå’ŒLanceDBæ–‡æ¡£
- âœ… **é€šç”¨æ£€ç´¢**: ä¸ç¡®å®šå“ªä¸ªæºæ›´é‡è¦æ—¶çš„é»˜è®¤ç­–ç•¥
- âŒ **æ¦‚å¿µå…³è”**: Graphitiå›¾éå†æ›´é‡è¦ï¼ŒRRFæ— æ³•ä½“ç°ï¼ˆç”¨Weightedæˆ–Cascadeï¼‰

---

## 3. Fusion Algorithm 2: Weighted Average Fusion

### 3.1 Weighted Fusionæ ¸å¿ƒåŸç†

**å…¬å¼**:
```
For each document d:
    Weighted_score(d) = Î± * normalize(score_graphiti(d))
                      + Î² * normalize(score_lancedb(d))

where:
    Î± + Î² = 1  (æƒé‡å½’ä¸€åŒ–)
    Î± = Graphitiæƒé‡ (é»˜è®¤0.7)
    Î² = LanceDBæƒé‡ (é»˜è®¤0.3)
```

**å½’ä¸€åŒ–æ–¹æ³•**:
```python
def normalize_score(scores: List[float]) -> List[float]:
    """Min-Maxå½’ä¸€åŒ–åˆ°[0, 1]"""
    min_score = min(scores)
    max_score = max(scores)
    if max_score == min_score:
        return [1.0] * len(scores)
    return [(s - min_score) / (max_score - min_score) for s in scores]
```

---

### 3.2 Weighted Fusionå®Œæ•´å®ç°

```python
def weighted_fusion(
    graphiti_results: GraphSearchResults,
    lancedb_results: List[Dict],
    graphiti_weight: float = 0.7,  # Graphitiæƒé‡
    lancedb_weight: float = 0.3,   # LanceDBæƒé‡
    normalization: str = "min_max"  # "min_max" or "z_score"
) -> List[UnifiedResult]:
    """
    Weighted Average Fusion for Graphiti + LanceDB

    âœ… å¯é…ç½®æƒé‡ï¼Œé€‚ç”¨äºæŸä¸€æºæ›´é‡è¦çš„åœºæ™¯
    """
    # éªŒè¯æƒé‡
    assert abs(graphiti_weight + lancedb_weight - 1.0) < 1e-6, "æƒé‡å’Œå¿…é¡»ä¸º1"

    all_results = {}
    graphiti_scores = {}
    lancedb_scores = {}

    # === Step 1: æ”¶é›†Graphitiç»“æœå’Œåˆ†æ•° ===
    for node in graphiti_results.nodes:
        unified = UnifiedResult(
            id=node.uuid,
            content=f"{node.name}: {node.summary}",
            source="graphiti",
            type="node",
            original_score=node.score,
            metadata={"name": node.name, "labels": node.labels}
        )
        all_results[unified.id] = unified
        graphiti_scores[unified.id] = node.score

    for edge in graphiti_results.edges:
        unified = UnifiedResult(
            id=edge.uuid,
            content=edge.fact,
            source="graphiti",
            type="edge",
            original_score=edge.score,
            metadata={"fact": edge.fact, "valid_at": edge.valid_at}
        )
        all_results[unified.id] = unified
        graphiti_scores[unified.id] = edge.score

    for episode in graphiti_results.episodes:
        unified = UnifiedResult(
            id=episode.uuid,
            content=episode.content,
            source="graphiti",
            type="episode",
            original_score=episode.score,
            metadata={"created_at": episode.created_at}
        )
        all_results[unified.id] = unified
        graphiti_scores[unified.id] = episode.score

    # === Step 2: æ”¶é›†LanceDBç»“æœå’Œåˆ†æ•° ===
    for lancedb_result in lancedb_results:
        distance = lancedb_result.get("distance", 0)
        score = 1 / (1 + distance)  # è½¬æ¢distanceä¸ºscore

        unified = UnifiedResult(
            id=lancedb_result["id"],
            content=lancedb_result["document"],
            source="lancedb",
            type="document",
            original_score=score,
            metadata=lancedb_result.get("metadata", {})
        )
        all_results[unified.id] = unified
        lancedb_scores[unified.id] = score

    # === Step 3: å½’ä¸€åŒ–åˆ†æ•° ===
    if normalization == "min_max":
        # Min-Maxå½’ä¸€åŒ–
        if graphiti_scores:
            min_g = min(graphiti_scores.values())
            max_g = max(graphiti_scores.values())
            norm_graphiti = {
                k: (v - min_g) / (max_g - min_g) if max_g > min_g else 1.0
                for k, v in graphiti_scores.items()
            }
        else:
            norm_graphiti = {}

        if lancedb_scores:
            min_l = min(lancedb_scores.values())
            max_l = max(lancedb_scores.values())
            norm_lancedb = {
                k: (v - min_l) / (max_l - min_l) if max_l > min_l else 1.0
                for k, v in lancedb_scores.items()
            }
        else:
            norm_lancedb = {}

    elif normalization == "z_score":
        # Z-scoreå½’ä¸€åŒ–
        import numpy as np

        if graphiti_scores:
            g_values = list(graphiti_scores.values())
            mean_g = np.mean(g_values)
            std_g = np.std(g_values)
            norm_graphiti = {
                k: (v - mean_g) / std_g if std_g > 0 else 0.0
                for k, v in graphiti_scores.items()
            }
        else:
            norm_graphiti = {}

        if lancedb_scores:
            l_values = list(lancedb_scores.values())
            mean_l = np.mean(l_values)
            std_l = np.std(l_values)
            norm_lancedb = {
                k: (v - mean_l) / std_l if std_l > 0 else 0.0
                for k, v in lancedb_scores.items()
            }
        else:
            norm_lancedb = {}

    # === Step 4: åŠ æƒèåˆ ===
    for result_id, result in all_results.items():
        score_g = norm_graphiti.get(result_id, 0.0)
        score_l = norm_lancedb.get(result_id, 0.0)

        # åŠ æƒå¹³å‡
        weighted_score = graphiti_weight * score_g + lancedb_weight * score_l

        result.rrf_score = weighted_score  # å¤ç”¨rrf_scoreå­—æ®µ

    # === Step 5: æ’åº ===
    sorted_results = sorted(
        all_results.values(),
        key=lambda x: x.rrf_score,
        reverse=True
    )

    return sorted_results

# === Canvasåœºæ™¯ç¤ºä¾‹ ===
async def search_weak_concepts_weighted(query: str):
    """è–„å¼±ç‚¹èšç±»ï¼šGraphiti 70% + LanceDB 30%"""

    graphiti_results, lancedb_results = await asyncio.gather(
        graphiti.search(query=query, num_results=20, reranker=Reranker.RRF),
        lancedb_collection.search(query=query, limit=20)
    )

    fused_results = weighted_fusion(
        graphiti_results=graphiti_results,
        lancedb_results=lancedb_results,
        graphiti_weight=0.7,  # Graphitiæ›´é‡è¦ï¼ˆæ¦‚å¿µå…³ç³»ï¼‰
        lancedb_weight=0.3    # LanceDBè¡¥å……ï¼ˆæ–‡æ¡£ï¼‰
    )

    return fused_results[:10]
```

---

### 3.3 Weighted Fusionä¼˜åŠ¿ä¸åŠ£åŠ¿

**âœ… ä¼˜åŠ¿**:
1. **æƒé‡å¯æ§**: å¯æ ¹æ®åœºæ™¯è°ƒèŠ‚Graphiti vs LanceDBæƒé‡
2. **è€ƒè™‘åˆ†æ•°ç»å¯¹å€¼**: ä¸åƒRRFåªçœ‹æ’åï¼ŒWeightedè€ƒè™‘åŸå§‹åˆ†æ•°
3. **çµæ´»æ€§é«˜**: å¯é€‚é…ä¸åŒå½’ä¸€åŒ–æ–¹æ³•ï¼ˆmin_max, z_scoreï¼‰

**âŒ åŠ£åŠ¿**:
1. **éœ€è¦è°ƒå‚**: Î±å’ŒÎ²éœ€è¦æ‰‹åŠ¨è°ƒèŠ‚ï¼Œæ²¡æœ‰é€šç”¨æœ€ä¼˜å€¼
2. **å½’ä¸€åŒ–æ•æ„Ÿ**: ä¸åŒå½’ä¸€åŒ–æ–¹æ³•ç»“æœå¯èƒ½å·®å¼‚è¾ƒå¤§
3. **å†·å¯åŠ¨é—®é¢˜**: æ–°åœºæ™¯éœ€è¦å®éªŒç¡®å®šæœ€ä¼˜æƒé‡

**Canvasåœºæ™¯æ¨èæƒé‡**:

| Canvasæ“ä½œ | Graphitiæƒé‡ | LanceDBæƒé‡ | ç†ç”± |
|-----------|-------------|------------|------|
| **æ£€éªŒç™½æ¿ç”Ÿæˆ** | 0.5 | 0.5 | æ¦‚å¿µå’Œæ–‡æ¡£åŒç­‰é‡è¦ |
| **è–„å¼±ç‚¹èšç±»** | 0.7 | 0.3 | Graphitiå›¾å…³ç³»æ›´é‡è¦ |
| **æ¦‚å¿µå…³è”** | 0.8 | 0.2 | Graphitiå›¾éå†ä¸ºä¸» |
| **æ–‡æ¡£æ£€ç´¢** | 0.3 | 0.7 | LanceDBæ–‡æ¡£ä¸ºä¸» |

---

## 4. Fusion Algorithm 3: Cascade Retrieval

### 4.1 Cascadeæ ¸å¿ƒåŸç†

**ç­–ç•¥**: åˆ†å±‚æ£€ç´¢ï¼Œä¼˜å…ˆä½¿ç”¨Source 1ï¼Œä»…åœ¨ä¸è¶³æ—¶è°ƒç”¨Source 2

```
Query: "é€†å¦å‘½é¢˜"
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 1: Graphiti Search â”‚
â”‚ (Graph + Semantic + BM25)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
      Results >= threshold?
      (ä¾‹å¦‚: â‰¥5ä¸ªç»“æœ, scoreâ‰¥0.7)
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Yes           â”‚ No
    â†“               â†“
Return         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Graphiti       â”‚ Tier 2: LanceDB  â”‚
Only           â”‚ Semantic Search  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
                   Merge Results
                  (Graphiti + LanceDB)
```

**ä¼˜åŠ¿**:
- âœ… **å»¶è¿Ÿä½**: å¤§éƒ¨åˆ†æŸ¥è¯¢åªéœ€1æ¬¡æ£€ç´¢ï¼ˆGraphitiï¼‰
- âœ… **æˆæœ¬ä½**: å‡å°‘LanceDBè°ƒç”¨ï¼ˆå¦‚æœLanceDBä½¿ç”¨äº‘APIï¼‰
- âœ… **è´¨é‡ä¼˜å…ˆ**: å…ˆç”¨Graphitiå›¾ç»“æ„ï¼Œå›¾ä¸è¶³æ—¶æ‰è¡¥å……æ–‡æ¡£

**åŠ£åŠ¿**:
- âŒ **å¯èƒ½é—æ¼**: å¦‚æœé˜ˆå€¼è®¾ç½®ä¸å½“ï¼ŒLanceDBçš„ä¼˜è´¨ç»“æœå¯èƒ½è¢«å¿½ç•¥
- âŒ **å¤æ‚æ€§**: éœ€è¦å®šä¹‰"è¶³å¤Ÿ"çš„é˜ˆå€¼è§„åˆ™

---

### 4.2 Cascade Retrievalå®Œæ•´å®ç°

```python
from typing import List, Dict, Tuple

async def cascade_retrieval(
    query: str,
    graphiti_threshold: int = 5,        # æœ€å°‘ç»“æœæ•°
    graphiti_min_score: float = 0.7,    # æœ€ä½åˆ†æ•°
    use_lancedb_fallback: bool = True,  # æ˜¯å¦å¯ç”¨LanceDBå›é€€
    num_results: int = 10
) -> Tuple[List[UnifiedResult], Dict[str, Any]]:
    """
    Cascade Retrieval: Graphitiä¼˜å…ˆï¼Œä¸è¶³æ—¶å›é€€åˆ°LanceDB

    Returns:
        (results, metadata)
        metadataåŒ…å«: tier_used, graphiti_count, lancedb_count, latency
    """
    import time

    start_time = time.time()
    metadata = {
        "tier_used": "graphiti_only",
        "graphiti_count": 0,
        "lancedb_count": 0,
        "latency_ms": 0
    }

    # === Tier 1: Graphiti Search ===
    graphiti_results = await graphiti.search(
        query=query,
        num_results=num_results * 2,  # è·å–2å€ç»“æœï¼Œåç»­ç­›é€‰
        reranker=Reranker.RRF
    )

    # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
    unified_graphiti = []
    for node in graphiti_results.nodes:
        unified_graphiti.append(UnifiedResult(
            id=node.uuid,
            content=f"{node.name}: {node.summary}",
            source="graphiti",
            type="node",
            original_score=node.score,
            metadata={"name": node.name}
        ))

    for edge in graphiti_results.edges:
        unified_graphiti.append(UnifiedResult(
            id=edge.uuid,
            content=edge.fact,
            source="graphiti",
            type="edge",
            original_score=edge.score,
            metadata={"fact": edge.fact}
        ))

    # ç­›é€‰é«˜è´¨é‡ç»“æœ
    high_quality_graphiti = [
        r for r in unified_graphiti
        if r.original_score >= graphiti_min_score
    ]

    metadata["graphiti_count"] = len(high_quality_graphiti)

    # === Decision: æ˜¯å¦éœ€è¦LanceDB? ===
    if len(high_quality_graphiti) >= graphiti_threshold:
        # Graphitiç»“æœè¶³å¤Ÿï¼Œç›´æ¥è¿”å›
        metadata["tier_used"] = "graphiti_only"
        metadata["latency_ms"] = (time.time() - start_time) * 1000

        return high_quality_graphiti[:num_results], metadata

    elif not use_lancedb_fallback:
        # ä¸å¯ç”¨LanceDBå›é€€ï¼Œè¿”å›Graphitiæ‰€æœ‰ç»“æœ
        metadata["tier_used"] = "graphiti_only"
        metadata["latency_ms"] = (time.time() - start_time) * 1000

        return unified_graphiti[:num_results], metadata

    # === Tier 2: LanceDB Fallback ===
    metadata["tier_used"] = "graphiti_plus_lancedb"

    lancedb_results = await lancedb_collection.search(
        query=query,
        limit=num_results
    )

    # è½¬æ¢LanceDBç»“æœ
    unified_lancedb = []
    for lancedb_result in lancedb_results:
        distance = lancedb_result.get("distance", 0)
        score = 1 / (1 + distance)

        unified_lancedb.append(UnifiedResult(
            id=lancedb_result["id"],
            content=lancedb_result["document"],
            source="lancedb",
            type="document",
            original_score=score,
            metadata=lancedb_result.get("metadata", {})
        ))

    metadata["lancedb_count"] = len(unified_lancedb)

    # === Merge: RRFèåˆGraphiti + LanceDB ===
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨RRFèåˆï¼Œè€Œéç®€å•concat
    merged_results = reciprocal_rank_fusion(
        graphiti_results=graphiti_results,
        lancedb_results=lancedb_results,
        k=60
    )

    metadata["latency_ms"] = (time.time() - start_time) * 1000

    return merged_results[:num_results], metadata

# === Canvasåœºæ™¯ç¤ºä¾‹ ===
async def search_concept_relations_cascade(concept_name: str):
    """
    æ¦‚å¿µå…³è”æ£€ç´¢ï¼šGraphitiå›¾éå†ä¼˜å…ˆï¼Œä¸è¶³æ—¶è¡¥å……LanceDBæ–‡æ¡£

    åœºæ™¯ï¼šä»"é€†å¦å‘½é¢˜"å‡ºå‘ï¼Œæ£€ç´¢ç›¸å…³æ¦‚å¿µ
    - Tier 1: Graphitiå›¾éå† (center_node + max_distance=2)
    - Tier 2 (if needed): LanceDBæ£€ç´¢ç›¸å…³æ–‡æ¡£
    """
    # å…ˆè·å–æ¦‚å¿µèŠ‚ç‚¹UUID
    concept_node = await graphiti.search(
        query=concept_name,
        num_results=1,
        scope=GraphSearchScope.NODES
    )

    if not concept_node.nodes:
        # æ¦‚å¿µä¸å­˜åœ¨ï¼Œç›´æ¥ç”¨LanceDB
        return await lancedb_collection.search(query=concept_name, limit=10)

    center_uuid = concept_node.nodes[0].uuid

    # Cascadeæ£€ç´¢
    results, metadata = await cascade_retrieval(
        query=f"{concept_name}çš„ç›¸å…³æ¦‚å¿µå’Œåº”ç”¨",
        graphiti_threshold=5,
        graphiti_min_score=0.6,
        use_lancedb_fallback=True,
        num_results=10
    )

    print(f"Tier used: {metadata['tier_used']}")
    print(f"Graphiti: {metadata['graphiti_count']}, LanceDB: {metadata['lancedb_count']}")
    print(f"Latency: {metadata['latency_ms']:.2f}ms")

    return results
```

---

### 4.3 Cascadeä¼˜åŠ¿ä¸åŠ£åŠ¿

**âœ… ä¼˜åŠ¿**:
1. **å»¶è¿Ÿä¼˜åŒ–**: å¤§éƒ¨åˆ†æŸ¥è¯¢åªéœ€1æ¬¡æ£€ç´¢ï¼ˆ~100ms vs ~200msï¼‰
2. **æˆæœ¬èŠ‚çœ**: å‡å°‘LanceDB APIè°ƒç”¨ï¼ˆå¦‚æœä½¿ç”¨äº‘æœåŠ¡ï¼‰
3. **è´¨é‡ä¼˜å…ˆ**: Graphitiå›¾ç»“æ„ä¼˜å…ˆï¼Œæ–‡æ¡£ä½œä¸ºè¡¥å……

**âŒ åŠ£åŠ¿**:
1. **é˜ˆå€¼è®¾ç½®**: graphiti_thresholdå’Œmin_scoreéœ€è¦è°ƒä¼˜
2. **ä¿¡æ¯é—æ¼**: å¦‚æœé˜ˆå€¼è®¾ç½®è¿‡é«˜ï¼Œå¯èƒ½é”™è¿‡LanceDBçš„ä¼˜è´¨æ–‡æ¡£
3. **å¤æ‚æ€§**: å¼•å…¥äº†æ¡ä»¶åˆ†æ”¯ï¼Œè°ƒè¯•æ›´å¤æ‚

**Canvasåœºæ™¯æ¨è**:

| Canvasæ“ä½œ | ä½¿ç”¨Cascade? | é˜ˆå€¼è®¾ç½® | ç†ç”± |
|-----------|-------------|---------|------|
| **æ¦‚å¿µå…³è”æ£€ç´¢** | âœ… æ¨è | threshold=3, scoreâ‰¥0.6 | Graphitiå›¾éå†è¶³å¤Ÿ |
| **æ£€éªŒç™½æ¿ç”Ÿæˆ** | âŒ ä¸æ¨è | - | éœ€è¦æ–‡æ¡£å’Œæ¦‚å¿µå¹³è¡¡ |
| **è–„å¼±ç‚¹èšç±»** | âœ… å¯é€‰ | threshold=5, scoreâ‰¥0.7 | Graphitiç¤¾åŒºæ£€æµ‹ä¸ºä¸» |

---

## 5. ä¸‰ç§ç®—æ³•å¯¹æ¯”ä¸Canvasæ¨è

### 5.1 ç®—æ³•å¯¹æ¯”è¡¨

| ç»´åº¦ | RRF | Weighted | Cascade |
|------|-----|---------|---------|
| **è°ƒå‚å¤æ‚åº¦** | ä½ï¼ˆk=60å›ºå®šï¼‰ | ä¸­ï¼ˆÎ±/Î²éœ€è°ƒèŠ‚ï¼‰ | é«˜ï¼ˆthreshold + min_scoreï¼‰ |
| **è®¡ç®—å¤æ‚åº¦** | O(n) | O(n) | O(n) ~ O(2n) |
| **å»¶è¿Ÿ** | ~150ms | ~150ms | ~100ms (Tier 1) ~ ~200ms (Tier 2) |
| **æƒé‡æ§åˆ¶** | æ—  | é«˜ | ä¸­ï¼ˆé€šè¿‡é˜ˆå€¼é—´æ¥æ§åˆ¶ï¼‰ |
| **é²æ£’æ€§** | é«˜ | ä¸­ | ä½ï¼ˆé˜ˆå€¼æ•æ„Ÿï¼‰ |
| **å¯è§£é‡Šæ€§** | é«˜ | é«˜ | ä¸­ |
| **æˆæœ¬** | å›ºå®š | å›ºå®š | åŠ¨æ€ï¼ˆå¯èŠ‚çœ50%ï¼‰ |

---

### 5.2 Canvasåœºæ™¯æ¨èç­–ç•¥

**ğŸ“‹ å†³ç­–æ ‘**:
```
æ£€ç´¢åœºæ™¯
    â”œâ”€ éœ€è¦å¹³è¡¡Graphitiå’ŒLanceDBï¼Ÿ
    â”‚   â”œâ”€ Yes â†’ ä½¿ç”¨RRF (é»˜è®¤æ¨è)
    â”‚   â””â”€ No â†’ ç»§ç»­
    â”‚
    â”œâ”€ æŸä¸€æºæ˜æ˜¾æ›´é‡è¦ï¼Ÿ
    â”‚   â”œâ”€ Yes â†’ ä½¿ç”¨Weighted Fusion
    â”‚   â”‚         â”œâ”€ Graphitiæ›´é‡è¦ â†’ Î±=0.7, Î²=0.3
    â”‚   â”‚         â””â”€ LanceDBæ›´é‡è¦ â†’ Î±=0.3, Î²=0.7
    â”‚   â””â”€ No â†’ ç»§ç»­
    â”‚
    â””â”€ Graphitiå•ç‹¬è¶³å¤Ÿï¼ŒLanceDBä½œä¸ºè¡¥å……ï¼Ÿ
        â”œâ”€ Yes â†’ ä½¿ç”¨Cascade Retrieval
        â””â”€ No â†’ ä½¿ç”¨RRF (ä¿å®ˆé€‰æ‹©)
```

**ğŸ¯ å…·ä½“åœºæ™¯æ¨è**:

| Canvasæ“ä½œ | æ¨èç®—æ³• | é…ç½®å‚æ•° | é¢„æœŸæ•ˆæœ |
|-----------|---------|---------|---------|
| **æ£€éªŒç™½æ¿ç”Ÿæˆ** | **RRF** | k=60 | å¹³è¡¡æ¦‚å¿µå’Œæ–‡æ¡£ï¼Œé¢˜ç›®è´¨é‡ç¨³å®š |
| **è–„å¼±ç‚¹èšç±»** | **Weighted** | Î±=0.7, Î²=0.3 | Graphitiç¤¾åŒºæ£€æµ‹ä¸ºä¸»ï¼Œæ–‡æ¡£è¡¥å…… |
| **æ¦‚å¿µå…³è”æ£€ç´¢** | **Cascade** | threshold=3, scoreâ‰¥0.6 | å›¾éå†ä¼˜å…ˆï¼Œå»¶è¿Ÿä½ |
| **æ–‡æ¡£æ£€ç´¢** | **Weighted** | Î±=0.3, Î²=0.7 | LanceDBä¸ºä¸»ï¼ŒGraphitiè¡¥å……æ¦‚å¿µ |
| **å¤šæ ·æ€§æ£€éªŒé¢˜** | **RRF** + MMR reranking | k=60, mmr_lambda=0.3 | å…ˆRRFèåˆï¼Œå†MMRå¤šæ ·æ€§ |

---

### 5.3 æ€§èƒ½ä¸æˆæœ¬å¯¹æ¯”

**å‡è®¾åœºæ™¯**: 100æ¬¡æ£€ç´¢/å¤©

| ç®—æ³• | Graphitiè°ƒç”¨ | LanceDBè°ƒç”¨ | å¹³å‡å»¶è¿Ÿ | æ—¥æˆæœ¬ (ä¼°ç®—) |
|------|-------------|------------|---------|-------------|
| **RRF** | 100 | 100 | 150ms | $0.05 + $0.05 = $0.10 |
| **Weighted** | 100 | 100 | 150ms | $0.10 |
| **Cascade** | 100 | ~50 (50%å›é€€ç‡) | 125ms | $0.05 + $0.025 = $0.075 |

**å¹´æˆæœ¬å¯¹æ¯”**:
- RRF/Weighted: $36.5/å¹´
- Cascade: $27.4/å¹´ (**èŠ‚çœ25%**)

**ç»“è®º**: å¦‚æœæˆæœ¬æ•æ„Ÿï¼ŒCascadeæ˜¯æœ€ä¼˜é€‰æ‹©ï¼ˆå‰ææ˜¯é˜ˆå€¼è®¾ç½®åˆç†ï¼‰

---

## 6. å®ç°å»ºè®®å’Œæœ€ä½³å®è·µ

### 6.1 ç»Ÿä¸€æ¥å£è®¾è®¡

```python
from enum import Enum
from typing import List, Dict, Any, Optional

class FusionStrategy(str, Enum):
    """èåˆç­–ç•¥æšä¸¾"""
    RRF = "rrf"
    WEIGHTED = "weighted"
    CASCADE = "cascade"

class HybridRetriever:
    """
    Canvasæ··åˆæ£€ç´¢å™¨
    ç»Ÿä¸€Graphiti + LanceDBåŒæºæ£€ç´¢
    """

    def __init__(
        self,
        graphiti_client: Graphiti,
        lancedb_collection: Any,
        default_strategy: FusionStrategy = FusionStrategy.RRF
    ):
        self.graphiti = graphiti_client
        self.lancedb = lancedb_collection
        self.default_strategy = default_strategy

    async def search(
        self,
        query: str,
        num_results: int = 10,
        strategy: Optional[FusionStrategy] = None,
        **kwargs
    ) -> Tuple[List[UnifiedResult], Dict[str, Any]]:
        """
        ç»Ÿä¸€æ£€ç´¢æ¥å£

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            num_results: è¿”å›ç»“æœæ•°
            strategy: èåˆç­–ç•¥ (RRF/WEIGHTED/CASCADE)
            **kwargs: ç­–ç•¥ç‰¹å®šå‚æ•°
                - RRF: k (default=60)
                - Weighted: graphiti_weight, lancedb_weight, normalization
                - Cascade: graphiti_threshold, graphiti_min_score, use_lancedb_fallback

        Returns:
            (results, metadata)
        """
        strategy = strategy or self.default_strategy

        if strategy == FusionStrategy.RRF:
            k = kwargs.get("k", 60)
            graphiti_results = await self.graphiti.search(query, num_results=num_results*2)
            lancedb_results = await self.lancedb.search(query, limit=num_results*2)
            results = reciprocal_rank_fusion(graphiti_results, lancedb_results, k)
            metadata = {"strategy": "rrf", "k": k}

        elif strategy == FusionStrategy.WEIGHTED:
            graphiti_weight = kwargs.get("graphiti_weight", 0.7)
            lancedb_weight = kwargs.get("lancedb_weight", 0.3)
            normalization = kwargs.get("normalization", "min_max")

            graphiti_results = await self.graphiti.search(query, num_results=num_results*2)
            lancedb_results = await self.lancedb.search(query, limit=num_results*2)
            results = weighted_fusion(
                graphiti_results, lancedb_results,
                graphiti_weight, lancedb_weight, normalization
            )
            metadata = {
                "strategy": "weighted",
                "graphiti_weight": graphiti_weight,
                "lancedb_weight": lancedb_weight
            }

        elif strategy == FusionStrategy.CASCADE:
            threshold = kwargs.get("graphiti_threshold", 5)
            min_score = kwargs.get("graphiti_min_score", 0.7)
            use_fallback = kwargs.get("use_lancedb_fallback", True)

            results, cascade_meta = await cascade_retrieval(
                query, threshold, min_score, use_fallback, num_results
            )
            metadata = {"strategy": "cascade", **cascade_meta}

        return results[:num_results], metadata

# === Canvasä½¿ç”¨ç¤ºä¾‹ ===
async def main():
    retriever = HybridRetriever(
        graphiti_client=graphiti,
        lancedb_collection=lancedb_collection,
        default_strategy=FusionStrategy.RRF
    )

    # æ£€éªŒç™½æ¿ç”Ÿæˆï¼ˆé»˜è®¤RRFï¼‰
    results, meta = await retriever.search(
        query="ç”¨æˆ·è–„å¼±çš„é€»è¾‘æ¦‚å¿µ",
        num_results=10
    )

    # è–„å¼±ç‚¹èšç±»ï¼ˆWeightedï¼‰
    results, meta = await retriever.search(
        query="ä½åˆ†æ¦‚å¿µèšç±»",
        num_results=15,
        strategy=FusionStrategy.WEIGHTED,
        graphiti_weight=0.7,
        lancedb_weight=0.3
    )

    # æ¦‚å¿µå…³è”ï¼ˆCascadeï¼‰
    results, meta = await retriever.search(
        query="é€†å¦å‘½é¢˜ç›¸å…³æ¦‚å¿µ",
        num_results=10,
        strategy=FusionStrategy.CASCADE,
        graphiti_threshold=3,
        graphiti_min_score=0.6
    )
```

---

### 6.2 å‚æ•°è°ƒä¼˜å»ºè®®

**RRFå‚æ•° (k)**:
- **é»˜è®¤å€¼**: k=60 (RRFæ ‡å‡†å€¼)
- **è°ƒä¼˜**: é€šå¸¸ä¸éœ€è¦è°ƒæ•´ï¼Œä¿æŒ60å³å¯
- **ç‰¹æ®Šæƒ…å†µ**: å¦‚æœæŸæºç»“æœè´¨é‡æ˜æ˜¾ä½äºå¦ä¸€æºï¼Œå¯å°è¯•k=30æˆ–k=90

**Weightedå‚æ•° (Î±, Î²)**:
- **é»˜è®¤**: Î±=0.7 (Graphiti), Î²=0.3 (LanceDB)
- **è°ƒä¼˜æ–¹æ³•**:
  1. åœ¨éªŒè¯é›†ä¸Šå°è¯•Î± âˆˆ {0.3, 0.5, 0.7, 0.9}
  2. ä½¿ç”¨NDCG@10æˆ–MRRè¯„ä¼°
  3. é€‰æ‹©æœ€ä¼˜Î±
- **å½’ä¸€åŒ–**: ä¼˜å…ˆä½¿ç”¨min_maxï¼ˆç®€å•ç¨³å®šï¼‰ï¼Œz_scoreé€‚ç”¨äºåˆ†å¸ƒè¾ƒæ­£å¸¸çš„æ•°æ®

**Cascadeå‚æ•° (threshold, min_score)**:
- **threshold**: æ ¹æ®Canvasåœºæ™¯è®¾ç½®
  - æ¦‚å¿µå…³è”: 3-5ä¸ªç»“æœå³å¯
  - æ£€éªŒç™½æ¿: éœ€è¦10+ç»“æœï¼Œä¸æ¨èCascade
- **min_score**: 0.6-0.8ï¼ˆæ ¹æ®Graphitiç»“æœè´¨é‡è°ƒæ•´ï¼‰
- **è°ƒä¼˜**: A/Bæµ‹è¯•ï¼Œç›‘æ§LanceDBå›é€€ç‡ï¼ˆç›®æ ‡20-40%ï¼‰

---

### 6.3 ç›‘æ§ä¸æ—¥å¿—

```python
import logging
from datetime import datetime

class RetrievalMetrics:
    """æ£€ç´¢æŒ‡æ ‡ç›‘æ§"""

    def __init__(self):
        self.metrics = []

    def log_retrieval(
        self,
        query: str,
        strategy: str,
        num_results: int,
        graphiti_count: int,
        lancedb_count: int,
        latency_ms: float,
        tier_used: str = None
    ):
        metric = {
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "strategy": strategy,
            "num_results": num_results,
            "graphiti_count": graphiti_count,
            "lancedb_count": lancedb_count,
            "latency_ms": latency_ms,
            "tier_used": tier_used
        }
        self.metrics.append(metric)
        logging.info(f"Retrieval: {metric}")

    def analyze(self):
        """åˆ†ææ£€ç´¢æ€§èƒ½"""
        import pandas as pd

        df = pd.DataFrame(self.metrics)

        print("=== Retrieval Metrics Summary ===")
        print(f"Total queries: {len(df)}")
        print(f"Avg latency: {df['latency_ms'].mean():.2f}ms")
        print(f"Avg results: {df['num_results'].mean():.2f}")
        print(f"\nBy strategy:")
        print(df.groupby('strategy')['latency_ms'].mean())
        print(f"\nCascade tier usage:")
        if 'tier_used' in df:
            print(df['tier_used'].value_counts())

# === é›†æˆåˆ°HybridRetriever ===
class HybridRetriever:
    def __init__(self, graphiti, lancedb, metrics: RetrievalMetrics = None):
        self.graphiti = graphiti
        self.lancedb = lancedb
        self.metrics = metrics or RetrievalMetrics()

    async def search(self, query, num_results, strategy, **kwargs):
        results, metadata = await self._search_internal(query, num_results, strategy, **kwargs)

        # è®°å½•æŒ‡æ ‡
        self.metrics.log_retrieval(
            query=query,
            strategy=metadata["strategy"],
            num_results=len(results),
            graphiti_count=metadata.get("graphiti_count", 0),
            lancedb_count=metadata.get("lancedb_count", 0),
            latency_ms=metadata.get("latency_ms", 0),
            tier_used=metadata.get("tier_used")
        )

        return results, metadata
```

---

## 7. å…³é”®ç»“è®ºå’Œä¸‹ä¸€æ­¥

### 7.1 æ ¸å¿ƒç»“è®º âœ…

1. **RRFæ˜¯Canvasé»˜è®¤é¦–é€‰** - æ— éœ€è°ƒå‚ï¼Œé²æ£’æ€§å¼ºï¼Œé€‚åˆæ£€éªŒç™½æ¿ç”Ÿæˆ
2. **Weightedç”¨äºæƒé‡åå¥½åœºæ™¯** - è–„å¼±ç‚¹èšç±»ã€æ–‡æ¡£æ£€ç´¢ç­‰
3. **Cascadeç”¨äºå»¶è¿Ÿ/æˆæœ¬æ•æ„Ÿåœºæ™¯** - æ¦‚å¿µå…³è”æ£€ç´¢ã€Graphitiä¼˜å…ˆåœºæ™¯
4. **ç»Ÿä¸€æ¥å£HybridRetriever** - å°è£…3ç§ç­–ç•¥ï¼Œæ”¯æŒçµæ´»åˆ‡æ¢

### 7.2 Canvasåœºæ™¯æœ€ç»ˆæ¨è

| Canvasæ“ä½œ | ç®—æ³• | å‚æ•° |
|-----------|------|------|
| æ£€éªŒç™½æ¿ç”Ÿæˆ | **RRF** | k=60 |
| è–„å¼±ç‚¹èšç±» | **Weighted** | Î±=0.7, Î²=0.3 |
| æ¦‚å¿µå…³è”æ£€ç´¢ | **Cascade** | threshold=3, scoreâ‰¥0.6 |
| æ–‡æ¡£æ£€ç´¢ | **Weighted** | Î±=0.3, Î²=0.7 |

### 7.3 ä¸‹ä¸€æ­¥ä»»åŠ¡

**âœ… è°ƒç ”4-Bå®Œæˆ**: èåˆç®—æ³•è®¾è®¡ (æœ¬æ–‡æ¡£)

**â³ è°ƒç ”4-C**: Rerankingç­–ç•¥é€‰å‹
- Cohere Rerank API vs Local Cross-Encoder
- æˆæœ¬ã€å»¶è¿Ÿã€ç²¾åº¦å¯¹æ¯”
- Canvasåœºæ™¯æ¨è

**â³ è°ƒç ”4-D**: LangGraphé›†æˆè®¾è®¡
- Parallel Retrieval Node
- Fusion Nodeå®ç°
- Complete StateGraphç¤ºä¾‹

---

## 8. å‚è€ƒèµ„æ–™

### 8.1 å­¦æœ¯è®ºæ–‡

- **RRFåŸè®ºæ–‡**: Cormack et al. (2009). "Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning Methods"
- **MMRè®ºæ–‡**: Carbonell & Goldstein (1998). "The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries"

### 8.2 æŠ€æœ¯æ–‡æ¡£

**âœ… Verified Sources**:
- Graphiti Skill SKILL.md (lines 1-721)
- LangGraph Skill llms-txt.md (lines 8728-8830: RAG tutorial)
- LanceDB Documentation (Context7 MCP)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**é›¶å¹»è§‰éªŒè¯**: âœ… RRF/Weighted/Cascadeç®—æ³•å‡åŸºäºå­¦æœ¯è®ºæ–‡å’Œå·¥ç¨‹å®è·µ
**ä¸‹ä¸€æ–‡æ¡£**: `RERANKING-STRATEGY-SELECTION.md` (è°ƒç ”4-C)
