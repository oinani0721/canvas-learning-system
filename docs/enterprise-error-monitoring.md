# Canvaså­¦ä¹ ç³»ç»Ÿä¼ä¸šçº§é”™è¯¯ç›‘æ§æ—¥å¿—ç³»ç»ŸæŠ€æœ¯æ–¹æ¡ˆ

**ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¥æœŸ**: 2025-10-18
**ä½œè€…**: Claude Code
**çŠ¶æ€**: æŠ€æœ¯è®¾è®¡é˜¶æ®µ

---

## ğŸ“‹ æ–¹æ¡ˆæ¦‚è¿°

### é¡¹ç›®èƒŒæ™¯

Canvaså­¦ä¹ ç³»ç»Ÿå½“å‰ç¼ºä¹å®Œæ•´çš„é”™è¯¯ç›‘æ§ä½“ç³»ï¼Œç°æœ‰é”™è¯¯å¤„ç†æœºåˆ¶ä¸»è¦ä¾èµ–æ‰‹åŠ¨è®°å½•çš„`CANVAS_ERROR_LOG.md`æ–‡ä»¶ã€‚ä¸ºå®ç°ç³»ç»Ÿçš„é«˜å¯ç”¨æ€§ã€å¯ç»´æŠ¤æ€§å’Œå¯æ‰©å±•æ€§ï¼Œéœ€è¦å»ºç«‹ä¼ä¸šçº§é”™è¯¯ç›‘æ§æ—¥å¿—ç³»ç»Ÿã€‚

### æ ¸å¿ƒç›®æ ‡

1. **å…¨é¢ç›‘æ§**: è¦†ç›–3å±‚æ¶æ„çš„æ‰€æœ‰æ“ä½œå’Œæ½œåœ¨é”™è¯¯ç‚¹
2. **å®æ—¶å“åº”**: é”™è¯¯å‘ç”Ÿæ—¶ç«‹å³æ£€æµ‹å’Œå‘Šè­¦
3. **æ™ºèƒ½æ¢å¤**: è‡ªåŠ¨è¯†åˆ«é”™è¯¯ç±»å‹å¹¶æ‰§è¡Œæ¢å¤ç­–ç•¥
4. **æ€§èƒ½ä¼˜åŒ–**: è¯†åˆ«æ€§èƒ½ç“¶é¢ˆï¼Œæä¾›ä¼˜åŒ–å»ºè®®
5. **æ•°æ®é©±åŠ¨**: åŸºäºé”™è¯¯æ•°æ®æŒ‡å¯¼ç³»ç»Ÿå‡çº§å’Œä¼˜åŒ–

### æŠ€æœ¯æ ˆé€‰æ‹©

- **Loguru**: ç»“æ„åŒ–æ—¥å¿—è®°å½• (156ä»£ç ç¤ºä¾‹, ä¿¡ä»»åº¦8.0)
- **PySnooper**: å‡½æ•°çº§è°ƒè¯•è¿½è¸ª (20ä»£ç ç¤ºä¾‹, ä¿¡ä»»åº¦9.9)
- **Sentry**: ä¼ä¸šçº§é”™è¯¯ç›‘æ§å¹³å° (70ä»£ç ç¤ºä¾‹, ä¿¡ä»»åº¦9.0)
- **Prometheus**: æŒ‡æ ‡æ”¶é›†å’Œå­˜å‚¨
- **Grafana**: å¯è§†åŒ–ç›‘æ§é¢æ¿

---

## ğŸ—ï¸ é”™è¯¯ç›‘æ§æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Canvaså­¦ä¹ ç³»ç»Ÿ                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 3: CanvasOrchestrator (é«˜çº§APIå±‚)                     â”‚
â”‚  â”œâ”€ Sub-agentè°ƒç”¨æ¥å£                                       â”‚
â”‚  â”œâ”€ å®Œæ•´æ“ä½œå·¥ä½œæµ                                          â”‚
â”‚  â””â”€ é”™è¯¯ç›‘æ§è£…é¥°å™¨é›†æˆ                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 2: CanvasBusinessLogic (ä¸šåŠ¡é€»è¾‘å±‚)                   â”‚
â”‚  â”œâ”€ v1.1å¸ƒå±€ç®—æ³•                                           â”‚
â”‚  â”œâ”€ ä¸Šä¸‹æ–‡æå–                                              â”‚
â”‚  â”œâ”€ é—®é¢˜èšç±»                                                â”‚
â”‚  â””â”€ ä¸šåŠ¡é€»è¾‘ç›‘æ§é’©å­                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 1: CanvasJSONOperator (åº•å±‚JSONæ“ä½œ)                  â”‚
â”‚  â”œâ”€ åŸå­åŒ–Canvasæ–‡ä»¶è¯»å†™                                    â”‚
â”‚  â”œâ”€ èŠ‚ç‚¹/è¾¹CRUDæ“ä½œ                                        â”‚
â”‚  â””â”€ åº•å±‚æ“ä½œå¼‚å¸¸æ•è·                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  é”™è¯¯ç›‘æ§ä¸­é—´å±‚                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Loguru    â”‚  â”‚  PySnooper  â”‚  â”‚      Sentry         â”‚   â”‚
â”‚  â”‚ ç»“æ„åŒ–æ—¥å¿—   â”‚  â”‚ å‡½æ•°è¿½è¸ª     â”‚  â”‚   å®æ—¶ç›‘æ§å‘Šè­¦       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Prometheus  â”‚  â”‚   Grafana   â”‚  â”‚   é”™è¯¯åˆ†æå¼•æ“       â”‚   â”‚
â”‚  â”‚  æŒ‡æ ‡æ”¶é›†    â”‚  â”‚  å¯è§†åŒ–é¢æ¿  â”‚  â”‚   æ™ºèƒ½åˆ†ç±»æ¢å¤       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   å­˜å‚¨å’Œå‘Šè­¦å±‚                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ æ–‡ä»¶ç³»ç»Ÿ     â”‚  â”‚    Redis    â”‚  â”‚     é‚®ä»¶/é’‰é’‰        â”‚   â”‚
â”‚  â”‚  æ—¥å¿—æ–‡ä»¶     â”‚  â”‚   ç¼“å­˜å­˜å‚¨   â”‚  â”‚    å‘Šè­¦é€šçŸ¥         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç›‘æ§å±‚æ¬¡è®¾è®¡

#### 1. åŸºç¡€ç›‘æ§å±‚ (Foundation Layer)
- **ç›®æ ‡**: æ•è·æ‰€æœ‰æœªå¤„ç†å¼‚å¸¸
- **èŒƒå›´**: å…¨å±€å¼‚å¸¸å¤„ç†ã€ç³»ç»Ÿèµ„æºç›‘æ§
- **å·¥å…·**: Loguru + Pythonæ ‡å‡†åº“

#### 2. ä¸šåŠ¡ç›‘æ§å±‚ (Business Layer)
- **ç›®æ ‡**: ç›‘æ§Canvasç‰¹å®šä¸šåŠ¡é€»è¾‘
- **èŒƒå›´**: æ–‡ä»¶æ“ä½œã€èŠ‚ç‚¹ç®¡ç†ã€é¢œè‰²éªŒè¯
- **å·¥å…·**: PySnooper + è‡ªå®šä¹‰è£…é¥°å™¨

#### 3. æ€§èƒ½ç›‘æ§å±‚ (Performance Layer)
- **ç›®æ ‡**: æ€§èƒ½æŒ‡æ ‡æ”¶é›†å’Œåˆ†æ
- **èŒƒå›´**: APIå“åº”æ—¶é—´ã€å†…å­˜ä½¿ç”¨ã€æ“ä½œè€—æ—¶
- **å·¥å…·**: Prometheus + Grafana

#### 4. æ™ºèƒ½åˆ†æå±‚ (Intelligence Layer)
- **ç›®æ ‡**: é”™è¯¯åˆ†ç±»ã€è¶‹åŠ¿åˆ†æã€è‡ªåŠ¨æ¢å¤
- **èŒƒå›´**: é”™è¯¯æ¨¡å¼è¯†åˆ«ã€æ¢å¤ç­–ç•¥æ‰§è¡Œ
- **å·¥å…·**: Sentry + è‡ªå®šä¹‰åˆ†æå¼•æ“

---

## ğŸ“Š Loguruç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ

### æ ¸å¿ƒé…ç½®

```python
"""
Canvaså­¦ä¹ ç³»ç»Ÿç»“æ„åŒ–æ—¥å¿—é…ç½®
åŸºäºLoguru v0.7.0
"""
import sys
import json
from pathlib import Path
from loguru import logger
from typing import Dict, Any, Optional
from datetime import datetime

class CanvasLogConfig:
    """Canvasæ—¥å¿—é…ç½®ç®¡ç†å™¨"""

    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)

        # ç§»é™¤é»˜è®¤å¤„ç†å™¨
        logger.remove()

        # é…ç½®æ ¼å¼
        self.log_format = (
            "<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | "
            "<level>{level: <8}</level> | "
            "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | "
            "<level>{message}</level>"
        )

        self.setup_handlers()

    def setup_handlers(self):
        """è®¾ç½®æ—¥å¿—å¤„ç†å™¨"""

        # 1. æ§åˆ¶å°è¾“å‡º - å¼€å‘ç¯å¢ƒ
        logger.add(
            sys.stdout,
            format=self.log_format,
            level="DEBUG",
            colorize=True,
            filter=lambda record: record["extra"].get("env") == "dev"
        )

        # 2. å…¨éƒ¨æ—¥å¿—æ–‡ä»¶ - è½®è½¬å­˜å‚¨
        logger.add(
            self.log_dir / "canvas_{time:YYYY-MM-DD}.log",
            format=self.log_format,
            level="DEBUG",
            rotation="10 MB",
            retention="30 days",
            compression="zip",
            encoding="utf-8"
        )

        # 3. é”™è¯¯æ—¥å¿—æ–‡ä»¶ - ä»…é”™è¯¯å’Œå¼‚å¸¸
        logger.add(
            self.log_dir / "errors_{time:YYYY-MM-DD}.log",
            format=self.log_format,
            level="ERROR",
            rotation="5 MB",
            retention="90 days",
            compression="zip",
            encoding="utf-8"
        )

        # 4. ç»“æ„åŒ–JSONæ—¥å¿— - ä¾¿äºåˆ†æ
        logger.add(
            self.log_dir / "structured_{time:YYYY-MM-DD}.jsonl",
            format="{message}",
            level="INFO",
            rotation="20 MB",
            retention="60 days",
            filter=self._structured_filter,
            serialize=True
        )

        # 5. Canvasæ“ä½œä¸“ç”¨æ—¥å¿—
        logger.add(
            self.log_dir / "canvas_operations_{time:YYYY-MM-DD}.log",
            format=self.log_format,
            level="INFO",
            rotation="15 MB",
            retention="45 days",
            filter=lambda record: "canvas_operation" in record["extra"],
            encoding="utf-8"
        )

    def _structured_filter(self, record):
        """ç»“æ„åŒ–æ—¥å¿—è¿‡æ»¤å™¨"""
        return record["extra"].get("structured", False)

    @staticmethod
    def log_canvas_operation(
        operation: str,
        canvas_file: str,
        node_id: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None,
        success: bool = True,
        error: Optional[str] = None
    ):
        """è®°å½•Canvasæ“ä½œæ—¥å¿—"""
        log_data = {
            "timestamp": datetime.now().isoformat(),
            "operation": operation,
            "canvas_file": canvas_file,
            "node_id": node_id,
            "details": details or {},
            "success": success,
            "error": error
        }

        if success:
            logger.info(
                f"Canvasæ“ä½œæˆåŠŸ: {operation}",
                canvas_operation=True,
                structured=True,
                **log_data
            )
        else:
            logger.error(
                f"Canvasæ“ä½œå¤±è´¥: {operation} - {error}",
                canvas_operation=True,
                structured=True,
                **log_data
            )

    @staticmethod
    def log_performance(
        operation: str,
        duration_ms: float,
        canvas_file: Optional[str] = None,
        node_count: Optional[int] = None,
        memory_usage: Optional[float] = None
    ):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡æ—¥å¿—"""
        perf_data = {
            "timestamp": datetime.now().isoformat(),
            "operation": operation,
            "duration_ms": duration_ms,
            "canvas_file": canvas_file,
            "node_count": node_count,
            "memory_usage_mb": memory_usage
        }

        logger.info(
            f"æ€§èƒ½æŒ‡æ ‡: {operation} è€—æ—¶ {duration_ms:.2f}ms",
            performance=True,
            structured=True,
            **perf_data
        )

# å…¨å±€æ—¥å¿—é…ç½®å®ä¾‹
canvas_logger = CanvasLogConfig()
```

### æ—¥å¿—çº§åˆ«å®šä¹‰

```python
class CanvasLogLevel:
    """Canvasç³»ç»Ÿæ—¥å¿—çº§åˆ«å®šä¹‰"""

    # æ ‡å‡†çº§åˆ«
    TRACE = 5      # è¯¦ç»†è·Ÿè¸ªä¿¡æ¯
    DEBUG = 10     # è°ƒè¯•ä¿¡æ¯
    INFO = 20      # ä¸€èˆ¬ä¿¡æ¯
    WARNING = 30   # è­¦å‘Šä¿¡æ¯
    ERROR = 40     # é”™è¯¯ä¿¡æ¯
    CRITICAL = 50  # ä¸¥é‡é”™è¯¯

    # ä¸šåŠ¡çº§åˆ«
    CANVAS_READ = 15     # Canvasæ–‡ä»¶è¯»å–
    CANVAS_WRITE = 17    # Canvasæ–‡ä»¶å†™å…¥
    NODE_OPERATION = 18  # èŠ‚ç‚¹æ“ä½œ
    AGENT_CALL = 22      # Agentè°ƒç”¨
    VALIDATION = 25      # éªŒè¯æ“ä½œ
    PERFORMANCE = 28     # æ€§èƒ½ç›‘æ§
```

### ç»“æ„åŒ–æ—¥å¿—æ¨¡å¼

```python
class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨"""

    def __init__(self):
        self.logger = logger

    def log_canvas_event(
        self,
        event_type: str,
        canvas_path: str,
        layer: str,
        operation: str,
        status: str,
        duration_ms: Optional[float] = None,
        metadata: Optional[Dict[str, Any]] = None
    ):
        """è®°å½•Canvasäº‹ä»¶"""
        event_data = {
            "event_type": event_type,
            "canvas_path": canvas_path,
            "layer": layer,  # Layer1/2/3
            "operation": operation,
            "status": status,  # success/failure/partial
            "duration_ms": duration_ms,
            "metadata": metadata or {},
            "timestamp": datetime.now().isoformat()
        }

        level = "ERROR" if status == "failure" else "INFO"
        getattr(self.logger, level.lower())(
            f"Canvas {event_type}: {operation} - {status}",
            structured=True,
            **event_data
        )

    def log_error_context(
        self,
        error: Exception,
        context: Dict[str, Any],
        recovery_attempted: bool = False,
        recovery_successful: bool = False
    ):
        """è®°å½•é”™è¯¯ä¸Šä¸‹æ–‡"""
        error_data = {
            "error_type": type(error).__name__,
            "error_message": str(error),
            "context": context,
            "recovery_attempted": recovery_attempted,
            "recovery_successful": recovery_successful,
            "stack_trace": traceback.format_exc(),
            "timestamp": datetime.now().isoformat()
        }

        self.logger.error(
            f"ç³»ç»Ÿé”™è¯¯: {type(error).__name__}",
            structured=True,
            **error_data
        )
```

---

## ğŸ” PySnooperå‡½æ•°çº§è°ƒè¯•è¿½è¸ªç³»ç»Ÿ

### æ ¸å¿ƒé…ç½®

```python
"""
Canvaså­¦ä¹ ç³»ç»Ÿå‡½æ•°çº§è°ƒè¯•è¿½è¸ªé…ç½®
åŸºäºPySnooper v1.2.0
"""
import pysnooper
import functools
import time
from pathlib import Path
from typing import Any, Callable, Dict, Optional

class CanvasDebugger:
    """Canvasç³»ç»Ÿè°ƒè¯•è¿½è¸ªç®¡ç†å™¨"""

    def __init__(self, debug_dir: str = "debug"):
        self.debug_dir = Path(debug_dir)
        self.debug_dir.mkdir(exist_ok=True)
        self.trace_files = {}

    def get_trace_file(self, component: str) -> str:
        """è·å–ç»„ä»¶è¿½è¸ªæ–‡ä»¶è·¯å¾„"""
        if component not in self.trace_files:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            self.trace_files[component] = str(
                self.debug_dir / f"{component}_trace_{timestamp}.log"
            )
        return self.trace_files[component]

def canvas_trace(
    component: str = "canvas",
    watch_vars: Optional[list] = None,
    depth: int = 1,
    prefix: Optional[str] = None
):
    """Canvasæ“ä½œè¿½è¸ªè£…é¥°å™¨"""
    def decorator(func: Callable) -> Callable:
        debugger = CanvasDebugger()
        trace_file = debugger.get_trace_file(component)

        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # é…ç½®PySnooperå‚æ•°
            snooper_config = {
                'output': trace_file,
                'depth': depth,
                'prefix': prefix or f"[{component}] ",
                'overwrite': False,
                'thread_info': True,
                'custom_repr': (
                    (dict, lambda d: f"dict({len(d)} items)"),
                    (list, lambda l: f"list({len(l)} items)"),
                    (str, lambda s: f"str({len(s)} chars)"),
                )
            }

            if watch_vars:
                snooper_config['watch'] = watch_vars

            return pysnooper.snoop(**snooper_config)(func)(*args, **kwargs)

        return wrapper
    return decorator

class CanvasLayerTracer:
    """Canvaså±‚çº§è¿½è¸ªå™¨"""

    @staticmethod
    def trace_layer1():
        """Layer1: JSONæ“ä½œè¿½è¸ª"""
        return canvas_trace(
            component="layer1_json",
            watch_vars=['canvas_data', 'node_id', 'operation'],
            depth=2,
            prefix="[L1-JSON] "
        )

    @staticmethod
    def trace_layer2():
        """Layer2: ä¸šåŠ¡é€»è¾‘è¿½è¸ª"""
        return canvas_trace(
            component="layer2_business",
            watch_vars=['canvas_path', 'nodes', 'cluster_result'],
            depth=1,
            prefix="[L2-BIZ] "
        )

    @staticmethod
    def trace_layer3():
        """Layer3: Agentè°ƒç”¨è¿½è¸ª"""
        return canvas_trace(
            component="layer3_agent",
            watch_vars=['agent_name', 'input_data', 'response'],
            depth=1,
            prefix="[L3-AGENT] "
        )

# ä½¿ç”¨ç¤ºä¾‹
@CanvasLayerTracer.trace_layer1()
def read_canvas(canvas_path: str) -> Dict[str, Any]:
    """è¯»å–Canvasæ–‡ä»¶ - å¸¦è¿½è¸ª"""
    # å®ç°é€»è¾‘...
    pass

@CanvasLayerTracer.trace_layer2()
def cluster_questions_by_topic(nodes: list) -> Dict[str, list]:
    """é—®é¢˜èšç±» - å¸¦è¿½è¸ª"""
    # å®ç°é€»è¾‘...
    pass
```

### æ™ºèƒ½è¿½è¸ªé…ç½®

```python
class SmartTracer:
    """æ™ºèƒ½è¿½è¸ªå™¨ - æ ¹æ®æ“ä½œç±»å‹åŠ¨æ€è°ƒæ•´è¿½è¸ªçº§åˆ«"""

    def __init__(self):
        self.operation_configs = {
            'file_io': {
                'component': 'file_operations',
                'watch_vars': ['file_path', 'file_size', 'operation'],
                'depth': 2
            },
            'node_operations': {
                'component': 'node_ops',
                'watch_vars': ['node_id', 'node_type', 'position', 'color'],
                'depth': 1
            },
            'agent_calls': {
                'component': 'agent_calls',
                'watch_vars': ['agent_name', 'input_length', 'response_length'],
                'depth': 1
            },
            'layout_calculations': {
                'component': 'layout',
                'watch_vars': ['node_count', 'canvas_width', 'positions'],
                'depth': 3
            }
        }

    def smart_trace(self, operation_type: str):
        """æ™ºèƒ½è¿½è¸ªè£…é¥°å™¨"""
        config = self.operation_configs.get(operation_type, {})
        return canvas_trace(**config)

# ä½¿ç”¨ç¤ºä¾‹
tracer = SmartTracer()

@tracer.smart_trace('file_io')
def write_canvas(canvas_path: str, canvas_data: Dict[str, Any]):
    """å†™å…¥Canvasæ–‡ä»¶ - æ™ºèƒ½è¿½è¸ª"""
    pass

@tracer.smart_trace('layout_calculations')
def calculate_layout(nodes: list) -> Dict[str, Any]:
    """å¸ƒå±€è®¡ç®— - æ™ºèƒ½è¿½è¸ª"""
    pass
```

### è¿½è¸ªæ•°æ®åˆ†æ

```python
class TraceAnalyzer:
    """è¿½è¸ªæ•°æ®åˆ†æå™¨"""

    def __init__(self, trace_dir: str = "debug"):
        self.trace_dir = Path(trace_dir)

    def analyze_performance_bottlenecks(self, component: str) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½ç“¶é¢ˆ"""
        trace_file = self._get_latest_trace(component)
        if not trace_file:
            return {}

        # è§£æè¿½è¸ªæ–‡ä»¶ï¼Œè¯†åˆ«æ…¢æ“ä½œ
        bottlenecks = []
        with open(trace_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # åˆ†æé€»è¾‘...
        return {
            'component': component,
            'bottlenecks': bottlenecks,
            'recommendations': self._generate_recommendations(bottlenecks)
        }

    def analyze_error_patterns(self, component: str) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯æ¨¡å¼"""
        # å®ç°é”™è¯¯æ¨¡å¼åˆ†æé€»è¾‘
        pass

    def _generate_recommendations(self, bottlenecks: list) -> list:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        for bottleneck in bottlenecks:
            if bottleneck['type'] == 'file_io':
                recommendations.append("è€ƒè™‘ä½¿ç”¨ç¼“å­˜å‡å°‘æ–‡ä»¶è¯»å†™")
            elif bottleneck['type'] == 'computation':
                recommendations.append("è€ƒè™‘ç®—æ³•ä¼˜åŒ–æˆ–å¹¶è¡Œå¤„ç†")
        return recommendations
```

---

## ğŸš¨ Sentryå®æ—¶ç›‘æ§å‘Šè­¦ç³»ç»Ÿ

### Sentryé…ç½®

```python
"""
Canvaså­¦ä¹ ç³»ç»ŸSentryé…ç½®
åŸºäºSentry SDK v1.40.0
"""
import sentry_sdk
from sentry_sdk.integrations.logging import LoggingIntegration
from sentry_sdk.integrations.threading import ThreadingIntegration
from sentry_sdk.integrations.redis import RedisIntegration
from sentry_sdk import configure_scope, set_tag
import os

class CanvasSentryConfig:
    """Canvasç³»ç»ŸSentryé…ç½®ç®¡ç†å™¨"""

    def __init__(self, dsn: Optional[str] = None, environment: str = "development"):
        self.dsn = dsn or os.getenv("SENTRY_DSN")
        self.environment = environment
        self.setup_sentry()

    def setup_sentry(self):
        """é…ç½®Sentry"""
        if not self.dsn:
            print("Warning: Sentry DSN not configured, monitoring disabled")
            return

        # é…ç½®æ—¥å¿—é›†æˆ
        sentry_logging = LoggingIntegration(
            level=logging.INFO,        # æ•è·INFOåŠä»¥ä¸Šçº§åˆ«
            event_level=logging.ERROR  # å‘é€ERRORåŠä»¥ä¸Šçº§åˆ«åˆ°Sentry
        )

        # é…ç½®çº¿ç¨‹é›†æˆ
        sentry_threading = ThreadingIntegration(
            propagate_hub=True,
            watchdog_thread_enabled=True
        )

        sentry_sdk.init(
            dsn=self.dsn,
            environment=self.environment,
            integrations=[
                sentry_logging,
                sentry_threading,
                RedisIntegration(),
            ],
            traces_sample_rate=0.1,  # 10%çš„æ€§èƒ½è¿½è¸ªé‡‡æ ·ç‡
            profiles_sample_rate=0.1,  # 10%çš„æ€§èƒ½åˆ†æé‡‡æ ·ç‡

            # é”™è¯¯è¿‡æ»¤å™¨
            before_send=self._before_send,
            before_breadcrumb=self._before_breadcrumb,

            # è‡ªå®šä¹‰æ ‡ç­¾
            release="canvas-learning-system@1.0.0",
            server_name=os.getenv("HOSTNAME", "localhost"),
        )

    @staticmethod
    def _before_send(event, hint):
        """å‘é€å‰è¿‡æ»¤å™¨ - æ’é™¤æ•æ„Ÿä¿¡æ¯"""
        # ç§»é™¤æ•æ„Ÿä¿¡æ¯
        if 'request' in event:
            if 'headers' in event['request']:
                event['request']['headers'].pop('authorization', None)

        # æ·»åŠ Canvasç³»ç»Ÿç‰¹å®šä¿¡æ¯
        with configure_scope() as scope:
            scope.set_context("canvas_system", {
                "version": "1.0.0",
                "component": "learning_system"
            })

        return event

    @staticmethod
    def _before_breadcrumb(breadcrumb, hint):
        """é¢åŒ…å±‘è¿‡æ»¤å™¨"""
        # è¿‡æ»¤æ‰ä¸é‡è¦çš„é¢åŒ…å±‘
        if breadcrumb.get('category') == 'http' and breadcrumb.get('data', {}).get('url', '').endswith('/health'):
            return None
        return breadcrumb

    @staticmethod
    def capture_canvas_error(
        error: Exception,
        canvas_file: Optional[str] = None,
        operation: Optional[str] = None,
        node_id: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None
    ):
        """æ•è·Canvasç³»ç»Ÿé”™è¯¯"""
        with configure_scope() as scope:
            # è®¾ç½®æ ‡ç­¾
            set_tag("component", "canvas_learning_system")
            if operation:
                set_tag("operation", operation)

            # è®¾ç½®é¢å¤–ä¸Šä¸‹æ–‡
            scope.set_context("canvas_operation", {
                "canvas_file": canvas_file,
                "node_id": node_id,
                "operation": operation,
                "error_context": context or {}
            })

        # å‘é€åˆ°Sentry
        sentry_sdk.capture_exception(error)

    @staticmethod
    def capture_canvas_message(
        message: str,
        level: str = "info",
        canvas_file: Optional[str] = None,
        operation: Optional[str] = None,
        **kwargs
    ):
        """æ•è·Canvasç³»ç»Ÿæ¶ˆæ¯"""
        with configure_scope() as scope:
            scope.set_context("canvas_info", {
                "canvas_file": canvas_file,
                "operation": operation,
                **kwargs
            })

        sentry_sdk.capture_message(message, level=level)

    @staticmethod
    def start_transaction(operation: str, canvas_file: Optional[str] = None):
        """å¼€å§‹æ€§èƒ½äº‹åŠ¡"""
        transaction = sentry_sdk.start_transaction(
            name=f"canvas.{operation}",
            op="canvas.operation"
        )

        with configure_scope() as scope:
            scope.set_tag("canvas_file", canvas_file or "unknown")

        return transaction

# å…¨å±€Sentryé…ç½®å®ä¾‹
canvas_sentry = CanvasSentryConfig(
    environment=os.getenv("ENVIRONMENT", "development")
)
```

### å‘Šè­¦è§„åˆ™é…ç½®

```python
class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""

    def __init__(self):
        self.alert_rules = self._setup_alert_rules()

    def _setup_alert_rules(self) -> Dict[str, Any]:
        """è®¾ç½®å‘Šè­¦è§„åˆ™"""
        return {
            # é”™è¯¯ç‡å‘Šè­¦
            'error_rate': {
                'threshold': 5.0,  # 5%é”™è¯¯ç‡
                'window': '5m',
                'severity': 'warning'
            },

            # Canvasæ–‡ä»¶æ“ä½œå¤±è´¥
            'canvas_file_errors': {
                'threshold': 3,  # 3æ¬¡å¤±è´¥
                'window': '1m',
                'severity': 'critical'
            },

            # Agentè°ƒç”¨å¤±è´¥
            'agent_call_failures': {
                'threshold': 2,  # 2æ¬¡å¤±è´¥
                'window': '30s',
                'severity': 'warning'
            },

            # å“åº”æ—¶é—´å‘Šè­¦
            'response_time': {
                'threshold': 5000,  # 5ç§’
                'window': '5m',
                'severity': 'warning'
            },

            # å†…å­˜ä½¿ç”¨å‘Šè­¦
            'memory_usage': {
                'threshold': 80.0,  # 80%
                'window': '1m',
                'severity': 'warning'
            }
        }

    def check_alerts(self, metrics: Dict[str, Any]):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        alerts = []

        for rule_name, rule_config in self.alert_rules.items():
            if self._evaluate_rule(rule_name, rule_config, metrics):
                alert = self._create_alert(rule_name, rule_config, metrics)
                alerts.append(alert)

        return alerts

    def _evaluate_rule(self, rule_name: str, rule_config: Dict[str, Any], metrics: Dict[str, Any]) -> bool:
        """è¯„ä¼°å‘Šè­¦è§„åˆ™"""
        # å®ç°è§„åˆ™è¯„ä¼°é€»è¾‘
        if rule_name == 'error_rate':
            error_rate = metrics.get('error_rate', 0)
            return error_rate > rule_config['threshold']

        # å…¶ä»–è§„åˆ™è¯„ä¼°...
        return False

    def _create_alert(self, rule_name: str, rule_config: Dict[str, Any], metrics: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºå‘Šè­¦"""
        return {
            'rule': rule_name,
            'severity': rule_config['severity'],
            'message': f"å‘Šè­¦: {rule_name} è¶…è¿‡é˜ˆå€¼ {rule_config['threshold']}",
            'metrics': metrics,
            'timestamp': time.time()
        }

# å‘Šè­¦é€šçŸ¥é…ç½®
class NotificationService:
    """é€šçŸ¥æœåŠ¡"""

    def __init__(self):
        self.webhook_url = os.getenv("DINGTALK_WEBHOOK")
        self.email_config = {
            'smtp_server': os.getenv("SMTP_SERVER"),
            'smtp_port': int(os.getenv("SMTP_PORT", "587")),
            'username': os.getenv("EMAIL_USERNAME"),
            'password': os.getenv("EMAIL_PASSWORD"),
            'recipients': os.getenv("ALERT_RECIPIENTS", "").split(',')
        }

    def send_alert(self, alert: Dict[str, Any]):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        # é’‰é’‰é€šçŸ¥
        if self.webhook_url:
            self._send_dingtalk_alert(alert)

        # é‚®ä»¶é€šçŸ¥
        if self.email_config['smtp_server']:
            self._send_email_alert(alert)

    def _send_dingtalk_alert(self, alert: Dict[str, Any]):
        """å‘é€é’‰é’‰å‘Šè­¦"""
        # å®ç°é’‰é’‰Webhooké€šçŸ¥é€»è¾‘
        pass

    def _send_email_alert(self, alert: Dict[str, Any]):
        """å‘é€é‚®ä»¶å‘Šè­¦"""
        # å®ç°é‚®ä»¶é€šçŸ¥é€»è¾‘
        pass
```

---

## ğŸ¤– æ™ºèƒ½é”™è¯¯åˆ†ç±»å’Œè‡ªåŠ¨æ¢å¤æœºåˆ¶

### é”™è¯¯åˆ†ç±»ç³»ç»Ÿ

```python
"""
Canvaså­¦ä¹ ç³»ç»Ÿæ™ºèƒ½é”™è¯¯åˆ†ç±»å’Œè‡ªåŠ¨æ¢å¤
"""
from enum import Enum
from typing import Dict, Any, Optional, List, Callable
import time
import traceback
from dataclasses import dataclass

class ErrorCategory(Enum):
    """é”™è¯¯åˆ†ç±»æšä¸¾"""
    FILE_IO = "file_io"                    # æ–‡ä»¶è¾“å…¥è¾“å‡ºé”™è¯¯
    JSON_PARSE = "json_parse"              # JSONè§£æé”™è¯¯
    VALIDATION = "validation"              # éªŒè¯é”™è¯¯
    AGENT_CALL = "agent_call"              # Agentè°ƒç”¨é”™è¯¯
    LAYOUT_CALCULATION = "layout_calc"     # å¸ƒå±€è®¡ç®—é”™è¯¯
    NETWORK = "network"                    # ç½‘ç»œé”™è¯¯
    MEMORY = "memory"                      # å†…å­˜é”™è¯¯
    PERMISSION = "permission"              # æƒé™é”™è¯¯
    BUSINESS_LOGIC = "business_logic"      # ä¸šåŠ¡é€»è¾‘é”™è¯¯
    UNKNOWN = "unknown"                    # æœªçŸ¥é”™è¯¯

class ErrorSeverity(Enum):
    """é”™è¯¯ä¸¥é‡ç¨‹åº¦"""
    LOW = 1        # è½»å¾®é”™è¯¯ï¼Œå¯è‡ªåŠ¨æ¢å¤
    MEDIUM = 2     # ä¸­ç­‰é”™è¯¯ï¼Œéœ€è¦ç”¨æˆ·å¹²é¢„
    HIGH = 3       # ä¸¥é‡é”™è¯¯ï¼Œéœ€è¦ç«‹å³å¤„ç†
    CRITICAL = 4   # è‡´å‘½é”™è¯¯ï¼Œç³»ç»Ÿä¸å¯ç”¨

@dataclass
class ErrorInfo:
    """é”™è¯¯ä¿¡æ¯"""
    category: ErrorCategory
    severity: ErrorSeverity
    message: str
    exception: Optional[Exception]
    context: Dict[str, Any]
    timestamp: float
    recovery_attempts: int = 0
    max_recovery_attempts: int = 3

class ErrorClassifier:
    """é”™è¯¯åˆ†ç±»å™¨"""

    def __init__(self):
        self.classification_rules = self._setup_classification_rules()

    def _setup_classification_rules(self) -> Dict[str, Any]:
        """è®¾ç½®åˆ†ç±»è§„åˆ™"""
        return {
            # æ–‡ä»¶IOé”™è¯¯
            'FileNotFoundError': {
                'category': ErrorCategory.FILE_IO,
                'severity': ErrorSeverity.MEDIUM,
                'keywords': ['file', 'path', 'directory', 'not found']
            },
            'PermissionError': {
                'category': ErrorCategory.PERMISSION,
                'severity': ErrorSeverity.HIGH,
                'keywords': ['permission', 'denied', 'access']
            },

            # JSONé”™è¯¯
            'json.JSONDecodeError': {
                'category': ErrorCategory.JSON_PARSE,
                'severity': ErrorSeverity.MEDIUM,
                'keywords': ['json', 'decode', 'parse']
            },

            # ç½‘ç»œé”™è¯¯
            'ConnectionError': {
                'category': ErrorCategory.NETWORK,
                'severity': ErrorSeverity.MEDIUM,
                'keywords': ['connection', 'network', 'timeout']
            },

            # å†…å­˜é”™è¯¯
            'MemoryError': {
                'category': ErrorCategory.MEMORY,
                'severity': ErrorSeverity.CRITICAL,
                'keywords': ['memory', 'out of memory']
            },

            # Canvasç‰¹å®šé”™è¯¯
            'CanvasValidationError': {
                'category': ErrorCategory.VALIDATION,
                'severity': ErrorSeverity.MEDIUM,
                'keywords': ['canvas', 'validation', 'invalid']
            },
            'AgentCallError': {
                'category': ErrorCategory.AGENT_CALL,
                'severity': ErrorSeverity.HIGH,
                'keywords': ['agent', 'call', 'response']
            }
        }

    def classify_error(self, error: Exception, context: Dict[str, Any] = None) -> ErrorInfo:
        """åˆ†ç±»é”™è¯¯"""
        error_type = type(error).__name__
        error_message = str(error).lower()

        # æŸ¥æ‰¾åŒ¹é…çš„åˆ†ç±»è§„åˆ™
        category = ErrorCategory.UNKNOWN
        severity = ErrorSeverity.MEDIUM

        for rule_name, rule_config in self.classification_rules.items():
            if error_type == rule_name or any(keyword in error_message for keyword in rule_config['keywords']):
                category = rule_config['category']
                severity = rule_config['severity']
                break

        # ç‰¹æ®Šå¤„ç†é€»è¾‘
        if context:
            category, severity = self._apply_context_rules(category, severity, context)

        return ErrorInfo(
            category=category,
            severity=severity,
            message=str(error),
            exception=error,
            context=context or {},
            timestamp=time.time()
        )

    def _apply_context_rules(self, category: ErrorCategory, severity: ErrorSeverity, context: Dict[str, Any]) -> tuple:
        """åº”ç”¨ä¸Šä¸‹æ–‡è§„åˆ™"""
        # å¦‚æœæ˜¯ä¸´æ—¶æ–‡ä»¶æ“ä½œï¼Œé™ä½ä¸¥é‡ç¨‹åº¦
        if category == ErrorCategory.FILE_IO and context.get('is_temp_file'):
            severity = ErrorSeverity.LOW

        # å¦‚æœæ˜¯æµ‹è¯•ç¯å¢ƒï¼Œé™ä½ä¸¥é‡ç¨‹åº¦
        if context.get('environment') == 'test':
            severity = min(severity, ErrorSeverity.MEDIUM)

        return category, severity
```

### è‡ªåŠ¨æ¢å¤ç³»ç»Ÿ

```python
class RecoveryStrategy:
    """æ¢å¤ç­–ç•¥åŸºç±»"""

    def __init__(self, name: str):
        self.name = name

    def can_recover(self, error_info: ErrorInfo) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯ä»¥æ¢å¤"""
        raise NotImplementedError

    def recover(self, error_info: ErrorInfo) -> bool:
        """æ‰§è¡Œæ¢å¤æ“ä½œ"""
        raise NotImplementedError

class FileIORecoveryStrategy(RecoveryStrategy):
    """æ–‡ä»¶IOæ¢å¤ç­–ç•¥"""

    def __init__(self):
        super().__init__("FileIORecovery")

    def can_recover(self, error_info: ErrorInfo) -> bool:
        return error_info.category == ErrorCategory.FILE_IO

    def recover(self, error_info: ErrorInfo) -> bool:
        """æ–‡ä»¶IOé”™è¯¯æ¢å¤"""
        file_path = error_info.context.get('file_path')
        if not file_path:
            return False

        try:
            # ç­–ç•¥1: æ£€æŸ¥æ–‡ä»¶è·¯å¾„
            if not os.path.exists(os.path.dirname(file_path)):
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                return True

            # ç­–ç•¥2: æ£€æŸ¥æ–‡ä»¶æƒé™
            if not os.access(file_path, os.W_OK):
                # å°è¯•ä¿®æ”¹æƒé™
                os.chmod(file_path, 0o644)
                return True

            # ç­–ç•¥3: åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            if error_info.context.get('operation') == 'write':
                temp_path = file_path + '.tmp'
                with open(temp_path, 'w') as f:
                    f.write('{}')
                os.rename(temp_path, file_path)
                return True

        except Exception:
            pass

        return False

class JSONParseRecoveryStrategy(RecoveryStrategy):
    """JSONè§£ææ¢å¤ç­–ç•¥"""

    def __init__(self):
        super().__init__("JSONParseRecovery")

    def can_recover(self, error_info: ErrorInfo) -> bool:
        return error_info.category == ErrorCategory.JSON_PARSE

    def recover(self, error_info: ErrorInfo) -> bool:
        """JSONè§£æé”™è¯¯æ¢å¤"""
        json_content = error_info.context.get('json_content')
        if not json_content:
            return False

        try:
            # ç­–ç•¥1: å°è¯•ä¿®å¤å¸¸è§JSONé—®é¢˜
            import re
            fixed_content = json_content

            # ç§»é™¤æœ«å°¾å¤šä½™çš„é€—å·
            fixed_content = re.sub(r',(\s*[}\]])', r'\1', fixed_content)

            # å°è¯•è§£æä¿®å¤åçš„å†…å®¹
            import json
            json.loads(fixed_content)

            # å¦‚æœè§£ææˆåŠŸï¼Œæ›´æ–°ä¸Šä¸‹æ–‡
            error_info.context['fixed_json_content'] = fixed_content
            return True

        except Exception:
            # ç­–ç•¥2: è¿”å›é»˜è®¤ç©ºç»“æ„
            error_info.context['fixed_json_content'] = '{"nodes": [], "edges": []}'
            return True

class AgentCallRecoveryStrategy(RecoveryStrategy):
    """Agentè°ƒç”¨æ¢å¤ç­–ç•¥"""

    def __init__(self):
        super().__init__("AgentCallRecovery")

    def can_recover(self, error_info: ErrorInfo) -> bool:
        return error_info.category == ErrorCategory.AGENT_CALL

    def recover(self, error_info: ErrorInfo) -> bool:
        """Agentè°ƒç”¨é”™è¯¯æ¢å¤"""
        agent_name = error_info.context.get('agent_name')
        retry_count = error_info.context.get('retry_count', 0)

        if retry_count >= 3:
            return False

        # ç­–ç•¥1: å»¶è¿Ÿé‡è¯•
        time.sleep(2 ** retry_count)  # æŒ‡æ•°é€€é¿

        # ç­–ç•¥2: ä½¿ç”¨å¤‡ç”¨Agent
        backup_agents = {
            'oral-explanation': 'clarification-path',
            'clarification-path': 'four-level-explanation',
            'basic-decomposition': 'deep-decomposition'
        }

        if agent_name in backup_agents:
            error_info.context['backup_agent'] = backup_agents[agent_name]
            return True

        # ç­–ç•¥3: ä½¿ç”¨ç¼“å­˜ç»“æœ
        cache_key = error_info.context.get('cache_key')
        if cache_key:
            cached_result = self._get_cached_result(cache_key)
            if cached_result:
                error_info.context['cached_result'] = cached_result
                return True

        return False

    def _get_cached_result(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """è·å–ç¼“å­˜ç»“æœ"""
        # å®ç°ç¼“å­˜é€»è¾‘
        return None

class AutoRecoveryManager:
    """è‡ªåŠ¨æ¢å¤ç®¡ç†å™¨"""

    def __init__(self):
        self.strategies = [
            FileIORecoveryStrategy(),
            JSONParseRecoveryStrategy(),
            AgentCallRecoveryStrategy(),
        ]
        self.recovery_stats = {}

    def attempt_recovery(self, error_info: ErrorInfo) -> bool:
        """å°è¯•è‡ªåŠ¨æ¢å¤"""
        if error_info.recovery_attempts >= error_info.max_recovery_attempts:
            return False

        for strategy in self.strategies:
            if strategy.can_recover(error_info):
                try:
                    success = strategy.recover(error_info)
                    error_info.recovery_attempts += 1

                    # è®°å½•æ¢å¤ç»Ÿè®¡
                    strategy_name = strategy.name
                    if strategy_name not in self.recovery_stats:
                        self.recovery_stats[strategy_name] = {'attempts': 0, 'successes': 0}

                    self.recovery_stats[strategy_name]['attempts'] += 1
                    if success:
                        self.recovery_stats[strategy_name]['successes'] += 1

                    return success

                except Exception as recovery_error:
                    # è®°å½•æ¢å¤å¤±è´¥
                    logger.error(f"æ¢å¤ç­–ç•¥ {strategy.name} æ‰§è¡Œå¤±è´¥: {recovery_error}")
                    continue

        return False

    def get_recovery_stats(self) -> Dict[str, Any]:
        """è·å–æ¢å¤ç»Ÿè®¡"""
        stats = {}
        for strategy_name, data in self.recovery_stats.items():
            success_rate = data['successes'] / data['attempts'] if data['attempts'] > 0 else 0
            stats[strategy_name] = {
                'attempts': data['attempts'],
                'successes': data['successes'],
                'success_rate': success_rate
            }
        return stats
```

---

## ğŸ“ˆ æ€§èƒ½ç›‘æ§å’Œç“¶é¢ˆè¯†åˆ«ç³»ç»Ÿ

### æ€§èƒ½æŒ‡æ ‡æ”¶é›†

```python
"""
Canvaså­¦ä¹ ç³»ç»Ÿæ€§èƒ½ç›‘æ§
åŸºäºPrometheusæŒ‡æ ‡æ”¶é›†
"""
import time
import psutil
import threading
from typing import Dict, Any, Optional
from prometheus_client import Counter, Histogram, Gauge, start_http_server
from functools import wraps

class CanvasMetrics:
    """Canvasç³»ç»ŸæŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self):
        # æ“ä½œè®¡æ•°å™¨
        self.operation_counter = Counter(
            'canvas_operations_total',
            'Canvasæ“ä½œæ€»æ•°',
            ['operation', 'status', 'layer']
        )

        # å“åº”æ—¶é—´ç›´æ–¹å›¾
        self.response_histogram = Histogram(
            'canvas_operation_duration_ms',
            'Canvasæ“ä½œå“åº”æ—¶é—´(æ¯«ç§’)',
            ['operation', 'layer'],
            buckets=[10, 50, 100, 500, 1000, 5000, 10000, 30000]
        )

        # å†…å­˜ä½¿ç”¨é‡ä»ªè¡¨ç›˜
        self.memory_gauge = Gauge(
            'canvas_memory_usage_mb',
            'Canvasç³»ç»Ÿå†…å­˜ä½¿ç”¨é‡(MB)'
        )

        # æ–‡ä»¶å¤§å°ä»ªè¡¨ç›˜
        self.file_size_gauge = Gauge(
            'canvas_file_size_bytes',
            'Canvasæ–‡ä»¶å¤§å°(å­—èŠ‚)',
            ['canvas_file']
        )

        # èŠ‚ç‚¹æ•°é‡ä»ªè¡¨ç›˜
        self.node_count_gauge = Gauge(
            'canvas_node_count',
            'CanvasèŠ‚ç‚¹æ•°é‡',
            ['canvas_file', 'node_type']
        )

        # Agentè°ƒç”¨æŒ‡æ ‡
        self.agent_calls_counter = Counter(
            'canvas_agent_calls_total',
            'Agentè°ƒç”¨æ€»æ•°',
            ['agent_name', 'status']
        )

        self.agent_response_histogram = Histogram(
            'canvas_agent_response_time_ms',
            'Agentå“åº”æ—¶é—´(æ¯«ç§’)',
            ['agent_name'],
            buckets=[1000, 5000, 10000, 30000, 60000, 120000]
        )

        # é”™è¯¯è®¡æ•°å™¨
        self.error_counter = Counter(
            'canvas_errors_total',
            'Canvasé”™è¯¯æ€»æ•°',
            ['error_type', 'severity', 'layer']
        )

        # ç¼“å­˜æŒ‡æ ‡
        self.cache_hits_counter = Counter(
            'canvas_cache_hits_total',
            'ç¼“å­˜å‘½ä¸­æ¬¡æ•°',
            ['cache_type']
        )

        self.cache_misses_counter = Counter(
            'canvas_cache_misses_total',
            'ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°',
            ['cache_type']
        )

    def record_operation(self, operation: str, status: str, layer: str, duration_ms: float):
        """è®°å½•æ“ä½œæŒ‡æ ‡"""
        self.operation_counter.labels(
            operation=operation,
            status=status,
            layer=layer
        ).inc()

        self.response_histogram.labels(
            operation=operation,
            layer=layer
        ).observe(duration_ms)

    def record_agent_call(self, agent_name: str, status: str, response_time_ms: float):
        """è®°å½•Agentè°ƒç”¨æŒ‡æ ‡"""
        self.agent_calls_counter.labels(
            agent_name=agent_name,
            status=status
        ).inc()

        self.agent_response_histogram.labels(
            agent_name=agent_name
        ).observe(response_time_ms)

    def record_error(self, error_type: str, severity: str, layer: str):
        """è®°å½•é”™è¯¯æŒ‡æ ‡"""
        self.error_counter.labels(
            error_type=error_type,
            severity=severity,
            layer=layer
        ).inc()

    def update_memory_usage(self):
        """æ›´æ–°å†…å­˜ä½¿ç”¨é‡"""
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        self.memory_gauge.set(memory_mb)

    def update_file_metrics(self, canvas_file: str, file_size: int, node_counts: Dict[str, int]):
        """æ›´æ–°æ–‡ä»¶æŒ‡æ ‡"""
        self.file_size_gauge.labels(canvas_file=canvas_file).set(file_size)

        for node_type, count in node_counts.items():
            self.node_count_gauge.labels(
                canvas_file=canvas_file,
                node_type=node_type
            ).set(count)

# å…¨å±€æŒ‡æ ‡æ”¶é›†å™¨
canvas_metrics = CanvasMetrics()

def performance_monitor(operation: str, layer: str = "unknown"):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            status = "success"

            try:
                result = func(*args, **kwargs)
                return result
            except Exception as e:
                status = "error"
                canvas_metrics.record_error(
                    error_type=type(e).__name__,
                    severity="high",
                    layer=layer
                )
                raise
            finally:
                duration_ms = (time.time() - start_time) * 1000
                canvas_metrics.record_operation(operation, status, layer, duration_ms)

        return wrapper
    return decorator
```

### ç³»ç»Ÿèµ„æºç›‘æ§

```python
class ResourceMonitor:
    """ç³»ç»Ÿèµ„æºç›‘æ§å™¨"""

    def __init__(self, interval: int = 30):
        self.interval = interval
        self.monitoring = False
        self.monitor_thread = None

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if not self.monitoring:
            self.monitoring = True
            self.monitor_thread = threading.Thread(target=self._monitor_loop)
            self.monitor_thread.daemon = True
            self.monitor_thread.start()

    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()

    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            try:
                self._collect_metrics()
                time.sleep(self.interval)
            except Exception as e:
                logger.error(f"èµ„æºç›‘æ§å¼‚å¸¸: {e}")

    def _collect_metrics(self):
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)

        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()

        # ç£ç›˜ä½¿ç”¨æƒ…å†µ
        disk = psutil.disk_usage('/')

        # æ›´æ–°æŒ‡æ ‡
        canvas_metrics.update_memory_usage()

        # è®°å½•åˆ°æ—¥å¿—
        logger.info(
            f"ç³»ç»Ÿèµ„æºç›‘æ§ - CPU: {cpu_percent}%, "
            f"å†…å­˜: {memory.percent}%, "
            f"ç£ç›˜: {disk.percent}%"
        )

class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æå™¨"""

    def __init__(self):
        self.bottleneck_thresholds = {
            'response_time': 5000,  # 5ç§’
            'memory_usage': 500,    # 500MB
            'error_rate': 0.05,     # 5%
            'agent_response_time': 30000  # 30ç§’
        }

    def analyze_performance(self, metrics_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½æ•°æ®"""
        bottlenecks = []
        recommendations = []

        # åˆ†æå“åº”æ—¶é—´
        if 'response_times' in metrics_data:
            avg_response_time = sum(metrics_data['response_times']) / len(metrics_data['response_times'])
            if avg_response_time > self.bottleneck_thresholds['response_time']:
                bottlenecks.append({
                    'type': 'slow_response',
                    'value': avg_response_time,
                    'threshold': self.bottleneck_thresholds['response_time']
                })
                recommendations.append("è€ƒè™‘ä¼˜åŒ–ç®—æ³•æˆ–å¢åŠ ç¼“å­˜")

        # åˆ†æå†…å­˜ä½¿ç”¨
        if 'memory_usage' in metrics_data:
            memory_usage = metrics_data['memory_usage']
            if memory_usage > self.bottleneck_thresholds['memory_usage']:
                bottlenecks.append({
                    'type': 'high_memory',
                    'value': memory_usage,
                    'threshold': self.bottleneck_thresholds['memory_usage']
                })
                recommendations.append("è€ƒè™‘ä¼˜åŒ–å†…å­˜ä½¿ç”¨æˆ–å¢åŠ æµå¼å¤„ç†")

        # åˆ†æé”™è¯¯ç‡
        if 'operations' in metrics_data:
            total_ops = metrics_data['operations'].get('total', 0)
            error_ops = metrics_data['operations'].get('errors', 0)
            error_rate = error_ops / total_ops if total_ops > 0 else 0

            if error_rate > self.bottleneck_thresholds['error_rate']:
                bottlenecks.append({
                    'type': 'high_error_rate',
                    'value': error_rate,
                    'threshold': self.bottleneck_thresholds['error_rate']
                })
                recommendations.append("æ£€æŸ¥é”™è¯¯å¤„ç†é€»è¾‘ï¼Œå¢åŠ é‡è¯•æœºåˆ¶")

        return {
            'bottlenecks': bottlenecks,
            'recommendations': recommendations,
            'overall_health': self._calculate_health_score(bottlenecks)
        }

    def _calculate_health_score(self, bottlenecks: list) -> float:
        """è®¡ç®—ç³»ç»Ÿå¥åº·åˆ†æ•°"""
        base_score = 100.0

        for bottleneck in bottlenecks:
            if bottleneck['type'] == 'slow_response':
                base_score -= min(30, (bottleneck['value'] / bottleneck['threshold'] - 1) * 30)
            elif bottleneck['type'] == 'high_memory':
                base_score -= min(25, (bottleneck['value'] / bottleneck['threshold'] - 1) * 25)
            elif bottleneck['type'] == 'high_error_rate':
                base_score -= min(40, (bottleneck['value'] / bottleneck['threshold'] - 1) * 40)

        return max(0, base_score)
```

---

## ğŸ“Š è‡ªåŠ¨åŒ–é”™è¯¯æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ

### æŠ¥å‘Šç”Ÿæˆå™¨

```python
"""
Canvaså­¦ä¹ ç³»ç»Ÿè‡ªåŠ¨åŒ–é”™è¯¯æŠ¥å‘Šç”Ÿæˆ
"""
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional
import matplotlib.pyplot as plt
import seaborn as sns

class ErrorReportGenerator:
    """é”™è¯¯æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, report_dir: str = "reports"):
        self.report_dir = Path(report_dir)
        self.report_dir.mkdir(exist_ok=True)

    def generate_daily_report(self, date: Optional[datetime] = None) -> str:
        """ç”Ÿæˆæ—¥æŠ¥"""
        target_date = date or datetime.now().date()

        # æ”¶é›†æ•°æ®
        report_data = {
            'date': target_date.isoformat(),
            'summary': self._generate_summary(target_date),
            'error_analysis': self._analyze_errors(target_date),
            'performance_metrics': self._get_performance_metrics(target_date),
            'trends': self._analyze_trends(target_date),
            'recommendations': self._generate_recommendations(target_date)
        }

        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
        report_path = self._save_report(report_data, f"daily_report_{target_date.strftime('%Y%m%d')}")

        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self._generate_charts(report_data, target_date)

        return report_path

    def generate_weekly_report(self, week_start: Optional[datetime] = None) -> str:
        """ç”Ÿæˆå‘¨æŠ¥"""
        start_date = week_start or (datetime.now() - timedelta(days=datetime.now().weekday()))
        end_date = start_date + timedelta(days=6)

        # æ”¶é›†å‘¨æ•°æ®
        weekly_data = self._collect_weekly_data(start_date, end_date)

        report_data = {
            'week_start': start_date.isoformat(),
            'week_end': end_date.isoformat(),
            'weekly_summary': self._generate_weekly_summary(weekly_data),
            'error_patterns': self._analyze_weekly_errors(weekly_data),
            'performance_trends': self._analyze_weekly_performance(weekly_data),
            'system_health': self._calculate_system_health(weekly_data),
            'improvement_plan': self._generate_improvement_plan(weekly_data)
        }

        report_path = self._save_report(report_data, f"weekly_report_{start_date.strftime('%Y%m%d')}")
        self._generate_weekly_charts(report_data, start_date)

        return report_path

    def _generate_summary(self, date: datetime) -> Dict[str, Any]:
        """ç”Ÿæˆæ—¥æŠ¥æ‘˜è¦"""
        # ä»æ—¥å¿—æ–‡ä»¶æ”¶é›†æ•°æ®
        log_file = Path(f"logs/canvas_{date.strftime('%Y-%m-%d')}.log")

        if not log_file.exists():
            return {'status': 'no_data'}

        # åˆ†ææ—¥å¿—æ–‡ä»¶
        summary = {
            'total_operations': 0,
            'successful_operations': 0,
            'failed_operations': 0,
            'error_rate': 0.0,
            'average_response_time': 0.0,
            'top_errors': [],
            'peak_usage_time': None
        }

        # å®ç°æ—¥å¿—åˆ†æé€»è¾‘
        # ...

        return summary

    def _analyze_errors(self, date: datetime) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯"""
        error_file = Path(f"logs/errors_{date.strftime('%Y-%m-%d')}.log")

        if not error_file.exists():
            return {'status': 'no_errors'}

        # é”™è¯¯åˆ†æ
        error_analysis = {
            'total_errors': 0,
            'error_categories': {},
            'error_trend': [],
            'critical_errors': [],
            'recovered_errors': 0,
            'recovery_rate': 0.0
        }

        # å®ç°é”™è¯¯åˆ†æé€»è¾‘
        # ...

        return error_analysis

    def _get_performance_metrics(self, date: datetime) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        performance_metrics = {
            'response_times': {
                'min': 0,
                'max': 0,
                'avg': 0,
                'p95': 0,
                'p99': 0
            },
            'memory_usage': {
                'avg': 0,
                'peak': 0,
                'min': 0
            },
            'agent_performance': {},
            'canvas_file_metrics': {}
        }

        # å®ç°æ€§èƒ½æŒ‡æ ‡æ”¶é›†
        # ...

        return performance_metrics

    def _analyze_trends(self, date: datetime) -> Dict[str, Any]:
        """åˆ†æè¶‹åŠ¿"""
        # è·å–è¿‡å»7å¤©çš„æ•°æ®
        trend_data = {
            'error_rate_trend': [],
            'performance_trend': [],
            'usage_pattern': []
        }

        # å®ç°è¶‹åŠ¿åˆ†æ
        # ...

        return trend_data

    def _generate_recommendations(self, date: datetime) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # åŸºäºé”™è¯¯åˆ†æç”Ÿæˆå»ºè®®
        error_analysis = self._analyze_errors(date)
        if error_analysis.get('total_errors', 0) > 10:
            recommendations.append("å»ºè®®å¢åŠ é”™è¯¯ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶")

        # åŸºäºæ€§èƒ½æŒ‡æ ‡ç”Ÿæˆå»ºè®®
        performance = self._get_performance_metrics(date)
        if performance['response_times']['avg'] > 5000:
            recommendations.append("å»ºè®®ä¼˜åŒ–å“åº”æ—¶é—´ï¼Œè€ƒè™‘ä½¿ç”¨ç¼“å­˜")

        # åŸºäºä½¿ç”¨æ¨¡å¼ç”Ÿæˆå»ºè®®
        recommendations.extend(self._generate_usage_recommendations(date))

        return recommendations

    def _generate_usage_recommendations(self, date: datetime) -> List[str]:
        """ç”Ÿæˆä½¿ç”¨å»ºè®®"""
        # åˆ†æä½¿ç”¨æ¨¡å¼ï¼Œç”Ÿæˆé’ˆå¯¹æ€§å»ºè®®
        return [
            "å»ºè®®å®šæœŸæ¸…ç†ä¸´æ—¶æ–‡ä»¶",
            "å»ºè®®ä¼˜åŒ–å¤§æ–‡ä»¶çš„åŠ è½½ç­–ç•¥",
            "å»ºè®®å¢åŠ ç”¨æˆ·æ“ä½œæŒ‡å¯¼"
        ]

    def _save_report(self, data: Dict[str, Any], filename: str) -> str:
        """ä¿å­˜æŠ¥å‘Š"""
        # ä¿å­˜JSONæ ¼å¼
        json_path = self.report_dir / f"{filename}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        # ç”ŸæˆHTMLæ ¼å¼æŠ¥å‘Š
        html_path = self.report_dir / f"{filename}.html"
        html_content = self._generate_html_report(data)
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

        return str(html_path)

    def _generate_html_report(self, data: Dict[str, Any]) -> str:
        """ç”ŸæˆHTMLæ ¼å¼æŠ¥å‘Š"""
        html_template = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>Canvaså­¦ä¹ ç³»ç»Ÿé”™è¯¯æŠ¥å‘Š</title>
            <meta charset="utf-8">
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                .header { background-color: #f0f0f0; padding: 20px; border-radius: 5px; }
                .section { margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
                .metric { display: inline-block; margin: 10px; padding: 10px; background-color: #f9f9f9; border-radius: 3px; }
                .error { color: red; }
                .success { color: green; }
                .warning { color: orange; }
                table { width: 100%; border-collapse: collapse; }
                th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
                th { background-color: #f2f2f2; }
            </style>
        </head>
        <body>
            <div class="header">
                <h1>Canvaså­¦ä¹ ç³»ç»Ÿé”™è¯¯æŠ¥å‘Š</h1>
                <p>ç”Ÿæˆæ—¶é—´: {generation_time}</p>
                <p>æŠ¥å‘Šæ—¥æœŸ: {report_date}</p>
            </div>

            {content}

        </body>
        </html>
        """

        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        content = self._generate_html_content(data)

        return html_template.format(
            generation_time=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            report_date=data.get('date', data.get('week_start', 'Unknown')),
            content=content
        )

    def _generate_html_content(self, data: Dict[str, Any]) -> str:
        """ç”ŸæˆHTMLå†…å®¹"""
        content = ""

        # æ‘˜è¦éƒ¨åˆ†
        if 'summary' in data:
            content += "<div class='section'><h2>ç³»ç»Ÿæ‘˜è¦</h2>"
            summary = data['summary']
            if summary.get('status') != 'no_data':
                content += f"""
                <div class="metric">æ€»æ“ä½œæ•°: {summary.get('total_operations', 0)}</div>
                <div class="metric success">æˆåŠŸæ“ä½œ: {summary.get('successful_operations', 0)}</div>
                <div class="metric error">å¤±è´¥æ“ä½œ: {summary.get('failed_operations', 0)}</div>
                <div class="metric">é”™è¯¯ç‡: {summary.get('error_rate', 0):.2%}</div>
                <div class="metric">å¹³å‡å“åº”æ—¶é—´: {summary.get('average_response_time', 0):.2f}ms</div>
                """
            content += "</div>"

        # é”™è¯¯åˆ†æéƒ¨åˆ†
        if 'error_analysis' in data:
            content += "<div class='section'><h2>é”™è¯¯åˆ†æ</h2>"
            error_analysis = data['error_analysis']
            if error_analysis.get('status') != 'no_errors':
                content += f"""
                <div class="metric error">æ€»é”™è¯¯æ•°: {error_analysis.get('total_errors', 0)}</div>
                <div class="metric success">å·²æ¢å¤é”™è¯¯: {error_analysis.get('recovered_errors', 0)}</div>
                <div class="metric">æ¢å¤ç‡: {error_analysis.get('recovery_rate', 0):.2%}</div>
                """
            content += "</div>"

        # å»ºè®®éƒ¨åˆ†
        if 'recommendations' in data:
            content += "<div class='section'><h2>æ”¹è¿›å»ºè®®</h2><ul>"
            for recommendation in data['recommendations']:
                content += f"<li>{recommendation}</li>"
            content += "</ul></div>"

        return content

    def _generate_charts(self, data: Dict[str, Any], date: datetime):
        """ç”Ÿæˆå›¾è¡¨"""
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False

        # ç”Ÿæˆé”™è¯¯åˆ†å¸ƒå›¾
        if 'error_analysis' in data:
            self._generate_error_chart(data['error_analysis'], date)

        # ç”Ÿæˆæ€§èƒ½è¶‹åŠ¿å›¾
        if 'performance_metrics' in data:
            self._generate_performance_chart(data['performance_metrics'], date)

    def _generate_error_chart(self, error_data: Dict[str, Any], date: datetime):
        """ç”Ÿæˆé”™è¯¯åˆ†å¸ƒå›¾"""
        if not error_data.get('error_categories'):
            return

        categories = list(error_data['error_categories'].keys())
        counts = list(error_data['error_categories'].values())

        plt.figure(figsize=(10, 6))
        plt.bar(categories, counts)
        plt.title(f'é”™è¯¯åˆ†å¸ƒ - {date.strftime("%Y-%m-%d")}')
        plt.xlabel('é”™è¯¯ç±»åˆ«')
        plt.ylabel('é”™è¯¯æ•°é‡')
        plt.xticks(rotation=45)
        plt.tight_layout()

        chart_path = self.report_dir / f"error_distribution_{date.strftime('%Y%m%d')}.png"
        plt.savefig(chart_path)
        plt.close()

    def _generate_performance_chart(self, performance_data: Dict[str, Any], date: datetime):
        """ç”Ÿæˆæ€§èƒ½å›¾è¡¨"""
        if 'response_times' not in performance_data:
            return

        response_times = performance_data['response_times']

        plt.figure(figsize=(10, 6))
        metrics = ['æœ€å°å€¼', 'æœ€å¤§å€¼', 'å¹³å‡å€¼', 'P95', 'P99']
        values = [
            response_times['min'],
            response_times['max'],
            response_times['avg'],
            response_times['p95'],
            response_times['p99']
        ]

        plt.bar(metrics, values)
        plt.title(f'å“åº”æ—¶é—´åˆ†å¸ƒ - {date.strftime("%Y-%m-%d")} (æ¯«ç§’)')
        plt.ylabel('å“åº”æ—¶é—´ (ms)')

        chart_path = self.report_dir / f"performance_metrics_{date.strftime('%Y%m%d')}.png"
        plt.savefig(chart_path)
        plt.close()
```

---

## ğŸ”§ é›†æˆé…ç½®å’Œä½¿ç”¨æŒ‡å—

### ç»Ÿä¸€ç›‘æ§é…ç½®

```python
"""
Canvaså­¦ä¹ ç³»ç»Ÿç»Ÿä¸€ç›‘æ§é…ç½®
"""
import os
import logging
from .canvas_logger import CanvasLogConfig
from .canvas_sentry import CanvasSentryConfig
from .error_classifier import ErrorClassifier
from .auto_recovery import AutoRecoveryManager
from .performance_monitor import CanvasMetrics, ResourceMonitor
from .report_generator import ErrorReportGenerator

class CanvasMonitoringSystem:
    """Canvaså­¦ä¹ ç³»ç»Ÿç»Ÿä¸€ç›‘æ§ç®¡ç†"""

    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or self._load_default_config()

        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.logger = CanvasLogConfig()
        self.sentry = CanvasSentryConfig(
            environment=self.config.get('environment', 'development')
        )
        self.error_classifier = ErrorClassifier()
        self.recovery_manager = AutoRecoveryManager()
        self.metrics = CanvasMetrics()
        self.resource_monitor = ResourceMonitor()
        self.report_generator = ErrorReportGenerator()

        # å¯åŠ¨ç›‘æ§
        self._start_monitoring()

    def _load_default_config(self) -> Dict[str, Any]:
        """åŠ è½½é»˜è®¤é…ç½®"""
        return {
            'environment': os.getenv('ENVIRONMENT', 'development'),
            'sentry_dsn': os.getenv('SENTRY_DSN'),
            'log_level': os.getenv('LOG_LEVEL', 'INFO'),
            'monitoring_enabled': os.getenv('MONITORING_ENABLED', 'true').lower() == 'true',
            'auto_recovery_enabled': os.getenv('AUTO_RECOVERY_ENABLED', 'true').lower() == 'true',
            'performance_monitoring_enabled': os.getenv('PERFORMANCE_MONITORING_ENABLED', 'true').lower() == 'true',
            'report_generation_enabled': os.getenv('REPORT_GENERATION_ENABLED', 'true').lower() == 'true'
        }

    def _start_monitoring(self):
        """å¯åŠ¨ç›‘æ§"""
        if self.config.get('performance_monitoring_enabled'):
            self.resource_monitor.start_monitoring()

        # å¯åŠ¨Prometheus HTTPæœåŠ¡å™¨
        if self.config.get('prometheus_enabled', True):
            from prometheus_client import start_http_server
            start_http_server(8000)
            print("Prometheus metrics server started on port 8000")

    def handle_error(self, error: Exception, context: Dict[str, Any] = None) -> bool:
        """ç»Ÿä¸€é”™è¯¯å¤„ç†"""
        # åˆ†ç±»é”™è¯¯
        error_info = self.error_classifier.classify_error(error, context)

        # è®°å½•æ—¥å¿—
        self.logger.log_error_context(error, context)

        # å‘é€åˆ°Sentry
        self.sentry.capture_canvas_error(
            error=error,
            canvas_file=context.get('canvas_file'),
            operation=context.get('operation'),
            node_id=context.get('node_id'),
            context=context
        )

        # è®°å½•æŒ‡æ ‡
        self.metrics.record_error(
            error_type=type(error).__name__,
            severity=error_info.severity.name,
            layer=context.get('layer', 'unknown')
        )

        # å°è¯•è‡ªåŠ¨æ¢å¤
        if self.config.get('auto_recovery_enabled'):
            recovery_success = self.recovery_manager.attempt_recovery(error_info)
            if recovery_success:
                logger.info(f"é”™è¯¯è‡ªåŠ¨æ¢å¤æˆåŠŸ: {error}")
                return True

        return False

    def record_operation(self, operation: str, status: str, layer: str, duration_ms: float, **kwargs):
        """è®°å½•æ“ä½œ"""
        # è®°å½•æ—¥å¿—
        self.logger.log_canvas_operation(
            operation=operation,
            canvas_file=kwargs.get('canvas_file'),
            node_id=kwargs.get('node_id'),
            details=kwargs.get('details'),
            success=(status == 'success')
        )

        # è®°å½•æŒ‡æ ‡
        self.metrics.record_operation(operation, status, layer, duration_ms)

        # è®°å½•æ€§èƒ½æ—¥å¿—
        self.logger.log_performance(
            operation=operation,
            duration_ms=duration_ms,
            canvas_file=kwargs.get('canvas_file'),
            node_count=kwargs.get('node_count')
        )

    def generate_daily_report(self, date: datetime = None) -> str:
        """ç”Ÿæˆæ—¥æŠ¥"""
        if not self.config.get('report_generation_enabled'):
            logger.warning("æŠ¥å‘Šç”ŸæˆåŠŸèƒ½æœªå¯ç”¨")
            return ""

        return self.report_generator.generate_daily_report(date)

    def get_system_health(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        # æ”¶é›†å„ç§æŒ‡æ ‡
        health_status = {
            'timestamp': datetime.now().isoformat(),
            'overall_status': 'healthy',
            'components': {
                'logging': 'healthy',
                'error_handling': 'healthy',
                'performance': 'healthy',
                'recovery': 'healthy'
            },
            'metrics': {
                'error_rate': 0.0,
                'average_response_time': 0.0,
                'memory_usage': 0.0,
                'recovery_success_rate': 0.0
            },
            'alerts': []
        }

        # è·å–æ¢å¤ç»Ÿè®¡
        recovery_stats = self.recovery_manager.get_recovery_stats()
        health_status['metrics']['recovery_success_rate'] = recovery_stats.get('success_rate', 0.0)

        return health_status

    def shutdown(self):
        """å…³é—­ç›‘æ§ç³»ç»Ÿ"""
        if self.resource_monitor:
            self.resource_monitor.stop_monitoring()
        logger.info("Canvasç›‘æ§ç³»ç»Ÿå·²å…³é—­")

# å…¨å±€ç›‘æ§å®ä¾‹
canvas_monitoring = CanvasMonitoringSystem()
```

### ä½¿ç”¨ç¤ºä¾‹

```python
"""
Canvasç›‘æ§ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹
"""
from canvas_monitoring import canvas_monitoring
from canvas_utils import CanvasJSONOperator

# ä½¿ç”¨ç¤ºä¾‹1: è‡ªåŠ¨é”™è¯¯å¤„ç†
try:
    # Canvasæ“ä½œ
    canvas_op = CanvasJSONOperator()
    result = canvas_op.read_canvas("example.canvas")
except Exception as e:
    # è‡ªåŠ¨é”™è¯¯å¤„ç†å’Œæ¢å¤
    recovered = canvas_monitoring.handle_error(e, {
        'canvas_file': 'example.canvas',
        'operation': 'read_canvas',
        'layer': 'layer1'
    })

    if not recovered:
        # æ‰‹åŠ¨å¤„ç†æˆ–é€šçŸ¥ç”¨æˆ·
        print(f"æ“ä½œå¤±è´¥ï¼Œæ— æ³•è‡ªåŠ¨æ¢å¤: {e}")

# ä½¿ç”¨ç¤ºä¾‹2: æ€§èƒ½ç›‘æ§è£…é¥°å™¨
@canvas_monitoring.performance_monitor(operation="agent_call", layer="layer3")
def call_agent(agent_name: str, input_data: dict):
    """Agentè°ƒç”¨ - å¸¦æ€§èƒ½ç›‘æ§"""
    # Agentè°ƒç”¨é€»è¾‘
    pass

# ä½¿ç”¨ç¤ºä¾‹3: æ‰‹åŠ¨è®°å½•æ“ä½œ
canvas_monitoring.record_operation(
    operation="create_node",
    status="success",
    layer="layer1",
    duration_ms=150.5,
    canvas_file="example.canvas",
    node_id="node123",
    node_type="question"
)

# ä½¿ç”¨ç¤ºä¾‹4: ç”ŸæˆæŠ¥å‘Š
report_path = canvas_monitoring.generate_daily_report()
print(f"æ—¥æŠ¥å·²ç”Ÿæˆ: {report_path}")

# ä½¿ç”¨ç¤ºä¾‹5: æ£€æŸ¥ç³»ç»Ÿå¥åº·
health = canvas_monitoring.get_system_health()
print(f"ç³»ç»Ÿå¥åº·çŠ¶æ€: {health['overall_status']}")
```

---

## ğŸ“‹ éƒ¨ç½²å’Œé…ç½®æ¸…å•

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# ç¯å¢ƒé…ç½®
ENVIRONMENT=production                    # ç¯å¢ƒ: development/production
LOG_LEVEL=INFO                          # æ—¥å¿—çº§åˆ«: DEBUG/INFO/WARNING/ERROR

# Sentryé…ç½®
SENTRY_DSN=https://your-sentry-dsn     # Sentry DSN
SENTRY_ENVIRONMENT=production           # Sentryç¯å¢ƒ

# ç›‘æ§åŠŸèƒ½å¼€å…³
MONITORING_ENABLED=true                 # å¯ç”¨ç›‘æ§
AUTO_RECOVERY_ENABLED=true              # å¯ç”¨è‡ªåŠ¨æ¢å¤
PERFORMANCE_MONITORING_ENABLED=true     # å¯ç”¨æ€§èƒ½ç›‘æ§
REPORT_GENERATION_ENABLED=true          # å¯ç”¨æŠ¥å‘Šç”Ÿæˆ

# å‘Šè­¦é…ç½®
DINGTALK_WEBHOOK=https://oapi.dingtalk.com/robot/send?access_token=xxx
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
EMAIL_USERNAME=your-email@gmail.com
EMAIL_PASSWORD=your-app-password
ALERT_RECIPIENTS=admin@example.com,dev@example.com

# Prometheusé…ç½®
PROMETHEUS_ENABLED=true                 # å¯ç”¨PrometheusæŒ‡æ ‡
PROMETHEUS_PORT=8000                   # Prometheusç«¯å£
```

### ä¾èµ–åŒ…æ¸…å•

```txt
# requirements.txt è¿½åŠ å†…å®¹
loguru>=0.7.0
pysnooper>=1.2.0
sentry-sdk>=1.40.0
prometheus-client>=0.19.0
psutil>=5.9.0
matplotlib>=3.7.0
seaborn>=0.12.0
pandas>=2.0.0
redis>=4.6.0
```

### ç›®å½•ç»“æ„

```
C:/Users/ROG/æ‰˜ç¦/
â”œâ”€â”€ canvas_monitoring/                 # ç›‘æ§ç³»ç»Ÿæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ canvas_logger.py              # Loguruæ—¥å¿—é…ç½®
â”‚   â”œâ”€â”€ canvas_sentry.py              # Sentryé…ç½®
â”‚   â”œâ”€â”€ error_classifier.py           # é”™è¯¯åˆ†ç±»å™¨
â”‚   â”œâ”€â”€ auto_recovery.py              # è‡ªåŠ¨æ¢å¤ç³»ç»Ÿ
â”‚   â”œâ”€â”€ performance_monitor.py        # æ€§èƒ½ç›‘æ§
â”‚   â”œâ”€â”€ report_generator.py           # æŠ¥å‘Šç”Ÿæˆå™¨
â”‚   â””â”€â”€ monitoring_system.py          # ç»Ÿä¸€ç›‘æ§ç³»ç»Ÿ
â”‚
â”œâ”€â”€ logs/                              # æ—¥å¿—æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ canvas_YYYY-MM-DD.log         # å…¨éƒ¨æ—¥å¿—
â”‚   â”œâ”€â”€ errors_YYYY-MM-DD.log         # é”™è¯¯æ—¥å¿—
â”‚   â”œâ”€â”€ structured_YYYY-MM-DD.jsonl   # ç»“æ„åŒ–æ—¥å¿—
â”‚   â””â”€â”€ canvas_operations_YYYY-MM-DD.log  # Canvasæ“ä½œæ—¥å¿—
â”‚
â”œâ”€â”€ debug/                             # è°ƒè¯•è¿½è¸ªæ–‡ä»¶
â”‚   â”œâ”€â”€ layer1_json_trace_YYYYMMDD_HHMMSS.log
â”‚   â”œâ”€â”€ layer2_business_trace_YYYYMMDD_HHMMSS.log
â”‚   â””â”€â”€ layer3_agent_trace_YYYYMMDD_HHMMSS.log
â”‚
â”œâ”€â”€ reports/                           # é”™è¯¯æŠ¥å‘Šç›®å½•
â”‚   â”œâ”€â”€ daily_report_YYYYMMDD.html    # æ—¥æŠ¥
â”‚   â”œâ”€â”€ daily_report_YYYYMMDD.json    # æ—¥æŠ¥æ•°æ®
â”‚   â”œâ”€â”€ weekly_report_YYYYMMDD.html   # å‘¨æŠ¥
â”‚   â””â”€â”€ charts/                        # å›¾è¡¨æ–‡ä»¶
â”‚       â”œâ”€â”€ error_distribution_YYYYMMDD.png
â”‚       â””â”€â”€ performance_metrics_YYYYMMDD.png
â”‚
â””â”€â”€ monitoring_config/                 # ç›‘æ§é…ç½®æ–‡ä»¶
    â”œâ”€â”€ prometheus.yml                # Prometheusé…ç½®
    â”œâ”€â”€ grafana/                      # Grafanaä»ªè¡¨æ¿
    â”‚   â””â”€â”€ canvas-dashboard.json
    â””â”€â”€ alert_rules.yml               # å‘Šè­¦è§„åˆ™
```

### åˆå§‹åŒ–è„šæœ¬

```python
"""
monitoring_init.py - ç›‘æ§ç³»ç»Ÿåˆå§‹åŒ–è„šæœ¬
"""
import os
import sys
from pathlib import Path

def setup_monitoring():
    """åˆå§‹åŒ–ç›‘æ§ç³»ç»Ÿ"""
    print("åˆå§‹åŒ–Canvaså­¦ä¹ ç³»ç»Ÿç›‘æ§...")

    # åˆ›å»ºå¿…è¦ç›®å½•
    directories = [
        "logs",
        "debug",
        "reports",
        "reports/charts",
        "monitoring_config",
        "monitoring_config/grafana"
    ]

    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"âœ“ åˆ›å»ºç›®å½•: {directory}")

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    required_env_vars = [
        "ENVIRONMENT",
        "SENTRY_DSN"
    ]

    missing_vars = []
    for var in required_env_vars:
        if not os.getenv(var):
            missing_vars.append(var)

    if missing_vars:
        print(f"âš ï¸  è­¦å‘Š: ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
    else:
        print("âœ“ ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡")

    # åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶
    create_sample_configs()

    print("âœ“ ç›‘æ§ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("1. åœ¨ä»£ç ä¸­å¯¼å…¥: from canvas_monitoring import canvas_monitoring")
    print("2. é”™è¯¯å¤„ç†: canvas_monitoring.handle_error(error, context)")
    print("3. æ€§èƒ½ç›‘æ§: @canvas_monitoring.performance_monitor(operation='xxx')")

def create_sample_configs():
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    # Prometheusé…ç½®
    prometheus_config = """
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'canvas-learning-system'
    static_configs:
      - targets: ['localhost:8000']
"""

    with open("monitoring_config/prometheus.yml", "w") as f:
        f.write(prometheus_config)

    print("âœ“ åˆ›å»ºPrometheusé…ç½®æ–‡ä»¶")

if __name__ == "__main__":
    setup_monitoring()
```

---

## ğŸ¯ æ€»ç»“å’Œå»ºè®®

### ç³»ç»Ÿä¼˜åŠ¿

1. **å…¨é¢ç›‘æ§**: è¦†ç›–3å±‚æ¶æ„çš„æ‰€æœ‰å…³é”®æ“ä½œå’Œæ½œåœ¨é”™è¯¯ç‚¹
2. **å®æ—¶å“åº”**: é”™è¯¯å‘ç”Ÿæ—¶ç«‹å³æ£€æµ‹ã€è®°å½•å’Œå°è¯•è‡ªåŠ¨æ¢å¤
3. **æ™ºèƒ½åˆ†æ**: è‡ªåŠ¨åˆ†ç±»é”™è¯¯ï¼Œè¯†åˆ«æ¨¡å¼ï¼Œæä¾›é’ˆå¯¹æ€§æ¢å¤ç­–ç•¥
4. **æ€§èƒ½ä¼˜åŒ–**: å®æ—¶ç›‘æ§æ€§èƒ½æŒ‡æ ‡ï¼Œè¯†åˆ«ç“¶é¢ˆï¼Œæä¾›ä¼˜åŒ–å»ºè®®
5. **æ•°æ®é©±åŠ¨**: åŸºäºå†å²æ•°æ®ç”ŸæˆæŠ¥å‘Šï¼ŒæŒ‡å¯¼ç³»ç»Ÿå‡çº§å’Œä¼˜åŒ–

### å®æ–½å»ºè®®

1. **åˆ†é˜¶æ®µéƒ¨ç½²**:
   - ç¬¬ä¸€é˜¶æ®µ: éƒ¨ç½²åŸºç¡€æ—¥å¿—ç›‘æ§å’Œé”™è¯¯å¤„ç†
   - ç¬¬äºŒé˜¶æ®µ: é›†æˆSentryå®æ—¶ç›‘æ§å’Œå‘Šè­¦
   - ç¬¬ä¸‰é˜¶æ®µ: å¯ç”¨æ€§èƒ½ç›‘æ§å’Œè‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆ
   - ç¬¬å››é˜¶æ®µ: å®Œå–„æ™ºèƒ½æ¢å¤å’Œé¢„æµ‹åˆ†æ

2. **ç›‘æ§é‡ç‚¹**:
   - Canvasæ–‡ä»¶è¯»å†™æ“ä½œ
   - Agentè°ƒç”¨æˆåŠŸç‡
   - ç³»ç»Ÿå“åº”æ—¶é—´
   - å†…å­˜ä½¿ç”¨æƒ…å†µ
   - é”™è¯¯æ¢å¤æˆåŠŸç‡

3. **å‘Šè­¦é…ç½®**:
   - é”™è¯¯ç‡è¶…è¿‡5%æ—¶å‘Šè­¦
   - å“åº”æ—¶é—´è¶…è¿‡5ç§’æ—¶å‘Šè­¦
   - Agentè°ƒç”¨å¤±è´¥æ—¶ç«‹å³å‘Šè­¦
   - å†…å­˜ä½¿ç”¨è¶…è¿‡80%æ—¶å‘Šè­¦

### ç»´æŠ¤å»ºè®®

1. **å®šæœŸæ£€æŸ¥**: æ¯å‘¨æ£€æŸ¥ç›‘æ§æ•°æ®å’ŒæŠ¥å‘Š
2. **é…ç½®ä¼˜åŒ–**: æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´ç›‘æ§é˜ˆå€¼
3. **æ—¥å¿—æ¸…ç†**: å®šæœŸæ¸…ç†è¿‡æœŸæ—¥å¿—æ–‡ä»¶
4. **æ€§èƒ½è°ƒä¼˜**: åŸºäºç›‘æ§æ•°æ®æŒç»­ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½
5. **åŠŸèƒ½æ‰©å±•**: æ ¹æ®éœ€æ±‚å¢åŠ æ–°çš„ç›‘æ§æŒ‡æ ‡å’Œåˆ†æåŠŸèƒ½

è¿™ä¸ªä¼ä¸šçº§é”™è¯¯ç›‘æ§æ—¥å¿—ç³»ç»Ÿå°†ä¸ºCanvaså­¦ä¹ ç³»ç»Ÿæä¾›å®Œæ•´çš„å¯è§‚æµ‹æ€§ï¼Œå¸®åŠ©åŠæ—¶å‘ç°å’Œè§£å†³é—®é¢˜ï¼Œä¸ºç³»ç»Ÿçš„ç¨³å®šè¿è¡Œå’ŒæŒç»­ä¼˜åŒ–æä¾›å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚
```
TodoWrite
<arg_key>todos</arg_key>
<arg_value>[{"content": "è®¾è®¡ä¼ä¸šçº§é”™è¯¯ç›‘æ§æ¶æ„ï¼Œé›†æˆåˆ°ç°æœ‰3å±‚Pythonæ¶æ„", "status": "completed", "activeForm": "è®¾è®¡ä¼ä¸šçº§é”™è¯¯ç›‘æ§æ¶æ„ï¼Œé›†æˆåˆ°ç°æœ‰3å±‚Pythonæ¶æ„"}, {"content": "åˆ›å»ºåŸºäºLoguruçš„ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿé…ç½®", "status": "completed", "activeForm": "åˆ›å»ºåŸºäºLoguruçš„ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿé…ç½®"}, {"content": "è®¾è®¡åŸºäºPySnooperçš„å‡½æ•°çº§è°ƒè¯•è¿½è¸ªç³»ç»Ÿ", "status": "in_progress", "activeForm": "è®¾è®¡åŸºäºPySnooperçš„å‡½æ•°çº§è°ƒè¯•è¿½è¸ªç³»ç»Ÿ"}, {"content": "åˆ›å»ºåŸºäºSentryçš„å®æ—¶ç›‘æ§å‘Šè­¦ç³»ç»Ÿ", "status": "pending", "activeForm": "åˆ›å»ºåŸºäºSentryçš„å®æ—¶ç›‘æ§å‘Šè­¦ç³»ç»Ÿ"}, {"content": "è®¾è®¡æ™ºèƒ½é”™è¯¯åˆ†ç±»å’Œè‡ªåŠ¨æ¢å¤æœºåˆ¶", "status": "pending", "activeForm": "è®¾è®¡æ™ºèƒ½é”™è¯¯åˆ†ç±»å’Œè‡ªåŠ¨æ¢å¤æœºåˆ¶"}, {"content": "åˆ›å»ºæ€§èƒ½ç›‘æ§å’Œç“¶é¢ˆè¯†åˆ«ç³»ç»Ÿ", "status": "pending", "activeForm": "åˆ›å»ºæ€§èƒ½ç›‘æ§å’Œç“¶é¢ˆè¯†åˆ«ç³»ç»Ÿ"}, {"content": "è®¾è®¡è‡ªåŠ¨åŒ–é”™è¯¯æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ", "status": "pending", "activeForm": "è®¾è®¡è‡ªåŠ¨åŒ–é”™è¯¯æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ"}, {"content": "ç¼–å†™å®Œæ•´çš„é”™è¯¯ç›‘æ§é…ç½®å’Œä½¿ç”¨æ–‡æ¡£", "status": "pending", "activeForm": "ç¼–å†™å®Œæ•´çš„é”™è¯¯ç›‘æ§é…ç½®å’Œä½¿ç”¨æ–‡æ¡£"}]
