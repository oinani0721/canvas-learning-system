# Story 23.4: 多源融合 (教材+历史+跨Canvas)

## Status: Draft

## Epic Context & Background

**所属Epic**: EPIC-23 - RAG智能推理系统
**Epic文档**: [EPIC-23-RAG-INTELLIGENT-INFERENCE.md](../prd/EPIC-23-RAG-INTELLIGENT-INFERENCE.md)
**优先级**: P1 (High)
**估计**: 4 Story Points

**本Story在Epic中的定位**:
- Epic 23的**第四个也是最后一个Story**，实现多源信息融合
- 将教材上下文、学习历史、跨Canvas关联整合到RAG检索中
- **依赖**: Story 23.1 (导入修复), Story 23.2 (Embedding Pipeline), Story 23.3 (StateGraph配置)
- 这是Epic 23的**收尾Story**，完成后RAG系统功能完整

**Epic核心问题回顾**:

### Bug 7相关: 多源融合未连接

**现象**:
- Graphiti/LanceDB/Multimodal已集成 (Story 23.3)
- 但教材上下文、跨Canvas关联尚未接入RAG
- 检索结果缺少来源标注，用户无法判断信息来源

**当前状态** (src/agentic_rag/):
```
✅ graphiti_results: Graphiti知识图谱检索 (Story 23.1)
✅ lancedb_results: LanceDB向量检索 (Story 23.2)
✅ multimodal_results: 多模态检索 (Story 6.8)
❌ textbook_results: 教材上下文检索 (待实现)
❌ cross_canvas_results: 跨Canvas关联检索 (待实现)
❌ 来源标注: 融合结果未标注数据来源
```

**修复目标**: 扩展RAG系统支持5路并行检索，融合结果包含来源标注

---

## Story

**As a** Canvas学习系统,
**I want** 实现多源信息融合，将教材上下文、学习历史、跨Canvas关联整合到RAG检索中,
**so that** 用户能获得更全面的学习上下文，检索结果可追溯来源

---

## Acceptance Criteria

### AC 1: RAG支持教材上下文注入
- **Given**: 用户正在学习离散数学Canvas，且已关联教材PDF
- **When**: 执行RAG查询 "什么是逆否命题"
- **Then**:
  - `textbook_results` 包含教材中关于逆否命题的相关段落
  - 每个结果包含 `metadata.source = "textbook"` 标注
  - 支持PDF内容检索 (利用现有pdf_processor.py)
  - 延迟 < 500ms (单独检索)

### AC 2: RAG支持学习历史检索
- **Given**: 用户之前学习过"命题逻辑"相关Canvas
- **When**: 执行RAG查询 "什么是逆否命题"
- **Then**:
  - Graphiti时序知识图谱返回相关历史学习记录
  - 结果按时间衰减加权 (近期学习权重更高)
  - 每个结果包含 `metadata.source = "learning_history"` 标注

### AC 3: RAG支持跨Canvas关联
- **Given**: "离散数学.canvas" 与 "逻辑学基础.canvas" 存在概念关联
- **When**: 执行RAG查询关于共同概念
- **Then**:
  - `cross_canvas_results` 返回关联Canvas中的相关节点
  - 每个结果包含 `metadata.source = "cross_canvas"` 和 `metadata.canvas_file` 标注
  - 关联发现基于概念匹配或显式链接

### AC 4: 支持数据源权重配置
- **Given**: 用户希望调整不同数据源的重要性
- **When**: 配置 `source_weights = {"graphiti": 0.3, "lancedb": 0.25, "textbook": 0.25, "cross_canvas": 0.2}`
- **Then**:
  - 融合算法使用配置的权重
  - 权重通过 `runtime.context["source_weights"]` 传递
  - 未配置时使用默认权重 (均等分配)

### AC 5: 融合结果包含来源标注
- **Given**: 执行完整的多源RAG查询
- **When**: 获取 `fused_results`
- **Then**:
  - 每个结果包含 `metadata.sources: List[str]` (可能来自多个源)
  - 每个结果包含 `metadata.source_scores: Dict[str, float]` (各源贡献分数)
  - 可按来源过滤结果

---

## Tasks / Subtasks

### 任务1: 扩展CanvasRAGState支持多源输入 (AC: 1-5)
- [ ] 1.1: 在 `state.py` 添加 `textbook_results: Annotated[List[SearchResult], "教材检索结果"]`
- [ ] 1.2: 在 `state.py` 添加 `cross_canvas_results: Annotated[List[SearchResult], "跨Canvas检索结果"]`
- [ ] 1.3: 在 `SearchResult` 添加 `source` 和 `sources` 元数据字段规范
- [ ] 1.4: 添加 `source_weights` 可选配置字段

### 任务2: 实现TextbookRetriever节点 (AC: 1)
- [ ] 2.1: 创建 `backend/app/services/textbook_context_service.py`
- [ ] 2.2: 实现 `TextbookContextService.search()` 方法
- [ ] 2.3: 集成 `pdf_processor.py` 提取PDF内容
- [ ] 2.4: 在 `nodes.py` 添加 `retrieve_textbook` 节点函数
- [ ] 2.5: 结果添加 `source="textbook"` 标注
- [ ] 2.6: 测试延迟 < 500ms

### 任务3: 实现CrossCanvasRetriever节点 (AC: 3)
- [ ] 3.1: 创建 `backend/app/services/cross_canvas_service.py`
- [ ] 3.2: 实现 `CrossCanvasService.find_related_canvases()` 方法
- [ ] 3.3: 实现 `CrossCanvasService.search_related_nodes()` 方法
- [ ] 3.4: 在 `nodes.py` 添加 `retrieve_cross_canvas` 节点函数
- [ ] 3.5: 结果添加 `source="cross_canvas"` 和 `canvas_file` 标注
- [ ] 3.6: 实现概念匹配算法 (基于LanceDB向量相似度)

### 任务4: 扩展fan_out_retrieval支持5路并行 (AC: 1-3)
- [ ] 4.1: 修改 `state_graph.py` 的 `fan_out_retrieval` 函数
- [ ] 4.2: 添加 `Send("retrieve_textbook", state)`
- [ ] 4.3: 添加 `Send("retrieve_cross_canvas", state)`
- [ ] 4.4: 添加新节点到图 `builder.add_node("retrieve_textbook", ...)`
- [ ] 4.5: 添加边 `builder.add_edge("retrieve_textbook", "fuse_results")`
- [ ] 4.6: 添加边 `builder.add_edge("retrieve_cross_canvas", "fuse_results")`

### 任务5: 修改融合算法支持5路输入 (AC: 4, 5)
- [ ] 5.1: 扩展 `fuse_results` 节点接收5路结果
- [ ] 5.2: 实现 `_fuse_multi_source()` 函数
- [ ] 5.3: 支持从 `runtime.context["source_weights"]` 读取权重
- [ ] 5.4: 为每个结果添加 `sources` 和 `source_scores` 元数据
- [ ] 5.5: 实现结果去重 (相同doc_id合并)

### 任务6: 增强学习历史时间衰减 (AC: 2)
- [ ] 6.1: 在 `retrieve_graphiti` 节点添加时间衰减逻辑
- [ ] 6.2: 实现衰减公式: `weight = base_score * exp(-decay * days_ago)`
- [ ] 6.3: 配置衰减参数 `time_decay_factor` (默认0.05)
- [ ] 6.4: 结果添加 `source="learning_history"` 标注

### 任务7: 编写多源融合测试 (AC: 1-5)
- [ ] 7.1: 创建 `src/tests/test_multi_source_fusion.py`
- [ ] 7.2: 测试5路并行检索执行
- [ ] 7.3: 测试权重配置生效
- [ ] 7.4: 测试来源标注完整性
- [ ] 7.5: 测试端到端性能 < 2秒 (5路并行)

---

## Dev Notes

### Technical Context

**当前State结构** (src/agentic_rag/state.py:57-128):
```python
# ✅ Verified from state.py:57-128
class CanvasRAGState(MessagesState):
    # 现有检索结果字段
    graphiti_results: Annotated[List[SearchResult], "Graphiti知识图谱检索结果"]
    lancedb_results: Annotated[List[SearchResult], "LanceDB向量检索结果"]
    multimodal_results: Annotated[List[SearchResult], "多模态检索结果"]
    fused_results: Annotated[List[SearchResult], "融合算法输出结果"]
    reranked_results: Annotated[List[SearchResult], "Reranking后的最终结果"]

    # 需新增字段 (Story 23.4)
    # textbook_results: Annotated[List[SearchResult], "教材检索结果"]
    # cross_canvas_results: Annotated[List[SearchResult], "跨Canvas检索结果"]
```

**当前fan_out_retrieval** (src/agentic_rag/state_graph.py:47-67):
```python
# ✅ Verified from state_graph.py:47-67
def fan_out_retrieval(state: CanvasRAGState) -> list[Send]:
    """当前3路并行，需扩展为5路"""
    return [
        Send("retrieve_graphiti", state),
        Send("retrieve_lancedb", state),
        Send("retrieve_multimodal", state),
        # 需新增 (Story 23.4):
        # Send("retrieve_textbook", state),
        # Send("retrieve_cross_canvas", state),
    ]
```

**现有PDF处理器** (src/agentic_rag/processors/pdf_processor.py):
```python
# ✅ Verified from Glob: src/agentic_rag/processors/pdf_processor.py 存在
# 可复用于教材PDF内容提取
```

**现有融合实现** (src/agentic_rag/nodes.py:223-330):
```python
# ✅ Verified from nodes.py:223-330
async def fuse_results(state, runtime) -> Dict[str, Any]:
    """当前支持: graphiti + lancedb
       需扩展: graphiti + lancedb + multimodal + textbook + cross_canvas
    """
    graphiti_results = state.get("graphiti_results", [])
    lancedb_results = state.get("lancedb_results", [])
    # 需添加:
    # multimodal_results = state.get("multimodal_results", [])
    # textbook_results = state.get("textbook_results", [])
    # cross_canvas_results = state.get("cross_canvas_results", [])
```

### Data Sources Overview

| 数据源 | 服务 | 存储 | 用途 |
|--------|------|------|------|
| **教材上下文** | TextbookContextService (新建) | LanceDB + PDF | 教材/笔记内容语义检索 |
| **学习历史** | GraphitiClient (现有) | Neo4j | 时序记忆+概念关系检索 |
| **跨Canvas** | CrossCanvasService (新建) | LanceDB | 关联Canvas节点检索 |
| **当前Canvas** | LanceDBClient (现有) | LanceDB | 当前Canvas语义检索 |
| **多模态** | MultimodalRetriever (现有) | LanceDB | 图片/PDF多模态检索 |

### API Endpoints (if applicable)

无新增API端点。多源融合通过内部RAG节点实现，不暴露为HTTP端点。

### Data Models

**SearchResult扩展** (需在state.py中更新):
```python
# ✅ Based on state.py:43-51, 需扩展metadata
class SearchResult(TypedDict):
    doc_id: str
    content: str
    score: float
    metadata: Dict[str, Any]  # 需包含:
    # - source: str ("graphiti" | "lancedb" | "textbook" | "cross_canvas" | "multimodal")
    # - sources: List[str] (融合后可能来自多源)
    # - source_scores: Dict[str, float] (各源贡献分数)
    # - canvas_file: Optional[str] (跨Canvas来源)
    # - timestamp: Optional[str] (学习历史时间)
```

**SourceWeights配置** (新增到CanvasRAGConfig):
```python
# 需在config.py添加
source_weights: Dict[str, float] = {
    "graphiti": 0.25,
    "lancedb": 0.25,
    "textbook": 0.20,
    "cross_canvas": 0.15,
    "multimodal": 0.15
}
```

### SDD References

**OpenAPI参考**:
- specs/api/canvas-api.openapi.yml - Canvas节点结构 (无直接RAG端点)

**JSON Schema参考**:
- specs/data/canvas-node.schema.json#L17-L74 - Canvas节点结构定义 (用于跨Canvas检索)
- specs/data/agent-response.schema.json - Agent响应格式

**ADR参考**:
- docs/architecture/decisions/0002-langgraph-agents.md#L46-L78 - LangGraph StateGraph选型
  - StateGraph支持动态节点添加
  - Send模式支持灵活的并行分发
- docs/architecture/decisions/0003-graphiti-memory.md - Graphiti时序记忆决策
  - 时序知识图谱用于学习历史
- docs/architecture/decisions/0004-async-execution-engine.md - 异步并行执行
  - 5路并行检索的性能保证

### Implementation Guidelines

**Step 1: 扩展State定义**
```python
# ✅ Based on LangGraph Skill (Pattern: MessagesState extension)
# 文件: src/agentic_rag/state.py

class CanvasRAGState(MessagesState):
    # 现有字段保持不变...

    # 新增字段 (Story 23.4)
    textbook_results: Annotated[List[SearchResult], "教材检索结果"]
    cross_canvas_results: Annotated[List[SearchResult], "跨Canvas检索结果"]

    # 新增延迟字段
    textbook_latency_ms: Annotated[Optional[float], "教材检索延迟 (ms)"]
    cross_canvas_latency_ms: Annotated[Optional[float], "跨Canvas检索延迟 (ms)"]
```

**Step 2: 创建TextbookContextService**
```python
# 文件: backend/app/services/textbook_context_service.py
# ✅ Verified: 目录结构存在于backend/app/services/

from typing import List, Optional
from agentic_rag.state import SearchResult
from agentic_rag.processors.pdf_processor import PDFProcessor

class TextbookContextService:
    """教材上下文检索服务"""

    def __init__(self, lancedb_client, pdf_processor: Optional[PDFProcessor] = None):
        self.lancedb = lancedb_client
        self.pdf_processor = pdf_processor or PDFProcessor()

    async def search(
        self,
        query: str,
        canvas_file: str,
        num_results: int = 10
    ) -> List[SearchResult]:
        """
        搜索与Canvas关联的教材内容

        1. 获取Canvas关联的教材文件 (PDF/MD)
        2. 在LanceDB中搜索教材向量
        3. 返回结果并标注source="textbook"
        """
        # 获取关联教材 (从Canvas metadata或配置)
        textbook_files = await self._get_associated_textbooks(canvas_file)

        # 搜索教材向量表
        results = await self.lancedb.search(
            query=query,
            table_name="textbooks",
            filter={"file": {"$in": textbook_files}},
            num_results=num_results
        )

        # 添加来源标注
        for r in results:
            r["metadata"]["source"] = "textbook"

        return results

    async def _get_associated_textbooks(self, canvas_file: str) -> List[str]:
        """获取Canvas关联的教材文件列表"""
        # TODO: 从Canvas metadata或配置文件获取
        return []
```

**Step 3: 创建CrossCanvasService**
```python
# 文件: backend/app/services/cross_canvas_service.py

class CrossCanvasService:
    """跨Canvas关联检索服务"""

    def __init__(self, lancedb_client, graphiti_client):
        self.lancedb = lancedb_client
        self.graphiti = graphiti_client

    async def find_related_canvases(
        self,
        canvas_file: str,
        num_results: int = 5
    ) -> List[str]:
        """
        找到与当前Canvas相关的其他Canvas
        基于Graphiti概念关系或LanceDB向量相似度
        """
        # 从Graphiti查询概念关系
        related = await self.graphiti.search_nodes(
            query=f"canvas:{canvas_file}",
            num_results=num_results
        )

        # 提取关联Canvas文件列表
        canvas_files = list(set(
            r["metadata"].get("canvas_file")
            for r in related
            if r["metadata"].get("canvas_file") != canvas_file
        ))

        return canvas_files[:num_results]

    async def search_related_nodes(
        self,
        query: str,
        canvas_file: str,
        num_results: int = 10
    ) -> List[SearchResult]:
        """
        在关联Canvas中搜索相关节点
        """
        # 找到关联Canvas
        related_canvases = await self.find_related_canvases(canvas_file)

        if not related_canvases:
            return []

        # 在关联Canvas中搜索
        results = await self.lancedb.search_multiple_tables(
            query=query,
            filter={"canvas_file": {"$in": related_canvases}},
            num_results_per_table=num_results // len(related_canvases) + 1
        )

        # 添加来源标注
        for r in results:
            r["metadata"]["source"] = "cross_canvas"

        return results[:num_results]
```

**Step 4: 实现新检索节点**
```python
# 文件: src/agentic_rag/nodes.py (添加)
# ✅ Based on nodes.py:90-147 retrieve_graphiti 模式

async def retrieve_textbook(
    state: CanvasRAGState,
    runtime: Runtime[CanvasRAGConfig]
) -> Dict[str, Any]:
    """
    教材上下文检索节点

    ✅ Story 23.4 AC 1: 支持教材上下文注入
    """
    start_time = time.perf_counter()

    messages = state.get("messages", [])
    query = _extract_query(messages)
    canvas_file = state.get("canvas_file")
    batch_size = runtime.context.get("retrieval_batch_size", 10)

    try:
        service = await _get_textbook_service()
        textbook_results = await service.search(
            query=query,
            canvas_file=canvas_file,
            num_results=batch_size
        )
    except Exception:
        textbook_results = []

    latency_ms = (time.perf_counter() - start_time) * 1000

    return {
        "textbook_results": textbook_results,
        "textbook_latency_ms": latency_ms
    }


async def retrieve_cross_canvas(
    state: CanvasRAGState,
    runtime: Runtime[CanvasRAGConfig]
) -> Dict[str, Any]:
    """
    跨Canvas关联检索节点

    ✅ Story 23.4 AC 3: 支持跨Canvas关联
    """
    start_time = time.perf_counter()

    messages = state.get("messages", [])
    query = _extract_query(messages)
    canvas_file = state.get("canvas_file")
    batch_size = runtime.context.get("retrieval_batch_size", 10)

    try:
        service = await _get_cross_canvas_service()
        cross_canvas_results = await service.search_related_nodes(
            query=query,
            canvas_file=canvas_file,
            num_results=batch_size
        )
    except Exception:
        cross_canvas_results = []

    latency_ms = (time.perf_counter() - start_time) * 1000

    return {
        "cross_canvas_results": cross_canvas_results,
        "cross_canvas_latency_ms": latency_ms
    }
```

**Step 5: 扩展fan_out_retrieval**
```python
# 文件: src/agentic_rag/state_graph.py
# ✅ Based on state_graph.py:47-67

def fan_out_retrieval(state: CanvasRAGState) -> list[Send]:
    """
    Fan-out to 5-way parallel retrieval nodes (Story 23.4 扩展)

    ✅ Verified from LangGraph Skill (Pattern: Send for parallel execution)
    """
    return [
        Send("retrieve_graphiti", state),
        Send("retrieve_lancedb", state),
        Send("retrieve_multimodal", state),
        Send("retrieve_textbook", state),      # Story 23.4
        Send("retrieve_cross_canvas", state),  # Story 23.4
    ]
```

**Step 6: 扩展融合算法**
```python
# 文件: src/agentic_rag/nodes.py
# ✅ Based on nodes.py:223-330

async def fuse_results(
    state: CanvasRAGState,
    runtime: Runtime[CanvasRAGConfig]
) -> Dict[str, Any]:
    """
    融合算法节点 - 支持5路输入 (Story 23.4)
    """
    start_time = time.perf_counter()

    # 获取所有5路结果
    graphiti_results = state.get("graphiti_results", [])
    lancedb_results = state.get("lancedb_results", [])
    multimodal_results = state.get("multimodal_results", [])
    textbook_results = state.get("textbook_results", [])          # Story 23.4
    cross_canvas_results = state.get("cross_canvas_results", [])  # Story 23.4

    # 获取权重配置
    default_weights = {
        "graphiti": 0.25,
        "lancedb": 0.25,
        "textbook": 0.20,
        "cross_canvas": 0.15,
        "multimodal": 0.15
    }
    source_weights = runtime.context.get("source_weights", default_weights)

    # 多源融合
    fused_results = _fuse_multi_source(
        graphiti=graphiti_results,
        lancedb=lancedb_results,
        multimodal=multimodal_results,
        textbook=textbook_results,
        cross_canvas=cross_canvas_results,
        weights=source_weights
    )

    latency_ms = (time.perf_counter() - start_time) * 1000

    return {
        "fused_results": fused_results,
        "fusion_latency_ms": latency_ms
    }


def _fuse_multi_source(
    graphiti: List[SearchResult],
    lancedb: List[SearchResult],
    multimodal: List[SearchResult],
    textbook: List[SearchResult],
    cross_canvas: List[SearchResult],
    weights: Dict[str, float]
) -> List[SearchResult]:
    """
    多源加权融合算法

    1. 为每个结果添加source标注
    2. 按doc_id去重，合并多源结果
    3. 计算加权分数
    4. 排序返回Top-K

    ✅ Story 23.4 AC 4, 5
    """
    # 标注来源
    all_results = []
    for r in graphiti:
        r = dict(r)
        r["metadata"] = dict(r.get("metadata", {}))
        r["metadata"]["source"] = "graphiti"
        r["weighted_score"] = r["score"] * weights.get("graphiti", 0.2)
        all_results.append(r)

    for r in lancedb:
        r = dict(r)
        r["metadata"] = dict(r.get("metadata", {}))
        r["metadata"]["source"] = "lancedb"
        r["weighted_score"] = r["score"] * weights.get("lancedb", 0.2)
        all_results.append(r)

    for r in multimodal:
        r = dict(r)
        r["metadata"] = dict(r.get("metadata", {}))
        r["metadata"]["source"] = "multimodal"
        r["weighted_score"] = r["score"] * weights.get("multimodal", 0.2)
        all_results.append(r)

    for r in textbook:
        r = dict(r)
        r["metadata"] = dict(r.get("metadata", {}))
        r["metadata"]["source"] = "textbook"
        r["weighted_score"] = r["score"] * weights.get("textbook", 0.2)
        all_results.append(r)

    for r in cross_canvas:
        r = dict(r)
        r["metadata"] = dict(r.get("metadata", {}))
        r["metadata"]["source"] = "cross_canvas"
        r["weighted_score"] = r["score"] * weights.get("cross_canvas", 0.2)
        all_results.append(r)

    # 按doc_id去重并合并
    merged = {}
    for r in all_results:
        doc_id = r["doc_id"]
        if doc_id not in merged:
            merged[doc_id] = {
                "doc_id": doc_id,
                "content": r["content"],
                "score": r["weighted_score"],
                "metadata": {
                    "sources": [r["metadata"]["source"]],
                    "source_scores": {r["metadata"]["source"]: r["score"]},
                    **{k: v for k, v in r["metadata"].items() if k != "source"}
                }
            }
        else:
            # 合并分数
            merged[doc_id]["score"] += r["weighted_score"]
            merged[doc_id]["metadata"]["sources"].append(r["metadata"]["source"])
            merged[doc_id]["metadata"]["source_scores"][r["metadata"]["source"]] = r["score"]

    # 排序并返回
    results = list(merged.values())
    results.sort(key=lambda x: x["score"], reverse=True)

    return results[:10]
```

### Testing Requirements

**测试文件**: `src/tests/test_multi_source_fusion.py`

```python
"""
多源融合测试

✅ Story 23.4: 验证5路并行检索和多源融合
"""
import pytest
import time
from agentic_rag import canvas_agentic_rag
from agentic_rag.state import CanvasRAGState


class TestMultiSourceState:
    """AC 1-3: State扩展测试"""

    def test_state_has_textbook_field(self):
        """测试State包含textbook_results字段"""
        from agentic_rag.state import CanvasRAGState
        annotations = CanvasRAGState.__annotations__
        assert "textbook_results" in annotations

    def test_state_has_cross_canvas_field(self):
        """测试State包含cross_canvas_results字段"""
        from agentic_rag.state import CanvasRAGState
        annotations = CanvasRAGState.__annotations__
        assert "cross_canvas_results" in annotations


class TestTextbookRetrieval:
    """AC 1: 教材上下文检索测试"""

    @pytest.mark.asyncio
    async def test_textbook_retrieval_returns_results(self):
        """测试教材检索返回结果"""
        initial_state = {
            "messages": [{"role": "user", "content": "什么是逆否命题"}],
            "canvas_file": "离散数学.canvas",
        }

        result = await canvas_agentic_rag.ainvoke(initial_state)

        assert "textbook_results" in result
        assert isinstance(result["textbook_results"], list)

    @pytest.mark.asyncio
    async def test_textbook_results_have_source_annotation(self):
        """测试教材结果包含source标注"""
        initial_state = {
            "messages": [{"role": "user", "content": "命题逻辑"}],
            "canvas_file": "test.canvas",
        }

        result = await canvas_agentic_rag.ainvoke(initial_state)

        for r in result.get("textbook_results", []):
            assert r["metadata"].get("source") == "textbook"


class TestCrossCanvasRetrieval:
    """AC 3: 跨Canvas关联测试"""

    @pytest.mark.asyncio
    async def test_cross_canvas_retrieval_returns_results(self):
        """测试跨Canvas检索返回结果"""
        initial_state = {
            "messages": [{"role": "user", "content": "逻辑学"}],
            "canvas_file": "离散数学.canvas",
        }

        result = await canvas_agentic_rag.ainvoke(initial_state)

        assert "cross_canvas_results" in result
        assert isinstance(result["cross_canvas_results"], list)

    @pytest.mark.asyncio
    async def test_cross_canvas_results_have_canvas_file(self):
        """测试跨Canvas结果包含canvas_file标注"""
        initial_state = {
            "messages": [{"role": "user", "content": "测试"}],
            "canvas_file": "test.canvas",
        }

        result = await canvas_agentic_rag.ainvoke(initial_state)

        for r in result.get("cross_canvas_results", []):
            assert r["metadata"].get("source") == "cross_canvas"


class TestSourceWeights:
    """AC 4: 权重配置测试"""

    @pytest.mark.asyncio
    async def test_custom_source_weights(self):
        """测试自定义权重配置"""
        initial_state = {
            "messages": [{"role": "user", "content": "测试"}],
        }

        config = {
            "source_weights": {
                "graphiti": 0.4,
                "lancedb": 0.3,
                "textbook": 0.15,
                "cross_canvas": 0.1,
                "multimodal": 0.05
            }
        }

        result = await canvas_agentic_rag.ainvoke(initial_state, config=config)

        assert "fused_results" in result


class TestSourceAnnotation:
    """AC 5: 来源标注测试"""

    @pytest.mark.asyncio
    async def test_fused_results_have_sources_list(self):
        """测试融合结果包含sources列表"""
        initial_state = {
            "messages": [{"role": "user", "content": "测试"}],
        }

        result = await canvas_agentic_rag.ainvoke(initial_state)

        for r in result.get("fused_results", []):
            assert "sources" in r["metadata"]
            assert isinstance(r["metadata"]["sources"], list)

    @pytest.mark.asyncio
    async def test_fused_results_have_source_scores(self):
        """测试融合结果包含source_scores"""
        initial_state = {
            "messages": [{"role": "user", "content": "测试"}],
        }

        result = await canvas_agentic_rag.ainvoke(initial_state)

        for r in result.get("fused_results", []):
            assert "source_scores" in r["metadata"]
            assert isinstance(r["metadata"]["source_scores"], dict)


class TestMultiSourcePerformance:
    """性能测试"""

    @pytest.mark.asyncio
    async def test_5way_parallel_performance(self):
        """测试5路并行检索性能 < 2秒"""
        initial_state = {
            "messages": [{"role": "user", "content": "什么是逆否命题的定义？"}],
            "canvas_file": "test.canvas",
        }

        start = time.perf_counter()
        result = await canvas_agentic_rag.ainvoke(initial_state)
        elapsed = time.perf_counter() - start

        assert "fused_results" in result
        assert elapsed < 2.0, f"5-way parallel took {elapsed:.2f}s, expected < 2s"
```

### Dependencies

**Story依赖**:
- ✅ Story 23.1 (LangGraph导入问题修复) - 必须完成
- ✅ Story 23.2 (LanceDB Embedding Pipeline) - 必须完成
- ✅ Story 23.3 (StateGraph智能推理链配置) - 必须完成

**技术依赖**:
- Python 3.9+
- langgraph>=0.2.0
- lancedb>=0.3.0
- sentence-transformers>=2.2.0
- pytest>=7.0.0
- pytest-asyncio>=0.21.0

### Key Files to Modify

| 文件路径 | 修改类型 | 说明 |
|---------|---------|------|
| `src/agentic_rag/state.py` | 修改 | 添加textbook_results, cross_canvas_results字段 |
| `src/agentic_rag/state_graph.py` | 修改 | 扩展fan_out_retrieval为5路并行 |
| `src/agentic_rag/nodes.py` | 修改 | 添加retrieve_textbook, retrieve_cross_canvas节点，扩展fuse_results |
| `src/agentic_rag/config.py` | 修改 | 添加source_weights配置 |
| `backend/app/services/textbook_context_service.py` | 新建 | 教材上下文检索服务 |
| `backend/app/services/cross_canvas_service.py` | 新建 | 跨Canvas关联检索服务 |
| `src/tests/test_multi_source_fusion.py` | 新建 | 多源融合测试用例 |

### Anti-Hallucination Verification

**验证的文件路径**:
- ✅ `src/agentic_rag/state.py` - 已验证存在并读取 (128行)
- ✅ `src/agentic_rag/state_graph.py` - 已验证存在并读取 (295行)
- ✅ `src/agentic_rag/nodes.py` - 已验证存在并读取 (562行)
- ✅ `src/agentic_rag/config.py` - 已验证存在 (Glob结果)
- ✅ `src/agentic_rag/processors/pdf_processor.py` - 已验证存在 (Glob结果)
- ❌ `backend/app/services/textbook_context_service.py` - 不存在，需创建
- ❌ `backend/app/services/cross_canvas_service.py` - 不存在，需创建

**验证的API签名**:
- ✅ `StateGraph(state_schema, context_schema)` - 已验证 (state_graph.py:190-193)
- ✅ `Send(node_name, state)` - 已验证 (state_graph.py:63-67)
- ✅ `async def node(state, runtime) -> dict` - 已验证 (nodes.py:90-147)
- ✅ `runtime.context.get("key")` - 已验证 (nodes.py:127, 251)

**验证的LangGraph模式** (from LangGraph Skill):
- ✅ Pattern: StateGraph construction with context_schema
- ✅ Pattern: Send for parallel execution
- ✅ Pattern: Node returns dict with state updates
- ✅ Pattern: Annotated[Type, description] for state fields

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-12 | 1.0 | 初始创建 - SM Agent自动化batch模式 | Bob (SM Agent) |

---

## Dev Agent Record

### Agent Model Used
*待填写*

### Debug Log References
*待填写*

### Completion Notes List
*待填写*

### File List
*待填写*

---

## QA Results

*待QA Agent审查*

---

## Related Documentation

**Epic文档**:
- [EPIC-23-RAG-INTELLIGENT-INFERENCE.md](../prd/EPIC-23-RAG-INTELLIGENT-INFERENCE.md) - Epic 23完整PRD

**架构文档**:
- [coding-standards.md](../architecture/coding-standards.md) - 编码规范 (零幻觉开发规范)
- [tech-stack.md](../architecture/tech-stack.md) - 技术栈说明

**ADR参考**:
- [0002-langgraph-agents.md](../architecture/decisions/0002-langgraph-agents.md) - LangGraph StateGraph选型决策
- [0003-graphiti-memory.md](../architecture/decisions/0003-graphiti-memory.md) - Graphiti时序记忆决策
- [0004-async-execution-engine.md](../architecture/decisions/0004-async-execution-engine.md) - 异步并行执行决策

**技能参考**:
- LangGraph Skill: `.claude/skills/langgraph/SKILL.md` - StateGraph模式、Send模式
- Graphiti Skill: `.claude/skills/graphiti/SKILL.md` - 时序知识图谱

**前置Story**:
- Story 23.1: LangGraph导入问题修复
- Story 23.2: LanceDB Embedding Pipeline
- Story 23.3: StateGraph智能推理链配置
