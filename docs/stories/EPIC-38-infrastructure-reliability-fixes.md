# EPIC 38: Infrastructure Reliability Fixes

> **Origin:** Deep Explore å®¡è®¡å‘ç° 6 ä¸ªç³»ç»Ÿæ€§åŸºç¡€è®¾æ–½é—®é¢˜ï¼Œå…¨éƒ¨æºäº BMad æ¨¡æ¿ç›²åŒºï¼ˆD1-D6 ç»´åº¦ç¼ºå¤±ï¼‰ã€‚
> **Checklist applied:** `_bmad/bmm/checklists/infrastructure-ac-checklist.md` v1.0.0
> **Priority:** P1 â€” åŠŸèƒ½"çœ‹èµ·æ¥å·¥ä½œ"ä½†æ•°æ®å¯èƒ½ä¸¢å¤±/ä¸å®Œæ•´
> **Status:** âœ… Stories 38.1â€“38.7 å·²å®ç° | ğŸŸ¡ Story 38.8 å¾…å®ç° (JSONâ†’Neo4j åŒæ­¥)
> **Audit:** å¯¹æŠ—æ€§å®¡æ ¸å®Œæˆ (2026-02-08) â€” è¯¦è§ `docs/reviews/EPIC-38-adversarial-review.md`

---

## Epic Goal

ä¿®å¤ 6 ä¸ªå·²è¯†åˆ«çš„åŸºç¡€è®¾æ–½å¯é æ€§é—®é¢˜ï¼Œç¡®ä¿æ•°æ®æŒä¹…åŒ–ã€é”™è¯¯æ¢å¤ã€è¾“å…¥éªŒè¯ã€é…ç½®å®‰å…¨ã€é™çº§é€æ˜ã€ç«¯åˆ°ç«¯é›†æˆå…¨éƒ¨è¾¾æ ‡ã€‚

## Reliability Objectives (SLO)

> è¡¥å……è‡ªå¯¹æŠ—æ€§å®¡æ ¸ Finding #4 â€” å¯é‡åŒ–å¯é æ€§ç›®æ ‡

| Metric | Target | Measurement |
|--------|--------|-------------|
| **æ•°æ®æŒä¹…åŒ–ç‡** | 99.9% å­¦ä¹ äº‹ä»¶ä¸ä¸¢å¤± | `failed_writes.jsonl` + startup replay ä¿éšœ |
| **RTO (Recovery Time)** | < 30s åº”ç”¨é‡å¯åæ•°æ®å¯ç”¨ | Episode recovery + FSRS card cache restore |
| **RPO (Recovery Point)** | 0 (é›¶æ•°æ®ä¸¢å¤±) | JSON dual-write ç¡®ä¿ Neo4j å®•æœºæœŸé—´æ•°æ®å†™å…¥æ–‡ä»¶ |
| **é™çº§å»¶è¿Ÿä¸Šé™** | < 100ms JSON fallback å†™å…¥ | æ–‡ä»¶ I/Oï¼Œéç½‘ç»œè°ƒç”¨ |
| **è¯„åˆ†å†™å…¥è¶…æ—¶** | 15s (å« 3 æ¬¡é‡è¯• 7s + margin) | `MEMORY_WRITE_TIMEOUT=15.0` |

**æ³¨æ„**: ä»¥ä¸Šä¸ºå†…éƒ¨è¿ç»´ç›®æ ‡ï¼Œéé¢å‘ç”¨æˆ·çš„ SLA æ‰¿è¯ºã€‚

## Known Limitations & Tech Debt

> ä»¥ä¸‹ä¸ºå¯¹æŠ—æ€§å®¡æ ¸ (2026-02-08) å‘ç°çš„éé˜»å¡é—®é¢˜ï¼Œè®°å½•ä¸ºæŠ€æœ¯å€ºåŠ¡ã€‚

| # | ç±»å‹ | æè¿° | ä¼˜å…ˆçº§ | å¤‡æ³¨ |
|---|------|------|--------|------|
| 1 | é…ç½®è€¦åˆ | `ENABLE_GRAPHITI_JSON_DUAL_WRITE` åŒæ—¶æ§åˆ¶å­¦ä¹ äº‹ä»¶åŒå†™ (36.9) å’Œ Canvas é™çº§å†™å…¥ (38.5) | ğŸŸ¡ ä¸­ | å»ºè®®å¼•å…¥ç‹¬ç«‹ `ENABLE_CANVAS_EVENT_FALLBACK` é…ç½®é¡¹ |
| 2 | å¹¶å‘å®‰å…¨ | JSON fallback å¹¶å‘ä¿æŠ¤å·²å®ç°ï¼š`failed_writes.jsonl` ç”¨ `threading.Lock`ï¼Œ`canvas_service.py` ç”¨ per-canvas `asyncio.Lock` (L79-80) + `_locks_lock`ï¼Œ`memory_service.py` ç”¨ `_recovery_lock` (L153) | âœ… å·²è§£å†³ | ä»£ç éªŒè¯: 2026-02-08 deep explore ç¡®è®¤æ‰€æœ‰å†™å…¥è·¯å¾„æœ‰é”ä¿æŠ¤ |
| 3 | æ–‡ä»¶è½®è½¬ | JSON fallback æ–‡ä»¶æ— å¤§å°é™åˆ¶å’Œæ¸…ç†ç­–ç•¥ | ğŸŸ¢ ä½ | Story 38.8 AC-5 å®šä¹‰äº†è½®è½¬ç­–ç•¥ |
| 4 | å¯è§‚æµ‹æ€§ | å¤±è´¥å¤„ç†ä»… WARNING æ—¥å¿—ï¼Œæ—  Prometheus æŒ‡æ ‡æˆ–å‘Šè­¦ | ğŸŸ¢ ä½ | 38.6 "consider metric counter" æœªå‡çº§ä¸º AC |
| 5 | å‰åç«¯æ··åˆ | 38.3 AC-2 å¼•ç”¨ TypeScript æ–‡ä»¶ï¼ˆUI å±‚ï¼‰ä¸å±äºåŸºç¡€è®¾æ–½ EPIC | ğŸŸ¢ ä½ | å»ºè®®å…³è” EPIC-32 |
| 6 | Pending Queue | 38.1 AC-3 çš„ pending index queue ä½¿ç”¨å†…å­˜é˜Ÿåˆ—ï¼ˆ`asyncio.Queue`ï¼‰ï¼Œé‡å¯åç”± LanceDB è‡ªèº«æ¢å¤æœºåˆ¶ä¿éšœä¸€è‡´æ€§ | ğŸŸ¢ ä½ | LanceDB ç´¢å¼•å¯ä» Canvas æ–‡ä»¶é‡å»ºï¼Œæ— éœ€ç‹¬ç«‹æŒä¹…åŒ– queue |

## Requirements Covered

| FR | Description | Story |
|----|-------------|-------|
| FR-38.1 | LanceDB è‡ªåŠ¨ç´¢å¼•æ›´æ–° | 38.1 |
| FR-38.2 | å­¦ä¹ å†å²æŒä¹…åŒ–ä¸æ¢å¤ | 38.2 |
| FR-38.3 | FSRS çŠ¶æ€åˆå§‹åŒ–ä¿éšœ | 38.3 |
| FR-38.4 | Dual-write é»˜è®¤å®‰å…¨é…ç½® | 38.4 |
| FR-38.5 | Canvas CRUD é™çº§å†™å…¥ | 38.5 |
| FR-38.6 | è¯„åˆ†å†™å…¥å¯é æ€§ | 38.6 |
| FR-38.7 | ç«¯åˆ°ç«¯é›†æˆéªŒè¯ | 38.7 |
| FR-38.8 | JSON Fallback â†’ Neo4j å®Œæ•´åŒæ­¥ | 38.8 |

---

## Story 38.1: LanceDB è‡ªåŠ¨ç´¢å¼•è§¦å‘

> **Status:** âœ… Implemented | Commits: `c01bd39`, `14f0412`

As a learner,
I want my Canvas node changes to be automatically indexed in LanceDB,
So that RAG context retrieval always has up-to-date content without manual API calls.

### Acceptance Criteria

**AC-1 (D1: Persistence â€” Write Trigger)**
**Given** a Canvas node is created or updated via the API
**When** the backend processes the CRUD request
**Then** a LanceDB index update is triggered automatically (async, non-blocking)
**And** the index update completes within 5 seconds of the CRUD operation
**And** no manual POST `/metadata/index` call is required

**AC-2 (D2: Resilience â€” Failure Handling)**
**Given** the automatic LanceDB index update fails (connection error, timeout)
**When** the error occurs
**Then** the CRUD operation still succeeds (index failure must not block CRUD)
**And** the failed index update is queued for retry (max 3 attempts, exponential backoff)
**And** a WARNING log is emitted: `"LanceDB index update failed for node {id}, queued for retry"`

**AC-3 (D1: Persistence â€” Startup Recovery)**
**Given** the application restarts with pending index updates in the queue
**When** the application starts
**Then** pending updates are retried during startup
**And** a startup log shows: `"LanceDB: {N} pending index updates recovered"`

### Code References

| File | Line | Current Behavior |
|------|------|-----------------|
| `backend/app/api/v1/endpoints/metadata.py` | L253-370 | POST `/metadata/index` â€” manual only |
| `backend/app/api/v1/endpoints/canvas.py` | L83-220 | Canvas CRUD â€” no LanceDB trigger |

### Implementation Notes

- Hook into CanvasService CRUD methods (add_node, update_node) to emit index event
- Use `asyncio.create_task()` with error callback (not bare fire-and-forget)
- Consider debouncing rapid updates (e.g., 500ms window)

---

## Story 38.2: Learning History Persistence & Restart Recovery

> **Status:** âœ… Implemented | Commits: `803793c`, `f9fb7e3`

As a learner,
I want my learning history to survive application restarts,
So that my progress is never lost and AI context always has my full history.

### Acceptance Criteria

**AC-1 (D1: Persistence â€” Storage Location)**
**Given** a learning event is recorded via `record_episode_to_neo4j()`
**When** the event is appended to `self._episodes`
**Then** the event is also persisted to Neo4j (already done) **AND** the `_episodes` cache is recoverable from Neo4j on restart
**And** storage location: Neo4j (primary), `self._episodes` (runtime cache only)

**AC-2 (D1: Persistence â€” Restart Recovery)**
**Given** the application restarts
**When** `MemoryService` initializes
**Then** `self._episodes` is populated from Neo4j (query recent episodes, limit 1000)
**And** `get_learning_history()` returns non-empty results if previous sessions exist
**And** a startup log shows: `"MemoryService: recovered {N} episodes from Neo4j"`

**AC-3 (D5: Degradation â€” Neo4j Unavailable at Startup)**
**Given** Neo4j is unavailable when the application starts
**When** `MemoryService` attempts to recover episodes
**Then** `self._episodes` remains empty (graceful degradation)
**And** a WARNING log is emitted: `"MemoryService: Neo4j unavailable, starting with empty history"`
**And** new episodes recorded during this session are still appended to `self._episodes`
**And** recovery is re-attempted when Neo4j becomes available (lazy recovery on first query)

### Code References

| File | Line | Current Behavior |
|------|------|-----------------|
| `backend/app/services/memory_service.py` | L138 | `self._episodes: List[Dict] = []` â€” always starts empty |
| `backend/app/services/memory_service.py` | L369 | `self._episodes.append(episode)` â€” memory only |
| `backend/app/services/memory_service.py` | L394-467 | `get_learning_history()` â€” reads from `self._episodes` only |

### Implementation Notes

- Add `async def _recover_episodes_from_neo4j()` called in `__init__` or first access
- Neo4j query: `MATCH (e:Episode) WHERE e.user_id = $uid RETURN e ORDER BY e.timestamp DESC LIMIT 1000`
- If Neo4j is down at init, set `self._episodes_recovered = False` and retry on first `get_learning_history()` call

---

## Story 38.3: FSRS State Initialization Guarantee

> **Status:** âœ… Implemented | Commits: `4867dd0`, `f9fb7e3`

As a learner,
I want the review priority calculation to always use real FSRS data when available,
So that my review schedule is truly personalized, not falling back to a fixed score.

### Acceptance Criteria

**AC-1 (D3: Input Validation â€” Non-null Guarantee)**
**Given** a review item is requested for the dashboard
**When** the backend queries FSRS state for a concept
**Then** if a valid FSRS card exists, `fsrs_state` is returned with all fields non-null
**And** if no FSRS card exists and auto-creation fails (AC-4), the response is `{found: false, reason: "auto_creation_failed"}`
**And** if `_fsrs_manager` is None, the response is `{found: false, reason: "fsrs_not_initialized"}`
> **Note:** AC-4 è‡ªåŠ¨åˆ›å»ºä½¿ `no_card_created` åˆ†æ”¯ç†è®ºä¸Šä¸å¯è¾¾ã€‚AC-1 ä»…è¦†ç›–è‡ªåŠ¨åˆ›å»ºæœ¬èº«å¤±è´¥çš„é˜²å¾¡è·¯å¾„ã€‚

**AC-2 (D3: Input Validation â€” Frontend Contract)**
> **è·¨ EPIC å¼•ç”¨**: å‰ç«¯ UI å˜æ›´å±äº EPIC-32 (Ebbinghaus Review System Enhancement) èŒƒç•´ã€‚
> æœ¬ AC ä»…å®šä¹‰åç«¯å¥‘çº¦ï¼Œå‰ç«¯å®ç°ç”± EPIC-32 è´Ÿè´£ã€‚

**Given** the frontend receives a review item with `fsrs_state: null`
**When** `calculatePriority()` is called
**Then** the FSRS dimension uses a default score of 50 (existing behavior â€” validated as correct)
**And** the UI shows an indicator: "FSRS data unavailable" next to the priority score
**And** the `reason` field from the backend is logged to console for debugging

**AC-3 (D5: Degradation â€” FSRS Manager Initialization)**
**Given** the application starts
**When** `ReviewService` initializes `_fsrs_manager`
**Then** if initialization succeeds, log: `"FSRS manager initialized successfully"`
**And** if initialization fails, log WARNING: `"FSRS manager failed to initialize: {reason}"`
**And** the `/health` endpoint includes `fsrs: "ok"` or `fsrs: "degraded"`

**AC-4 (D4: Configuration â€” Auto Card Creation)**
**Given** a concept enters the review system for the first time
**When** no FSRS card exists for this concept
**Then** a default FSRS card is automatically created (stability=1.0, difficulty=5.0, state=New)
**And** subsequent queries for this concept return `{found: true}` with real data

### Code References

| File | Line | Current Behavior |
|------|------|-----------------|
| `backend/app/services/review_service.py` | L1693-1768 | `get_fsrs_state()` â€” returns `{found: False}` when no card |
| `backend/app/api/v1/endpoints/review.py` | L985-1034 | API endpoint â€” converts to `fsrs_state=None` |
| `canvas-progress-tracker/.../PriorityCalculatorService.ts` | L282-287 | `if (!state) â†’ score: 50` (default) |
| `canvas-progress-tracker/.../TodayReviewListService.ts` | L714-768 | `queryFSRSStateForPriority()` â€” returns null on not found |

### Implementation Notes

- AC-4 is the root fix: create default FSRS cards when concepts enter the review system
- AC-1/AC-2 are defense-in-depth for cases where card creation fails
- Consider batch card creation for existing concepts without FSRS cards (migration)

---

## Story 38.4: Dual-Write Default Configuration Safety

> **Status:** âœ… Implemented | Commits: `e784a71`, `c01bd39`

As an operator deploying the system,
I want dual-write to JSON fallback to be enabled by default,
So that a fresh installation has Neo4j offline resilience out of the box.

### Acceptance Criteria

**AC-1 (D4: Configuration â€” Safe Default)**
**Given** a fresh installation with no `.env` file customization
**When** the application starts
**Then** `ENABLE_GRAPHITI_JSON_DUAL_WRITE` defaults to `true`
**And** the startup log shows: `"Dual-write: enabled (default)"`

**AC-2 (D4: Configuration â€” Explicit Disable)**
**Given** an operator sets `ENABLE_GRAPHITI_JSON_DUAL_WRITE=false` in `.env`
**When** the application starts
**Then** dual-write is disabled as configured
**And** the startup log shows: `"Dual-write: disabled (explicit configuration)"`
**And** a WARNING log is emitted: `"JSON fallback is disabled. Neo4j outage will cause data loss."`

**AC-3 (D4: Configuration â€” Missing Env Var)**
**Given** the `ENABLE_GRAPHITI_JSON_DUAL_WRITE` environment variable is not set
**When** the Settings class initializes
**Then** the default value is `True` (safe default)
**And** behavior is identical to AC-1

### Code References

| File | Line | Current Behavior |
|------|------|-----------------|
| `backend/app/config.py` | L409-412 | `ENABLE_GRAPHITI_JSON_DUAL_WRITE: bool = Field(default=False)` |
| `backend/app/services/memory_service.py` | L376-386 | `record_learning_event()` checks this flag |
| `backend/app/services/memory_service.py` | L990-1004 | `record_temporal_event()` checks this flag |

### Implementation Notes

- **One-line fix**: Change `default=False` to `default=True` in `config.py:L410`
- Add startup log in `main.py` or `dependencies.py` to announce dual-write status
- Add WARNING when explicitly disabled
- Update `.env.example` to document this flag

---

## Story 38.5: Canvas CRUD Graceful Degradation with JSON Fallback

> **Status:** âœ… Implemented | Commits: `5026488`, `c01bd39`

As a learner,
I want my Canvas editing actions to be recorded even when Neo4j is unavailable,
So that my knowledge graph is eventually complete regardless of infrastructure status.

### Acceptance Criteria

**AC-1 (D5: Degradation â€” Memory Client None)**
**Given** `CanvasService._memory_client` is None (no memory system configured)
**When** a Canvas CRUD event occurs (create/update/delete node or edge)
**Then** if `ENABLE_GRAPHITI_JSON_DUAL_WRITE` is true, the event is written to JSON fallback
**And** the CRUD operation completes successfully
**And** a WARNING log (not DEBUG) is emitted: `"Memory client unavailable, writing to JSON fallback"`

**AC-2 (D5: Degradation â€” Neo4j Down but Memory Client Exists)**
**Given** `CanvasService._memory_client` exists but `memory_client.neo4j` is None or Neo4j is unreachable
**When** a Canvas CRUD event occurs
**Then** the event is written to JSON fallback (if dual-write enabled)
**And** the CRUD operation completes successfully
**And** a WARNING log is emitted: `"Neo4j unreachable, event written to JSON fallback"`

**AC-3 (D5: Degradation â€” Health Visibility)**
**Given** Canvas CRUD is operating in degraded mode (JSON fallback only)
**When** the `/health` endpoint is queried
**Then** the response includes `canvas_events: "degraded"` with `fallback: "json"`

**AC-4 (D2: Resilience â€” Log Level Upgrade)**
**Given** Canvas CRUD events are being skipped due to missing dependencies
**When** the skip occurs
**Then** the log level is WARNING (not DEBUG)
**And** the log message includes the event type and affected node/edge ID

### Code References

| File | Line | Current Behavior |
|------|------|-----------------|
| `backend/app/services/canvas_service.py` | L173-175 | `if _memory_client is None: return` â€” silent skip |
| `backend/app/services/canvas_service.py` | L278-286 | `_sync_edge_to_neo4j_with_retry()` â€” skip if None |

### Implementation Notes

- Refactor `_trigger_memory_event()`: before `return`, check if JSON fallback is enabled
- JSON fallback writes to `backend/data/canvas_events_fallback.json`
- Upgrade `logger.debug` â†’ `logger.warning` for all skip paths
- Add fallback write function that doesn't require memory_client

---

## Story 38.6: Scoring Write Reliability (Timeout vs Retry Fix)

> **Status:** âœ… Implemented | Commits: `3bd7a66`, `e784a71`

As a learner,
I want my quiz scores to be reliably saved after submission,
So that my learning progress is accurately tracked and not silently lost.

### Acceptance Criteria

**AC-1 (D2: Resilience â€” Timeout-Retry Alignment)**
**Given** a score is submitted and the memory write is triggered
**When** `_write_with_timeout()` executes
**Then** the timeout is >= 10 seconds (not 2 seconds)
**And** the internal retry mechanism (3 retries, exponential backoff 1s/2s/4s = 7s total) can complete within the timeout
**And** the timeout formula: `timeout >= sum(backoff) + margin` = `7s + 3s = 10s`

**AC-2 (D2: Resilience â€” Task Failure Tracking)**
**Given** a memory write task fails after all retries
**When** the final failure occurs
**Then** the failed write is recorded to a local fallback file: `data/failed_writes.jsonl`
**And** each entry includes: `{timestamp, event_type, concept_id, score, error_reason}`
**And** a WARNING log is emitted: `"Score write failed after 3 retries, saved to fallback: {concept_id}"`

**AC-3 (D2: Resilience â€” Fallback Recovery)**
**Given** failed writes exist in `data/failed_writes.jsonl`
**When** the application starts (or a recovery endpoint is called)
**Then** the system attempts to replay failed writes
**And** successfully replayed entries are removed from the fallback file
**And** a startup log shows: `"Recovered {N} failed writes, {M} still pending"`

**AC-4 (D6: Integration â€” User Feedback)**
**Given** a score write fails silently in the background
**When** the user checks their learning history
**Then** scores from the fallback file are included in the query results (merged view)
**And** the user never sees a "missing score" gap

### Code References

| File | Line | Current Behavior |
|------|------|-----------------|
| `backend/app/services/agent_service.py` | L3047-3059 | `asyncio.wait_for(timeout=2.0)` â€” too short for retry |
| `backend/app/services/agent_service.py` | L3066-3072 | `asyncio.create_task()` â€” no failure tracking |
| `backend/app/services/memory_service.py` | `_write_to_neo4j_with_retry()` | 3 retries, exponential backoff |

### Implementation Notes

- **Quick fix**: Change `timeout=2.0` â†’ `timeout=10.0` in `agent_service.py:L3051`
- **Full fix**: Add `failed_writes.jsonl` fallback and startup recovery
- Consider adding a metric counter for failed writes (observable via /health)

---

## Story 38.7: End-to-End Integration Verification

> **Status:** âœ… Implemented | Commits: `a29148c`, `cd28f0b`

As a developer,
I want to verify all Stories in this EPIC work together end-to-end,
So that the infrastructure reliability fixes are truly complete.

### Acceptance Criteria

**AC-1 (D6: Integration â€” Fresh Environment)**
**Given** a fresh environment with default configuration (no `.env` overrides)
**When** the application starts
**Then** dual-write is enabled (Story 38.4)
**And** FSRS manager is initialized (Story 38.3)
**And** startup log confirms: episodes recovered, dual-write enabled, FSRS ok

**AC-2 (D6: Integration â€” Full Learning Flow)**
**Given** the application is running
**When** a complete learning flow is executed:
  1. Create a Canvas node
  2. Start a learning session on that node
  3. Submit a quiz answer and receive a score
  4. Check the review dashboard for priority
**Then** the Canvas node is auto-indexed in LanceDB (Story 38.1)
**And** the learning event is in `get_learning_history()` (Story 38.2)
**And** the score is persisted (Story 38.6)
**And** the review priority uses real FSRS data (Story 38.3)

**AC-3 (D6: Integration â€” Restart Survival)**
**Given** the learning flow from AC-2 has completed
**When** the application is restarted
**Then** `get_learning_history()` returns the previously recorded events (Story 38.2)
**And** FSRS cards are still queryable (Story 38.3)
**And** LanceDB index is still valid (Story 38.1)

**AC-4 (D6: Integration â€” Degraded Mode)**
**Given** Neo4j is stopped (simulating infrastructure failure)
**When** the same learning flow is attempted
**Then** Canvas CRUD events go to JSON fallback (Story 38.5)
**And** learning events go to JSON fallback via dual-write (Story 38.4)
**And** scoring writes go to `failed_writes.jsonl` if all retries fail (Story 38.6)
**And** the `/health` endpoint shows degraded status for Neo4j-dependent features

**AC-5 (D6: Integration â€” Recovery)**
**Given** Neo4j is restarted after a degraded period
**When** the application detects Neo4j is back
**Then** failed writes from `failed_writes.jsonl` are replayed (Story 38.6)
**And** JSON fallback events are eventually synced to Neo4j (see Story 38.8: JSONâ†’Neo4j Complete Sync)
**And** the `/health` endpoint returns to normal status

### Infrastructure Verification Checklist

- [ ] Deploy to clean environment (no pre-existing data)
- [ ] Exercise core learning flow end-to-end
- [ ] Kill and restart application, verify data survives
- [ ] Stop Neo4j, verify degradation behavior
- [ ] Restart Neo4j, verify recovery
- [ ] Send null/invalid inputs to review API, verify rejection
- [ ] Check logs for silent failures or swallowed errors
- [ ] Verify `/health` endpoint reflects actual system state

---

## Story 38.8: JSON Fallback â†’ Neo4j Complete Sync Mechanism

> **Status:** ğŸ“‹ Defined (æœªå®ç°) | Origin: å¯¹æŠ—æ€§å®¡æ ¸ é˜»å¡ #3
> **Addresses:** Adversarial Review Finding #3 â€” æ¶æ„ç©ºæ´ï¼šé™çº§â†’æ¢å¤çš„ JSONâ†’Neo4j åŒæ­¥æœºåˆ¶ä¸å­˜åœ¨

As an operator,
I want fallback data written during Neo4j outages to be automatically synced back to Neo4j when it recovers,
So that the knowledge graph eventually reaches full consistency without manual intervention.

### Background

Stories 38.4ã€38.5ã€38.6 åœ¨ Neo4j ä¸å¯ç”¨æ—¶å°†æ•°æ®å†™å…¥ JSON fallback æ–‡ä»¶ï¼š
- `canvas_events_fallback.json` (Story 38.5 â€” Canvas CRUD äº‹ä»¶)
- `failed_writes.jsonl` (Story 38.6 â€” è¯„åˆ†å†™å…¥å¤±è´¥)
- `learning_events_fallback.json` (Story 38.4 â€” å­¦ä¹ äº‹ä»¶ dual-write)

Story 38.6 çš„ AC-3 å·²å®šä¹‰äº† `failed_writes.jsonl` çš„å¯åŠ¨å›æ”¾æœºåˆ¶ï¼ˆéƒ¨åˆ†å®ç°ï¼‰ï¼Œ
ä½† `canvas_events_fallback.json` å’Œ `learning_events_fallback.json` **æ²¡æœ‰ä»»ä½•å›å†™æœºåˆ¶**ã€‚

### Acceptance Criteria

**AC-1 (Startup Replay)**
**Given** the application starts and Neo4j is available
**When** JSON fallback files contain unsynced entries
**Then** the system replays all entries to Neo4j in chronological order
**And** successfully synced entries are marked as replayed (not deleted, to support audit)
**And** startup log shows: `"Fallback sync: replayed {N} events, {M} failed"`

**AC-2 (Idempotency)**
**Given** a fallback entry is replayed to Neo4j
**When** Neo4j already contains the same data (e.g., duplicate replay after crash)
**Then** the replay uses MERGE (not CREATE) to ensure idempotency
**And** no duplicate nodes/edges are created

**AC-3 (Partial Failure)**
**Given** replay is in progress and Neo4j becomes unavailable mid-replay
**When** some entries have been synced and others have not
**Then** a checkpoint is saved indicating the last successfully synced entry
**And** the next startup resumes from the checkpoint (not from the beginning)

**AC-4 (Conflict Resolution)**
**Given** a fallback entry refers to a concept that was modified in Neo4j after the fallback was written
**When** the entry is replayed
**Then** the system uses last-write-wins based on timestamp
**And** a WARNING log: `"Conflict detected for {concept_id}: fallback ts={X}, neo4j ts={Y}, using latest"`

**AC-5 (File Rotation)**
**Given** synced fallback files accumulate over time
**When** all entries in a fallback file have been successfully synced
**Then** the file is rotated to `{filename}.synced.{date}` (not deleted)
**And** files older than 30 days in `.synced` state are eligible for cleanup

### Code References

| File | Current State |
|------|--------------|
| `backend/app/services/canvas_service.py` | `_fallback_file_path` å®šä¹‰ï¼Œå†™å…¥é€»è¾‘å·²æœ‰ï¼Œæ— å›è¯»/åŒæ­¥ |
| `backend/app/services/agent_service.py` | `_record_failed_write()` + `_replay_failed_writes()` å·²æœ‰å¯åŠ¨å›æ”¾ |
| `backend/app/services/memory_service.py` | dual-write JSON å†™å…¥å·²æœ‰ï¼Œæ— å›è¯»/åŒæ­¥ |

### Implementation Notes

- å¤ç”¨ `agent_service.py` ä¸­å·²æœ‰çš„ `_replay_failed_writes()` æ¨¡å¼ï¼Œæ‰©å±•åˆ°å…¶ä»– fallback æ–‡ä»¶
- ä½¿ç”¨ Neo4j MERGE ç¡®ä¿å¹‚ç­‰æ€§
- è€ƒè™‘æ·»åŠ  `/api/v1/admin/sync-fallback` æ‰‹åŠ¨è§¦å‘ç«¯ç‚¹ï¼ˆè¿ç»´åœºæ™¯ï¼‰
- å›æ”¾ä¼˜å…ˆçº§ï¼š`failed_writes.jsonl` > `canvas_events_fallback.json` > `learning_events_fallback.json`

### Requirements Covered (Update)

åœ¨ EPIC çº§ Requirements è¡¨ä¸­æ·»åŠ ï¼š

| FR | Description | Story |
|----|-------------|-------|
| FR-38.8 | JSON Fallback â†’ Neo4j å®Œæ•´åŒæ­¥ | 38.8 |
