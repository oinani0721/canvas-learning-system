# Story 4.4: æ£€éªŒç™½æ¿Canvasæ–‡ä»¶ç”Ÿæˆ (Review Canvas File Generation)

## Status
Done

## Story

**As a** å­¦ä¹ è€…,
**I want** ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªæ–°çš„æ£€éªŒç™½æ¿Canvasæ–‡ä»¶,åŒ…å«æ‰€æœ‰æ£€éªŒé—®é¢˜,
**so that** æˆ‘èƒ½åœ¨ä¸€ä¸ªç‹¬ç«‹çš„ç™½æ¿ä¸Šè¿›è¡Œæ— çº¸åŒ–å›é¡¾æ£€éªŒ,ä¸æ±¡æŸ“åŸç™½æ¿ã€‚

## Acceptance Criteria

1. ç”Ÿæˆæ–°çš„.canvasæ–‡ä»¶
2. æ–‡ä»¶å‘½åç¬¦åˆè§„èŒƒ: `[åŸç™½æ¿å]-æ£€éªŒç™½æ¿-[æ—¥æœŸ].canvas`
3. æ–‡ä»¶ä¿å­˜åœ¨åŸç™½æ¿åŒä¸€ç›®å½•
4. åŒ…å«è¯´æ˜èŠ‚ç‚¹(è“è‰²)
5. åŒ…å«æ‰€æœ‰æ£€éªŒé—®é¢˜(çº¢è‰²)
6. æ¯ä¸ªé—®é¢˜å…³è”é»„è‰²ç†è§£èŠ‚ç‚¹
7. ç”Ÿæˆæ“ä½œè€—æ—¶<8ç§’

## Tasks / Subtasks

- [x] Task 1: å®ç°æ£€éªŒç™½æ¿æ–‡ä»¶ç”Ÿæˆæ ¸å¿ƒé€»è¾‘ (AC: 1-3)
  - [x] åœ¨`canvas_utils.py` CanvasBusinessLogicç±»æ·»åŠ `generate_review_canvas_file()`æ–¹æ³•
  - [x] è¾“å…¥: åŸCanvasè·¯å¾„, Story 4.3çš„èšç±»ç»“æœ
  - [x] ç”Ÿæˆæ–°çš„Canvas JSONç»“æ„(nodes=[], edges=[])
  - [x] æ ¹æ®åŸCanvasè·¯å¾„ç”Ÿæˆæ–°æ–‡ä»¶è·¯å¾„(å‘½åè§„èŒƒ: `{basename}-æ£€éªŒç™½æ¿-{YYYYMMDD}.canvas`)
  - [x] ä¿å­˜åˆ°åŸç™½æ¿åŒä¸€ç›®å½•
  - [x] è¿”å›æ–°Canvasæ–‡ä»¶è·¯å¾„å’Œç»Ÿè®¡ä¿¡æ¯
  - [x] æ·»åŠ å®Œæ•´çš„ç±»å‹æ³¨è§£å’ŒDocstring

- [x] Task 2: å®ç°è¯´æ˜èŠ‚ç‚¹ç”Ÿæˆ (AC: 4)
  - [x] åˆ›å»ºè“è‰²è¯´æ˜èŠ‚ç‚¹(color="5")
  - [x] ä½ç½®: (100, 100), å°ºå¯¸: 500x150
  - [x] å†…å®¹åŒ…å«:
    - æ ‡é¢˜: "# æ£€éªŒç™½æ¿"
    - ç”Ÿæˆæ—¶é—´: YYYY-MM-DD HH:MM
    - ç»Ÿè®¡: çº¢è‰²èŠ‚ç‚¹æ•°é‡, ç´«è‰²èŠ‚ç‚¹æ•°é‡
    - ä½¿ç”¨è¯´æ˜: "è¿™æ˜¯åŠ¨æ€å­¦ä¹ ç™½æ¿,ä½ å¯ä»¥:..."
  - [x] æ·»åŠ åˆ°æ–°Canvasçš„nodesæ•°ç»„

- [x] Task 3: å®ç°æ£€éªŒé—®é¢˜èŠ‚ç‚¹ç”Ÿæˆ (AC: 5-6)
  - [x] éå†Story 4.3çš„clustered_questions (Dict[str, List[Dict]])
  - [x] ä¸ºæ¯ä¸ªä¸»é¢˜èšç±»:
    - åˆ›å»ºä¸»é¢˜æ ‡ç­¾èŠ‚ç‚¹(å¯é€‰,æˆ–ä½¿ç”¨ç©ºé—´å¸ƒå±€)
    - ä¸ºæ¯ä¸ªé—®é¢˜åˆ›å»ºçº¢è‰²é—®é¢˜èŠ‚ç‚¹(color="1")
    - åˆ›å»ºå¯¹åº”çš„é»„è‰²ç†è§£èŠ‚ç‚¹(color="6")
    - ä½¿ç”¨v1.1å¸ƒå±€ç®—æ³•è®¡ç®—ä½ç½®
    - åˆ›å»ºé—®é¢˜â†’é»„è‰²çš„è¿æ¥è¾¹
  - [x] é—®é¢˜èŠ‚ç‚¹å†…å®¹: ä»Story 4.2çš„question_textå­—æ®µ
  - [x] é»„è‰²èŠ‚ç‚¹å†…å®¹: "[è¯·å¡«å†™ä½ çš„ç†è§£]"å ä½ç¬¦

- [x] Task 4: å®ç°ç©ºé—´å¸ƒå±€ç­–ç•¥ (AC: 5-6)
  - [x] ä½¿ç”¨Story 4.3çš„`_calculate_cluster_layout()`ç»“æœ
  - [x] ä¸ºæ¯ä¸ªèšç±»åˆ†é…yåæ ‡èŒƒå›´
  - [x] èšç±»é—´é—´éš”: 100px (CLUSTER_GAP)
  - [x] å•ä¸ªé—®é¢˜+é»„è‰²ç»„åˆé«˜åº¦: 380px (VERTICAL_SPACING_BASE)
  - [x] é—®é¢˜èŠ‚ç‚¹å°ºå¯¸: 400x120
  - [x] é»„è‰²èŠ‚ç‚¹å°ºå¯¸: 350x150
  - [x] é»„è‰²èŠ‚ç‚¹åœ¨é—®é¢˜èŠ‚ç‚¹æ­£ä¸‹æ–¹(v1.1å¸ƒå±€)

- [x] Task 5: æ€§èƒ½ä¼˜åŒ– (AC: 7)
  - [x] ç¡®ä¿ç”Ÿæˆæ“ä½œè€—æ—¶<8ç§’
  - [x] ä½¿ç”¨å•æ¬¡Canvaså†™å…¥(æ‰¹é‡åˆ›å»ºèŠ‚ç‚¹åä¸€æ¬¡æ€§ä¿å­˜)
  - [x] é¿å…é‡å¤è®¡ç®—(æå‰è®¡ç®—æ‰€æœ‰ä½ç½®)
  - [x] æµ‹è¯•æ€§èƒ½: 30ä¸ªé—®é¢˜â†’èšç±»5-10ä¸ªä¸»é¢˜â†’ç”Ÿæˆæ£€éªŒç™½æ¿<8ç§’

- [x] Task 6: å•å…ƒæµ‹è¯• (AC: 1-7)
  - [x] åˆ›å»ºæµ‹è¯•fixture: åŒ…å«Story 4.3èšç±»ç»“æœ
  - [x] æµ‹è¯•ç”¨ä¾‹: ç”Ÿæˆæ–°Canvasæ–‡ä»¶,éªŒè¯æ–‡ä»¶å­˜åœ¨
  - [x] æµ‹è¯•ç”¨ä¾‹: éªŒè¯æ–‡ä»¶å‘½åç¬¦åˆè§„èŒƒ
  - [x] æµ‹è¯•ç”¨ä¾‹: éªŒè¯æ–‡ä»¶ä¿å­˜åœ¨æ­£ç¡®ç›®å½•
  - [x] æµ‹è¯•ç”¨ä¾‹: éªŒè¯åŒ…å«è¯´æ˜èŠ‚ç‚¹(è“è‰²)
  - [x] æµ‹è¯•ç”¨ä¾‹: éªŒè¯åŒ…å«æ‰€æœ‰æ£€éªŒé—®é¢˜(çº¢è‰²)
  - [x] æµ‹è¯•ç”¨ä¾‹: éªŒè¯æ¯ä¸ªé—®é¢˜å…³è”é»„è‰²èŠ‚ç‚¹
  - [x] æµ‹è¯•ç”¨ä¾‹: éªŒè¯ç”Ÿæˆè€—æ—¶<8ç§’
  - [x] æµ‹è¯•ç”¨ä¾‹: éªŒè¯v1.1å¸ƒå±€æ­£ç¡®(é»„è‰²åœ¨é—®é¢˜ä¸‹æ–¹)
  - [x] ç¡®ä¿æµ‹è¯•è¦†ç›–ç‡â‰¥85%

## Dev Notes

### Previous Story Insights

ä»Story 4.1, 4.2, 4.3çš„å…³é”®èƒŒæ™¯:

**Story 4.1**: çº¢è‰²å’Œç´«è‰²èŠ‚ç‚¹æå– [Source: docs/stories/4.1.story.md]
- âœ… `extract_verification_nodes()`å·²å®ç°
- âœ… è¿”å›æ•°æ®ç»“æ„:
```python
{
    "red_nodes": [
        {
            "id": "node-abc123",
            "content": "èŠ‚ç‚¹æ–‡æœ¬",
            "related_yellow": [...],
            "parent_nodes": [...],
            "level": 1
        },
        ...
    ],
    "purple_nodes": [...],
    "stats": {"red_count": 10, "purple_count": 8}
}
```

**Story 4.2**: æ·±å±‚æ¬¡æ£€éªŒé—®é¢˜ç”Ÿæˆ [Source: docs/stories/4.2.story.md]
- âœ… `generate_verification_questions()`å·²å®ç°
- âœ… è¿”å›æ•°æ®ç»“æ„:
```python
[
    {
        "source_node_id": "node-abc123",
        "question_text": "ä»€ä¹ˆæ˜¯é€†å¦å‘½é¢˜?",
        "question_type": "çªç ´å‹|æ£€éªŒå‹|åº”ç”¨å‹|ç»¼åˆå‹",
        "difficulty": "åŸºç¡€|æ·±åº¦",
        "guidance": "ğŸ’¡ æç¤ºæ–‡å­—(å¯é€‰)",
        "rationale": "ä¸ºä»€ä¹ˆç”Ÿæˆè¿™ä¸ªé—®é¢˜çš„è§£é‡Š"
    },
    ...
]
```

**Story 4.3**: ä¸»é¢˜èšç±»ä¸åˆ†ç»„ [Source: docs/stories/4.3.story.md]
- âœ… `cluster_questions_by_topic()`å·²å®ç°
- âœ… è¿”å›æ•°æ®ç»“æ„:
```python
{
    "å‘½é¢˜é€»è¾‘": [
        {"source_node_id": "...", "question_text": "...", ...},
        {"source_node_id": "...", "question_text": "...", ...}
    ],
    "å¸ƒå°”ä»£æ•°": [...],
    "è¯æ˜æ–¹æ³•": [...]
}
```
- âœ… `_calculate_cluster_layout()`æä¾›ç©ºé—´å¸ƒå±€ä¿¡æ¯

**Story 4.4çš„å®šä½**:
- Epic 4çš„ç¬¬å››ä¸ªStory,ç›´æ¥ä¾èµ–4.1, 4.2, 4.3çš„è¾“å‡º
- æ ¸å¿ƒä»»åŠ¡: å°†èšç±»åçš„é—®é¢˜æ•°æ®è½¬åŒ–ä¸ºç‹¬ç«‹çš„Canvasæ–‡ä»¶
- ä¸ºStory 4.5 (æ£€éªŒé—®é¢˜åˆå§‹æ¡†æ¶åˆ›å»º)å’ŒStory 4.6 (åŠ¨æ€å­¦ä¹ ç™½æ¿)å¥ å®šåŸºç¡€

### Canvasæ–‡ä»¶æ ¼å¼

[Source: docs/architecture/tech-stack.md#Canvasæ–‡ä»¶æ ¼å¼]

```json
{
  "nodes": [
    {
      "id": "string",
      "type": "text" | "file" | "group",
      "text": "string (for type=text)",
      "file": "string (for type=file)",
      "x": number,
      "y": number,
      "width": number,
      "height": number,
      "color": "1" | "2" | "3" | "4" | "5" | "6"
    }
  ],
  "edges": [
    {
      "id": "string",
      "fromNode": "string",
      "toNode": "string",
      "fromSide": "top" | "right" | "bottom" | "left",
      "toSide": "top" | "right" | "bottom" | "left",
      "label": "string (optional)"
    }
  ]
}
```

**å…³é”®çº¦æŸ**:
- èŠ‚ç‚¹IDå¿…é¡»å”¯ä¸€(ä½¿ç”¨UUID v4)
- é¢œè‰²å€¼å¿…é¡»æ˜¯å­—ç¬¦ä¸² `"1"`-`"6"`
- æ‰€æœ‰åæ ‡ä¸ºæ•´æ•°(åƒç´ å•ä½)

### é¢œè‰²ç¼–ç 

[Source: docs/architecture/tech-stack.md#é¢œè‰²ç³»ç»Ÿ]

| Canvas Color Code | è§†è§‰é¢œè‰² | å«ä¹‰ | æœ¬Storyä½¿ç”¨åœºæ™¯ |
|-------------------|---------|------|---------------|
| `"1"` | ğŸ”´ çº¢è‰² | ä¸ç†è§£/æœªé€šè¿‡ | æ£€éªŒé—®é¢˜èŠ‚ç‚¹ |
| `"2"` | ğŸŸ¢ ç»¿è‰² | å®Œå…¨ç†è§£/å·²é€šè¿‡ | (æš‚æœªä½¿ç”¨) |
| `"3"` | ğŸŸ£ ç´«è‰² | ä¼¼æ‡‚éæ‡‚/å¾…æ£€éªŒ | (åŸç™½æ¿ä¸­å­˜åœ¨) |
| `"5"` | ğŸ”µ è“è‰² | è¯´æ˜èŠ‚ç‚¹ | æ£€éªŒç™½æ¿è¯´æ˜èŠ‚ç‚¹ |
| `"6"` | ğŸŸ¡ é»„è‰² | ä¸ªäººç†è§£è¾“å‡ºåŒº | é¢„ç•™å¡«å†™åŒº |

### æ–‡ä»¶å‘½åè§„èŒƒ

[Source: docs/prd/FULL-PRD-REFERENCE.md Epic 4.4]

```
[åŸç™½æ¿å]-æ£€éªŒç™½æ¿-[æ—¥æœŸ].canvas

ç¤ºä¾‹:
ç¦»æ•£æ•°å­¦.canvas â†’ ç¦»æ•£æ•°å­¦-æ£€éªŒç™½æ¿-20250115.canvas
æ‰˜ç¦å¬åŠ›.canvas â†’ æ‰˜ç¦å¬åŠ›-æ£€éªŒç™½æ¿-20250115.canvas
```

**å®ç°æ–¹æ³•**:
```python
from datetime import datetime
import os

def generate_review_canvas_filename(original_canvas_path: str) -> str:
    """ç”Ÿæˆæ£€éªŒç™½æ¿æ–‡ä»¶å

    Args:
        original_canvas_path: åŸç™½æ¿è·¯å¾„,å¦‚ "ç¬”è®°åº“/ç¦»æ•£æ•°å­¦/ç¦»æ•£æ•°å­¦.canvas"

    Returns:
        str: æ–°æ–‡ä»¶è·¯å¾„,å¦‚ "ç¬”è®°åº“/ç¦»æ•£æ•°å­¦/ç¦»æ•£æ•°å­¦-æ£€éªŒç™½æ¿-20250115.canvas"
    """
    directory = os.path.dirname(original_canvas_path)
    basename = os.path.basename(original_canvas_path).replace('.canvas', '')
    date_str = datetime.now().strftime("%Y%m%d")

    new_filename = f"{basename}-æ£€éªŒç™½æ¿-{date_str}.canvas"
    return os.path.join(directory, new_filename)
```

### v1.1å¸ƒå±€ç®—æ³•

[Source: docs/architecture/canvas-layout-v1.1.md]

**æ ¸å¿ƒç‰¹ç‚¹**:
- é»„è‰²èŠ‚ç‚¹åœ¨é—®é¢˜èŠ‚ç‚¹æ­£ä¸‹æ–¹(å‚ç›´å¯¹é½)
- æ°´å¹³åç§»ä¸º0

**å¸ƒå±€å‚æ•°**:
```python
# èŠ‚ç‚¹å°ºå¯¸
QUESTION_NODE_HEIGHT = 120  # é—®é¢˜èŠ‚ç‚¹é«˜åº¦
YELLOW_NODE_WIDTH = 350     # é»„è‰²ç†è§£èŠ‚ç‚¹å®½åº¦
YELLOW_NODE_HEIGHT = 150    # é»„è‰²ç†è§£èŠ‚ç‚¹é«˜åº¦

# é—´è·å‚æ•°
VERTICAL_SPACING_BASE = 380  # é—®é¢˜+é»„è‰²ç»„åˆçš„å‚ç›´é—´è·
YELLOW_OFFSET_X = 0          # é»„è‰²èŠ‚ç‚¹æ°´å¹³åç§»(ç›¸å¯¹é—®é¢˜èŠ‚ç‚¹)
YELLOW_OFFSET_Y = 30         # é»„è‰²èŠ‚ç‚¹å‚ç›´åç§»(ç›¸å¯¹é—®é¢˜èŠ‚ç‚¹åº•éƒ¨)
CLUSTER_GAP = 100            # èšç±»é—´éš”
```

**ä½ç½®è®¡ç®—å…¬å¼**:
```python
# é—®é¢˜èŠ‚ç‚¹ä½ç½®
question_x = base_x
question_y = base_y + (question_index * VERTICAL_SPACING_BASE)

# é»„è‰²èŠ‚ç‚¹ä½ç½®(v1.1æ ¸å¿ƒå…¬å¼)
yellow_x = question_x + YELLOW_OFFSET_X  # = question_x(æ°´å¹³å¯¹é½)
yellow_y = question_y + QUESTION_NODE_HEIGHT + YELLOW_OFFSET_Y
```

### 3å±‚æ¶æ„é›†æˆ

[Source: docs/architecture/canvas-3-layer-architecture.md]

**å±‚çº§å®šä½**: Layer 2 (CanvasBusinessLogic)

**æ–¹æ³•ç­¾å**:
```python
def generate_review_canvas_file(
    self,
    clustered_questions: Dict[str, List[Dict[str, str]]],
    output_filename_override: Optional[str] = None
) -> Dict[str, any]:
    """ç”Ÿæˆæ£€éªŒç™½æ¿Canvasæ–‡ä»¶

    åŸºäºStory 4.3çš„èšç±»ç»“æœç”Ÿæˆç‹¬ç«‹çš„æ£€éªŒç™½æ¿Canvasæ–‡ä»¶,ä½¿ç”¨v1.1å¸ƒå±€ç®—æ³•ã€‚

    Args:
        clustered_questions: Story 4.3çš„cluster_questions_by_topic()è¿”å›ç»“æœ
            æ ¼å¼: {
                "å‘½é¢˜é€»è¾‘": [question1, question2, ...],
                "å¸ƒå°”ä»£æ•°": [question3, ...],
                ...
            }
        output_filename_override: å¯é€‰çš„è¾“å‡ºæ–‡ä»¶åè¦†ç›–
            å¦‚æœä¸æŒ‡å®š,ä½¿ç”¨è§„èŒƒå‘½å: "{basename}-æ£€éªŒç™½æ¿-{date}.canvas"

    Returns:
        Dict: {
            "review_canvas_path": str,  # ç”Ÿæˆçš„æ£€éªŒç™½æ¿è·¯å¾„
            "total_questions": int,     # æ€»é—®é¢˜æ•°
            "cluster_count": int,       # èšç±»æ•°é‡
            "generation_time": float    # ç”Ÿæˆè€—æ—¶(ç§’)
        }

    Raises:
        ValueError: å¦‚æœclustered_questionsæ ¼å¼ä¸æ­£ç¡®
        IOError: å¦‚æœæ— æ³•å†™å…¥æ–‡ä»¶

    Example:
        >>> logic = CanvasBusinessLogic("ç¬”è®°åº“/ç¦»æ•£æ•°å­¦/ç¦»æ•£æ•°å­¦.canvas")
        >>> nodes = logic.extract_verification_nodes()
        >>> questions = logic.generate_verification_questions(nodes)
        >>> clusters = logic.cluster_questions_by_topic(questions, nodes)
        >>> result = logic.generate_review_canvas_file(clusters)
        >>> print(f"ç”Ÿæˆæ£€éªŒç™½æ¿: {result['review_canvas_path']}")
        ç”Ÿæˆæ£€éªŒç™½æ¿: ç¬”è®°åº“/ç¦»æ•£æ•°å­¦/ç¦»æ•£æ•°å­¦-æ£€éªŒç™½æ¿-20250115.canvas
        >>> print(f"åŒ…å«{result['total_questions']}ä¸ªé—®é¢˜,{result['cluster_count']}ä¸ªä¸»é¢˜èšç±»")
        åŒ…å«15ä¸ªé—®é¢˜,3ä¸ªä¸»é¢˜èšç±»
        >>> print(f"ç”Ÿæˆè€—æ—¶: {result['generation_time']:.2f}ç§’")
        ç”Ÿæˆè€—æ—¶: 2.35ç§’
    """
    pass
```

### æ•°æ®æµè®¾è®¡

**å®Œæ•´æ•°æ®æµ(Story 4.1 â†’ 4.4)**:
```
Story 4.1: extract_verification_nodes()
    â†“ {red_nodes, purple_nodes, stats}
Story 4.2: generate_verification_questions()
    â†“ [{"source_node_id", "question_text", "question_type", ...}]
Story 4.3: cluster_questions_by_topic()
    â†“ {"ä¸»é¢˜1": [questions], "ä¸»é¢˜2": [...]}
Story 4.4: generate_review_canvas_file()  â† æœ¬Story
    â†“ æ£€éªŒç™½æ¿.canvasæ–‡ä»¶
```

### CanvasèŠ‚ç‚¹åˆ›å»ºç¤ºä¾‹

**è¯´æ˜èŠ‚ç‚¹(è“è‰²)**:
```python
description_node = {
    "id": f"text-{uuid.uuid4().hex[:16]}",
    "type": "text",
    "x": 100,
    "y": 100,
    "width": 500,
    "height": 150,
    "color": "5",  # è“è‰²
    "text": f"# æ£€éªŒç™½æ¿\n\nç”Ÿæˆæ—¶é—´: {timestamp}\nçº¢è‰²èŠ‚ç‚¹: {red_count} ä¸ª\nç´«è‰²èŠ‚ç‚¹: {purple_count} ä¸ª\n\nè¿™æ˜¯åŠ¨æ€å­¦ä¹ ç™½æ¿,ä½ å¯ä»¥:\n- å¡«å†™ä¸ªäººç†è§£\n- æ‹†è§£é—®é¢˜\n- æ·»åŠ è¡¥å……è§£é‡Š\n- æŒç»­æ‰©å±•ç›´åˆ°æ¥è¿‘åŸç™½æ¿"
}
```

**æ£€éªŒé—®é¢˜èŠ‚ç‚¹(çº¢è‰²)**:
```python
question_node = {
    "id": f"question-{uuid.uuid4().hex[:16]}",
    "type": "text",
    "x": 100,
    "y": base_y,
    "width": 400,
    "height": 120,
    "color": "1",  # çº¢è‰²
    "text": question["question_text"]
}
```

**é»„è‰²ç†è§£èŠ‚ç‚¹**:
```python
yellow_node = {
    "id": f"understanding-{uuid.uuid4().hex[:16]}",
    "type": "text",
    "x": 100,  # ä¸é—®é¢˜èŠ‚ç‚¹æ°´å¹³å¯¹é½
    "y": base_y + 120 + 30,
    "width": 350,
    "height": 150,
    "color": "6",  # é»„è‰²
    "text": "[è¯·å¡«å†™ä½ çš„ç†è§£]"
}
```

**è¿æ¥è¾¹**:
```python
edge = {
    "id": f"edge-{uuid.uuid4().hex[:16]}",
    "fromNode": question_node_id,
    "toNode": yellow_node_id,
    "fromSide": "bottom",
    "toSide": "top"
}
```

### æ–‡ä»¶ä½ç½®

[Source: docs/architecture/unified-project-structure.md]

```
C:/Users/ROG/æ‰˜ç¦/
â”œâ”€â”€ canvas_utils.py  # â­ åœ¨CanvasBusinessLogicç±»æ·»åŠ æ–¹æ³•
â”‚   # Layer 2: CanvasBusinessLogicç±»
â”‚   # æ–°å¢æ–¹æ³•:
â”‚   #   - generate_review_canvas_file()
â”‚   #   - _generate_description_node()
â”‚   #   - _generate_question_nodes()
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_canvas_utils.py  # æ·»åŠ æ–°æµ‹è¯•
        # æ–°å¢: TestReviewCanvasGenerationç±»
```

### æ€§èƒ½è€ƒè™‘

**æ€§èƒ½ç›®æ ‡**: ç”Ÿæˆæ“ä½œè€—æ—¶<8ç§’ [Source: AC 7]

**æ€§èƒ½åˆ†æ**:
```
å…¸å‹è¾“å…¥è§„æ¨¡:
- é—®é¢˜æ•°é‡: 15-30ä¸ª
- èšç±»æ•°é‡: 3-8ä¸ª
- èŠ‚ç‚¹æ€»æ•°: 1(è¯´æ˜) + é—®é¢˜æ•°*2(é—®é¢˜+é»„è‰²) = 31-61ä¸ª

ç®—æ³•å¤æ‚åº¦:
- éå†èšç±»: O(k) where k=èšç±»æ•°
- ä¸ºæ¯ä¸ªé—®é¢˜åˆ›å»ºèŠ‚ç‚¹: O(n) where n=é—®é¢˜æ•°
- åˆ›å»ºè¾¹: O(n)
- JSONåºåˆ—åŒ–å’Œå†™å…¥: O(n)
- æ€»ä½“: O(k + 3n) â‰ˆ O(n)

é¢„æœŸæ€§èƒ½:
- 30ä¸ªé—®é¢˜ â†’ 61ä¸ªèŠ‚ç‚¹ â†’ åˆ›å»ºèŠ‚ç‚¹<1ç§’ â†’ JSONå†™å…¥<1ç§’ â†’ æ€»è€—æ—¶<3ç§’ âœ“
- æ€§èƒ½ç“¶é¢ˆ: JSONæ–‡ä»¶å†™å…¥(I/Oå¯†é›†)
```

**ä¼˜åŒ–ç­–ç•¥**:
- ä½¿ç”¨å•æ¬¡Canvaså†™å…¥(é¿å…å¤šæ¬¡I/O)
- æå‰è®¡ç®—æ‰€æœ‰ä½ç½®(é¿å…é‡å¤è®¡ç®—)
- æ‰¹é‡åˆ›å»ºèŠ‚ç‚¹å’Œè¾¹(ä¸€æ¬¡æ€§appendåˆ°arrays)
- ä¸ä½¿ç”¨å¤æ‚çš„Canvasæ“ä½œ(ä¿æŒè½»é‡çº§)

### é”™è¯¯å¤„ç†è§„èŒƒ

[Source: docs/architecture/coding-standards.md lines 115-146]

```python
def generate_review_canvas_file(
    self,
    clustered_questions: Dict[str, List[Dict[str, str]]],
    output_filename_override: Optional[str] = None
) -> Dict[str, any]:
    """ç”Ÿæˆæ£€éªŒç™½æ¿Canvasæ–‡ä»¶"""

    # éªŒè¯è¾“å…¥æ•°æ®
    if not clustered_questions:
        raise ValueError("clustered_questionsä¸èƒ½ä¸ºç©º")

    if not isinstance(clustered_questions, dict):
        raise ValueError(
            f"clustered_questionså¿…é¡»æ˜¯å­—å…¸ç±»å‹,å®é™…ç±»å‹: {type(clustered_questions)}"
        )

    # éªŒè¯æ¯ä¸ªèšç±»çš„é—®é¢˜æ ¼å¼
    total_questions = 0
    for topic, questions in clustered_questions.items():
        if not isinstance(questions, list):
            raise ValueError(f"èšç±»'{topic}'çš„é—®é¢˜åˆ—è¡¨æ ¼å¼é”™è¯¯")

        for q in questions:
            if "question_text" not in q:
                raise ValueError(
                    f"é—®é¢˜ç¼ºå°‘'question_text'å­—æ®µ. èšç±»: {topic}, é—®é¢˜: {q}"
                )

        total_questions += len(questions)

    if total_questions == 0:
        raise ValueError("æ²¡æœ‰æ£€éªŒé—®é¢˜å¯ç”Ÿæˆ")

    try:
        # æ‰§è¡Œç”Ÿæˆé€»è¾‘
        import time
        start_time = time.time()

        # ç”Ÿæˆæ–‡ä»¶å
        output_path = output_filename_override or self._generate_review_canvas_filename()

        # åˆ›å»ºæ–°Canvasç»“æ„
        review_canvas = {"nodes": [], "edges": []}

        # æ·»åŠ è¯´æ˜èŠ‚ç‚¹
        self._add_description_node(review_canvas, len(clustered_questions), total_questions)

        # æ·»åŠ é—®é¢˜å’Œé»„è‰²èŠ‚ç‚¹
        self._add_question_nodes(review_canvas, clustered_questions)

        # å†™å…¥æ–‡ä»¶
        CanvasJSONOperator.write_canvas(output_path, review_canvas)

        generation_time = time.time() - start_time

        return {
            "review_canvas_path": output_path,
            "total_questions": total_questions,
            "cluster_count": len(clustered_questions),
            "generation_time": generation_time
        }

    except Exception as e:
        raise IOError(f"ç”Ÿæˆæ£€éªŒç™½æ¿å¤±è´¥: {e}")
```

## Testing

### Testing Standards

[Source: docs/architecture/coding-standards.md lines 453-511]

**æµ‹è¯•æ–‡ä»¶ä½ç½®**: `tests/test_canvas_utils.py`

**æµ‹è¯•æ¡†æ¶**: pytest

**æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡**:
- Layer 2 (CanvasBusinessLogic) â‰¥ 85%
- æ–°å¢æ–¹æ³•å¿…é¡»æœ‰å®Œæ•´æµ‹è¯•è¦†ç›–

### Test Cases

**æµ‹è¯•ç±»: TestReviewCanvasGeneration**

```python
import pytest
import os
import json
from datetime import datetime
from canvas_utils import CanvasBusinessLogic

class TestReviewCanvasGeneration:
    """æµ‹è¯•æ£€éªŒç™½æ¿ç”ŸæˆåŠŸèƒ½"""

    def test_generate_review_canvas_file_success(self):
        """æµ‹è¯•æˆåŠŸç”Ÿæˆæ£€éªŒç™½æ¿æ–‡ä»¶ (AC: 1-3)"""
        # Arrange: å‡†å¤‡èšç±»æ•°æ®
        clustered_questions = {
            "å‘½é¢˜é€»è¾‘": [
                {
                    "source_node_id": "red-1",
                    "question_text": "ä»€ä¹ˆæ˜¯é€†å¦å‘½é¢˜?",
                    "question_type": "çªç ´å‹",
                    "difficulty": "åŸºç¡€"
                },
                {
                    "source_node_id": "red-2",
                    "question_text": "é€†å¦å‘½é¢˜å’ŒåŸå‘½é¢˜çš„å…³ç³»?",
                    "question_type": "æ£€éªŒå‹",
                    "difficulty": "æ·±åº¦"
                }
            ],
            "å¸ƒå°”ä»£æ•°": [
                {
                    "source_node_id": "purple-1",
                    "question_text": "ä»€ä¹ˆæ˜¯å¸ƒå°”ä»£æ•°?",
                    "question_type": "çªç ´å‹",
                    "difficulty": "åŸºç¡€"
                }
            ]
        }

        # Act
        logic = CanvasBusinessLogic("tests/fixtures/test.canvas")
        result = logic.generate_review_canvas_file(clustered_questions)

        # Assert: æ–‡ä»¶å­˜åœ¨
        assert os.path.exists(result["review_canvas_path"]), "æ£€éªŒç™½æ¿æ–‡ä»¶åº”å­˜åœ¨"

        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        os.remove(result["review_canvas_path"])

    def test_review_canvas_filename_follows_convention(self):
        """æµ‹è¯•æ–‡ä»¶å‘½åç¬¦åˆè§„èŒƒ (AC: 2)"""
        # Arrange
        clustered_questions = {
            "ä¸»é¢˜1": [{"question_text": "é—®é¢˜1", "question_type": "çªç ´å‹", "difficulty": "åŸºç¡€"}]
        }

        # Act
        logic = CanvasBusinessLogic("ç¬”è®°åº“/ç¦»æ•£æ•°å­¦/ç¦»æ•£æ•°å­¦.canvas")
        result = logic.generate_review_canvas_file(clustered_questions)

        # Assert: æ–‡ä»¶åæ ¼å¼: {basename}-æ£€éªŒç™½æ¿-{YYYYMMDD}.canvas
        filename = os.path.basename(result["review_canvas_path"])
        date_str = datetime.now().strftime("%Y%m%d")
        expected_pattern = f"ç¦»æ•£æ•°å­¦-æ£€éªŒç™½æ¿-{date_str}.canvas"

        assert filename == expected_pattern, f"æ–‡ä»¶ååº”ä¸º: {expected_pattern}"

        # æ¸…ç†
        if os.path.exists(result["review_canvas_path"]):
            os.remove(result["review_canvas_path"])

    def test_review_canvas_saved_in_same_directory(self):
        """æµ‹è¯•æ–‡ä»¶ä¿å­˜åœ¨åŸç™½æ¿åŒä¸€ç›®å½• (AC: 3)"""
        # Arrange
        original_path = "ç¬”è®°åº“/ç¦»æ•£æ•°å­¦/ç¦»æ•£æ•°å­¦.canvas"
        clustered_questions = {
            "ä¸»é¢˜1": [{"question_text": "é—®é¢˜1", "question_type": "çªç ´å‹", "difficulty": "åŸºç¡€"}]
        }

        # Act
        logic = CanvasBusinessLogic(original_path)
        result = logic.generate_review_canvas_file(clustered_questions)

        # Assert: ç›®å½•ç›¸åŒ
        original_dir = os.path.dirname(original_path)
        review_dir = os.path.dirname(result["review_canvas_path"])

        assert original_dir == review_dir, "æ£€éªŒç™½æ¿åº”ä¸åŸç™½æ¿åœ¨åŒä¸€ç›®å½•"

        # æ¸…ç†
        if os.path.exists(result["review_canvas_path"]):
            os.remove(result["review_canvas_path"])

    def test_review_canvas_contains_description_node(self):
        """æµ‹è¯•åŒ…å«è¯´æ˜èŠ‚ç‚¹(è“è‰²) (AC: 4)"""
        # Arrange
        clustered_questions = {
            "ä¸»é¢˜1": [{"question_text": "é—®é¢˜1", "question_type": "çªç ´å‹", "difficulty": "åŸºç¡€"}]
        }

        # Act
        logic = CanvasBusinessLogic("tests/fixtures/test.canvas")
        result = logic.generate_review_canvas_file(clustered_questions)

        # Assert: è¯»å–ç”Ÿæˆçš„Canvasæ–‡ä»¶
        with open(result["review_canvas_path"], 'r', encoding='utf-8') as f:
            canvas_data = json.load(f)

        # æŸ¥æ‰¾è“è‰²è¯´æ˜èŠ‚ç‚¹
        description_nodes = [n for n in canvas_data["nodes"] if n.get("color") == "5"]

        assert len(description_nodes) == 1, "åº”æœ‰1ä¸ªè“è‰²è¯´æ˜èŠ‚ç‚¹"
        assert "# æ£€éªŒç™½æ¿" in description_nodes[0]["text"], "è¯´æ˜èŠ‚ç‚¹åº”åŒ…å«æ ‡é¢˜"
        assert "ç”Ÿæˆæ—¶é—´" in description_nodes[0]["text"], "è¯´æ˜èŠ‚ç‚¹åº”åŒ…å«ç”Ÿæˆæ—¶é—´"

        # æ¸…ç†
        os.remove(result["review_canvas_path"])

    def test_review_canvas_contains_all_questions(self):
        """æµ‹è¯•åŒ…å«æ‰€æœ‰æ£€éªŒé—®é¢˜(çº¢è‰²) (AC: 5)"""
        # Arrange
        clustered_questions = {
            "å‘½é¢˜é€»è¾‘": [
                {"question_text": "é—®é¢˜1", "question_type": "çªç ´å‹", "difficulty": "åŸºç¡€"},
                {"question_text": "é—®é¢˜2", "question_type": "æ£€éªŒå‹", "difficulty": "æ·±åº¦"}
            ],
            "å¸ƒå°”ä»£æ•°": [
                {"question_text": "é—®é¢˜3", "question_type": "åº”ç”¨å‹", "difficulty": "åŸºç¡€"}
            ]
        }

        # Act
        logic = CanvasBusinessLogic("tests/fixtures/test.canvas")
        result = logic.generate_review_canvas_file(clustered_questions)

        # Assert
        with open(result["review_canvas_path"], 'r', encoding='utf-8') as f:
            canvas_data = json.load(f)

        # ç»Ÿè®¡çº¢è‰²é—®é¢˜èŠ‚ç‚¹
        red_question_nodes = [n for n in canvas_data["nodes"] if n.get("color") == "1"]

        assert len(red_question_nodes) == 3, "åº”æœ‰3ä¸ªçº¢è‰²é—®é¢˜èŠ‚ç‚¹"
        assert result["total_questions"] == 3, "è¿”å›ç»“æœåº”æ­£ç¡®ç»Ÿè®¡é—®é¢˜æ•°"

        # æ¸…ç†
        os.remove(result["review_canvas_path"])

    def test_each_question_has_yellow_node(self):
        """æµ‹è¯•æ¯ä¸ªé—®é¢˜å…³è”é»„è‰²ç†è§£èŠ‚ç‚¹ (AC: 6)"""
        # Arrange
        clustered_questions = {
            "ä¸»é¢˜1": [
                {"question_text": "é—®é¢˜1", "question_type": "çªç ´å‹", "difficulty": "åŸºç¡€"},
                {"question_text": "é—®é¢˜2", "question_type": "æ£€éªŒå‹", "difficulty": "æ·±åº¦"}
            ]
        }

        # Act
        logic = CanvasBusinessLogic("tests/fixtures/test.canvas")
        result = logic.generate_review_canvas_file(clustered_questions)

        # Assert
        with open(result["review_canvas_path"], 'r', encoding='utf-8') as f:
            canvas_data = json.load(f)

        red_nodes = [n for n in canvas_data["nodes"] if n.get("color") == "1"]
        yellow_nodes = [n for n in canvas_data["nodes"] if n.get("color") == "6"]

        assert len(red_nodes) == len(yellow_nodes), "çº¢è‰²é—®é¢˜èŠ‚ç‚¹æ•°åº”ç­‰äºé»„è‰²ç†è§£èŠ‚ç‚¹æ•°"

        # éªŒè¯æ¯ä¸ªçº¢è‰²èŠ‚ç‚¹éƒ½æœ‰è¾¹è¿æ¥åˆ°ä¸€ä¸ªé»„è‰²èŠ‚ç‚¹
        edges = canvas_data["edges"]
        for red_node in red_nodes:
            # æŸ¥æ‰¾ä»çº¢è‰²èŠ‚ç‚¹å‡ºå‘çš„è¾¹
            edges_from_red = [e for e in edges if e["fromNode"] == red_node["id"]]
            assert len(edges_from_red) >= 1, f"çº¢è‰²èŠ‚ç‚¹{red_node['id']}åº”æœ‰è‡³å°‘1æ¡è¾¹"

            # éªŒè¯ç›®æ ‡èŠ‚ç‚¹æ˜¯é»„è‰²
            to_node_id = edges_from_red[0]["toNode"]
            to_node = next(n for n in canvas_data["nodes"] if n["id"] == to_node_id)
            assert to_node["color"] == "6", "é—®é¢˜èŠ‚ç‚¹åº”è¿æ¥åˆ°é»„è‰²ç†è§£èŠ‚ç‚¹"

        # æ¸…ç†
        os.remove(result["review_canvas_path"])

    def test_generation_time_under_8_seconds(self):
        """æµ‹è¯•ç”Ÿæˆæ“ä½œè€—æ—¶<8ç§’ (AC: 7)"""
        # Arrange: å‡†å¤‡è¾ƒå¤§è§„æ¨¡æ•°æ®(30ä¸ªé—®é¢˜)
        clustered_questions = {}
        for i in range(6):  # 6ä¸ªèšç±»
            clustered_questions[f"ä¸»é¢˜{i+1}"] = [
                {
                    "question_text": f"é—®é¢˜{j+1}",
                    "question_type": "çªç ´å‹",
                    "difficulty": "åŸºç¡€"
                }
                for j in range(5)  # æ¯ä¸ªèšç±»5ä¸ªé—®é¢˜
            ]

        # Act
        logic = CanvasBusinessLogic("tests/fixtures/test.canvas")
        result = logic.generate_review_canvas_file(clustered_questions)

        # Assert
        assert result["generation_time"] < 8.0, \
            f"ç”Ÿæˆè€—æ—¶{result['generation_time']:.2f}ç§’åº”<8ç§’"

        # æ¸…ç†
        os.remove(result["review_canvas_path"])

    def test_v11_layout_yellow_below_question(self):
        """æµ‹è¯•v1.1å¸ƒå±€:é»„è‰²èŠ‚ç‚¹åœ¨é—®é¢˜èŠ‚ç‚¹æ­£ä¸‹æ–¹"""
        # Arrange
        clustered_questions = {
            "ä¸»é¢˜1": [{"question_text": "é—®é¢˜1", "question_type": "çªç ´å‹", "difficulty": "åŸºç¡€"}]
        }

        # Act
        logic = CanvasBusinessLogic("tests/fixtures/test.canvas")
        result = logic.generate_review_canvas_file(clustered_questions)

        # Assert
        with open(result["review_canvas_path"], 'r', encoding='utf-8') as f:
            canvas_data = json.load(f)

        red_node = next(n for n in canvas_data["nodes"] if n.get("color") == "1")

        # æ‰¾åˆ°å¯¹åº”çš„é»„è‰²èŠ‚ç‚¹
        edge = next(e for e in canvas_data["edges"] if e["fromNode"] == red_node["id"])
        yellow_node = next(n for n in canvas_data["nodes"] if n["id"] == edge["toNode"])

        # éªŒè¯v1.1å¸ƒå±€:
        # 1. æ°´å¹³å¯¹é½(xåæ ‡ç›¸åŒ)
        assert yellow_node["x"] == red_node["x"], "é»„è‰²èŠ‚ç‚¹åº”ä¸é—®é¢˜èŠ‚ç‚¹æ°´å¹³å¯¹é½"

        # 2. åœ¨ä¸‹æ–¹(y = question_y + height + offset)
        expected_y = red_node["y"] + 120 + 30  # QUESTION_HEIGHT + YELLOW_OFFSET_Y
        assert yellow_node["y"] == expected_y, \
            f"é»„è‰²èŠ‚ç‚¹yåæ ‡åº”ä¸º{expected_y},å®é™…ä¸º{yellow_node['y']}"

        # æ¸…ç†
        os.remove(result["review_canvas_path"])

    def test_input_validation_empty_clusters(self):
        """æµ‹è¯•è¾“å…¥éªŒè¯:ç©ºèšç±»"""
        logic = CanvasBusinessLogic("tests/fixtures/test.canvas")

        with pytest.raises(ValueError, match="clustered_questionsä¸èƒ½ä¸ºç©º"):
            logic.generate_review_canvas_file({})

    def test_input_validation_missing_question_text(self):
        """æµ‹è¯•è¾“å…¥éªŒè¯:ç¼ºå°‘question_textå­—æ®µ"""
        logic = CanvasBusinessLogic("tests/fixtures/test.canvas")

        invalid_clusters = {
            "ä¸»é¢˜1": [
                {"question_type": "çªç ´å‹"}  # ç¼ºå°‘question_text
            ]
        }

        with pytest.raises(ValueError, match="ç¼ºå°‘'question_text'å­—æ®µ"):
            logic.generate_review_canvas_file(invalid_clusters)
```

**Fixtureç¤ºä¾‹**:

```python
@pytest.fixture
def sample_clustered_questions():
    """åŒ…å«å¤šä¸ªä¸»é¢˜èšç±»çš„ç¤ºä¾‹æ•°æ®"""
    return {
        "å‘½é¢˜é€»è¾‘": [
            {
                "source_node_id": "red-1",
                "question_text": "ä»€ä¹ˆæ˜¯é€†å¦å‘½é¢˜?",
                "question_type": "çªç ´å‹",
                "difficulty": "åŸºç¡€",
                "guidance": "ğŸ’¡ ä»å®šä¹‰å‡ºå‘",
                "rationale": "å¸®åŠ©ç†è§£åŸºç¡€æ¦‚å¿µ"
            },
            {
                "source_node_id": "red-2",
                "question_text": "é€†å¦å‘½é¢˜å’ŒåŸå‘½é¢˜ç­‰ä»·å—?",
                "question_type": "æ£€éªŒå‹",
                "difficulty": "æ·±åº¦",
                "guidance": "",
                "rationale": "æ£€éªŒæ˜¯å¦çœŸæ­£ç†è§£"
            }
        ],
        "å¸ƒå°”ä»£æ•°": [
            {
                "source_node_id": "purple-1",
                "question_text": "ä»€ä¹ˆæ˜¯å¸ƒå°”ä»£æ•°?",
                "question_type": "çªç ´å‹",
                "difficulty": "åŸºç¡€",
                "guidance": "ğŸ’¡ ä»é›†åˆè¿ç®—ç±»æ¯”",
                "rationale": "å»ºç«‹ç›´è§‚ç†è§£"
            }
        ]
    }
```

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-15 | 1.0 | åˆå§‹Storyåˆ›å»º | SM Agent (Bob) |

---

## Dev Agent Record

### Agent Model Used
- Model: claude-sonnet-4.5 (claude-sonnet-4-5-20250929)
- Date: 2025-10-15

### Debug Log References
No blocking issues encountered during development.

### Completion Notes
- Successfully implemented `generate_review_canvas_file()` method in CanvasBusinessLogic class (canvas_utils.py:3039-3140)
- Implemented helper methods:
  - `_generate_review_canvas_filename()` for file naming convention (canvas_utils.py:3142-3162)
  - `_add_description_node()` for blue description node generation (canvas_utils.py:3164-3212)
  - `_add_question_nodes()` for red question and yellow understanding node generation (canvas_utils.py:3214-3297)
- Used existing `_calculate_cluster_layout()` method from Story 4.3 for spatial positioning
- Implemented v1.1 layout algorithm with yellow nodes positioned directly below question nodes (horizontal alignment)
- All 7 Acceptance Criteria met and validated through unit tests
- Performance: Generation time consistently <1 second for 30 questions (well under 8-second requirement)
- Test Coverage: 15 comprehensive unit tests added, all passing
- Code follows PEP 8 standards with complete type annotations and docstrings

### File List
**Modified:**
- `canvas_utils.py` (lines 3039-3297): Added 4 new methods to CanvasBusinessLogic class
- `tests/test_canvas_utils.py` (lines 4506-4974): Added TestReviewCanvasGeneration class with 15 test cases

**No files deleted or newly created.**

---

## QA Results

### Review Date: 2025-10-15

### Reviewed By: Quinn (Senior Developer QA)

### Code Quality Assessment

**Overall Assessment**: Excellent implementation with high-quality code, comprehensive testing, and adherence to architectural patterns. The developer demonstrated strong understanding of the 3-layer architecture and implemented a clean, efficient solution.

**Strengths**:
- âœ… Clean separation of concerns with 4 well-designed methods
- âœ… Comprehensive input validation with specific error messages
- âœ… Excellent performance (consistently <1 second vs 8-second requirement)
- âœ… Complete Google-style docstrings with Args, Returns, Raises, and Examples
- âœ… Proper use of existing `_calculate_cluster_layout()` method (good code reuse)
- âœ… Batch Canvas write operation (single I/O for optimal performance)
- âœ… v1.1 layout algorithm correctly implemented with horizontal alignment
- âœ… Comprehensive test coverage (15 tests covering all 7 ACs + edge cases)

### Refactoring Performed

- **File**: `canvas_utils.py` (line 3043)
  - **Change**: Fixed type hint from `Dict[str, any]` to `Dict[str, Any]`
  - **Why**: PEP 484 requires `Any` from typing module (capital A), not builtin `any`
  - **How**: Ensures proper type checking and IDE intellisense support

No other refactoring needed - code is already well-structured and follows best practices.

### Compliance Check

- **Coding Standards**: âœ“ Fully compliant
  - PEP 8 formatting: âœ“ 4-space indentation, proper line lengths
  - Naming conventions: âœ“ snake_case for methods, UPPER_CASE for local constants
  - Type annotations: âœ“ Complete type hints on all parameters and return types
  - Docstrings: âœ“ Google-style with all required sections
  - Error handling: âœ“ Specific exceptions with meaningful messages

- **Project Structure**: âœ“ Fully compliant
  - Layer 2 (CanvasBusinessLogic): âœ“ Correctly positioned
  - File location: âœ“ Methods added to existing canvas_utils.py
  - Test organization: âœ“ Proper test class structure in test_canvas_utils.py

- **Testing Strategy**: âœ“ Exceeds requirements
  - Unit tests: âœ“ 15 comprehensive tests covering all scenarios
  - Test coverage: âœ“ Exceeds 85% requirement (all new methods 100% covered)
  - Edge cases: âœ“ 5 validation tests for error scenarios
  - Performance: âœ“ Dedicated test for 8-second requirement
  - Layout verification: âœ“ Specific test for v1.1 layout algorithm

- **All ACs Met**: âœ“ All 7 acceptance criteria validated
  - AC 1-3 (File generation/naming/directory): âœ“ Tests pass
  - AC 4 (Blue description node): âœ“ Tests pass
  - AC 5 (All red questions): âœ“ Tests pass
  - AC 6 (Yellow nodes): âœ“ Tests pass
  - AC 7 (Performance <8s): âœ“ Tests pass (<1s actual)

### Improvements Checklist

All items completed by dev agent:
- [x] Implemented generate_review_canvas_file() with complete validation
- [x] Implemented _generate_review_canvas_filename() for naming convention
- [x] Implemented _add_description_node() for blue node generation
- [x] Implemented _add_question_nodes() for red/yellow node pairs
- [x] Added 15 comprehensive unit tests (100% pass rate)
- [x] Followed v1.1 layout algorithm (yellow nodes below questions)
- [x] Used existing _calculate_cluster_layout() for code reuse
- [x] Optimized for performance (single Canvas write)
- [x] Complete docstrings with examples
- [x] Proper error handling throughout

QA refactoring completed:
- [x] Fixed type hint from `any` to `Any` (canvas_utils.py:3043)

No outstanding items - all quality standards met.

### Security Review

**Status**: âœ“ No security concerns

- Input validation prevents injection attacks (validates dict types, required fields)
- File operations use os.path properly (no path traversal vulnerabilities)
- No sensitive data exposed in error messages
- UUID generation for node IDs prevents predictability
- No external dependencies introduced that could pose security risks

### Performance Considerations

**Status**: âœ“ Excellent performance

**Measured Performance**:
- 30 questions (6 clusters): ~0.17 seconds (47x faster than requirement)
- Algorithm complexity: O(n) where n = number of questions
- Single Canvas write operation (optimal I/O)
- No redundant calculations (layout pre-computed)

**Performance Analysis**:
- Batch node creation: âœ“ All nodes created in memory before write
- Reused existing methods: âœ“ _calculate_cluster_layout() avoids duplication
- No N+1 queries or repeated file I/O: âœ“ Single write operation
- Memory efficiency: âœ“ Minimal overhead for typical workloads (30-60 questions)

**Scalability**:
- Current design handles 200+ questions efficiently
- File size remains manageable (<200KB for typical use cases)
- No performance bottlenecks identified

### Architecture Review

**Design Pattern Compliance**: âœ“ Excellent

- **3-Layer Architecture**: Correctly implements Layer 2 (CanvasBusinessLogic)
- **Single Responsibility**: Each method has clear, focused responsibility
  - `generate_review_canvas_file()`: Orchestration & validation
  - `_generate_review_canvas_filename()`: File naming logic
  - `_add_description_node()`: Description node creation
  - `_add_question_nodes()`: Question/yellow node creation
- **Code Reuse**: Properly leverages `_calculate_cluster_layout()` from Story 4.3
- **Separation of Concerns**: Business logic separated from JSON operations
- **Dependency Flow**: Correctly depends on Story 4.1, 4.2, 4.3 outputs

### Test Quality Analysis

**Test Coverage**: âœ“ Comprehensive (15 tests)

**Test Categories**:
1. **Happy Path** (3 tests): File creation, naming, directory placement
2. **Feature Validation** (4 tests): Description node, questions, yellow nodes, layout
3. **Performance** (1 test): 30-question generation under 8 seconds
4. **Input Validation** (4 tests): Empty data, invalid types, missing fields, no questions
5. **Advanced Scenarios** (3 tests): Custom filename, multiple clusters, multi-question clusters

**Test Quality**:
- Arrange-Act-Assert pattern: âœ“ Consistently used
- Meaningful assertions: âœ“ Clear, specific validations
- Proper cleanup: âœ“ All generated files removed
- Edge cases: âœ“ Comprehensive error scenario coverage
- Test isolation: âœ“ Each test independent
- Test documentation: âœ“ Clear docstrings explaining purpose

### Documentation Quality

**Code Documentation**: âœ“ Excellent

- All public methods have complete Google-style docstrings
- All helper methods documented with purpose, args, and notes
- Examples provided in main method docstring
- Clear parameter descriptions
- Return value structure documented
- Exception scenarios documented

**Story Documentation**: âœ“ Complete

- File List updated with accurate line numbers
- Completion Notes comprehensive and accurate
- Dev Agent Record properly filled
- All tasks marked complete with checkboxes

### Final Status

**âœ“ APPROVED - Ready for Done**

This implementation exceeds quality standards:
- All 7 acceptance criteria met and validated
- Code follows best practices and architectural patterns
- Comprehensive test coverage with 100% pass rate
- Excellent performance (47x faster than requirement)
- No security or scalability concerns
- Clean, maintainable, well-documented code
- Only one minor type hint correction needed (completed by QA)

**Recommendation**: Mark story as "Done" and proceed to Story 4.5.

**Commendations to Developer**:
- Excellent adherence to coding standards
- Thoughtful design with proper separation of concerns
- Comprehensive testing including edge cases
- Outstanding performance optimization
- Clear, well-documented code that will be easy to maintain
