# Story 35.8: RAG多模态搜索集成

## Status

| Field | Value |
|-------|-------|
| **Story ID** | 35.8 |
| **Epic** | [Epic 35: 多模态功能完整激活](../epics/EPIC-35-MULTIMODAL-ACTIVATION.md) |
| **Priority** | P2 (Medium) |
| **Phase** | Sprint 3 - P2 增强层 |
| **Estimated Duration** | 2 days |
| **Status** | Draft |
| **Created** | 2026-01-20 |
| **Dependencies** | Story 35.1 (上传API), Story 35.2 (搜索API) |

---

## Story

**As a** Canvas Learning System user performing RAG queries,
**I want** RAG search results to automatically include relevant multimodal content (images, PDFs, audio, video),
**So that** I receive comprehensive learning materials including visual and multimedia resources alongside text-based knowledge retrieval.

---

## Background

### Current State Analysis

1. **RAG Endpoint exists** (`backend/app/api/v1/endpoints/rag.py:153-225`)
   - `POST /api/v1/rag/query` endpoint functional
   - `RAGQueryResponse` model missing `multimodal_results` field
   - `LatencyInfo` already has `multimodal: Optional[float]` field (line 73)

2. **RAG Service ready** (`backend/app/services/rag_service.py:246-261`)
   - Initial state already includes `multimodal_results: []`
   - LangGraph StateGraph integration functional

3. **MultimodalRetriever complete** (`src/agentic_rag/retrievers/multimodal_retriever.py`)
   - 758 lines of production-ready code
   - `retrieve()` method returns `List[MultimodalResult]`
   - `multimodal_retrieval_node()` LangGraph node ready
   - Caching, 2s timeout, thumbnail formatting

4. **MultimodalStore complete** (`src/agentic_rag/storage/multimodal_store.py`)
   - 511 lines with LanceDB + Neo4j dual storage
   - `search()` method: async vector similarity search
   - Returns `list[tuple[MultimodalContent, float]]`

### Integration Gap

The multimodal retrieval components exist but are not wired to the RAG API response. This story bridges that gap with RRF fusion.

---

## Acceptance Criteria

### AC 35.8.1: RAG Response Contains multimodal_results Field

**Given** a user sends a POST request to `/api/v1/rag/query`
**When** the query is processed by the RAG service
**Then** the response includes a `multimodal_results` field as an array

**Technical Specification:**
```python
# In backend/app/api/v1/endpoints/rag.py
class MultimodalResultItem(BaseModel):
    """多模态检索结果项"""
    id: str = Field(..., description="内容ID")
    media_type: Literal["image", "pdf", "audio", "video"]
    path: str = Field(..., description="文件路径")
    thumbnail: Optional[str] = Field(None, description="缩略图Base64或URL")
    relevance_score: float = Field(..., ge=0.0, le=1.0)
    metadata: dict = Field(default_factory=dict)

class RAGQueryResponse(BaseModel):
    results: List[SearchResultItem]
    multimodal_results: List[MultimodalResultItem] = Field(
        default_factory=list,
        description="多模态检索结果"
    )
    quality_grade: str
    # ... existing fields
```

**Verification:**
```bash
curl -X POST http://localhost:8000/api/v1/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query": "逆否命题图解"}' | jq '.multimodal_results'
# Expected: Array (may be empty if no multimodal content)
```

---

### AC 35.8.2: Parallel MultimodalStore.search() Invocation

**Given** a RAG query is submitted
**When** the RAG service processes the query
**Then** `MultimodalStore.search()` is called in parallel with other retrieval sources

**Technical Specification:**
```python
# In backend/app/services/rag_service.py or src/agentic_rag/graph/canvas_rag_graph.py
import asyncio

async def parallel_retrieval(query: str, query_vector: list[float]):
    # Parallel execution of all retrieval sources
    graphiti_task = asyncio.create_task(graphiti_store.search(query))
    lancedb_task = asyncio.create_task(lancedb_store.search(query_vector))
    multimodal_task = asyncio.create_task(
        multimodal_store.search(query_vector, top_k=5)
    )

    graphiti_results, lancedb_results, multimodal_results = await asyncio.gather(
        graphiti_task, lancedb_task, multimodal_task,
        return_exceptions=True
    )
    return graphiti_results, lancedb_results, multimodal_results
```

**Verification:**
- Log timestamps show parallel execution (not sequential)
- Total latency < sum of individual latencies
- `latency_ms.multimodal` field populated in response

---

### AC 35.8.3: Results Include Thumbnail URLs

**Given** multimodal content has associated thumbnails
**When** results are returned in `multimodal_results`
**Then** each result includes a `thumbnail` field with URL or Base64 data

**Technical Specification:**
```python
# MultimodalResultItem already includes thumbnail field
# Ensure MultimodalRetriever.retrieve() populates this:

class MultimodalResult:
    content_id: str
    media_type: MediaType
    file_path: str
    thumbnail: Optional[str]  # Base64 or URL
    relevance_score: float
    metadata: dict
```

**Verification:**
```python
# Test case
def test_multimodal_results_have_thumbnails():
    response = client.post("/api/v1/rag/query", json={"query": "diagram"})
    for item in response.json()["multimodal_results"]:
        if item["media_type"] == "image":
            assert item["thumbnail"] is not None
            assert item["thumbnail"].startswith("data:image/") or \
                   item["thumbnail"].startswith("http")
```

---

### AC 35.8.4: RRF Fusion Weight 0.3 for Multimodal

**Given** multimodal results are retrieved alongside text results
**When** results are fused using RRF algorithm
**Then** multimodal results use weight factor 0.3

**Technical Specification:**
```python
# In src/agentic_rag/fusion/rrf_fusion.py or equivalent

RRF_WEIGHTS = {
    "graphiti": 0.4,      # Temporal/relationship results
    "lancedb": 0.3,       # Semantic vector results
    "multimodal": 0.3,    # Multimodal content results
}

def rrf_fuse(
    graphiti_results: list,
    lancedb_results: list,
    multimodal_results: list,
    k: int = 60
) -> list:
    """
    Reciprocal Rank Fusion with weighted sources.

    RRF formula: score = sum(weight / (k + rank))
    """
    fused_scores = defaultdict(float)

    for rank, result in enumerate(graphiti_results):
        fused_scores[result.id] += RRF_WEIGHTS["graphiti"] / (k + rank + 1)

    for rank, result in enumerate(lancedb_results):
        fused_scores[result.id] += RRF_WEIGHTS["lancedb"] / (k + rank + 1)

    for rank, result in enumerate(multimodal_results):
        fused_scores[result.id] += RRF_WEIGHTS["multimodal"] / (k + rank + 1)

    return sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)
```

**Verification:**
```python
def test_rrf_multimodal_weight():
    # Mock results where multimodal should rank higher due to relevance
    graphiti = [{"id": "a", "score": 0.9}]
    lancedb = [{"id": "b", "score": 0.85}]
    multimodal = [{"id": "c", "score": 0.95}]  # Highest raw score

    fused = rrf_fuse(graphiti, lancedb, multimodal)

    # With weight 0.3, multimodal shouldn't dominate despite high score
    # Verify weight is correctly applied
    assert RRF_WEIGHTS["multimodal"] == 0.3
```

---

## Tasks

### Task 0: Add RAG Endpoints to OpenAPI Spec (SDD Prerequisite)

**File:** `specs/api/fastapi-backend-api.openapi.yml`

**Rationale:** RAG endpoints exist in code but are NOT defined in OpenAPI spec. Per SoT hierarchy (OpenAPI Level 4 > Code Level 6), spec must be updated first.

1. Add `RAG` tag to tags section:
   ```yaml
   - name: RAG
     description: 智能检索增强生成
   ```
2. Add `/api/v1/rag/query` POST endpoint definition
3. Add `/api/v1/rag/status` GET endpoint definition
4. Add `RAGQueryRequest` schema to components
5. Add `RAGQueryResponse` schema with `multimodal_results` field
6. Add `MultimodalResultItem` schema definition
7. Add `SearchResultItem`, `LatencyInfo`, `RAGQueryMetadata` schemas

**Estimated:** 1 hour

**Prerequisite for:** Tasks 1-7 (all subsequent tasks depend on spec being defined first)

---

### Task 1: Add MultimodalResultItem Model (AC 35.8.1)

**File:** `backend/app/api/v1/endpoints/rag.py`

1. Add `MultimodalResultItem` Pydantic model after `SearchResultItem`
2. Add `multimodal_results` field to `RAGQueryResponse`
3. Update OpenAPI example in Config

**Estimated:** 30 minutes

---

### Task 2: Wire MultimodalRetriever to RAG Service (AC 35.8.2)

**File:** `backend/app/services/rag_service.py`

1. Import `MultimodalRetriever` from `src/agentic_rag/retrievers/`
2. Add parallel retrieval in `query()` method using `asyncio.gather()`
3. Populate `multimodal_results` in return state

**Integration Point:** Line 266-270 where `canvas_agentic_rag.ainvoke()` is called

**Estimated:** 1 hour

---

### Task 3: Ensure Thumbnail Population (AC 35.8.3)

**File:** `src/agentic_rag/retrievers/multimodal_retriever.py`

1. Verify `retrieve()` method populates `thumbnail` field
2. Add thumbnail URL/Base64 formatting if missing
3. Handle cases where thumbnail generation failed

**Estimated:** 45 minutes

---

### Task 4: Implement RRF Multimodal Fusion (AC 35.8.4)

**Files:**
- `src/agentic_rag/fusion/rrf_fusion.py` (create if not exists)
- `backend/app/services/rag_service.py`

1. Define `RRF_WEIGHTS` constant with multimodal = 0.3
2. Implement or extend `rrf_fuse()` function
3. Integrate fusion into RAG query pipeline

**Estimated:** 1.5 hours

---

### Task 5: Update OpenAPI Specification (SDD Compliance)

**File:** `specs/api/fastapi-backend-api.openapi.yml`

1. Add `MultimodalResultItem` schema
2. Update `RAGQueryResponse` schema with `multimodal_results` field
3. Add examples

**Estimated:** 30 minutes

---

### Task 6: Write Unit Tests

**File:** `backend/tests/unit/test_rag_multimodal_integration.py`

Test cases:
1. `test_rag_response_has_multimodal_results_field`
2. `test_parallel_retrieval_execution`
3. `test_multimodal_results_have_thumbnails`
4. `test_rrf_multimodal_weight_is_0_3`
5. `test_empty_multimodal_results_when_no_content`

**Estimated:** 1 hour

---

### Task 7: Integration Test

**File:** `backend/tests/integration/test_rag_multimodal_e2e.py`

1. Upload test image via multimodal API
2. Execute RAG query related to image content
3. Verify image appears in `multimodal_results`
4. Verify thumbnail is present

**Estimated:** 45 minutes

---

## Dev Notes

### SDD规范参考

| Spec Type | File | Section | Status |
|-----------|------|---------|--------|
| OpenAPI | `specs/api/fastapi-backend-api.openapi.yml` | `/rag/query` response schema | ⚠️ **Task 0 Required** - RAG endpoints not yet in spec |
| JSON Schema | `specs/data/multimodal-content.schema.json` | MultimodalContent definition | ✅ Exists |
| JSON Schema | `specs/data/agent-response.schema.json` | Response patterns | ✅ Exists |

> **Note:** After Task 0 completion, update this table with actual OpenAPI line numbers for RAG endpoints.

### ADR决策关联

| ADR | Decision | Impact on Story |
|-----|----------|-----------------|
| [ADR-0002](../architecture/decisions/0002-langgraph-agents.md) | LangGraph multi-agent architecture | Use StateGraph for orchestration |
| [ADR-0003](../architecture/decisions/0003-graphiti-memory.md) | 3-layer memory (Temporal + Graphiti + Semantic) | Hybrid search integration |

### Architecture References

- **4-Layer Architecture:** `docs/architecture/canvas-layer-architecture.md`
- **Tech Stack:** `docs/architecture/tech-stack.md`
- **Coding Standards:** `docs/architecture/coding-standards.md`

### Files to Modify

| File | Changes | Lines Affected |
|------|---------|----------------|
| `backend/app/api/v1/endpoints/rag.py` | Add MultimodalResultItem, update RAGQueryResponse | ~20 new lines |
| `backend/app/services/rag_service.py` | Wire multimodal retrieval, parallel execution | ~30 modified |
| `specs/api/fastapi-backend-api.openapi.yml` | Add multimodal_results schema | ~25 new lines |

### Files to Reuse (Read-Only)

| File | Purpose | Reference |
|------|---------|-----------|
| `src/agentic_rag/retrievers/multimodal_retriever.py` | Retrieval logic | Lines 1-758 |
| `src/agentic_rag/storage/multimodal_store.py` | Storage interface | `search()` method |
| `src/agentic_rag/models/multimodal_content.py` | Data models | MultimodalContent class |

### Key Integration Points

```
RAG Query Flow with Multimodal:
┌──────────────────┐
│  POST /rag/query │
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│   rag_service    │
│     .query()     │
└────────┬─────────┘
         │
    ┌────┴────┬──────────────┐
    ▼         ▼              ▼
┌───────┐ ┌───────┐ ┌─────────────────┐
│Graphiti│ │LanceDB│ │MultimodalStore  │
│ .search │ │.search│ │   .search()     │
└───┬────┘ └───┬───┘ └────────┬────────┘
    │          │              │
    └────┬─────┴──────────────┘
         │ asyncio.gather()
         ▼
┌──────────────────┐
│   RRF Fusion     │
│ (multimodal: 0.3)│
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│ RAGQueryResponse │
│ + multimodal_results │
└──────────────────┘
```

### Testing Strategy

1. **Unit Tests**: Mock MultimodalStore, verify RRF weights
2. **Integration Tests**: Real multimodal content, verify E2E flow
3. **Performance Tests**: Verify parallel execution reduces latency

### Rollback Plan

- Remove `multimodal_results` field from response model
- Comment out parallel retrieval call
- Revert OpenAPI spec changes

### Performance Considerations

- Multimodal search adds ~50-200ms latency
- Parallel execution mitigates impact
- Consider adding feature flag: `ENABLE_MULTIMODAL_RAG=true`

---

### Conflict Resolutions (Step 8d)

| # | Conflict | Decision | Action | Resolved By | Timestamp |
|---|----------|----------|--------|-------------|-----------|
| 1 | RAG endpoints not in OpenAPI spec (Code exists at rag.py:153-225, but OpenAPI Level 4 has no RAG endpoints) | Accept SoT hierarchy | Task 0 added as prerequisite | User | 2026-01-20 |

**SoT Hierarchy Applied:** OpenAPI (Level 4) > Story (Level 5) > Code (Level 6)

---

## Change Log

| Date | Author | Changes |
|------|--------|---------|
| 2026-01-20 | SM Agent (Bob) | Initial story creation |
| 2026-01-20 | PO Agent (Sarah) | Validation: Added Task 0 (OpenAPI prerequisite), Conflict Resolution section, updated SDD规范参考 |
| 2026-01-31 | Quinn (QA) | QA Review completed |

---

## QA Results

### Review Date: 2026-01-31

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

实现质量总体良好。代码结构清晰，遵循了现有的架构模式。主要的代码组件已经完成：

1. **API 层** (`rag.py`): `MultimodalResultItem` 模型定义完整，`RAGQueryResponse` 正确包含 `multimodal_results` 字段
2. **服务层** (`rag_service.py`): 初始状态正确包含 `multimodal_results`，StateGraph 集成完善
3. **检索层** (`multimodal_retriever.py`): 758 行生产级代码，支持缓存和 2s 超时
4. **融合层** (`rrf_fusion.py`): 支持多源 RRF 融合，包含 multimodal 权重

### Refactoring Performed

无重构执行 - 代码质量满足标准。

### Compliance Check

- Coding Standards: ✓ 遵循 Python 命名规范，Pydantic 模型使用正确
- Project Structure: ✓ 文件位置正确，符合项目结构
- Testing Strategy: ✓ 单元测试 + 集成测试覆盖 4 个 AC
- All ACs Met: ⚠️ AC 35.8.4 权重配置与规范不一致 (见下方)

### Improvements Checklist

- [x] MultimodalResultItem 模型定义 (AC 35.8.1)
- [x] RAGQueryResponse 包含 multimodal_results 字段 (AC 35.8.1)
- [x] MultimodalRetriever 集成到 StateGraph (AC 35.8.2)
- [x] Thumbnail 字段映射逻辑 (AC 35.8.3)
- [x] 单元测试覆盖 (test_rag_multimodal_integration.py)
- [x] 集成测试覆盖 (test_rag_multimodal_api.py)
- [x] OpenAPI 规范更新 (MultimodalResultItem schema)
- [ ] **RRF 权重对齐**: Story 规范要求 `multimodal: 0.3`，但 `nodes.py:280` 实现为 `0.15`

### Security Review

无安全问题。API 使用标准 Pydantic 验证，无敏感数据暴露。

### Performance Considerations

- Multimodal 检索有 2s 超时保护 (`multimodal_retriever.py`)
- 并行检索架构 (`asyncio.gather`) 确保延迟可控
- `latency_ms.multimodal` 字段提供性能监控

### Files Modified During Review

无文件修改。

### Gate Status

Gate: **CONCERNS** → `docs/qa/gates/35.8-rag-multimodal-search-integration.yml`

**CONCERNS 原因**: AC 35.8.4 规范与实现不一致
- Story 规范: `multimodal: 0.3`
- 实际实现: `multimodal: 0.15` (nodes.py:280)
- 建议: 确认设计意图后统一规范或代码

### Recommended Status

**[⚠️ Changes Required]** - 需解决 RRF 权重不一致问题

**建议操作**:
1. 若 5 源权重设计 (0.25/0.25/0.20/0.15/0.15) 是正确的，更新 Story AC 35.8.4 规范
2. 若 0.3 是正确的，更新 `nodes.py` DEFAULT_SOURCE_WEIGHTS

(Story owner 决定最终状态)
