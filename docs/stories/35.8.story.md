# Story 35.8: RAG多模态搜索集成

## Status

| Field | Value |
|-------|-------|
| **Story ID** | 35.8 |
| **Epic** | [Epic 35: 多模态功能完整激活](../epics/EPIC-35-MULTIMODAL-ACTIVATION.md) |
| **Priority** | P1 (High) — 对抗性审查升级 |
| **Phase** | Sprint 3 - P2 增强层 |
| **Estimated Duration** | 0.5 days (仅规范对齐 + 测试修复) |
| **Status** | Ready |
| **Created** | 2026-01-20 |
| **Updated** | 2026-02-09 (对抗性审查后更新) |
| **Dependencies** | Story 35.1 (上传API), Story 35.2 (搜索API) |

---

## Story

**As a** Canvas Learning System user performing RAG queries,
**I want** RAG search results to automatically include relevant multimodal content (images, PDFs, audio, video),
**So that** I receive comprehensive learning materials including visual and multimedia resources alongside text-based knowledge retrieval.

---

## Background

### Current State Analysis

1. **RAG Endpoint exists** (`backend/app/api/v1/endpoints/rag.py:153-225`)
   - `POST /api/v1/rag/query` endpoint functional
   - `RAGQueryResponse` model missing `multimodal_results` field
   - `LatencyInfo` already has `multimodal: Optional[float]` field (line 73)

2. **RAG Service ready** (`backend/app/services/rag_service.py:246-261`)
   - Initial state already includes `multimodal_results: []`
   - LangGraph StateGraph integration functional

3. **MultimodalRetriever complete** (`src/agentic_rag/retrievers/multimodal_retriever.py`)
   - 758 lines of production-ready code
   - `retrieve()` method returns `List[MultimodalResult]`
   - `multimodal_retrieval_node()` LangGraph node ready
   - Caching, 2s timeout, thumbnail formatting

4. **MultimodalStore complete** (`src/agentic_rag/storage/multimodal_store.py`)
   - 511 lines with LanceDB + Neo4j dual storage
   - `search()` method: async vector similarity search
   - Returns `list[tuple[MultimodalContent, float]]`

### Integration Gap

The multimodal retrieval components exist but are not wired to the RAG API response. This story bridges that gap with RRF fusion.

---

## Acceptance Criteria

### AC 35.8.1: RAG Response Contains multimodal_results Field

**Given** a user sends a POST request to `/api/v1/rag/query`
**When** the query is processed by the RAG service
**Then** the response includes a `multimodal_results` field as an array

**Technical Specification:**
```python
# In backend/app/api/v1/endpoints/rag.py
class MultimodalResultItem(BaseModel):
    """多模态检索结果项"""
    id: str = Field(..., description="内容ID")
    media_type: Literal["image", "pdf", "audio", "video"]
    path: str = Field(..., description="文件路径")
    thumbnail: Optional[str] = Field(None, description="缩略图Base64或URL")
    relevance_score: float = Field(..., ge=0.0, le=1.0)
    metadata: dict = Field(default_factory=dict)

class RAGQueryResponse(BaseModel):
    results: List[SearchResultItem]
    multimodal_results: List[MultimodalResultItem] = Field(
        default_factory=list,
        description="多模态检索结果"
    )
    quality_grade: str
    # ... existing fields
```

**Verification:**
```bash
curl -X POST http://localhost:8000/api/v1/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query": "逆否命题图解"}' | jq '.multimodal_results'
# Expected: Array (may be empty if no multimodal content)
```

---

### AC 35.8.2: Parallel MultimodalStore.search() Invocation

**Given** a RAG query is submitted
**When** the RAG service processes the query
**Then** `MultimodalStore.search()` is called in parallel with other retrieval sources

**Technical Specification (实际实现):**
```python
# In src/agentic_rag/state_graph.py — 使用 LangGraph Send 模式实现 5 路并行
from langgraph.types import Send

def fan_out_retrieval(state: CanvasRAGState) -> list[Send]:
    """5-way parallel retrieval via LangGraph Send pattern"""
    return [
        Send("retrieve_graphiti", state),
        Send("retrieve_lancedb", state),
        Send("retrieve_textbook", state),
        Send("retrieve_cross_canvas", state),
        Send("retrieve_multimodal", state),  # ← multimodal 并行检索
    ]
```

**Verification:**
- Log timestamps show parallel execution (not sequential)
- Total latency < sum of individual latencies
- `latency_ms.multimodal` field populated in response
- `fan_out_retrieval()` returns 5 个 Send 对象

---

### AC 35.8.3: Results Include Thumbnail URLs

**Given** multimodal content has associated thumbnails
**When** results are returned in `multimodal_results`
**Then** each result includes a `thumbnail` field with URL or Base64 data

**Technical Specification:**
```python
# MultimodalResultItem already includes thumbnail field
# Ensure MultimodalRetriever.retrieve() populates this:

class MultimodalResult:
    content_id: str
    media_type: MediaType
    file_path: str
    thumbnail: Optional[str]  # Base64 or URL
    relevance_score: float
    metadata: dict
```

**Verification:**
```python
# Test case
def test_multimodal_results_have_thumbnails():
    response = client.post("/api/v1/rag/query", json={"query": "diagram"})
    for item in response.json()["multimodal_results"]:
        if item["media_type"] == "image":
            assert item["thumbnail"] is not None
            assert item["thumbnail"].startswith("data:image/") or \
                   item["thumbnail"].startswith("http")
```

---

### AC 35.8.4: RRF Fusion Weight for Multimodal (规范修正: 0.3 → 0.15)

> **对抗性审查修正 (2026-02-09)**:
> 原始 AC 假设 3 源 RRF (graphiti 0.4 + lancedb 0.3 + multimodal 0.3)。
> 实际代码采用 5 源设计 (`src/agentic_rag/nodes.py:277-283`)，总和 = 1.0。
> **决策**: 保留代码中的 5 源权重设计，更新 Story 规范以匹配。

**Given** multimodal results are retrieved alongside text results from 5 sources
**When** results are fused using RRF algorithm
**Then** multimodal results use weight factor **0.15** (5 源平衡设计)

**实际权重配置** (`src/agentic_rag/nodes.py:277-283`):
```python
DEFAULT_SOURCE_WEIGHTS = {
    "graphiti": 0.25,       # Temporal/relationship results
    "lancedb": 0.25,        # Semantic vector results
    "textbook": 0.20,       # Textbook content results
    "cross_canvas": 0.15,   # Cross-canvas results
    "multimodal": 0.15,     # Multimodal content results
}
# Total: 1.0
```

**设计理由**: Multimodal 和 cross_canvas 作为辅助数据源，权重低于核心文本源 (graphiti + lancedb)。

**Verification:**
```python
def test_rrf_multimodal_weight():
    from agentic_rag.nodes import DEFAULT_SOURCE_WEIGHTS
    assert DEFAULT_SOURCE_WEIGHTS["multimodal"] == 0.15
    assert sum(DEFAULT_SOURCE_WEIGHTS.values()) == pytest.approx(1.0)
```

**测试修复**: `test_rag_multimodal_integration.py:309` 已断言 `== 0.15`，与代码一致。

---

## Tasks

### Task 0: Add RAG Endpoints to OpenAPI Spec (SDD Prerequisite)

**File:** `specs/api/fastapi-backend-api.openapi.yml`

**Rationale:** RAG endpoints exist in code but are NOT defined in OpenAPI spec. Per SoT hierarchy (OpenAPI Level 4 > Code Level 6), spec must be updated first.

1. Add `RAG` tag to tags section:
   ```yaml
   - name: RAG
     description: 智能检索增强生成
   ```
2. Add `/api/v1/rag/query` POST endpoint definition
3. Add `/api/v1/rag/status` GET endpoint definition
4. Add `RAGQueryRequest` schema to components
5. Add `RAGQueryResponse` schema with `multimodal_results` field
6. Add `MultimodalResultItem` schema definition
7. Add `SearchResultItem`, `LatencyInfo`, `RAGQueryMetadata` schemas

**Estimated:** 1 hour

**Prerequisite for:** Tasks 1-7 (all subsequent tasks depend on spec being defined first)

---

### Task 1: Add MultimodalResultItem Model (AC 35.8.1)

**File:** `backend/app/api/v1/endpoints/rag.py`

1. Add `MultimodalResultItem` Pydantic model after `SearchResultItem`
2. Add `multimodal_results` field to `RAGQueryResponse`
3. Update OpenAPI example in Config

**Estimated:** 30 minutes

---

### Task 2: Wire MultimodalRetriever to RAG Service (AC 35.8.2)

**File:** `src/agentic_rag/state_graph.py`

1. ✅ `retrieve_multimodal` node 已添加到 StateGraph (line 270-278)
2. ✅ `fan_out_retrieval()` 使用 LangGraph `Send` 模式实现 5 路并行检索
3. ✅ `multimodal_results` 通过 StateGraph state 传递

**实际实现**: 并行检索通过 LangGraph StateGraph `Send` 模式实现（非 `asyncio.gather()`）。
`rag_service.py:268` 调用 `canvas_agentic_rag.ainvoke()` 委托给 StateGraph。

**Estimated:** 1 hour

---

### Task 3: Ensure Thumbnail Population (AC 35.8.3)

**File:** `src/agentic_rag/retrievers/multimodal_retriever.py`

1. Verify `retrieve()` method populates `thumbnail` field
2. Add thumbnail URL/Base64 formatting if missing
3. Handle cases where thumbnail generation failed

**Estimated:** 45 minutes

---

### Task 4: Implement RRF Multimodal Fusion (AC 35.8.4)

**Files:**
- `src/agentic_rag/fusion/rrf_fusion.py` (create if not exists)
- `backend/app/services/rag_service.py`

1. ✅ `DEFAULT_SOURCE_WEIGHTS` 已定义 multimodal = 0.15 (`nodes.py:277-283`)
2. ✅ `_fuse_rrf_multi_source()` 实现纯 RRF (不使用权重)
3. ✅ `_fuse_weighted_multi_source()` 使用 `DEFAULT_SOURCE_WEIGHTS` 加权融合
4. ✅ 融合算法通过 `fuse_results()` 节点集成到 StateGraph

**Estimated:** 1.5 hours

---

### Task 5: Update OpenAPI Specification (SDD Compliance)

**File:** `specs/api/fastapi-backend-api.openapi.yml`

1. Add `MultimodalResultItem` schema
2. Update `RAGQueryResponse` schema with `multimodal_results` field
3. Add examples

**Estimated:** 30 minutes

---

### Task 6: Write Unit Tests

**File:** `backend/tests/unit/test_rag_multimodal_integration.py`

Test cases:
1. `test_rag_response_has_multimodal_results_field`
2. `test_parallel_retrieval_execution`
3. `test_multimodal_results_have_thumbnails`
4. `test_rrf_multimodal_weight_is_0_15`
5. `test_empty_multimodal_results_when_no_content`

**Estimated:** 1 hour

---

### Task 7: Integration Test

**File:** `backend/tests/integration/test_rag_multimodal_e2e.py`

1. Upload test image via multimodal API
2. Execute RAG query related to image content
3. Verify image appears in `multimodal_results`
4. Verify thumbnail is present

**Estimated:** 45 minutes

---

## Dev Notes

### SDD规范参考

| Spec Type | File | Section | Status |
|-----------|------|---------|--------|
| OpenAPI | `specs/api/fastapi-backend-api.openapi.yml` | `/rag/query` response schema | ⚠️ **Task 0 Required** - RAG endpoints not yet in spec |
| JSON Schema | `specs/data/multimodal-content.schema.json` | MultimodalContent definition | ✅ Exists |
| JSON Schema | `specs/data/agent-response.schema.json` | Response patterns | ✅ Exists |

> **Note:** After Task 0 completion, update this table with actual OpenAPI line numbers for RAG endpoints.

### ADR决策关联

| ADR | Decision | Impact on Story |
|-----|----------|-----------------|
| [ADR-0002](../architecture/decisions/0002-langgraph-agents.md) | LangGraph multi-agent architecture | Use StateGraph for orchestration |
| [ADR-0003](../architecture/decisions/0003-graphiti-memory.md) | 3-layer memory (Temporal + Graphiti + Semantic) | Hybrid search integration |

### Architecture References

- **4-Layer Architecture:** `docs/architecture/canvas-layer-architecture.md`
- **Tech Stack:** `docs/architecture/tech-stack.md`
- **Coding Standards:** `docs/architecture/coding-standards.md`

### Files to Modify

| File | Changes | Lines Affected |
|------|---------|----------------|
| `backend/app/api/v1/endpoints/rag.py` | Add MultimodalResultItem, update RAGQueryResponse | ~20 new lines |
| `backend/app/services/rag_service.py` | Wire multimodal retrieval, parallel execution | ~30 modified |
| `specs/api/fastapi-backend-api.openapi.yml` | Add multimodal_results schema | ~25 new lines |

### Files to Reuse (Read-Only)

| File | Purpose | Reference |
|------|---------|-----------|
| `src/agentic_rag/retrievers/multimodal_retriever.py` | Retrieval logic | Lines 1-758 |
| `src/agentic_rag/storage/multimodal_store.py` | Storage interface | `search()` method |
| `src/agentic_rag/models/multimodal_content.py` | Data models | MultimodalContent class |

### Key Integration Points

```
RAG Query Flow with Multimodal (5-way parallel via StateGraph Send):
┌──────────────────┐
│  POST /rag/query │
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│   rag_service    │
│     .query()     │
└────────┬─────────┘
         │ canvas_agentic_rag.ainvoke()
         ▼
┌──────────────────┐
│ fan_out_retrieval│ ← LangGraph Send pattern
└────────┬─────────┘
         │
    ┌────┴────┬────────┬──────────┬───────────┐
    ▼         ▼        ▼          ▼           ▼
┌───────┐ ┌───────┐ ┌────────┐ ┌──────────┐ ┌────────────┐
│Graphiti│ │LanceDB│ │Textbook│ │CrossCanvas│ │Multimodal  │
│ 0.25   │ │ 0.25  │ │ 0.20   │ │  0.15    │ │  0.15      │
└───┬────┘ └───┬───┘ └───┬────┘ └────┬─────┘ └─────┬──────┘
    │          │         │           │              │
    └────┬─────┴─────────┴───────────┴──────────────┘
         │ fuse_results (RRF / Weighted / Cascade)
         ▼
┌──────────────────┐
│ RAGQueryResponse │
│ + multimodal_results │
└──────────────────┘
```

### Testing Strategy

1. **Unit Tests**: Mock MultimodalStore, verify RRF weights
2. **Integration Tests**: Real multimodal content, verify E2E flow
3. **Performance Tests**: Verify parallel execution reduces latency

### Rollback Plan

- Remove `multimodal_results` field from response model
- Comment out parallel retrieval call
- Revert OpenAPI spec changes

### Performance Considerations

- Multimodal search adds ~50-200ms latency
- Parallel execution mitigates impact
- Consider adding feature flag: `ENABLE_MULTIMODAL_RAG=true`

---

### Conflict Resolutions (Step 8d)

| # | Conflict | Decision | Action | Resolved By | Timestamp |
|---|----------|----------|--------|-------------|-----------|
| 1 | RAG endpoints not in OpenAPI spec (Code exists at rag.py:153-225, but OpenAPI Level 4 has no RAG endpoints) | Accept SoT hierarchy | Task 0 added as prerequisite | User | 2026-01-20 |

**SoT Hierarchy Applied:** OpenAPI (Level 4) > Story (Level 5) > Code (Level 6)

---

## Change Log

| Date | Author | Changes |
|------|--------|---------|
| 2026-01-20 | SM Agent (Bob) | Initial story creation |
| 2026-01-20 | PO Agent (Sarah) | Validation: Added Task 0 (OpenAPI prerequisite), Conflict Resolution section, updated SDD规范参考 |
| 2026-01-31 | Quinn (QA) | QA Review completed |
| 2026-02-09 | John (PM Agent) | 对抗性审查: AC 35.8.4 权重规范从 0.3 修正为 0.15 (匹配 5 源设计), Status Draft→Ready, Priority P2→P1 |

---

## QA Results

### Review Date: 2026-01-31

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

实现质量总体良好。代码结构清晰，遵循了现有的架构模式。主要的代码组件已经完成：

1. **API 层** (`rag.py`): `MultimodalResultItem` 模型定义完整，`RAGQueryResponse` 正确包含 `multimodal_results` 字段
2. **服务层** (`rag_service.py`): 初始状态正确包含 `multimodal_results`，StateGraph 集成完善
3. **检索层** (`multimodal_retriever.py`): 758 行生产级代码，支持缓存和 2s 超时
4. **融合层** (`rrf_fusion.py`): 支持多源 RRF 融合，包含 multimodal 权重

### Refactoring Performed

无重构执行 - 代码质量满足标准。

### Compliance Check

- Coding Standards: ✓ 遵循 Python 命名规范，Pydantic 模型使用正确
- Project Structure: ✓ 文件位置正确，符合项目结构
- Testing Strategy: ✓ 单元测试 + 集成测试覆盖 4 个 AC
- All ACs Met: ⚠️ AC 35.8.4 权重配置与规范不一致 (见下方)

### Improvements Checklist

- [x] MultimodalResultItem 模型定义 (AC 35.8.1)
- [x] RAGQueryResponse 包含 multimodal_results 字段 (AC 35.8.1)
- [x] MultimodalRetriever 集成到 StateGraph (AC 35.8.2)
- [x] Thumbnail 字段映射逻辑 (AC 35.8.3)
- [x] 单元测试覆盖 (test_rag_multimodal_integration.py)
- [x] 集成测试覆盖 (test_rag_multimodal_api.py)
- [x] OpenAPI 规范更新 (MultimodalResultItem schema)
- [x] **RRF 权重对齐**: Story AC 35.8.4 已更新为 `multimodal: 0.15` 匹配 5 源设计

### Security Review

无安全问题。API 使用标准 Pydantic 验证，无敏感数据暴露。

### Performance Considerations

- Multimodal 检索有 2s 超时保护 (`multimodal_retriever.py`)
- 并行检索架构 (`asyncio.gather`) 确保延迟可控
- `latency_ms.multimodal` 字段提供性能监控

### Files Modified During Review

无文件修改。

### Gate Status

Gate: **CONCERNS → RESOLVED** → `docs/qa/gates/35.8-rag-multimodal-search-integration.yml`

**原 CONCERNS 原因**: AC 35.8.4 规范与实现不一致
- Story 规范 (旧): `multimodal: 0.3` (3 源设计假设)
- 实际实现: `multimodal: 0.15` (5 源设计, nodes.py:282)

**解决方案 (2026-02-09)**: 更新 Story AC 35.8.4 规范为 0.15，匹配 5 源设计。
代码 + 测试 (`test_rag_multimodal_integration.py:309`) 已一致。

### Recommended Status

**✓ Ready for Done** — CONCERNS 已解决 (AC 规范已对齐代码)
