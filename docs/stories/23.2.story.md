# Story 23.2: LanceDB Embedding Pipeline

## Status: Draft

## Epic Context & Background

**所属Epic**: EPIC-23 - RAG智能推理系统
**Epic文档**: [EPIC-23-RAG-INTELLIGENT-INFERENCE.md](../prd/EPIC-23-RAG-INTELLIGENT-INFERENCE.md)
**优先级**: P0 (Critical)
**估计**: 3 Story Points

**本Story在Epic中的定位**:
- Epic 23的**第二个Story**，构建LanceDB完整向量化流程
- 解决Embedding Pipeline未正确配置的问题
- **依赖**: Story 23.1 (LangGraph导入问题修复)
- **被依赖**: Story 23.3 (StateGraph配置), Story 23.4 (多源融合)

**Epic核心问题回顾**:

### Bug 7相关: Embedding Pipeline缺失

**现象**:
- `lancedb_client.py` 存在但向量化pipeline未连接
- Embedding模型配置不完整
- Canvas节点批量索引功能缺失

**当前状态** (src/agentic_rag/clients/lancedb_client.py):
```
✅ LanceDBClient类已存在
✅ search()方法已实现
⚠️ _get_query_vector()使用随机向量fallback
❌ embed()方法不存在 - 需实现
❌ index_canvas()方法不存在 - 需实现
❌ 与MultimodalVectorizer未连接
```

**修复目标**: 实现完整的Embedding Pipeline，支持Canvas节点的语义检索

---

## Story

**As a** Canvas学习系统,
**I want** 实现完整的LanceDB向量化流程,
**so that** Canvas节点内容可以被语义检索，支持RAG系统的向量检索需求

---

## Acceptance Criteria

### AC 1: 支持文本内容向量化
- **Given**: 文本内容字符串 (如 Canvas节点的text字段)
- **When**: 调用 `LanceDBClient.embed(text)` 方法
- **Then**:
  - 返回384维向量 (使用sentence-transformers/all-MiniLM-L6-v2)
  - 或返回可配置维度向量 (支持768维等其他模型)
  - 响应时间 < 100ms/单条文本

### AC 2: 支持Canvas节点批量索引
- **Given**: Canvas文件路径和节点列表
- **When**: 调用 `LanceDBClient.index_canvas(canvas_path, nodes)` 方法
- **Then**:
  - 所有节点被索引到 `canvas_nodes` 表
  - 每个节点记录包含: doc_id, content, vector, canvas_file, node_id, color, metadata
  - 批量处理支持100+节点
  - 处理速度 < 1秒/10节点

### AC 3: 支持语义相似度查询
- **Given**: 查询文本和Canvas文件过滤器
- **When**: 调用 `LanceDBClient.search(query, canvas_file=filter)` 方法
- **Then**:
  - 返回Top-K最相似节点 (默认K=10)
  - 结果按相似度分数降序排列
  - 分数范围0-1 (余弦相似度)
  - P95延迟 < 400ms (符合Story 12.2 AC 2.3)

### AC 4: 向量维度和模型可配置
- **Given**: 配置参数 `embedding_model` 和 `embedding_dim`
- **When**: 初始化 `LanceDBClient` 或通过配置文件设置
- **Then**:
  - 支持切换embedding模型:
    - `all-MiniLM-L6-v2` (384维, 默认)
    - `all-mpnet-base-v2` (768维, 更高质量)
    - `paraphrase-multilingual-MiniLM-L12-v2` (384维, 多语言)
  - 支持通过环境变量配置: `LANCEDB_EMBEDDING_MODEL`
  - 配置变更后自动重建索引

### AC 5: 索引持久化到本地文件
- **Given**: 索引操作完成
- **When**: 检查 `backend/data/lancedb/` 目录
- **Then**:
  - LanceDB数据文件存在且可读取
  - 重启应用后索引不丢失
  - 支持增量更新 (不必全量重建)

---

## Tasks / Subtasks

### 任务1: 集成MultimodalVectorizer到LanceDBClient (AC: 1)
- [ ] 1.1: 在LanceDBClient中引入MultimodalVectorizer依赖
- [ ] 1.2: 实现 `embed(text)` 方法，使用vectorizer
- [ ] 1.3: 替换 `_get_query_vector()` 中的随机向量fallback
- [ ] 1.4: 添加embedding模型懒加载机制

### 任务2: 实现Canvas节点批量索引 (AC: 2)
- [ ] 2.1: 实现 `index_canvas(canvas_path, nodes)` 方法
- [ ] 2.2: 定义 `canvas_nodes` 表schema
- [ ] 2.3: 实现Canvas JSON解析和节点提取
- [ ] 2.4: 添加批量处理支持 (batch_size=100)
- [ ] 2.5: 实现增量索引 (跳过已存在的节点)

### 任务3: 增强语义搜索功能 (AC: 3)
- [ ] 3.1: 优化 `search()` 方法性能
- [ ] 3.2: 添加Canvas文件过滤器支持
- [ ] 3.3: 实现相似度分数归一化 (0-1范围)
- [ ] 3.4: 添加搜索结果缓存

### 任务4: 配置系统增强 (AC: 4)
- [ ] 4.1: 扩展 `src/agentic_rag/config.py` 添加embedding配置
- [ ] 4.2: 添加环境变量支持 (`LANCEDB_EMBEDDING_MODEL`)
- [ ] 4.3: 实现模型动态切换
- [ ] 4.4: 添加配置验证

### 任务5: 持久化和存储管理 (AC: 5)
- [ ] 5.1: 创建 `backend/data/lancedb/` 目录结构
- [ ] 5.2: 实现索引持久化逻辑
- [ ] 5.3: 添加索引状态检查方法
- [ ] 5.4: 实现增量更新机制

### 任务6: 编写测试用例 (AC: 1-5)
- [ ] 6.1: 创建 `src/tests/test_lancedb_embedding.py`
- [ ] 6.2: 测试embed()方法
- [ ] 6.3: 测试index_canvas()方法
- [ ] 6.4: 测试search()性能
- [ ] 6.5: 测试配置切换
- [ ] 6.6: 测试持久化

---

## Dev Notes

### Technical Context

**现有代码结构分析**:

```
src/agentic_rag/
├── clients/
│   └── lancedb_client.py      # ✅ 已存在，需增强
├── processors/
│   └── multimodal_vectorizer.py  # ✅ 已存在，提供embedding能力
└── config.py                   # ✅ 已存在，需扩展embedding配置
```

**现有LanceDBClient关键代码** (src/agentic_rag/clients/lancedb_client.py:298-337):
```python
async def _get_query_vector(
    self,
    query: str
) -> Optional[List[float]]:
    """获取查询向量"""
    # 当前问题: 使用随机向量fallback
    if self._embedder is not None:
        try:
            return await self._embedder(query)
        except Exception as e:
            logger.error(f"Embedder failed: {e}")

    # ❌ 需要替换: 使用MultimodalVectorizer
    if NUMPY_AVAILABLE:
        logger.warning("Using random vector for search (embedder not configured)")
        return np.random.rand(self.embedding_dim).tolist()

    return None
```

**现有MultimodalVectorizer能力** (src/agentic_rag/processors/multimodal_vectorizer.py):
```python
# ✅ 已实现的功能:
- vectorize_text(text) → VectorizedContent (384维向量)
- vectorize_image_content(ocr_text, description) → VectorizedContent
- vectorize_pdf_chunk(chunk_text) → VectorizedContent
- batch_vectorize(texts) → List[VectorizedContent]

# 配置:
DEFAULT_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
DEFAULT_EMBEDDING_DIM = 384
```

### API Endpoints (if applicable)

**参考**: specs/api/canvas-api.openapi.yml (无直接RAG端点，通过后端服务调用)

### Data Models (if applicable)

**Canvas节点Schema** (specs/data/canvas-node.schema.json):
- `id`: string - 节点唯一标识
- `type`: "text" | "file" | "group" | "link"
- `text`: string - 文本内容 (type=text时)
- `color`: "1"-"6" - 颜色代码
- `x`, `y`, `width`, `height`: integer - 位置和尺寸

**LanceDB表Schema (新增)**:
```python
CANVAS_NODES_SCHEMA = {
    "doc_id": str,           # 文档唯一ID
    "content": str,          # 节点文本内容
    "vector": List[float],   # embedding向量 (384/768维)
    "canvas_file": str,      # Canvas文件路径
    "node_id": str,          # 原始节点ID
    "node_type": str,        # 节点类型 (text/file/group/link)
    "color": str,            # 颜色代码 (1-6)
    "x": int,                # X坐标
    "y": int,                # Y坐标
    "timestamp": str,        # 索引时间
    "metadata_json": str,    # 其他元数据JSON
}
```

### SDD References

**OpenAPI参考**:
- specs/api/canvas-api.openapi.yml - Canvas节点API定义

**JSON Schema参考**:
- specs/data/canvas-node.schema.json#L17-L74 - Canvas节点结构定义
- specs/data/langgraph-state.schema.json - RAG State定义

**ADR参考**:
- docs/architecture/decisions/0002-langgraph-agents.md - LangGraph选型决策
- docs/architecture/decisions/0003-graphiti-memory.md - 知识图谱架构

### Implementation Guidelines

**Step 1: 扩展CanvasRAGConfig (src/agentic_rag/config.py)**
```python
# ✅ Verified from existing config.py structure
class CanvasRAGConfig(TypedDict, total=False):
    # ... 现有字段 ...

    # 新增Embedding配置
    embedding_model: str  # 默认: "sentence-transformers/all-MiniLM-L6-v2"
    embedding_dim: int    # 默认: 384
    lancedb_path: str     # 默认: "backend/data/lancedb"
    lancedb_table: str    # 默认: "canvas_nodes"

LANCEDB_CONFIG = {
    "db_path": "backend/data/lancedb",
    "table_name": "canvas_nodes",
    "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
    "embedding_dim": 384,
    "batch_size": 100,
}
```

**Step 2: 增强LanceDBClient (src/agentic_rag/clients/lancedb_client.py)**
```python
# ✅ Verified from LanceDB documentation
# ✅ Verified from MultimodalVectorizer (src/agentic_rag/processors/multimodal_vectorizer.py:111-200)

from agentic_rag.processors.multimodal_vectorizer import MultimodalVectorizer

class LanceDBClient:
    def __init__(
        self,
        db_path: str = "backend/data/lancedb",
        embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2",
        embedding_dim: int = 384,
        **kwargs
    ):
        # ... 现有初始化 ...
        self._vectorizer = None
        self.embedding_model = embedding_model

    async def _init_vectorizer(self):
        """懒加载embedding模型"""
        if self._vectorizer is None:
            self._vectorizer = MultimodalVectorizer(
                model_name=self.embedding_model,
                device="cpu"  # 或从配置读取
            )
            await self._vectorizer.initialize()

    async def embed(self, text: str) -> List[float]:
        """
        文本向量化

        ✅ Story 23.2 AC 1: 支持文本内容向量化

        Args:
            text: 要向量化的文本

        Returns:
            List[float]: embedding向量 (384或768维)
        """
        await self._init_vectorizer()
        result = await self._vectorizer.vectorize_text(text)
        return result.vector

    async def index_canvas(
        self,
        canvas_path: str,
        nodes: List[Dict[str, Any]] = None,
        table_name: str = "canvas_nodes"
    ) -> int:
        """
        批量索引Canvas节点

        ✅ Story 23.2 AC 2: 支持Canvas节点批量索引

        Args:
            canvas_path: Canvas文件路径
            nodes: 节点列表 (可选，不提供则从文件读取)
            table_name: LanceDB表名

        Returns:
            int: 索引的节点数量
        """
        await self._init_vectorizer()

        # 如果未提供nodes，从Canvas文件读取
        if nodes is None:
            nodes = self._read_canvas_nodes(canvas_path)

        # 准备批量向量化的文本
        texts = [
            node.get("text", "")
            for node in nodes
            if node.get("type") == "text" and node.get("text")
        ]

        if not texts:
            return 0

        # 批量向量化
        vectorized = await self._vectorizer.batch_vectorize(texts)

        # 准备LanceDB文档
        documents = []
        for i, (node, vec_result) in enumerate(zip(
            [n for n in nodes if n.get("type") == "text" and n.get("text")],
            vectorized
        )):
            documents.append({
                "doc_id": f"canvas_{node['id']}",
                "content": node.get("text", ""),
                "vector": vec_result.vector,
                "canvas_file": canvas_path,
                "node_id": node["id"],
                "node_type": node.get("type", "text"),
                "color": node.get("color", ""),
                "x": node.get("x", 0),
                "y": node.get("y", 0),
                "metadata": {
                    "width": node.get("width"),
                    "height": node.get("height"),
                }
            })

        # 写入LanceDB
        return await self.add_documents(table_name, documents)

    def _read_canvas_nodes(self, canvas_path: str) -> List[Dict[str, Any]]:
        """从Canvas文件读取节点"""
        import json
        with open(canvas_path, 'r', encoding='utf-8') as f:
            canvas_data = json.load(f)
        return canvas_data.get("nodes", [])
```

**Step 3: 替换_get_query_vector (src/agentic_rag/clients/lancedb_client.py:298)**
```python
async def _get_query_vector(
    self,
    query: str
) -> Optional[List[float]]:
    """
    获取查询向量 - 使用MultimodalVectorizer

    ✅ Story 23.2: 替换随机向量fallback
    """
    # 如果已经是向量
    if isinstance(query, list):
        return query

    if NUMPY_AVAILABLE and isinstance(query, np.ndarray):
        return query.tolist()

    # ✅ 使用embed()方法 (Story 23.2 AC 1)
    try:
        return await self.embed(query)
    except Exception as e:
        logger.error(f"Embedding failed: {e}")
        return None
```

**Step 4: 创建数据目录**
```bash
mkdir -p backend/data/lancedb
```

### Testing Requirements

**测试文件**: `src/tests/test_lancedb_embedding.py`

```python
import pytest
from agentic_rag.clients.lancedb_client import LanceDBClient

@pytest.fixture
async def client():
    client = LanceDBClient(
        db_path="tests/data/lancedb_test",
        embedding_model="sentence-transformers/all-MiniLM-L6-v2"
    )
    await client.initialize()
    return client

# AC 1: 文本向量化
@pytest.mark.asyncio
async def test_embed_text(client):
    """测试文本向量化"""
    vector = await client.embed("什么是逆否命题？")

    assert vector is not None
    assert len(vector) == 384  # all-MiniLM-L6-v2 维度
    assert all(isinstance(v, float) for v in vector)

@pytest.mark.asyncio
async def test_embed_performance(client):
    """测试向量化性能 < 100ms"""
    import time

    start = time.perf_counter()
    await client.embed("测试文本")
    elapsed_ms = (time.perf_counter() - start) * 1000

    assert elapsed_ms < 100, f"Embedding took {elapsed_ms:.2f}ms, expected < 100ms"

# AC 2: Canvas批量索引
@pytest.mark.asyncio
async def test_index_canvas(client, tmp_path):
    """测试Canvas节点批量索引"""
    import json

    # 创建测试Canvas文件
    canvas_data = {
        "nodes": [
            {"id": "node1", "type": "text", "text": "逆否命题定义", "x": 0, "y": 0, "color": "1"},
            {"id": "node2", "type": "text", "text": "命题的逆否命题", "x": 100, "y": 0, "color": "2"},
        ],
        "edges": []
    }
    canvas_path = tmp_path / "test.canvas"
    canvas_path.write_text(json.dumps(canvas_data, ensure_ascii=False))

    # 索引
    count = await client.index_canvas(str(canvas_path))

    assert count == 2

# AC 3: 语义搜索
@pytest.mark.asyncio
async def test_semantic_search(client):
    """测试语义相似度搜索"""
    # 先索引一些内容
    await client.add_documents("canvas_nodes", [
        {"doc_id": "test1", "content": "逆否命题的定义", "vector": await client.embed("逆否命题的定义")},
        {"doc_id": "test2", "content": "原命题与逆否命题等价", "vector": await client.embed("原命题与逆否命题等价")},
    ])

    # 搜索
    results = await client.search("什么是逆否命题", table_name="canvas_nodes")

    assert len(results) > 0
    assert results[0]["score"] >= 0 and results[0]["score"] <= 1

@pytest.mark.asyncio
async def test_search_performance(client):
    """测试搜索性能 P95 < 400ms"""
    import time

    latencies = []
    for _ in range(20):
        start = time.perf_counter()
        await client.search("测试查询")
        latencies.append((time.perf_counter() - start) * 1000)

    latencies.sort()
    p95 = latencies[int(len(latencies) * 0.95)]

    assert p95 < 400, f"P95 latency {p95:.2f}ms exceeds 400ms"

# AC 4: 配置切换
def test_model_config():
    """测试模型配置"""
    client_384 = LanceDBClient(
        embedding_model="sentence-transformers/all-MiniLM-L6-v2",
        embedding_dim=384
    )
    assert client_384.embedding_dim == 384

    client_768 = LanceDBClient(
        embedding_model="sentence-transformers/all-mpnet-base-v2",
        embedding_dim=768
    )
    assert client_768.embedding_dim == 768

# AC 5: 持久化
@pytest.mark.asyncio
async def test_persistence(tmp_path):
    """测试索引持久化"""
    db_path = str(tmp_path / "lancedb")

    # 创建并写入
    client1 = LanceDBClient(db_path=db_path)
    await client1.initialize()
    await client1.add_documents("test_table", [
        {"doc_id": "persist1", "content": "持久化测试", "vector": [0.1] * 384}
    ])

    # 重新打开并读取
    client2 = LanceDBClient(db_path=db_path)
    await client2.initialize()
    stats = client2.get_stats()

    assert "test_table" in stats["tables"]
```

### Dependencies

**Story依赖**:
- ✅ Story 23.1 (LangGraph导入问题修复) - 本Story依赖

**技术依赖**:
- Python 3.9+
- lancedb>=0.14.0
- sentence-transformers>=2.2.0
- numpy>=1.21.0

### Key Files to Modify

| 文件路径 | 修改类型 | 说明 |
|---------|---------|------|
| `src/agentic_rag/clients/lancedb_client.py` | 修改 | 添加embed(), index_canvas(), 替换_get_query_vector() |
| `src/agentic_rag/config.py` | 修改 | 添加LANCEDB_CONFIG配置 |
| `backend/data/lancedb/` | 新建目录 | LanceDB数据存储目录 |
| `src/tests/test_lancedb_embedding.py` | 新建 | Embedding功能测试 |

### Anti-Hallucination Verification

**验证的文件路径**:
- ✅ `src/agentic_rag/clients/lancedb_client.py` - 已验证存在 (Glob结果)
- ✅ `src/agentic_rag/processors/multimodal_vectorizer.py` - 已验证存在 (已读取)
- ✅ `src/agentic_rag/config.py` - 已验证存在 (已读取)
- ✅ `specs/data/canvas-node.schema.json` - 已验证存在 (已读取)

**验证的API签名**:
- ✅ `MultimodalVectorizer.vectorize_text(text)` - 已验证 (multimodal_vectorizer.py:244-290)
- ✅ `MultimodalVectorizer.batch_vectorize(texts)` - 已验证 (multimodal_vectorizer.py:455-515)
- ✅ `LanceDBClient.search()` - 已验证 (lancedb_client.py:157-241)
- ✅ `LanceDBClient.add_documents()` - 已验证 (lancedb_client.py:417-474)

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-12 | 1.0 | 初始创建 - SM Agent自动化batch模式 | Bob (SM Agent) |

---

## Dev Agent Record

### Agent Model Used
*待填写*

### Debug Log References
*待填写*

### Completion Notes List
*待填写*

### File List
*待填写*

---

## QA Results

*待QA Agent审查*

---

## Related Documentation

**Epic文档**:
- [EPIC-23-RAG-INTELLIGENT-INFERENCE.md](../prd/EPIC-23-RAG-INTELLIGENT-INFERENCE.md) - Epic 23完整PRD

**架构文档**:
- [coding-standards.md](../architecture/coding-standards.md) - 编码规范 (零幻觉开发规范)
- [tech-stack.md](../architecture/tech-stack.md) - 技术栈说明

**ADR参考**:
- [0002-langgraph-agents.md](../architecture/decisions/0002-langgraph-agents.md) - LangGraph ADR
- [0003-graphiti-memory.md](../architecture/decisions/0003-graphiti-memory.md) - Graphiti ADR

**技能参考**:
- LangGraph Skill: `.claude/skills/langgraph/SKILL.md`
- Graphiti Skill: `.claude/skills/graphiti/SKILL.md`

**前置Story**:
- Story 23.1: LangGraph导入问题修复

**后续Story**:
- Story 23.3: StateGraph智能推理链配置
- Story 23.4: 多源融合 (教材+历史+跨Canvas)
