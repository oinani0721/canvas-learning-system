# MCPè¯­ä¹‰è®°å¿†æœåŠ¡APIæ–‡æ¡£

**ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-23

---

## ğŸ“š ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ ¸å¿ƒç±»å’Œæ–¹æ³•](#æ ¸å¿ƒç±»å’Œæ–¹æ³•)
  - [MCPSemanticMemory](#mcsemanticmemory)
  - [SemanticProcessor](#semanticprocessor)
  - [CreativeAssociationEngine](#creativeassociationengine)
  - [MemoryCompressor](#memorycompressor)
  - [CanvasMCPIntegration](#canvasmcpintegration)
- [é”™è¯¯å¤„ç†](#é”™è¯¯å¤„ç†)
- [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

---

## æ¦‚è¿°

MCPè¯­ä¹‰è®°å¿†æœåŠ¡æä¾›å®Œæ•´çš„è¯­ä¹‰è®°å¿†ã€æ¦‚å¿µæå–ã€åˆ›æ„è”æƒ³å’Œè®°å¿†å‹ç¼©åŠŸèƒ½ã€‚æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†æ‰€æœ‰å…¬å…±APIçš„ä½¿ç”¨æ–¹æ³•ã€å‚æ•°è¯´æ˜å’Œè¿”å›å€¼æ ¼å¼ã€‚

---

## æ ¸å¿ƒç±»å’Œæ–¹æ³•

### MCPSemanticMemory

MCPè¯­ä¹‰è®°å¿†æœåŠ¡çš„æ ¸å¿ƒå®¢æˆ·ç«¯ï¼Œè´Ÿè´£è®°å¿†çš„å­˜å‚¨ã€æœç´¢å’Œç®¡ç†ã€‚

#### åˆå§‹åŒ–

```python
def __init__(self, config_path: str = "config/mcp_config.yaml") -> None:
    """
    åˆå§‹åŒ–MCPè¯­ä¹‰è®°å¿†æœåŠ¡

    Args:
        config_path: MCPé…ç½®æ–‡ä»¶è·¯å¾„

    Raises:
        ImportError: å½“å¿…è¦çš„ä¾èµ–åº“æœªå®‰è£…æ—¶
        yaml.YAMLError: å½“é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯æ—¶
        Exception: å…¶ä»–åˆå§‹åŒ–é”™è¯¯

    Example:
        >>> client = MCPSemanticMemory("config/mcp_config.yaml")
        >>> print(f"ä½¿ç”¨è®¾å¤‡: {client.device}")
    """
```

#### æ ¸å¿ƒæ–¹æ³•

##### store_semantic_memory

```python
def store_semantic_memory(self, content: str, metadata: Dict) -> str:
    """
    å­˜å‚¨è¯­ä¹‰è®°å¿†

    Args:
        content: éœ€è¦è®°å¿†çš„å†…å®¹æ–‡æœ¬ï¼Œæœ€å¤§é•¿åº¦10KB
        metadata: å†…å®¹å…ƒæ•°æ®å­—å…¸ï¼Œæ”¯æŒä»¥ä¸‹å­—æ®µï¼š
            - source_canvas: Canvasæ–‡ä»¶å
            - source_node_id: CanvasèŠ‚ç‚¹ID
            - content_type: å†…å®¹ç±»å‹ ("question", "explanation", "understanding", "concept")
            - tags: æ‰‹åŠ¨æ ‡ç­¾åˆ—è¡¨
            - priority: ä¼˜å…ˆçº§ (1-10)

    Returns:
        str: è®°å¿†IDï¼Œæ ¼å¼ä¸º "memory-{16ä½åå…­è¿›åˆ¶å­—ç¬¦}"

    Raises:
        ValueError: å½“å†…å®¹ä¸ºç©ºæˆ–è¶…è¿‡é•¿åº¦é™åˆ¶æ—¶
        Exception: å½“å­˜å‚¨å¤±è´¥æ—¶

    Example:
        >>> metadata = {
        ...     "source_canvas": "ç¦»æ•£æ•°å­¦.canvas",
        ...     "content_type": "concept",
        ...     "tags": ["é€»è¾‘", "æ•°å­¦"]
        ... }
        >>> memory_id = client.store_semantic_memory("é€†å¦å‘½é¢˜æ˜¯é‡è¦çš„é€»è¾‘æ¦‚å¿µ", metadata)
        >>> print(f"è®°å¿†ID: {memory_id}")
        memory-id-abc123def4567890
    """
```

##### search_semantic_memory

```python
def search_semantic_memory(self, query: str, limit: int = 10) -> List[Dict]:
    """
    è¯­ä¹‰æœç´¢è®°å¿†

    Args:
        query: æœç´¢æŸ¥è¯¢æ–‡æœ¬ï¼Œæ”¯æŒä¸­è‹±æ–‡è‡ªç„¶è¯­è¨€
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ŒèŒƒå›´1-100

    Returns:
        List[Dict]: ç›¸å…³è®°å¿†åˆ—è¡¨ï¼Œæ¯ä¸ªè®°å¿†åŒ…å«ï¼š
            - memory_id: è®°å¿†ID
            - content: è®°å¿†å†…å®¹
            - metadata: å…ƒæ•°æ®å­—å…¸
            - similarity_score: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
            - distance: è¯­ä¹‰è·ç¦» (0-1)

    Raises:
        ValueError: å½“æŸ¥è¯¢ä¸ºç©ºæ—¶
        Exception: å½“æœç´¢å¤±è´¥æ—¶

    Example:
        >>> results = client.search_semantic_memory("é€†å¦å‘½é¢˜", limit=5)
        >>> for result in results:
        ...     print(f"{result['memory_id']}: {result['similarity_score']:.3f}")
    """
```

##### auto_generate_tags

```python
def auto_generate_tags(self, content: str, max_tags: int = 10) -> List[str]:
    """
    è‡ªåŠ¨ç”Ÿæˆå†…å®¹æ ‡ç­¾

    Args:
        content: éœ€è¦åˆ†æçš„å†…å®¹æ–‡æœ¬
        max_tags: æœ€å¤§æ ‡ç­¾æ•°é‡ï¼ŒèŒƒå›´1-50

    Returns:
        List[str]: ç”Ÿæˆçš„æ ‡ç­¾åˆ—è¡¨ï¼ŒæŒ‰ç›¸å…³æ€§æ’åº

    Raises:
        ValueError: å½“å†…å®¹ä¸ºç©ºæˆ–max_tagsæ— æ•ˆæ—¶

    Example:
        >>> tags = client.auto_generate_tags("é€†å¦å‘½é¢˜çš„é€»è¾‘ç»“æ„å’Œåº”ç”¨", 5)
        >>> print(tags)
        ['é€†å¦å‘½é¢˜', 'é€»è¾‘ç»“æ„', 'å‘½é¢˜é€»è¾‘', 'æ•°å­¦æ¦‚å¿µ', 'é€»è¾‘æ¨ç†']
    """
```

##### get_memory_stats

```python
def get_memory_stats(self) -> Dict:
    """
    è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯

    Returns:
        Dict: ç»Ÿè®¡ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ï¼š
            - total_memories: æ€»è®°å¿†æ•°é‡
            - device: ä½¿ç”¨çš„è®¾å¤‡ç±»å‹
            - model_name: åµŒå…¥æ¨¡å‹åç§°
            - hardware_info: ç¡¬ä»¶ä¿¡æ¯
            - last_updated: æœ€åæ›´æ–°æ—¶é—´

    Example:
        >>> stats = client.get_memory_stats()
        >>> print(f"æ€»è®°å¿†æ•°: {stats['total_memories']}")
        >>> print(f"ä½¿ç”¨è®¾å¤‡: {stats['device']}")
        æ€»è®°å¿†æ•°: 42
        ä½¿ç”¨è®¾å¤‡: cuda
    """
```

### SemanticProcessor

è¯­ä¹‰å¤„ç†å™¨ï¼Œè´Ÿè´£æ–‡æœ¬åˆ†æã€æ¦‚å¿µæå–å’Œæ ‡ç­¾ç”Ÿæˆã€‚

#### åˆå§‹åŒ–

```python
def __init__(self) -> None:
    """
    åˆå§‹åŒ–è¯­ä¹‰å¤„ç†å™¨

    Example:
        >>> processor = SemanticProcessor()
        >>> result = processor.process_text("æµ‹è¯•æ–‡æœ¬")
    """
```

#### æ ¸å¿ƒæ–¹æ³•

##### process_text

```python
def process_text(self, text: str, options: Dict = None) -> Dict:
    """
    å¤„ç†æ–‡æœ¬è¯­ä¹‰ä¿¡æ¯

    Args:
        text: éœ€è¦å¤„ç†çš„æ–‡æœ¬å†…å®¹
        options: å¤„ç†é€‰é¡¹å­—å…¸ï¼Œæ”¯æŒï¼š
            - extract_concepts: bool, æ˜¯å¦æå–æ¦‚å¿µ (é»˜è®¤True)
            - generate_tags: bool, æ˜¯å¦ç”Ÿæˆæ ‡ç­¾ (é»˜è®¤True)
            - max_concepts: int, æœ€å¤§æ¦‚å¿µæ•°é‡ (é»˜è®¤20)
            - max_tags: int, æœ€å¤§æ ‡ç­¾æ•°é‡ (é»˜è®¤10)
            - concept_confidence_threshold: float, æ¦‚å¿µç½®ä¿¡åº¦é˜ˆå€¼ (é»˜è®¤0.5)
            - tag_relevance_threshold: float, æ ‡ç­¾ç›¸å…³æ€§é˜ˆå€¼ (é»˜è®¤0.3)

    Returns:
        Dict: å¤„ç†ç»“æœï¼ŒåŒ…å«ï¼š
            - text_length: æ–‡æœ¬é•¿åº¦
            - word_count: è¯æ•°é‡
            - processing_time: å¤„ç†æ—¶é—´(ç§’)
            - concepts: æå–çš„æ¦‚å¿µåˆ—è¡¨
            - tags: ç”Ÿæˆçš„æ ‡ç­¾åˆ—è¡¨
            - language: æ£€æµ‹çš„è¯­è¨€

    Example:
        >>> processor = SemanticProcessor()
        >>> text = "é€†å¦å‘½é¢˜æ˜¯é€»è¾‘å­¦ä¸­çš„é‡è¦æ¦‚å¿µï¼Œå®ƒç”¨äºæ•°å­¦è¯æ˜"
        >>> result = processor.process_text(text)
        >>> print(f"æå–æ¦‚å¿µæ•°: {len(result['concepts'])}")
        >>> print(f"ç”Ÿæˆæ ‡ç­¾æ•°: {len(result['tags'])}")
        æå–æ¦‚å¿µæ•°: 2
        ç”Ÿæˆæ ‡ç­¾æ•°: 5
    """
```

### CreativeAssociationEngine

åˆ›æ„è”æƒ³å¼•æ“ï¼Œè´Ÿè´£ç”Ÿæˆåˆ›æ„æ´å¯Ÿã€ç±»æ¯”æ¨ç†å’Œå­¦ä¹ è·¯å¾„å»ºè®®ã€‚

#### åˆå§‹åŒ–

```python
def __init__(self, memory_client: MCPSemanticMemory = None, config: Dict = None) -> None:
    """
    åˆå§‹åŒ–åˆ›æ„è”æƒ³å¼•æ“

    Args:
        memory_client: MCPè®°å¿†å®¢æˆ·ç«¯å®ä¾‹ï¼Œå¯é€‰
        config: é…ç½®å­—å…¸ï¼Œå¯é€‰

    Example:
        >>> engine = CreativeAssociationEngine(memory_client)
        >>> result = engine.generate_creative_associations("é€†å¦å‘½é¢˜")
    """
```

#### æ ¸å¿ƒæ–¹æ³•

##### generate_creative_associations

```python
def generate_creative_associations(self, concept: str, creativity_level: str = "moderate") -> Dict:
    """
    ç”Ÿæˆåˆ›æ„è”æƒ³

    Args:
        concept: æ ¸å¿ƒæ¦‚å¿µæ–‡æœ¬
        creativity_level: åˆ›æ„çº§åˆ«ï¼Œæ”¯æŒï¼š
            - "conservative": ä¿å®ˆçº§åˆ«ï¼Œæ¸©åº¦0.7ï¼Œæœ€å¤š5ä¸ªè”æƒ³
            - "moderate": ä¸­ç­‰çº§åˆ«ï¼Œæ¸©åº¦0.9ï¼Œæœ€å¤š8ä¸ªè”æƒ³
            - "creative": åˆ›æ„çº§åˆ«ï¼Œæ¸©åº¦1.2ï¼Œæœ€å¤š12ä¸ªè”æƒ³

    Returns:
        Dict: åˆ›æ„è”æƒ³ç»“æœï¼ŒåŒ…å«ï¼š
            - association_id: è”æƒ³ID
            - query_concept: æŸ¥è¯¢æ¦‚å¿µ
            - creativity_level: ä½¿ç”¨çš„åˆ›æ„çº§åˆ«
            - creative_insights: åˆ›æ„æ´å¯Ÿåˆ—è¡¨
            - analogies: ç±»æ¯”æ¨ç†åˆ—è¡¨
            - practical_applications: å®é™…åº”ç”¨åˆ—è¡¨
            - learning_paths: å­¦ä¹ è·¯å¾„åˆ—è¡¨
            - overall_creativity_score: æ€»ä½“åˆ›æ„åˆ†æ•° (0-1)

    Example:
        >>> engine = CreativeAssociationEngine()
        >>> result = engine.generate_creative_associations("é€†å¦å‘½é¢˜", "creative")
        >>> print(f"åˆ›æ„åˆ†æ•°: {result['overall_creativity_score']:.3f}")
        >>> print(f"æ´å¯Ÿæ•°é‡: {len(result['creative_insights'])}")
        åˆ›æ„åˆ†æ•°: 0.856
        æ´å¯Ÿæ•°é‡: 8
    """
```

### MemoryCompressor

è®°å¿†æ•°æ®å‹ç¼©å™¨ï¼Œè´Ÿè´£è¯­ä¹‰è®°å¿†çš„å‹ç¼©å’Œä¼˜åŒ–ã€‚

#### åˆå§‹åŒ–

```python
def __init__(self, memory_client: MCPSemanticMemory, config: Dict = None) -> None:
    """
    åˆå§‹åŒ–è®°å¿†å‹ç¼©å™¨

    Args:
        memory_client: MCPè®°å¿†å®¢æˆ·ç«¯å®ä¾‹
        config: é…ç½®å­—å…¸ï¼Œå¯é€‰

    Example:
        >>> compressor = MemoryCompressor(memory_client)
        >>> result = compressor.compress_memories(memory_ids, 0.3)
    """
```

#### æ ¸å¿ƒæ–¹æ³•

##### compress_memories

```python
def compress_memories(self, memory_ids: List[str], compression_ratio: float = 0.3, strategy: str = None) -> CompressionResult:
    """
    å‹ç¼©è®°å¿†æ•°æ®

    Args:
        memory_ids: éœ€è¦å‹ç¼©çš„è®°å¿†IDåˆ—è¡¨
        compression_ratio: ç›®æ ‡å‹ç¼©æ¯”ä¾‹ (0.0-1.0)
        strategy: å‹ç¼©ç­–ç•¥ï¼Œæ”¯æŒï¼š
            - "semantic_clustering": è¯­ä¹‰èšç±» (é»˜è®¤)
            - "frequency_based": åŸºäºé¢‘ç‡
            - "temporal_grouping": æ—¶é—´åˆ†ç»„
            - "topic_merging": ä¸»é¢˜åˆå¹¶

    Returns:
        CompressionResult: å‹ç¼©ç»“æœï¼ŒåŒ…å«ï¼š
            - original_memory_count: åŸå§‹è®°å¿†æ•°é‡
            - compressed_memory_count: å‹ç¼©åæ•°é‡
            - compression_ratio: å®é™…å‹ç¼©æ¯”ä¾‹
            - information_retention_score: ä¿¡æ¯ä¿ç•™åˆ†æ•° (0-1)
            - compression_time_seconds: å‹ç¼©è€—æ—¶
            - clusters: å‹ç¼©ç°‡åˆ—è¡¨

    Example:
        >>> compressor = MemoryCompressor(memory_client)
        >>> result = compressor.compress_memories(memory_ids, 0.3, "semantic_clustering")
        >>> print(f"å‹ç¼©æ¯”: {result.compression_ratio:.3f}")
        >>> print(f"ä¿¡æ¯ä¿ç•™: {result.information_retention_score:.3f}")
        å‹ç¼©æ¯”: 0.285
        ä¿¡æ¯ä¿ç•™: 0.912
    """
```

##### auto_compress_memories

```python
def auto_compress_memories(self, threshold: int = 5000, strategy: str = None) -> Dict:
    """
    è‡ªåŠ¨å‹ç¼©è®°å¿†

    Args:
        threshold: å‹ç¼©é˜ˆå€¼ï¼Œå½“è®°å¿†æ•°é‡è¶…è¿‡æ­¤å€¼æ—¶è§¦å‘å‹ç¼©
        strategy: å‹ç¼©ç­–ç•¥ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„ç­–ç•¥

    Returns:
        Dict: è‡ªåŠ¨å‹ç¼©ç»“æœ

    Example:
        >>> result = compressor.auto_compress_memories(3000)
        >>> if result['compressed']:
        ...     print(f"å‹ç¼©å®Œæˆ: {result['compression_ratio']:.2%}")
        >>> else:
        ...     print(f"æœªå‹ç¼©: {result['reason']}")
    """
```

### CanvasMCPIntegration

Canvasä¸MCPé›†æˆç®¡ç†å™¨ï¼Œæä¾›Canvaså†…å®¹çš„è¯­ä¹‰åŒ–å¤„ç†ã€‚

#### åˆå§‹åŒ–

```python
def __init__(self, mcp_config_path: str = "config/mcp_config.yaml") -> None:
    """
    åˆå§‹åŒ–é›†æˆç®¡ç†å™¨

    Args:
        mcp_config_path: MCPé…ç½®æ–‡ä»¶è·¯å¾„

    Example:
        >>> integration = CanvasMCPIntegration()
        >>> result = integration.integrate_canvas_with_mcp("canvas.canvas")
    """
```

#### æ ¸å¿ƒæ–¹æ³•

##### integrate_canvas_with_mcp

```python
def integrate_canvas_with_mcp(self, canvas_path: str, node_ids: List[str] = None) -> Dict:
    """
    å°†Canvaså†…å®¹é›†æˆåˆ°MCPè¯­ä¹‰è®°å¿†

    Args:
        canvas_path: Canvasæ–‡ä»¶è·¯å¾„
        node_ids: æŒ‡å®šèŠ‚ç‚¹IDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰æ–‡æœ¬èŠ‚ç‚¹

    Returns:
        Dict: é›†æˆç»“æœï¼ŒåŒ…å«ï¼š
            - canvas_path: Canvasè·¯å¾„
            - processed_nodes: å¤„ç†çš„èŠ‚ç‚¹æ•°é‡
            - skipped_nodes: è·³è¿‡çš„èŠ‚ç‚¹æ•°é‡
            - memory_ids: åˆ›å»ºçš„è®°å¿†IDåˆ—è¡¨
            - processing_errors: å¤„ç†é”™è¯¯åˆ—è¡¨
            - integration_summary: é›†æˆæ‘˜è¦

    Example:
        >>> integration = CanvasMCPIntegration()
        >>> result = integration.integrate_canvas_with_mcp("ç¦»æ•£æ•°å­¦.canvas")
        >>> print(f"å¤„ç†èŠ‚ç‚¹: {result['processed_nodes']}")
        >>> print(f"åˆ›å»ºè®°å¿†: {len(result['memory_ids'])}")
        å¤„ç†èŠ‚ç‚¹: 15
        åˆ›å»ºè®°å¿†: 15
    """
```

##### semantic_search_canvas

```python
def semantic_search_canvas(self, query: str, canvas_filter: List[str] = None, limit: int = 10) -> List[Dict]:
    """
    åœ¨Canvasè®°å¿†ä¸­è¿›è¡Œè¯­ä¹‰æœç´¢

    Args:
        query: æœç´¢æŸ¥è¯¢æ–‡æœ¬
        canvas_filter: Canvasæ–‡ä»¶è¿‡æ»¤åˆ—è¡¨
        limit: ç»“æœæ•°é‡é™åˆ¶

    Returns:
        List[Dict]: æœç´¢ç»“æœåˆ—è¡¨

    Example:
        >>> results = integration.semantic_search_canvas("é€†å¦å‘½é¢˜", ["ç¦»æ•£æ•°å­¦.canvas"])
        >>> for result in results:
        ...     print(f"{result['source_canvas']}: {result['similarity_score']:.3f}")
    """
```

##### generate_cross_canvas_insights

```python
def generate_cross_canvas_insights(self, concept: str, max_canvases: int = 5) -> Dict:
    """
    è·¨Canvasç”Ÿæˆæ·±åº¦æ´å¯Ÿ

    Args:
        concept: æ ¸å¿ƒæ¦‚å¿µ
        max_canvases: æœ€å¤§æœç´¢Canvasæ•°é‡

    Returns:
        Dict: è·¨Canvasæ´å¯Ÿç»“æœ

    Example:
        >>> insights = integration.generate_cross_canvas_insights("é€»è¾‘")
        >>> print(f"æ¶‰åŠCanvasæ•°: {insights['total_canvases_found']}")
        >>> print(f"è·¨åŸŸè¿æ¥æ•°: {len(insights['cross_canvas_connections'])}")
        æ¶‰åŠCanvasæ•°: 3
        è·¨åŸŸè¿æ¥æ•°: 2
    """
```

---

## é”™è¯¯å¤„ç†

### å¼‚å¸¸ç±»å‹

ç³»ç»Ÿä½¿ç”¨åˆ†å±‚å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼Œä¸»è¦å¼‚å¸¸ç±»å‹ï¼š

#### ä¾èµ–å¼‚å¸¸
```python
class MCPDependencyError(Exception):
    """MCPæœåŠ¡ä¾èµ–é”™è¯¯"""
    pass

class ModelLoadError(Exception):
    """æ¨¡å‹åŠ è½½é”™è¯¯"""
    pass

class DatabaseConnectionError(Exception):
    """æ•°æ®åº“è¿æ¥é”™è¯¯"""
    pass
```

#### é…ç½®å¼‚å¸¸
```python
class MCPConfigurationError(Exception):
    """MCPé…ç½®é”™è¯¯"""
    pass

class ValidationError(Exception):
    """å‚æ•°éªŒè¯é”™è¯¯"""
    pass
```

#### è¿è¡Œæ—¶å¼‚å¸¸
```python
class MCPRuntimeError(Exception):
    """MCPè¿è¡Œæ—¶é”™è¯¯"""
    pass

class MemoryStorageError(Exception):
    """è®°å¿†å­˜å‚¨é”™è¯¯"""
    pass

class SearchError(Exception):
    """æœç´¢æ“ä½œé”™è¯¯"""
    pass
```

### é”™è¯¯å¤„ç†æœ€ä½³å®è·µ

```python
try:
    client = MCPSemanticMemory(config_path)
    memory_id = client.store_semantic_memory(content, metadata)
except MCPDependencyError as e:
    logger.error(f"ä¾èµ–é”™è¯¯: {e}")
    # ä¾èµ–åº“å®‰è£…æç¤º
except MCPConfigurationError as e:
    logger.error(f"é…ç½®é”™è¯¯: {e}")
    # é…ç½®æ–‡ä»¶ä¿®å¤æç¤º
except MemoryStorageError as e:
    logger.error(f"å­˜å‚¨é”™è¯¯: {e}")
    # å­˜å‚¨ç³»ç»Ÿæ£€æŸ¥æç¤º
except Exception as e:
    logger.error(f"æœªçŸ¥é”™è¯¯: {e}")
    # é€šç”¨é”™è¯¯å¤„ç†
```

---

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨æµç¨‹

```python
from mcp_memory_client import MCPSemanticMemory
from semantic_processor import SemanticProcessor
from creative_association_engine import CreativeAssociationEngine

# 1. åˆå§‹åŒ–ç»„ä»¶
client = MCPSemanticMemory("config/mcp_config.yaml")
processor = SemanticProcessor()
engine = CreativeAssociationEngine(client)

# 2. å­˜å‚¨è®°å¿†
content = "é€†å¦å‘½é¢˜æ˜¯é€»è¾‘å­¦ä¸­çš„é‡è¦æ¦‚å¿µï¼Œç”¨äºæ•°å­¦è¯æ˜"
metadata = {
    "source_canvas": "ç¦»æ•£æ•°å­¦.canvas",
    "content_type": "concept",
    "tags": ["é€»è¾‘", "æ•°å­¦"]
}
memory_id = client.store_semantic_memory(content, metadata)

# 3. è¯­ä¹‰å¤„ç†
semantic_result = processor.process_text(content)
print(f"æå–æ¦‚å¿µ: {len(semantic_result['concepts'])}")
print(f"ç”Ÿæˆæ ‡ç­¾: {semantic_result['tags']}")

# 4. åˆ›æ„è”æƒ³
creative_result = engine.generate_creative_associations("é€†å¦å‘½é¢˜", "moderate")
print(f"åˆ›æ„åˆ†æ•°: {creative_result['overall_creativity_score']:.3f}")

# 5. æœç´¢è®°å¿†
search_results = client.search_semantic_memory("é€»è¾‘æ¦‚å¿µ")
for result in search_results:
    print(f"{result['memory_id']}: {result['similarity_score']:.3f}")

# 6. æ¸…ç†èµ„æº
client.close()
```

### Canvasé›†æˆç¤ºä¾‹

```python
from canvas_mcp_integration import create_canvas_integration

# 1. åˆ›å»ºé›†æˆç®¡ç†å™¨
integration = create_canvas_integration()

# 2. é›†æˆCanvas
result = integration.integrate_canvas_with_mcp("ç¬”è®°åº“/ç¦»æ•£æ•°å­¦/ç¦»æ•£æ•°å­¦.canvas")
print(f"å¤„ç†èŠ‚ç‚¹: {result['processed_nodes']}")
print(f"åˆ›å»ºè®°å¿†: {len(result['memory_ids'])}")

# 3. è¯­ä¹‰æœç´¢
search_results = integration.semantic_search_canvas("é€†å¦å‘½é¢˜", limit=5)
for result in search_results:
    print(f"æ¥æº: {result['source_canvas']}")
    print(f"ç›¸ä¼¼åº¦: {result['similarity_score']:.3f}")

# 4. è·¨Canvasæ´å¯Ÿ
insights = integration.generate_cross_canvas_insights("é€»è¾‘", max_canvases=3)
print(f"æ¶‰åŠCanvas: {insights['total_canvases_found']}")
print(f"å­¦ä¹ å»ºè®®æ•°: {len(insights['learning_recommendations'])}")

# 5. è·å–ç»Ÿè®¡
stats = integration.get_integration_statistics()
print(f"æ€»è®°å¿†æ•°: {stats['memory_statistics']['total_memories']}")
print(f"ç³»ç»ŸçŠ¶æ€: {stats['integration_health']['overall_status']}")

# 6. æ¸…ç†èµ„æº
integration.close()
```

### é«˜çº§é…ç½®ç¤ºä¾‹

```python
# è‡ªå®šä¹‰é…ç½®
config = {
    "mcp_service": {
        "embedding_model": {
            "model_name": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            "device": "cuda",
            "batch_size": 64
        },
        "semantic_processing": {
            "chunk_size": 1024,
            "extract_concepts": True,
            "generate_tags": True
        },
        "creative_association": {
            "enable": True,
            "creativity_levels": {
                "creative": {
                    "temperature": 1.5,
                    "max_associations": 15
                }
            }
        }
    }
}

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆå§‹åŒ–
client = MCPSemanticMemory(config_path="custom_config.yaml")
engine = CreativeAssociationEngine(client, config)

# é«˜çº§å‹ç¼©
memory_compressor = MemoryCompressor(client, config)
compression_result = memory_compressor.compress_memories(
    memory_ids=["memory-1", "memory-2", ...],
    compression_ratio=0.2,
    strategy="semantic_clustering"
)
```

---

## æ€§èƒ½ä¼˜åŒ–

### æ‰¹å¤„ç†ä¼˜åŒ–

```python
# æ‰¹é‡å­˜å‚¨è®°å¿†
batch_size = 32
contents = [f"è®°å¿†å†…å®¹{i}" for i in range(100)]
metadata_list = [{"source": "batch"} for _ in contents]

# åˆ†æ‰¹å¤„ç†
for i in range(0, len(contents), batch_size):
    batch_contents = contents[i:i+batch_size]
    batch_metadata = metadata_list[i:i+batch_size]

    # æ‰¹é‡å­˜å‚¨
    memory_ids = []
    for content, metadata in zip(batch_contents, batch_metadata):
        memory_id = client.store_semantic_memory(content, metadata)
        memory_ids.append(memory_id)

    print(f"æ‰¹æ¬¡ {i//batch_size + 1}: å­˜å‚¨äº† {len(memory_ids)} ä¸ªè®°å¿†")
```

### æœç´¢ä¼˜åŒ–

```python
# ä½¿ç”¨åˆé€‚çš„æŸ¥è¯¢ç­–ç•¥
def smart_search(client, query, filters=None):
    # 1. ç›´æ¥æœç´¢
    results = client.search_semantic_memory(query, limit=20)

    # 2. å¦‚æœç»“æœä¸è¶³ï¼Œæ‰©å±•æœç´¢
    if len(results) < 5:
        # ä½¿ç”¨åŒä¹‰è¯æ‰©å±•
        expanded_query = f"{query} ç›¸å…³æ¦‚å¿µ"
        additional_results = client.search_semantic_memory(expanded_query, limit=10)
        results.extend(additional_results)

    # 3. åº”ç”¨è¿‡æ»¤å™¨
    if filters:
        results = [r for r in results if all(r['metadata'].get(k) == v
                                           for k, v in filters.items())]

    return results
```

### å†…å­˜ç®¡ç†

```python
# å®šæœŸå‹ç¼©ç­–ç•¥
def periodic_compression(client, threshold=5000):
    stats = client.get_memory_stats()

    if stats['total_memories'] > threshold:
        # è·å–æ‰€æœ‰è®°å¿†ID
        all_memory_ids = []  # å®é™…å®ç°ä¸­éœ€è¦ä»æ•°æ®åº“è·å–

        # æ‰§è¡Œå‹ç¼©
        compressor = MemoryCompressor(client)
        result = compressor.auto_compress_memories(threshold)

        if result['compressed']:
            print(f"å‹ç¼©å®Œæˆ: {result['compression_ratio']:.2%}")
            return result

    return {"compressed": False, "reason": "æœªè¾¾åˆ°å‹ç¼©é˜ˆå€¼"}
```

---

## æ›´æ–°æ—¥å¿—

### v1.0 (2025-10-23)
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- å®Œæ•´çš„MCPè¯­ä¹‰è®°å¿†æœåŠ¡API
- æ”¯æŒè¯­ä¹‰å­˜å‚¨ã€æœç´¢ã€å‹ç¼©å’Œåˆ›æ„è”æƒ³
- æä¾›Canvasé›†æˆæ¥å£
- å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œé…ç½®ç®¡ç†

---

**æ–‡æ¡£ç»´æŠ¤**: Canvas Learning System Development Team
**æœ€åæ›´æ–°**: 2025-10-23
**è”ç³»æ–¹å¼**: å¦‚æœ‰ç–‘é—®ï¼Œè¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£æˆ–æäº¤Issue
