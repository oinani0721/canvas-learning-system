# Gherkin Behavior Specification Template

Use this template to create `.feature` files in `specs/behavior/`.

---

## Template Structure

```gherkin
# specs/behavior/{feature-name}.feature
# Generated by: PM Agent *create-behavior-spec
# Date: {YYYY-MM-DD}
# Related: Epic {N}, Story {N.M}

@epic-{N} @priority-{level}
Feature: {Feature Name}
  As a {role}
  I want {capability}
  So that {benefit}

  # Optional: Common setup for all scenarios
  Background:
    Given {common precondition}
    And {another common setup}

  # ═══════════════════════════════════════════════════════════
  # HAPPY PATH SCENARIOS
  # ═══════════════════════════════════════════════════════════

  @story-{N.M} @smoke
  Scenario: {Descriptive scenario name - success case}
    Given {initial context}
    And {additional context}
    When {action performed}
    Then {expected outcome}
    And {additional verification}

  @story-{N.M}
  Scenario: {Another success scenario}
    Given {context}
    When {action}
    Then {result}

  # ═══════════════════════════════════════════════════════════
  # EDGE CASES AND ERROR HANDLING
  # ═══════════════════════════════════════════════════════════

  @story-{N.M} @error
  Scenario: {Error scenario name}
    Given {context that will cause error}
    When {action}
    Then {error handling}
    And {system remains stable}

  @story-{N.M} @boundary
  Scenario: {Boundary condition}
    Given {edge case context}
    When {action at boundary}
    Then {appropriate handling}

  # ═══════════════════════════════════════════════════════════
  # PARAMETERIZED SCENARIOS (Optional)
  # ═══════════════════════════════════════════════════════════

  @story-{N.M}
  Scenario Outline: {Parameterized scenario}
    Given {context with <variable>}
    When {action with <input>}
    Then {result should be <expected>}

    Examples:
      | variable | input | expected |
      | value1   | in1   | out1     |
      | value2   | in2   | out2     |
      | value3   | in3   | out3     |
```

---

## Tag Reference

### Epic/Story Tags
- `@epic-N` - Associated Epic number
- `@story-N.M` - Associated Story number

### Priority Tags
- `@priority-critical` - Must pass for release
- `@priority-high` - Important functionality
- `@priority-medium` - Standard features
- `@priority-low` - Nice to have

### Test Type Tags
- `@smoke` - Include in smoke test suite
- `@regression` - Include in regression suite
- `@integration` - Integration test
- `@e2e` - End-to-end test

### Status Tags
- `@wip` - Work in progress
- `@skip` - Temporarily skipped
- `@manual` - Requires manual testing

### Scenario Type Tags
- `@error` - Error handling scenario
- `@boundary` - Boundary condition test
- `@performance` - Performance-related test

---

## Canvas Learning System Examples

### Example 1: Scoring Agent

```gherkin
@epic-1 @priority-high
Feature: Scoring Agent - 4-Dimension Evaluation
  As a learner
  I want my understanding scored on 4 dimensions
  So that I know where to improve

  Background:
    Given a Canvas file is loaded
    And the Canvas contains yellow nodes with user responses

  @story-1.5 @smoke
  Scenario: Score yellow node with complete understanding
    Given a yellow node "yellow-001" with response "完整的费曼解释..."
    When the scoring-agent evaluates "yellow-001"
    Then the accuracy score is between 80 and 100
    And the imagery score is between 80 and 100
    And the completeness score is between 80 and 100
    And the originality score is between 70 and 100
    And the total score is above 85
    And the node color changes to green

  @story-1.5 @error
  Scenario: Attempt to score non-yellow node
    Given a red node "red-001" without user response
    When the scoring-agent attempts to evaluate "red-001"
    Then an error is returned "Only yellow nodes can be scored"
    And the node remains unchanged

  @story-1.5
  Scenario Outline: Score determines color transition
    Given a yellow node with total score <score>
    When the color transition is determined
    Then the node color should be "<color>"

    Examples:
      | score | color  |
      | 95    | green  |
      | 85    | green  |
      | 70    | purple |
      | 50    | red    |
```

### Example 2: Ebbinghaus Review

```gherkin
@epic-14 @priority-high
Feature: Ebbinghaus Review Scheduling
  As a learner
  I want review sessions scheduled based on forgetting curve
  So that I retain knowledge long-term

  @story-14.1 @smoke
  Scenario: 24-hour review trigger
    Given a concept was learned 24 hours ago
    And no review has been completed
    When the review scheduler checks due items
    Then the concept appears in the review queue
    And the review type is "24-hour recall"

  @story-14.4
  Scenario: Trigger Point 4 - Adaptive Review
    Given a concept has completed 3 review cycles
    And the latest scores are [85, 78, 82]
    When Trigger Point 4 is evaluated
    Then a targeted review Canvas is generated
    And it focuses on weak areas identified in scoring
```

---

## Writing Guidelines

### Given (Preconditions)
- Describe the initial state
- Set up test data
- Establish context

**Good**: `Given a Canvas with 5 red nodes and 3 yellow nodes`
**Bad**: `Given the system is ready`

### When (Actions)
- Single action per When
- Use active voice
- Be specific about the trigger

**Good**: `When the user clicks "Generate Verification Canvas"`
**Bad**: `When stuff happens`

### Then (Outcomes)
- Verify observable results
- Check state changes
- Validate outputs

**Good**: `Then a new Canvas file is created with 5 question nodes`
**Bad**: `Then it works`

### And/But (Additional Steps)
- Use for multiple conditions
- Keep related to parent step
- But = exception to Then

**Example**:
```gherkin
Then the score is calculated
And the result is saved to history
But no notification is sent for scores below 60
```

---

## File Naming

- Location: `specs/behavior/`
- Format: `{feature-name}.feature`
- Examples:
  - `scoring-agent.feature`
  - `ebbinghaus-review.feature`
  - `canvas-validation.feature`
  - `parallel-execution.feature`

---

## Integration Notes

### pytest-bdd Integration
```python
# tests/bdd/test_scoring.py
from pytest_bdd import scenarios, given, when, then

scenarios('../../../specs/behavior/scoring-agent.feature')

@given('a yellow node "yellow-001" with response "..."')
def yellow_node(canvas):
    return canvas.get_node("yellow-001")
```

### CI/CD Pipeline
```yaml
# .github/workflows/test.yml
- name: Run BDD Tests
  run: pytest tests/bdd/ --gherkin-terminal-reporter
```
