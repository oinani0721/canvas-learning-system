"""
Canvaså­¦ä¹ ç³»ç»Ÿ v2.0 - å¤šAgentå¹¶å‘åˆ†æç³»ç»Ÿæ ¸å¿ƒå®ç°

æœ¬æ–‡ä»¶å®ç°äº†å¤šAgentå¹¶å‘åˆ†æç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ï¼ŒåŒ…æ‹¬ï¼š
- Task Coordinator: ä»»åŠ¡åè°ƒå™¨
- Process Pool Manager: è¿›ç¨‹æ± ç®¡ç†å™¨
- Result Merger: ç»“æœèåˆå™¨
- Content Validator: å†…å®¹éªŒè¯å™¨
- Optimized Canvas Writer: ä¼˜åŒ–çš„Canvaså†™å…¥å™¨

Author: Claude (Dev Agent)
Version: 2.0
Created: 2025-10-18
"""

import asyncio
import json
import time
import uuid
from dataclasses import dataclass, field, asdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple
import hashlib
import os
import sys

# æ·»åŠ ç°æœ‰canvas_utilsåˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from canvas_utils import CanvasJSONOperator, CanvasBusinessLogic

# å°è¯•å¯¼å…¥aiomultiprocessï¼ˆå¦‚æœå¯ç”¨ï¼‰
try:
    import aiomultiprocess
    AIOMULTIPROCESS_AVAILABLE = True
except ImportError:
    AIOMULTIPROCESS_AVAILABLE = False
    print("è­¦å‘Š: aiomultiprocessæœªå®‰è£…ï¼Œå°†ä½¿ç”¨asyncioæ¨¡æ‹Ÿå¹¶å‘")

# å°è¯•å¯¼å…¥psutilï¼ˆç”¨äºæ€§èƒ½ç›‘æ§ï¼‰
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("è­¦å‘Š: psutilæœªå®‰è£…ï¼Œæ€§èƒ½ç›‘æ§åŠŸèƒ½å—é™")


# ========== æ•°æ®ç»“æ„å®šä¹‰ ==========

@dataclass
class AgentTask:
    """Agentä»»åŠ¡å®šä¹‰"""
    task_id: str
    agent_name: str
    input_data: Dict[str, Any]
    target_node_id: str
    priority: int = 1
    estimated_duration: float = 5.0
    dependencies: List[str] = field(default_factory=list)
    resource_requirements: Dict[str, Any] = field(default_factory=dict)
    retry_count: int = 0
    max_retries: int = 3

@dataclass
class TaskResult:
    """ä»»åŠ¡æ‰§è¡Œç»“æœ"""
    task_id: str
    agent_name: str
    target_node_id: str
    status: str  # "success", "failed", "timeout"
    result_data: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    execution_time: float = 0.0
    content_length: int = 0
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ValidationResult:
    """å†…å®¹éªŒè¯ç»“æœ"""
    is_valid: bool = True
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    confidence_score: float = 1.0

    def add_error(self, error: str):
        self.errors.append(error)
        self.is_valid = False
        self.confidence_score = max(0.0, self.confidence_score - 0.2)

    def add_warning(self, warning: str):
        self.warnings.append(warning)
        self.confidence_score = max(0.0, self.confidence_score - 0.1)

    def merge(self, other: 'ValidationResult'):
        self.is_valid = self.is_valid and other.is_valid
        self.errors.extend(other.errors)
        self.warnings.extend(other.warnings)
        self.confidence_score = min(self.confidence_score, other.confidence_score)

@dataclass
class ErrorHandlingResult:
    """é”™è¯¯å¤„ç†ç»“æœ"""
    should_retry: bool = False
    retry_delay: float = 0.0
    modifications: Dict[str, Any] = field(default_factory=dict)
    message: str = ""


# ========== å¼‚å¸¸ç±»å®šä¹‰ ==========

class ConcurrentAnalysisError(Exception):
    """å¹¶å‘åˆ†æå¼‚å¸¸"""
    pass

class CanvasWriteError(Exception):
    """Canvaså†™å…¥å¼‚å¸¸"""
    pass

class ConnectionPoolError(Exception):
    """è¿æ¥æ± å¼‚å¸¸"""
    pass


# ========== æ ¸å¿ƒç»„ä»¶å®ç° ==========

class AgentClassifier:
    """Agentåˆ†ç±»å™¨"""

    AGENT_CATEGORIES = {
        "computation_intensive": {
            "agents": ["oral-explanation", "clarification-path", "four-level-explanation"],
            "executor": "process_pool",
            "max_concurrent": 2,
            "timeout": 30.0,
            "memory_mb": 300
        },
        "io_intensive": {
            "agents": ["comparison-table", "memory-anchor", "basic-decomposition", "deep-decomposition"],
            "executor": "async_pool",
            "max_concurrent": 4,
            "timeout": 15.0,
            "memory_mb": 150
        },
        "lightweight": {
            "agents": ["scoring-agent", "verification-question-agent", "example-teaching"],
            "executor": "direct",
            "max_concurrent": 6,
            "timeout": 10.0,
            "memory_mb": 100
        }
    }

    @classmethod
    def classify_agent(cls, agent_name: str) -> Dict[str, Any]:
        """åˆ†ç±»Agentå¹¶è¿”å›æ‰§è¡Œé…ç½®"""
        for category, config in cls.AGENT_CATEGORIES.items():
            if agent_name in config["agents"]:
                return config.copy()

        # é»˜è®¤åˆ†ç±»ä¸ºè½»é‡çº§
        return cls.AGENT_CATEGORIES["lightweight"].copy()


class ProcessPoolManager:
    """è¿›ç¨‹æ± ç®¡ç†å™¨"""

    def __init__(self, max_workers: int = None):
        self.max_workers = max_workers or min(4, os.cpu_count() or 2)
        self.process_pool = None
        self.async_pool = None
        self.initialized = False

    async def initialize(self):
        """åˆå§‹åŒ–è¿›ç¨‹æ± """
        if self.initialized:
            return

        if AIOMULTIPROCESS_AVAILABLE:
            # ä½¿ç”¨aiomultiprocesså®ç°çœŸæ­£çš„å¹¶è¡Œ
            self.async_pool = aiomultiprocess.Pool(processes=self.max_workers)
            print(f"âœ… aiomultiprocessæ± åˆå§‹åŒ–æˆåŠŸï¼Œè¿›ç¨‹æ•°: {self.max_workers}")
        else:
            # é™çº§åˆ°asyncio
            print("âš ï¸  ä½¿ç”¨asyncioæ¨¡æ‹Ÿå¹¶å‘ï¼ˆæ€§èƒ½å—é™ï¼‰")

        self.initialized = True

    async def execute_task(self, task: AgentTask) -> TaskResult:
        """æ‰§è¡ŒAgentä»»åŠ¡"""
        if not self.initialized:
            await self.initialize()

        start_time = time.time()
        task_id = task.task_id

        try:
            # è·å–Agentåˆ†ç±»é…ç½®
            config = AgentClassifier.classify_agent(task.agent_name)
            timeout = config["timeout"]

            if AIOMULTIPROCESS_AVAILABLE and config["executor"] == "process_pool":
                # çœŸæ­£çš„å¹¶è¡Œæ‰§è¡Œ
                result = await self._execute_with_aiomultiprocess(task, timeout)
            else:
                # å¼‚æ­¥æ‰§è¡Œ
                result = await self._execute_with_asyncio(task, timeout)

            result.execution_time = time.time() - start_time
            return result

        except asyncio.TimeoutError:
            return TaskResult(
                task_id=task_id,
                agent_name=task.agent_name,
                target_node_id=task.target_node_id,
                status="timeout",
                execution_time=time.time() - start_time,
                error_message=f"ä»»åŠ¡è¶…æ—¶ ({config['timeout']}ç§’)"
            )
        except Exception as e:
            return TaskResult(
                task_id=task_id,
                agent_name=task.agent_name,
                target_node_id=task.target_node_id,
                status="failed",
                execution_time=time.time() - start_time,
                error_message=str(e)
            )

    async def _execute_with_aiomultiprocess(
        self,
        task: AgentTask,
        timeout: float
    ) -> TaskResult:
        """ä½¿ç”¨aiomultiprocessæ‰§è¡Œä»»åŠ¡"""

        async def agent_worker():
            """Agentå·¥ä½œè¿›ç¨‹"""
            return await self._call_agent_simulation(task)

        try:
            # ä½¿ç”¨aiomultiprocessæ‰§è¡Œ
            result_data = await asyncio.wait_for(
                self.async_pool.apply(agent_worker),
                timeout=timeout
            )

            return TaskResult(
                task_id=task.task_id,
                agent_name=task.agent_name,
                target_node_id=task.target_node_id,
                status="success",
                result_data=result_data,
                content_length=len(str(result_data))
            )

        except asyncio.TimeoutError:
            raise

    async def _execute_with_asyncio(
        self,
        task: AgentTask,
        timeout: float
    ) -> TaskResult:
        """ä½¿ç”¨asyncioæ‰§è¡Œä»»åŠ¡"""

        try:
            result_data = await asyncio.wait_for(
                self._call_agent_simulation(task),
                timeout=timeout
            )

            return TaskResult(
                task_id=task.task_id,
                agent_name=task.agent_name,
                target_node_id=task.target_node_id,
                status="success",
                result_data=result_data,
                content_length=len(str(result_data))
            )

        except asyncio.TimeoutError:
            raise

    async def _call_agent_simulation(self, task: AgentTask) -> Dict[str, Any]:
        """æ¨¡æ‹ŸAgentè°ƒç”¨ï¼ˆå®é™…å®ç°ä¸­ä¼šè°ƒç”¨çœŸå®çš„Claude Code Agentï¼‰"""

        # æ¨¡æ‹ŸAgentå¤„ç†æ—¶é—´
        config = AgentClassifier.classify_agent(task.agent_name)
        processing_time = config.get("timeout", 5.0) * 0.6  # 60%çš„è¶…æ—¶æ—¶é—´
        await asyncio.sleep(processing_time)

        # æ¨¡æ‹Ÿä¸åŒAgentçš„è¾“å‡º
        user_understanding = task.input_data.get("user_understanding", "")
        question_text = task.input_data.get("question_text", "")

        if task.agent_name == "oral-explanation":
            content = f"""ğŸ—£ï¸ æ•™æˆå¼è®²è§£ï¼š{question_text}

{user_understanding}

è¿™æ˜¯ä¸€ä¸ªå…³äº"{question_text}"çš„è¯¦ç»†å£è¯­åŒ–è§£é‡Šï¼ŒåŒ…å«äº†èƒŒæ™¯é“ºå«ã€æ ¸å¿ƒæ¦‚å¿µè®²è§£ã€ç”ŸåŠ¨ä¸¾ä¾‹å’Œå¸¸è§è¯¯åŒºåˆ†æã€‚

## èƒŒæ™¯é“ºå«
{question_text}æ˜¯å­¦ä¹ è¿‡ç¨‹ä¸­çš„é‡è¦æ¦‚å¿µï¼Œç†è§£å®ƒå¯¹äºæŒæ¡æ•´ä¸ªçŸ¥è¯†ä½“ç³»è‡³å…³é‡è¦ã€‚

## æ ¸å¿ƒè§£é‡Š
åŸºäºæ‚¨çš„ç†è§£"{user_understanding[:100]}..."ï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥æ·±åŒ–...

## ç”ŸåŠ¨ä¸¾ä¾‹
ä¸¾ä¸ªç®€å•çš„ä¾‹å­...

## å¸¸è§è¯¯åŒº
å­¦ä¹ {question_text}æ—¶å®¹æ˜“çŠ¯çš„é”™è¯¯åŒ…æ‹¬...

*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        elif task.agent_name == "clarification-path":
            content = f"""ğŸ” æ·±åº¦æ¾„æ¸…è·¯å¾„ï¼š{question_text}

## 1. é—®é¢˜æ¾„æ¸…
æˆ‘ä»¬è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜æ˜¯"{question_text}"ã€‚

## 2. æ¦‚å¿µæ‹†è§£
åŸºäºæ‚¨çš„ç†è§£"{user_understanding[:100]}..."ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªæ¦‚å¿µæ‹†è§£ä¸ºä»¥ä¸‹å‡ ä¸ªå…³é”®éƒ¨åˆ†...

## 3. æ·±åº¦è§£é‡Š
æ¯ä¸ªéƒ¨åˆ†çš„è¯¦ç»†è§£é‡Š...

## 4. éªŒè¯æ€»ç»“
é€šè¿‡ä»¥ä¸Šåˆ†æï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®º...

*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        elif task.agent_name == "comparison-table":
            content = f"""ğŸ“Š æ¦‚å¿µå¯¹æ¯”è¡¨

| ç»´åº¦ | æ¦‚å¿µA | æ¦‚å¿µB |
|------|-------|-------|
| å®šä¹‰ | å®šä¹‰A | å®šä¹‰B |
| ç‰¹å¾ | ç‰¹å¾A | ç‰¹å¾B |
| ä½¿ç”¨åœºæ™¯ | åœºæ™¯A | åœºæ™¯B |
| ç¤ºä¾‹ | ç¤ºä¾‹A | ç¤ºä¾‹B |

åŸºäºæ‚¨çš„ç†è§£ï¼š{user_understanding[:100]}...

*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        else:
            # é»˜è®¤å†…å®¹
            content = f"""ğŸ¤– {task.agent_name} åˆ†æç»“æœ

åŸºäºæ‚¨å¯¹"{question_text}"çš„ç†è§£ï¼š{user_understanding}

è¿™æ˜¯{task.agent_name}ç”Ÿæˆçš„åˆ†æå†…å®¹ã€‚

*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

        return {
            "content": content,
            "agent_name": task.agent_name,
            "target_node_id": task.target_node_id,
            "processing_time": processing_time
        }

    async def shutdown(self):
        """å…³é—­è¿›ç¨‹æ± """
        if self.async_pool:
            await self.async_pool.close()
        print("âœ… è¿›ç¨‹æ± å·²å…³é—­")


class TaskCoordinator:
    """ä»»åŠ¡åè°ƒå™¨"""

    def __init__(self, max_workers: int = 4, max_concurrent_agents: int = 3):
        self.max_workers = max_workers
        self.max_concurrent_agents = max_concurrent_agents
        self.process_manager = ProcessPoolManager(max_workers)
        self.active_tasks: Dict[str, AgentTask] = {}
        self.completed_results: List[TaskResult] = []

    async def initialize(self):
        """åˆå§‹åŒ–ä»»åŠ¡åè°ƒå™¨"""
        await self.process_manager.initialize()

    async def coordinate_concurrent_analysis(
        self,
        canvas_path: str,
        yellow_nodes: List[Dict],
        selected_agents: List[str],
        analysis_mode: str = "parallel"
    ) -> Dict[str, Any]:
        """åè°ƒå¤šAgentå¹¶å‘åˆ†æ"""

        print(f"ğŸš€ å¼€å§‹å¹¶å‘åˆ†æï¼š{len(yellow_nodes)}ä¸ªèŠ‚ç‚¹ï¼Œ{len(selected_agents)}ä¸ªAgent")
        start_time = time.time()

        try:
            # 1. ç”Ÿæˆä»»åŠ¡
            tasks = await self._generate_tasks(yellow_nodes, selected_agents)
            print(f"ğŸ“‹ ç”Ÿæˆäº†{len(tasks)}ä¸ªä»»åŠ¡")

            # 2. æ‰§è¡Œå¹¶å‘ä»»åŠ¡
            if analysis_mode == "parallel":
                results = await self._execute_parallel(tasks)
            elif analysis_mode == "sequential":
                results = await self._execute_sequential(tasks)
            else:
                results = await self._execute_hybrid(tasks)

            # 3. ç»Ÿè®¡ç»“æœ
            successful = sum(1 for r in results if r.status == "success")
            failed = sum(1 for r in results if r.status == "failed")
            timeout = sum(1 for r in results if r.status == "timeout")

            total_time = time.time() - start_time
            performance_improvement = len(tasks) * 5.0 / total_time  # å‡è®¾ä¸²è¡Œæ¯ä¸ªä»»åŠ¡5ç§’

            print(f"âœ… å¹¶å‘åˆ†æå®Œæˆï¼š{successful}æˆåŠŸï¼Œ{failed}å¤±è´¥ï¼Œ{timeout}è¶…æ—¶")
            print(f"â±ï¸  æ€»è€—æ—¶ï¼š{total_time:.2f}ç§’ï¼Œæ€§èƒ½æå‡ï¼š{performance_improvement:.1f}å€")

            return {
                "status": "completed",
                "total_time": total_time,
                "performance_improvement": performance_improvement,
                "results": results,
                "statistics": {
                    "total_tasks": len(tasks),
                    "successful": successful,
                    "failed": failed,
                    "timeout": timeout
                }
            }

        except Exception as e:
            print(f"âŒ å¹¶å‘åˆ†æå¤±è´¥ï¼š{str(e)}")
            raise ConcurrentAnalysisError(f"å¹¶å‘åˆ†æå¤±è´¥: {str(e)}")

    async def _generate_tasks(
        self,
        yellow_nodes: List[Dict],
        selected_agents: List[str]
    ) -> List[AgentTask]:
        """ç”Ÿæˆå¹¶å‘ä»»åŠ¡åˆ—è¡¨"""

        tasks = []

        for node in yellow_nodes:
            node_id = node.get("id", "")
            node_text = node.get("text", "")

            for agent_name in selected_agents:
                task = AgentTask(
                    task_id=f"{node_id}_{agent_name}_{uuid.uuid4().hex[:8]}",
                    agent_name=agent_name,
                    input_data={
                        "question_text": node.get("question_text", ""),
                        "user_understanding": node_text,
                        "reference_material": node.get("reference_material", "")
                    },
                    target_node_id=node_id,
                    estimated_duration=5.0
                )
                tasks.append(task)

        return tasks

    async def _execute_parallel(self, tasks: List[AgentTask]) -> List[TaskResult]:
        """å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡"""

        semaphore = asyncio.Semaphore(self.max_concurrent_agents)

        async def execute_with_semaphore(task: AgentTask):
            async with semaphore:
                return await self.process_manager.execute_task(task)

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(
            *[execute_with_semaphore(task) for task in tasks],
            return_exceptions=True
        )

        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for result in results:
            if isinstance(result, Exception):
                processed_results.append(TaskResult(
                    task_id="unknown",
                    agent_name="unknown",
                    target_node_id="unknown",
                    status="failed",
                    error_message=str(result)
                ))
            else:
                processed_results.append(result)

        return processed_results

    async def _execute_sequential(self, tasks: List[AgentTask]) -> List[TaskResult]:
        """é¡ºåºæ‰§è¡Œä»»åŠ¡ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        results = []
        for task in tasks:
            result = await self.process_manager.execute_task(task)
            results.append(result)
        return results

    async def _execute_hybrid(self, tasks: List[AgentTask]) -> List[TaskResult]:
        """æ··åˆæ‰§è¡Œï¼šæŒ‰Agentç±»å‹åˆ†ç»„å¹¶è¡Œ"""

        # æŒ‰Agentç±»å‹åˆ†ç»„
        grouped_tasks = {}
        for task in tasks:
            category = AgentClassifier.classify_agent(task.agent_name)["executor"]
            if category not in grouped_tasks:
                grouped_tasks[category] = []
            grouped_tasks[category].append(task)

        # é€ç»„æ‰§è¡Œ
        all_results = []
        for category, category_tasks in grouped_tasks.items():
            if category == "process_pool" and len(category_tasks) > 1:
                # å¹¶è¡Œæ‰§è¡Œè®¡ç®—å¯†é›†å‹ä»»åŠ¡
                results = await self._execute_parallel(category_tasks)
            else:
                # å…¶ä»–ç±»å‹é¡ºåºæ‰§è¡Œ
                results = await self._execute_sequential(category_tasks)
            all_results.extend(results)

        return all_results

    async def shutdown(self):
        """å…³é—­ä»»åŠ¡åè°ƒå™¨"""
        await self.process_manager.shutdown()


class ContentValidator:
    """å†…å®¹éªŒè¯å™¨"""

    def __init__(self):
        self.validation_rules = {
            "length_check": self._validate_content_length,
            "encoding_check": self._validate_encoding,
            "structure_check": self._validate_structure,
            "completeness_check": self._validate_completeness
        }

    async def validate_content(
        self,
        content: str,
        source_agent: str
    ) -> ValidationResult:
        """éªŒè¯å†…å®¹å®Œæ•´æ€§"""

        result = ValidationResult()

        # æ‰§è¡Œå„é¡¹éªŒè¯
        for rule_name, rule_func in self.validation_rules.items():
            try:
                validation_result = await rule_func(content, source_agent)
                result.merge(validation_result)
            except Exception as e:
                result.add_error(f"{rule_name}: {str(e)}")

        return result

    async def _validate_content_length(
        self,
        content: str,
        source_agent: str
    ) -> ValidationResult:
        """éªŒè¯å†…å®¹é•¿åº¦"""

        result = ValidationResult()

        # æ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
        ellipsis_count = content.count("...")
        if ellipsis_count > 3:
            result.add_warning(f"æ£€æµ‹åˆ°{ellipsis_count}ä¸ªçœç•¥å·ï¼Œå¯èƒ½å­˜åœ¨æˆªæ–­")

        # æ£€æŸ¥é¢„æœŸé•¿åº¦
        expected_lengths = {
            "oral-explanation": (800, 1200),
            "clarification-path": (1500, 2500),
            "four-level-explanation": (1200, 1600)
        }

        if source_agent in expected_lengths:
            min_len, max_len = expected_lengths[source_agent]
            actual_len = len(content)

            if actual_len < min_len * 0.5:
                result.add_error(f"å†…å®¹è¿‡çŸ­: {actual_len}å­—ç¬¦ (é¢„æœŸ: {min_len}-{max_len})")
            elif actual_len < min_len * 0.8:
                result.add_warning(f"å†…å®¹è¾ƒçŸ­: {actual_len}å­—ç¬¦ (é¢„æœŸ: {min_len}-{max_len})")

        return result

    async def _validate_encoding(self, content: str, source_agent: str) -> ValidationResult:
        """éªŒè¯å­—ç¬¦ç¼–ç """

        result = ValidationResult()

        try:
            # æµ‹è¯•UTF-8ç¼–ç /è§£ç 
            encoded = content.encode('utf-8')
            decoded = encoded.decode('utf-8')

            if decoded != content:
                result.add_error("UTF-8ç¼–ç éªŒè¯å¤±è´¥")

        except UnicodeEncodeError as e:
            result.add_error(f"ç¼–ç é”™è¯¯: {str(e)}")

        # æ£€æŸ¥ç‰¹æ®Šå­—ç¬¦
        problematic_chars = ['ï¿½', '\ufffd', '\x00']
        for char in problematic_chars:
            if char in content:
                result.add_error(f"æ£€æµ‹åˆ°é—®é¢˜å­—ç¬¦: {repr(char)}")

        return result

    async def _validate_structure(self, content: str, source_agent: str) -> ValidationResult:
        """éªŒè¯å†…å®¹ç»“æ„"""

        result = ValidationResult()

        # æ£€æŸ¥åŸºæœ¬ç»“æ„
        if not content.strip():
            result.add_error("å†…å®¹ä¸ºç©º")
            return result

        # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„æœŸçš„ç»“æ„å…ƒç´ 
        if source_agent == "oral-explanation":
            required_elements = ["èƒŒæ™¯", "æ ¸å¿ƒ", "ä¸¾ä¾‹", "è¯¯åŒº"]
            for element in required_elements:
                if element not in content:
                    result.add_warning(f"ç¼ºå°‘{element}éƒ¨åˆ†")

        elif source_agent == "clarification-path":
            required_elements = ["æ¾„æ¸…", "æ‹†è§£", "è§£é‡Š", "æ€»ç»“"]
            for element in required_elements:
                if element not in content:
                    result.add_warning(f"ç¼ºå°‘{element}éƒ¨åˆ†")

        return result

    async def _validate_completeness(self, content: str, source_agent: str) -> ValidationResult:
        """éªŒè¯å†…å®¹å®Œæ•´æ€§"""

        result = ValidationResult()

        # æ£€æŸ¥ç”Ÿæˆæ—¶é—´æˆ³
        if "ç”Ÿæˆæ—¶é—´:" not in content:
            result.add_warning("ç¼ºå°‘ç”Ÿæˆæ—¶é—´æˆ³")

        # æ£€æŸ¥Agentæ ‡è¯†
        if source_agent not in content:
            result.add_warning("ç¼ºå°‘Agentæ ‡è¯†")

        return result


class ResultMerger:
    """ç»“æœèåˆå™¨"""

    def __init__(self):
        self.content_validator = ContentValidator()

    async def merge_results(
        self,
        results: List[TaskResult],
        fusion_strategy: str = "complementary"
    ) -> Dict[str, Any]:
        """èåˆå¤šä¸ªAgentçš„æ‰§è¡Œç»“æœ"""

        print(f"ğŸ”— å¼€å§‹èåˆ{len(results)}ä¸ªAgentç»“æœ")

        # 1. è¿‡æ»¤æˆåŠŸçš„ç»“æœ
        successful_results = [r for r in results if r.status == "success"]
        if not successful_results:
            raise ValueError("æ²¡æœ‰æˆåŠŸçš„Agentç»“æœå¯ä»¥èåˆ")

        # 2. éªŒè¯ç»“æœå®Œæ•´æ€§
        validated_results = []
        for result in successful_results:
            content = result.result_data.get("content", "")
            validation = await self.content_validator.validate_content(
                content, result.agent_name
            )

            if validation.is_valid:
                validated_results.append(result)
            else:
                print(f"âš ï¸  {result.agent_name}ç»“æœéªŒè¯å¤±è´¥: {validation.errors}")

        if not validated_results:
            raise ValueError("æ‰€æœ‰ç»“æœéƒ½æœªé€šè¿‡éªŒè¯")

        # 3. æ‰§è¡Œèåˆ
        if fusion_strategy == "complementary":
            merged_content = await self._merge_complementary(validated_results)
        elif fusion_strategy == "supplementary":
            merged_content = await self._merge_supplementary(validated_results)
        else:
            merged_content = await self._merge_complementary(validated_results)

        # 4. æ·»åŠ å…ƒæ•°æ®
        merged_content["metadata"] = {
            "fusion_strategy": fusion_strategy,
            "agent_count": len(validated_results),
            "fusion_time": datetime.now().isoformat(),
            "source_agents": [r.agent_name for r in validated_results]
        }

        print(f"âœ… ç»“æœèåˆå®Œæˆï¼Œä½¿ç”¨äº†{len(validated_results)}ä¸ªAgentçš„ç»“æœ")
        return merged_content

    async def _merge_complementary(self, results: List[TaskResult]) -> Dict[str, Any]:
        """äº’è¡¥èåˆç­–ç•¥"""

        merged_content = {
            "sections": [],
            "cross_references": [],
            "summary_points": []
        }

        # æŒ‰Agentç±»å‹åˆ†ç»„
        results_by_type = {}
        for result in results:
            agent_name = result.agent_name
            results_by_type[agent_name] = result.result_data

        # æ„å»ºäº’è¡¥å†…å®¹ç»“æ„
        section_order = [
            "oral-explanation",
            "clarification-path",
            "comparison-table",
            "memory-anchor",
            "four-level-explanation",
            "example-teaching"
        ]

        for agent_name in section_order:
            if agent_name in results_by_type:
                result = results_by_type[agent_name]
                content = result.get("content", "")

                # ç¡®å®šæ ‡é¢˜
                titles = {
                    "oral-explanation": "ğŸ—£ï¸ æ•™æˆå¼è®²è§£",
                    "clarification-path": "ğŸ” æ·±åº¦æ¾„æ¸…è·¯å¾„",
                    "comparison-table": "ğŸ“Š æ¦‚å¿µå¯¹æ¯”è¡¨",
                    "memory-anchor": "âš“ è®°å¿†é”šç‚¹",
                    "four-level-explanation": "ğŸ¯ å››å±‚æ¬¡è§£é‡Š",
                    "example-teaching": "ğŸ“ ä¾‹é¢˜æ•™å­¦"
                }

                merged_content["sections"].append({
                    "type": agent_name,
                    "title": titles.get(agent_name, f"ğŸ¤– {agent_name}"),
                    "content": content
                })

        # ç”Ÿæˆäº¤å‰å¼•ç”¨
        merged_content["cross_references"] = self._generate_cross_references(
            merged_content["sections"]
        )

        # ç”Ÿæˆè¦ç‚¹æ€»ç»“
        merged_content["summary_points"] = self._extract_summary_points(
            merged_content["sections"]
        )

        return merged_content

    async def _merge_supplementary(self, results: List[TaskResult]) -> Dict[str, Any]:
        """è¡¥å……èåˆç­–ç•¥"""
        # å®ç°ç•¥...
        return await self._merge_complementary(results)

    def _generate_cross_references(self, sections: List[Dict]) -> List[str]:
        """ç”Ÿæˆäº¤å‰å¼•ç”¨"""

        references = []

        if len(sections) > 1:
            references.append("ğŸ“– ä»¥ä¸Šåˆ†æä»ä¸åŒè§’åº¦æ·±å…¥è§£é‡Šäº†ç›¸å…³æ¦‚å¿µ")

            # æ ¹æ®sectionsç”Ÿæˆå…·ä½“å¼•ç”¨
            for i, section in enumerate(sections):
                if i < len(sections) - 1:
                    next_section = sections[i + 1]
                    references.append(
                        f"â¡ï¸  å‚è§ã€Œ{section['title']}ã€ä¸ã€Œ{next_section['title']}ã€çš„å…³è”åˆ†æ"
                    )

        return references

    def _extract_summary_points(self, sections: List[Dict]) -> List[str]:
        """æå–è¦ç‚¹æ€»ç»“"""

        summary_points = []

        # ä»æ¯ä¸ªsectionä¸­æå–è¦ç‚¹
        for section in sections:
            content = section.get("content", "")

            # ç®€å•çš„è¦ç‚¹æå–é€»è¾‘
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if line.startswith('#') or line.startswith('*') or line.startswith('-'):
                    # æ¸…ç†æ ¼å¼
                    point = line.lstrip('#*- ').strip()
                    if len(point) > 10 and len(point) < 200:
                        summary_points.append(point)

        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_points = []
        for point in summary_points:
            if point not in unique_points:
                unique_points.append(point)

        return unique_points[:10]  # æœ€å¤š10ä¸ªè¦ç‚¹


class OptimizedCanvasWriter:
    """ä¼˜åŒ–çš„Canvaså†™å…¥å™¨"""

    def __init__(self, canvas_path: str):
        self.canvas_path = canvas_path
        self.operator = CanvasJSONOperator
        self.backup_dir = Path(canvas_path).parent / ".backups"
        self.backup_dir.mkdir(exist_ok=True)

    async def write_merged_content(
        self,
        yellow_node_id: str,
        merged_content: Dict[str, Any],
        backup_enabled: bool = True
    ) -> bool:
        """å†™å…¥èåˆåçš„å†…å®¹åˆ°é»„è‰²èŠ‚ç‚¹"""

        print(f"âœï¸  å¼€å§‹å†™å…¥èŠ‚ç‚¹ {yellow_node_id}")

        try:
            # 1. åˆ›å»ºå¤‡ä»½
            if backup_enabled:
                await self._create_backup()

            # 2. è¯»å–Canvasæ•°æ®
            canvas_data = self.operator.read_canvas(self.canvas_path)

            # 3. æ ¼å¼åŒ–å†…å®¹
            formatted_content = await self._format_content_for_canvas(merged_content)

            # 4. æ‰¾åˆ°å¹¶æ›´æ–°é»„è‰²èŠ‚ç‚¹
            success = self._update_yellow_node(canvas_data, yellow_node_id, formatted_content)

            if not success:
                raise ValueError(f"é»„è‰²èŠ‚ç‚¹ {yellow_node_id} ä¸å­˜åœ¨")

            # 5. ä¿å­˜Canvasæ–‡ä»¶
            self.operator.write_canvas(self.canvas_path, canvas_data)

            # 6. éªŒè¯å†™å…¥ç»“æœ
            verification_success = await self._verify_write_result(
                yellow_node_id, formatted_content
            )

            if verification_success:
                print(f"âœ… èŠ‚ç‚¹ {yellow_node_id} å†™å…¥æˆåŠŸ")
                return True
            else:
                print(f"âš ï¸  èŠ‚ç‚¹ {yellow_node_id} å†™å…¥éªŒè¯å¤±è´¥")
                return False

        except Exception as e:
            print(f"âŒ èŠ‚ç‚¹ {yellow_node_id} å†™å…¥å¤±è´¥: {str(e)}")
            if backup_enabled:
                await self._restore_from_backup()
            raise CanvasWriteError(f"å†™å…¥å¤±è´¥: {str(e)}")

    async def _create_backup(self):
        """åˆ›å»ºCanvasæ–‡ä»¶å¤‡ä»½"""

        canvas_file = Path(self.canvas_path)
        if not canvas_file.exists():
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = self.backup_dir / f"{canvas_file.stem}_{timestamp}{canvas_file.suffix}"

        try:
            import shutil
            shutil.copy2(canvas_file, backup_file)
            print(f"ğŸ’¾ å¤‡ä»½å·²åˆ›å»º: {backup_file}")
        except Exception as e:
            print(f"âš ï¸  å¤‡ä»½åˆ›å»ºå¤±è´¥: {str(e)}")

    async def _format_content_for_canvas(self, merged_content: Dict[str, Any]) -> str:
        """ä¸ºCanvasæ ¼å¼åŒ–å†…å®¹"""

        formatted_parts = []

        # æ·»åŠ æ ‡é¢˜
        formatted_parts.append("# ğŸ¤– å¤šAgentæ™ºèƒ½åˆ†æç»“æœ\n")

        # æ·»åŠ å„ä¸ªsection
        for section in merged_content.get("sections", []):
            formatted_parts.append(f"## {section['title']}\n")
            formatted_parts.append(f"{section['content']}\n\n")

        # æ·»åŠ äº¤å‰å¼•ç”¨
        if merged_content.get("cross_references"):
            formatted_parts.append("## ğŸ”— å…³è”å‚è€ƒ\n")
            for ref in merged_content["cross_references"]:
                formatted_parts.append(f"- {ref}\n")
            formatted_parts.append("\n")

        # æ·»åŠ è¦ç‚¹æ€»ç»“
        if merged_content.get("summary_points"):
            formatted_parts.append("## ğŸ’¡ æ ¸å¿ƒè¦ç‚¹\n")
            for point in merged_content["summary_points"]:
                formatted_parts.append(f"- {point}\n")
            formatted_parts.append("\n")

        # æ·»åŠ å…ƒæ•°æ®
        metadata = merged_content.get("metadata", {})
        formatted_parts.append("---\n")
        formatted_parts.append(f"**èåˆç­–ç•¥**: {metadata.get('fusion_strategy', 'unknown')}\n")
        formatted_parts.append(f"**å‚ä¸Agentæ•°**: {metadata.get('agent_count', 0)}\n")
        formatted_parts.append(f"**ç”Ÿæˆæ—¶é—´**: {metadata.get('fusion_time', 'unknown')}\n")
        formatted_parts.append("**å¤„ç†æ–¹å¼**: å¤šAgentå¹¶å‘åˆ†æ + æ™ºèƒ½èåˆ\n")

        return "".join(formatted_parts)

    def _update_yellow_node(
        self,
        canvas_data: Dict,
        node_id: str,
        content: str
    ) -> bool:
        """æ›´æ–°é»„è‰²èŠ‚ç‚¹å†…å®¹"""

        for node in canvas_data.get("nodes", []):
            if node.get("id") == node_id:
                # éªŒè¯èŠ‚ç‚¹é¢œè‰²
                if node.get("color") != "6":  # é»„è‰²
                    print(f"âš ï¸  è­¦å‘Š: èŠ‚ç‚¹ {node_id} ä¸æ˜¯é»„è‰²èŠ‚ç‚¹")

                node["text"] = content
                return True

        return False

    async def _verify_write_result(
        self,
        node_id: str,
        expected_content: str
    ) -> bool:
        """éªŒè¯å†™å…¥ç»“æœ"""

        try:
            # é‡æ–°è¯»å–Canvas
            canvas_data = self.operator.read_canvas(self.canvas_path)

            # æ‰¾åˆ°èŠ‚ç‚¹å¹¶éªŒè¯å†…å®¹
            for node in canvas_data.get("nodes", []):
                if node.get("id") == node_id:
                    actual_content = node.get("text", "")

                    # æ£€æŸ¥å†…å®¹é•¿åº¦
                    if len(actual_content) < len(expected_content) * 0.9:
                        print(f"âš ï¸  å†…å®¹é•¿åº¦æ£€æŸ¥å¤±è´¥: {len(actual_content)} vs {len(expected_content)}")
                        return False

                    # æ£€æŸ¥å…³é”®å­—æ®µ
                    if "å¤šAgentæ™ºèƒ½åˆ†æç»“æœ" not in actual_content:
                        print("âš ï¸  å…³é”®å­—æ®µæ£€æŸ¥å¤±è´¥: ç¼ºå°‘åˆ†æç»“æœæ ‡è¯†")
                        return False

                    return True

            print(f"âš ï¸  éªŒè¯å¤±è´¥: èŠ‚ç‚¹ {node_id} ä¸å­˜åœ¨")
            return False

        except Exception as e:
            print(f"âš ï¸  éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return False

    async def _restore_from_backup(self):
        """ä»å¤‡ä»½æ¢å¤"""
        # å®ç°ç•¥...
        print("ğŸ”„ å°è¯•ä»å¤‡ä»½æ¢å¤...")


# ========== ä¸»è¦æ¥å£ç±» ==========

class ConcurrentCanvasOrchestrator:
    """å¹¶å‘Canvasæ“ä½œå™¨ - ä¸»è¦æ¥å£ç±»"""

    def __init__(self, canvas_path: str, concurrent_enabled: bool = True):
        self.canvas_path = canvas_path
        self.concurrent_enabled = concurrent_enabled

        if concurrent_enabled:
            self.task_coordinator = TaskCoordinator()
            self.result_merger = ResultMerger()
            self.canvas_writer = OptimizedCanvasWriter(canvas_path)
            self.logic = CanvasBusinessLogic(canvas_path)

    async def initialize(self):
        """åˆå§‹åŒ–å¹¶å‘ç³»ç»Ÿ"""
        if self.concurrent_enabled:
            await self.task_coordinator.initialize()

    async def concurrent_analyze_yellow_nodes(
        self,
        yellow_node_ids: List[str],
        selected_agents: List[str],
        analysis_mode: str = "parallel"
    ) -> Dict[str, Any]:
        """å¹¶å‘åˆ†æå¤šä¸ªé»„è‰²èŠ‚ç‚¹

        Args:
            yellow_node_ids: é»„è‰²èŠ‚ç‚¹IDåˆ—è¡¨
            selected_agents: é€‰æ‹©çš„Agentåˆ—è¡¨
            analysis_mode: åˆ†ææ¨¡å¼ ("parallel", "sequential", "hybrid")

        Returns:
            Dict: åˆ†æç»“æœæŠ¥å‘Š
        """

        print(f"ğŸ¯ å¼€å§‹å¹¶å‘åˆ†æ: {len(yellow_node_ids)}ä¸ªèŠ‚ç‚¹, {len(selected_agents)}ä¸ªAgent")
        session_id = str(uuid.uuid4())[:8]

        try:
            # 1. è¯»å–é»„è‰²èŠ‚ç‚¹å†…å®¹
            yellow_nodes = await self._extract_yellow_nodes(yellow_node_ids)

            if not yellow_nodes:
                raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„é»„è‰²èŠ‚ç‚¹")

            # 2. æ‰§è¡Œå¹¶å‘åˆ†æ
            analysis_results = await self.task_coordinator.coordinate_concurrent_analysis(
                self.canvas_path,
                yellow_nodes,
                selected_agents,
                analysis_mode
            )

            # 3. èåˆç»“æœå¹¶å†™å…¥Canvas
            merged_results = {}
            successful_nodes = 0

            for node_id in yellow_node_ids:
                # è·å–è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰ç»“æœ
                node_results = [
                    result for result in analysis_results["results"]
                    if result.target_node_id == node_id and result.status == "success"
                ]

                if node_results:
                    try:
                        # èåˆç»“æœ
                        merged_content = await self.result_merger.merge_results(node_results)

                        # å†™å…¥Canvas
                        success = await self.canvas_writer.write_merged_content(
                            node_id, merged_content
                        )

                        merged_results[node_id] = {
                            "success": success,
                            "agent_count": len(node_results),
                            "content_length": len(str(merged_content))
                        }

                        if success:
                            successful_nodes += 1

                    except Exception as e:
                        print(f"âŒ èŠ‚ç‚¹ {node_id} å¤„ç†å¤±è´¥: {str(e)}")
                        merged_results[node_id] = {
                            "success": False,
                            "error": str(e),
                            "agent_count": len(node_results)
                        }
                else:
                    merged_results[node_id] = {
                        "success": False,
                        "error": "æ²¡æœ‰æˆåŠŸçš„Agentç»“æœ",
                        "agent_count": 0
                    }

            # 4. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            total_time = analysis_results["total_time"]
            performance_improvement = analysis_results["performance_improvement"]

            report = {
                "session_id": session_id,
                "status": "completed",
                "total_nodes": len(yellow_node_ids),
                "successful_nodes": successful_nodes,
                "failed_nodes": len(yellow_node_ids) - successful_nodes,
                "total_time": total_time,
                "performance_improvement": performance_improvement,
                "node_results": merged_results,
                "analysis_statistics": analysis_results["statistics"],
                "selected_agents": selected_agents,
                "analysis_mode": analysis_mode
            }

            print(f"ğŸ‰ å¹¶å‘åˆ†æä¼šè¯ {session_id} å®Œæˆ!")
            print(f"   æˆåŠŸèŠ‚ç‚¹: {successful_nodes}/{len(yellow_node_ids)}")
            print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"   æ€§èƒ½æå‡: {performance_improvement:.1f}å€")

            return report

        except Exception as e:
            print(f"âŒ å¹¶å‘åˆ†æä¼šè¯ {session_id} å¤±è´¥: {str(e)}")
            raise ConcurrentAnalysisError(f"å¹¶å‘åˆ†æå¤±è´¥: {str(e)}")

    async def _extract_yellow_nodes(self, yellow_node_ids: List[str]) -> List[Dict]:
        """æå–é»„è‰²èŠ‚ç‚¹æ•°æ®"""

        canvas_data = self.operator.read_canvas(self.canvas_path)
        yellow_nodes = []

        for node_id in yellow_node_ids:
            for node in canvas_data.get("nodes", []):
                if node.get("id") == node_id and node.get("color") == "6":  # é»„è‰²
                    # æŸ¥æ‰¾å…³è”çš„é—®é¢˜èŠ‚ç‚¹
                    question_node = self._find_related_question_node(
                        canvas_data, node_id
                    )

                    yellow_nodes.append({
                        "id": node_id,
                        "text": node.get("text", ""),
                        "question_text": question_node.get("text", "") if question_node else "",
                        "reference_material": ""
                    })
                    break

        return yellow_nodes

    def _find_related_question_node(self, canvas_data: Dict, yellow_node_id: str) -> Optional[Dict]:
        """æŸ¥æ‰¾ä¸é»„è‰²èŠ‚ç‚¹å…³è”çš„é—®é¢˜èŠ‚ç‚¹"""

        # æŸ¥æ‰¾è¿æ¥åˆ°é»„è‰²èŠ‚ç‚¹çš„è¾¹
        for edge in canvas_data.get("edges", []):
            if edge.get("to") == yellow_node_id:
                from_node_id = edge.get("from")

                # æ‰¾åˆ°æ¥æºèŠ‚ç‚¹
                for node in canvas_data.get("nodes", []):
                    if node.get("id") == from_node_id:
                        # æ£€æŸ¥æ˜¯å¦ä¸ºé—®é¢˜èŠ‚ç‚¹ï¼ˆçº¢è‰²æˆ–ç´«è‰²ï¼‰
                        if node.get("color") in ["1", "3", "4"]:  # çº¢è‰²ã€ç´«è‰²
                            return node

        return None

    async def shutdown(self):
        """å…³é—­å¹¶å‘ç³»ç»Ÿ"""
        if self.concurrent_enabled:
            await self.task_coordinator.shutdown()


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========

async def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""

    # é…ç½®
    canvas_path = "ç¬”è®°åº“/ç¦»æ•£æ•°å­¦/ç¦»æ•£æ•°å­¦.canvas"
    yellow_node_ids = ["yellow-001", "yellow-002", "yellow-003"]  # å®é™…çš„é»„è‰²èŠ‚ç‚¹ID
    selected_agents = [
        "oral-explanation",
        "clarification-path",
        "comparison-table",
        "memory-anchor"
    ]

    # åˆ›å»ºå¹¶å‘æ“ä½œå™¨
    orchestrator = ConcurrentCanvasOrchestrator(
        canvas_path=canvas_path,
        concurrent_enabled=True
    )

    try:
        # åˆå§‹åŒ–
        await orchestrator.initialize()

        # æ‰§è¡Œå¹¶å‘åˆ†æ
        result = await orchestrator.concurrent_analyze_yellow_nodes(
            yellow_node_ids=yellow_node_ids,
            selected_agents=selected_agents,
            analysis_mode="parallel"  # å¯é€‰: "parallel", "sequential", "hybrid"
        )

        # æ‰“å°ç»“æœ
        print("\n" + "="*50)
        print("å¹¶å‘åˆ†æç»“æœæŠ¥å‘Š")
        print("="*50)
        print(f"ä¼šè¯ID: {result['session_id']}")
        print(f"æ€»èŠ‚ç‚¹æ•°: {result['total_nodes']}")
        print(f"æˆåŠŸèŠ‚ç‚¹: {result['successful_nodes']}")
        print(f"å¤±è´¥èŠ‚ç‚¹: {result['failed_nodes']}")
        print(f"æ€»è€—æ—¶: {result['total_time']:.2f}ç§’")
        print(f"æ€§èƒ½æå‡: {result['performance_improvement']:.1f}å€")
        print(f"åˆ†ææ¨¡å¼: {result['analysis_mode']}")

        print("\nèŠ‚ç‚¹è¯¦æƒ…:")
        for node_id, node_result in result['node_results'].items():
            status = "âœ… æˆåŠŸ" if node_result['success'] else "âŒ å¤±è´¥"
            agent_count = node_result.get('agent_count', 0)
            print(f"  {node_id}: {status} (Agentæ•°: {agent_count})")
            if not node_result['success'] and 'error' in node_result:
                print(f"    é”™è¯¯: {node_result['error']}")

    except Exception as e:
        print(f"ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {str(e)}")

    finally:
        # æ¸…ç†èµ„æº
        await orchestrator.shutdown()


if __name__ == "__main__":
    """ç›´æ¥è¿è¡Œæ—¶çš„ç¤ºä¾‹"""
    print("ğŸš€ Canvaså­¦ä¹ ç³»ç»Ÿ v2.0 - å¤šAgentå¹¶å‘åˆ†æç³»ç»Ÿ")
    print("=" * 60)

    # æ£€æŸ¥ä¾èµ–
    if not AIOMULTIPROCESS_AVAILABLE:
        print("âš ï¸  å»ºè®®å®‰è£… aiomultiprocess ä»¥è·å¾—æœ€ä½³æ€§èƒ½:")
        print("   pip install aiomultiprocess")

    if not PSUTIL_AVAILABLE:
        print("âš ï¸  å»ºè®®å®‰è£… psutil ä»¥å¯ç”¨æ€§èƒ½ç›‘æ§:")
        print("   pip install psutil")

    print("\nğŸ“– ä½¿ç”¨æ–¹æ³•:")
    print("1. å¯¼å…¥: from concurrent_canvas_system import ConcurrentCanvasOrchestrator")
    print("2. åˆ›å»º: orchestrator = ConcurrentCanvasOrchestrator(canvas_path)")
    print("3. åˆå§‹åŒ–: await orchestrator.initialize()")
    print("4. åˆ†æ: await orchestrator.concurrent_analyze_yellow_nodes(...)")

    # è¿è¡Œç¤ºä¾‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
    run_example = input("\næ˜¯å¦è¿è¡Œç¤ºä¾‹? (y/N): ").lower().strip()
    if run_example == 'y':
        asyncio.run(example_usage())

    print("\nâœ… ç³»ç»Ÿå°±ç»ª!")