"""
å¹¶è¡ŒAgentæ‰§è¡Œå™¨ - Canvaså­¦ä¹ ç³»ç»Ÿ

å®ç°åŸºäºasyncioå’Œaiomultiprocessçš„é«˜æ€§èƒ½å¹¶è¡ŒAgentå¤„ç†å¼•æ“ã€‚
æ”¯æŒ5-10ä¸ªAgentçš„å¹¶å‘æ‰§è¡Œï¼Œå…·å¤‡å®Œæ•´çš„ä¸Šä¸‹æ–‡éš”ç¦»ã€é”™è¯¯å¤„ç†å’Œæ€§èƒ½ç›‘æ§åŠŸèƒ½ã€‚

Author: Canvas Learning System Team
Version: 1.0
Created: 2025-01-22
Story: 8.14
"""

import asyncio
import json
import uuid
import time
import traceback
from datetime import datetime, timezone
from typing import Dict, List, Optional, Tuple, Any, Callable
from pathlib import Path
from dataclasses import dataclass, field, asdict
from enum import Enum
import yaml
import psutil
import os

# å¹¶è¡Œå¤„ç†ä¾èµ–
from aiomultiprocess import Process, Pool
from concurrent.futures import ProcessPoolExecutor
import multiprocessing as mp

# å†…éƒ¨æ¨¡å—
try:
    from canvas_utils import CanvasOrchestrator
except ImportError:
    from mock_canvas_orchestrator import MockCanvasOrchestrator as CanvasOrchestrator


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€æšä¸¾"""
    PENDING = "pending"
    QUEUED = "queued"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    TIMEOUT = "timeout"


class Priority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§æšä¸¾"""
    LOW = "low"
    NORMAL = "normal"
    HIGH = "high"
    URGENT = "urgent"


@dataclass
class TaskMetrics:
    """ä»»åŠ¡æ‰§è¡ŒæŒ‡æ ‡"""
    execution_id: str
    task_id: str
    agent_name: str
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    execution_duration_ms: Optional[float] = None

    # èµ„æºä½¿ç”¨
    memory_usage_mb: Optional[float] = None
    cpu_usage_percent: Optional[float] = None
    worker_process_id: Optional[int] = None

    # ç»“æœç»Ÿè®¡
    token_usage: Optional[Dict[str, int]] = None
    success: Optional[bool] = None
    error_message: Optional[str] = None
    retry_count: int = 0

    def calculate_duration(self) -> Optional[float]:
        """è®¡ç®—æ‰§è¡ŒæŒç»­æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"""
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time) * 1000
        return None


@dataclass
class AgentTask:
    """Agentä»»åŠ¡å®šä¹‰"""
    task_id: str = field(default_factory=lambda: f"task-{uuid.uuid4().hex[:16]}")
    execution_id: str = field(default_factory=lambda: f"exec-{uuid.uuid4().hex[:16]}")
    agent_name: str = ""
    canvas_path: str = ""
    input_data: Dict[str, Any] = field(default_factory=dict)
    priority: Priority = Priority.NORMAL
    timeout_seconds: int = 120
    retry_attempts: int = 3
    retry_delay_seconds: int = 5
    metadata: Dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        """åå¤„ç†éªŒè¯"""
        if not self.agent_name:
            raise ValueError("agent_name is required")
        if not self.canvas_path:
            raise ValueError("canvas_path is required")


@dataclass
class ExecutionSession:
    """æ‰§è¡Œä¼šè¯æ•°æ®æ¨¡å‹"""
    session_id: str = field(default_factory=lambda: f"session-{uuid.uuid4().hex[:16]}")
    task_id: str = ""
    execution_id: str = ""
    agent_name: str = ""
    status: TaskStatus = TaskStatus.PENDING
    submission_time: float = field(default_factory=lambda: time.time())
    start_time: Optional[float] = None
    completion_time: Optional[float] = None

    # ä»»åŠ¡å’Œç»“æœæ•°æ®
    input_data: Dict[str, Any] = field(default_factory=dict)
    execution_context: Dict[str, Any] = field(default_factory=dict)
    result: Dict[str, Any] = field(default_factory=dict)
    error_handling: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ParallelExecutionSummary:
    """å¹¶è¡Œæ‰§è¡Œæ€»ç»“æ•°æ®æ¨¡å‹"""
    execution_id: str
    submission_timestamp: str
    execution_mode: str
    max_concurrent_agents: int
    overall_status: str

    # ä»»åŠ¡é˜Ÿåˆ—ç»Ÿè®¡
    task_queue: Dict[str, int] = field(default_factory=dict)

    # Agentæ‰§è¡Œä¼šè¯åˆ—è¡¨
    agent_execution_sessions: List[ExecutionSession] = field(default_factory=list)

    # æ€§èƒ½æŒ‡æ ‡
    performance_metrics: Dict[str, Any] = field(default_factory=dict)

    # é”™è¯¯ç®¡ç†
    error_management: Dict[str, Any] = field(default_factory=dict)

    # ç»“æœèšåˆ
    result_aggregation: Dict[str, Any] = field(default_factory=dict)


class ContextIsolationManager:
    """ä¸Šä¸‹æ–‡éš”ç¦»ç®¡ç†å™¨

    è´Ÿè´£ç®¡ç†æ¯ä¸ªAgentçš„ç‹¬ç«‹æ‰§è¡Œä¸Šä¸‹æ–‡ï¼Œç¡®ä¿è¿›ç¨‹é—´å®Œå…¨éš”ç¦»ï¼Œ
    é¿å…ä¸Šä¸‹æ–‡å†²çªå’Œæ•°æ®æ··ä¹±ã€‚
    """

    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–ä¸Šä¸‹æ–‡éš”ç¦»ç®¡ç†å™¨

        Args:
            config: ä¸Šä¸‹æ–‡éš”ç¦»é…ç½®
        """
        self.config = config
        self.active_contexts: Dict[str, Dict] = {}
        self.context_cleanup_enabled = config.get("context_cleanup_enabled", True)

    async def create_isolated_context(self, task: AgentTask) -> Dict[str, Any]:
        """ä¸ºä»»åŠ¡åˆ›å»ºéš”ç¦»çš„æ‰§è¡Œä¸Šä¸‹æ–‡

        Args:
            task: Agentä»»åŠ¡

        Returns:
            Dict: éš”ç¦»ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        context_id = f"ctx-{task.task_id}"

        # ç”Ÿæˆç‹¬ç«‹ä¸Šä¸‹æ–‡é…ç½®
        context = {
            "context_id": context_id,
            "task_id": task.task_id,
            "agent_name": task.agent_name,
            "isolation_level": self.config.get("isolation_level", "process"),
            "size_tokens": self.config.get("context_size_limit_mb", 256) * 4,  # ä¼°ç®—tokenæ•°
            "memory_limit_mb": self.config.get("max_memory_per_agent_mb", 256),
            "creation_time": time.time()
        }

        # è·å–ç³»ç»Ÿèµ„æºä¿¡æ¯
        context.update({
            "worker_process_id": os.getpid(),
            "available_memory_mb": psutil.virtual_memory().available / 1024 / 1024,
            "cpu_count": psutil.cpu_count()
        })

        self.active_contexts[context_id] = context
        return context

    async def cleanup_context(self, context_id: str) -> bool:
        """æ¸…ç†æŒ‡å®šçš„æ‰§è¡Œä¸Šä¸‹æ–‡

        Args:
            context_id: ä¸Šä¸‹æ–‡ID

        Returns:
            bool: æ¸…ç†æ˜¯å¦æˆåŠŸ
        """
        if context_id in self.active_contexts:
            # æ‰§è¡Œä¸Šä¸‹æ–‡æ¸…ç†é€»è¾‘
            context = self.active_contexts[context_id]

            # è®°å½•æ¸…ç†æ—¶é—´å’Œèµ„æºé‡Šæ”¾
            context["cleanup_time"] = time.time()
            context["cleanup_success"] = True

            del self.active_contexts[context_id]
            return True
        return False

    async def get_context_usage(self, context_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¸Šä¸‹æ–‡ä½¿ç”¨æƒ…å†µ

        Args:
            context_id: ä¸Šä¸‹æ–‡ID

        Returns:
            Optional[Dict]: ä¸Šä¸‹æ–‡ä½¿ç”¨ä¿¡æ¯
        """
        if context_id not in self.active_contexts:
            return None

        context = self.active_contexts[context_id]
        process = psutil.Process()

        return {
            "context_id": context_id,
            "memory_usage_mb": process.memory_info().rss / 1024 / 1024,
            "cpu_usage_percent": process.cpu_percent(),
            "num_threads": process.num_threads(),
            "creation_time": context.get("creation_time"),
            "runtime_seconds": time.time() - context.get("creation_time", time.time())
        }


class TaskQueueManager:
    """ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨

    è´Ÿè´£ä»»åŠ¡åˆ†å‘ã€ä¼˜å…ˆçº§è°ƒåº¦ã€è´Ÿè½½å‡è¡¡å’Œè¿›åº¦ç›‘æ§ã€‚
    æ”¯æŒå¤šç§é˜Ÿåˆ—ç­–ç•¥å’Œæ™ºèƒ½ä»»åŠ¡åˆ†å‘ç®—æ³•ã€‚
    """

    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨

        Args:
            config: é˜Ÿåˆ—é…ç½®
        """
        self.config = config
        self.queue_type = config.get("queue_type", "priority")
        self.max_queue_size = config.get("max_queue_size", 1000)

        # ä¼˜å…ˆçº§é˜Ÿåˆ—
        self.queues: Dict[Priority, asyncio.Queue] = {
            Priority.URGENT: asyncio.Queue(),
            Priority.HIGH: asyncio.Queue(),
            Priority.NORMAL: asyncio.Queue(),
            Priority.LOW: asyncio.Queue()
        }

        # ä»»åŠ¡ç»Ÿè®¡
        self.task_stats = {
            "total_tasks": 0,
            "pending_tasks": 0,
            "running_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "cancelled_tasks": 0
        }

        # è¿è¡Œä¸­çš„ä»»åŠ¡
        self.running_tasks: Dict[str, AgentTask] = {}

        # é”
        self._stats_lock = asyncio.Lock()

    async def submit_task(self, task: AgentTask) -> bool:
        """æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—

        Args:
            task: Agentä»»åŠ¡

        Returns:
            bool: æäº¤æ˜¯å¦æˆåŠŸ
        """
        async with self._stats_lock:
            total_queued = sum(q.qsize() for q in self.queues.values())
            if total_queued >= self.max_queue_size:
                return False

            # æ ¹æ®ä¼˜å…ˆçº§å…¥é˜Ÿ
            await self.queues[task.priority].put(task)

            # æ›´æ–°ç»Ÿè®¡
            self.task_stats["total_tasks"] += 1
            self.task_stats["pending_tasks"] += 1

            return True

    async def get_next_task(self) -> Optional[AgentTask]:
        """è·å–ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰

        Returns:
            Optional[AgentTask]: ä¸‹ä¸€ä¸ªä»»åŠ¡
        """
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥é˜Ÿåˆ—
        priority_order = [Priority.URGENT, Priority.HIGH, Priority.NORMAL, Priority.LOW]

        for priority in priority_order:
            try:
                # ä½¿ç”¨éé˜»å¡æ–¹å¼è·å–ä»»åŠ¡
                task = self.queues[priority].get_nowait()

                async with self._stats_lock:
                    self.task_stats["pending_tasks"] -= 1
                    self.task_stats["running_tasks"] += 1
                    self.running_tasks[task.task_id] = task

                return task
            except asyncio.QueueEmpty:
                continue

        return None

    async def complete_task(self, task_id: str, success: bool = True) -> None:
        """æ ‡è®°ä»»åŠ¡å®Œæˆ

        Args:
            task_id: ä»»åŠ¡ID
            success: æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        async with self._stats_lock:
            if task_id in self.running_tasks:
                del self.running_tasks[task_id]
                self.task_stats["running_tasks"] -= 1

                if success:
                    self.task_stats["completed_tasks"] += 1
                else:
                    self.task_stats["failed_tasks"] += 1

    async def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            bool: å–æ¶ˆæ˜¯å¦æˆåŠŸ
        """
        # ä»è¿è¡Œä¸­ä»»åŠ¡ä¸­ç§»é™¤
        async with self._stats_lock:
            if task_id in self.running_tasks:
                del self.running_tasks[task_id]
                self.task_stats["running_tasks"] -= 1
                self.task_stats["cancelled_tasks"] += 1
                return True

        return False

    async def get_queue_status(self) -> Dict[str, Any]:
        """è·å–é˜Ÿåˆ—çŠ¶æ€

        Returns:
            Dict: é˜Ÿåˆ—çŠ¶æ€ä¿¡æ¯
        """
        queue_sizes = {
            priority.name.lower(): queue.qsize()
            for priority, queue in self.queues.items()
        }

        async with self._stats_lock:
            return {
                **queue_sizes,
                **self.task_stats.copy(),
                "queue_capacity_utilization": sum(queue_sizes.values()) / self.max_queue_size
            }


class ParallelAgentExecutor:
    """å¹¶è¡ŒAgentæ‰§è¡Œå™¨ä¸»ç±»

    å®ç°åŸºäºContext7éªŒè¯çš„aiomultiprocessæŠ€æœ¯çš„é«˜æ€§èƒ½å¹¶è¡ŒAgentå¤„ç†å¼•æ“ã€‚
    æ”¯æŒå®Œæ•´çš„ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€ä¸Šä¸‹æ–‡éš”ç¦»ã€é”™è¯¯å¤„ç†å’Œæ€§èƒ½ç›‘æ§ã€‚
    """

    def __init__(self, config_path: str = "config/parallel_agents.yaml"):
        """åˆå§‹åŒ–å¹¶è¡ŒAgentæ‰§è¡Œå™¨

        Args:
            config_path: å¹¶è¡Œå¤„ç†é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = Path(config_path)
        self.config = self._load_config()

        # åˆå§‹åŒ–ç»„ä»¶
        self.context_manager = ContextIsolationManager(
            self.config.get("context_isolation", {})
        )
        self.queue_manager = TaskQueueManager(
            self.config.get("task_queue", {})
        )

        # æ‰§è¡ŒçŠ¶æ€
        self.executions: Dict[str, ParallelExecutionSummary] = {}
        self.active_workers: Dict[str, Process] = {}

        # æ€§èƒ½ç›‘æ§
        self.metrics: Dict[str, Any] = {
            "total_executions": 0,
            "successful_executions": 0,
            "failed_executions": 0,
            "total_tasks_processed": 0,
            "average_execution_time_ms": 0.0
        }

        # è¿›ç¨‹æ± 
        self.process_pool: Optional[Pool] = None
        self.max_concurrent = self.config.get(
            "parallel_processing", {}
        ).get("default_max_concurrent", 8)

        # äº‹ä»¶å¾ªç¯
        self.loop = asyncio.get_event_loop()
        self._shutdown_event = asyncio.Event()

    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶

        Returns:
            Dict: é…ç½®æ•°æ®
        """
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            # è¿”å›é»˜è®¤é…ç½®
            return self._get_default_config()
        except yaml.YAMLError as e:
            raise ValueError(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")

    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®

        Returns:
            Dict: é»˜è®¤é…ç½®
        """
        return {
            "parallel_processing": {
                "default_max_concurrent": 8,
                "max_concurrent_limit": 10
            },
            "context_isolation": {
                "isolation_level": "process",
                "context_size_limit_mb": 256,
                "context_cleanup_enabled": True
            },
            "task_queue": {
                "queue_type": "priority",
                "max_queue_size": 1000,
                "task_retry_attempts": 3
            },
            "error_handling": {
                "continue_on_error": True,
                "error_isolation": True,
                "fallback_strategy": "retry"
            }
        }

    async def initialize(self) -> None:
        """åˆå§‹åŒ–æ‰§è¡Œå™¨

        è®¾ç½®è¿›ç¨‹æ± å’Œå¼‚æ­¥ä»»åŠ¡è°ƒåº¦å™¨ã€‚
        """
        # åˆå§‹åŒ–è¿›ç¨‹æ± 
        pool_config = self.config.get("process_pool", {})
        max_workers = pool_config.get("worker_processes", self.max_concurrent)

        self.process_pool = Pool(
            processes=max_workers,
            queue=pool_config.get("task_queue_size", 1000)
        )

        # å¯åŠ¨å·¥ä½œåç¨‹
        asyncio.create_task(self._worker_scheduler())

    async def submit_batch_tasks(self, tasks: List[Dict], max_concurrent: Optional[int] = None) -> str:
        """æäº¤æ‰¹é‡ä»»åŠ¡åˆ°å¹¶è¡Œå¤„ç†é˜Ÿåˆ—

        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å«agent_name, canvas_path, input_dataç­‰
            max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ŒNoneä½¿ç”¨é»˜è®¤é…ç½®

        Returns:
            str: æ‰§è¡ŒID
        """
        # åˆ›å»ºæ‰§è¡ŒID
        execution_id = f"exec-{uuid.uuid4().hex[:16]}"

        # åˆ›å»ºä»»åŠ¡å¯¹è±¡
        agent_tasks = []
        for task_data in tasks:
            try:
                task = AgentTask(
                    agent_name=task_data.get("agent_name", ""),
                    canvas_path=task_data.get("canvas_path", ""),
                    input_data=task_data.get("input_data", {}),
                    priority=Priority(task_data.get("priority", "normal")),
                    timeout_seconds=task_data.get("timeout_seconds", 120),
                    execution_id=execution_id
                )
                agent_tasks.append(task)
            except (ValueError, KeyError) as e:
                # è®°å½•æ— æ•ˆä»»åŠ¡
                print(f"æ— æ•ˆä»»åŠ¡æ•°æ®: {task_data}, é”™è¯¯: {e}")
                continue

        # åˆ›å»ºæ‰§è¡Œæ€»ç»“
        summary = ParallelExecutionSummary(
            execution_id=execution_id,
            submission_timestamp=datetime.now(timezone.utc).isoformat(),
            execution_mode="parallel_batch",
            max_concurrent_agents=max_concurrent or self.max_concurrent,
            overall_status="running"
        )

        # è®¾ç½®ä»»åŠ¡é˜Ÿåˆ—ç»Ÿè®¡
        summary.task_queue = {
            "total_tasks": len(agent_tasks),
            "pending_tasks": len(agent_tasks),
            "running_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "queue_priority": "normal"
        }

        self.executions[execution_id] = summary

        # æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—
        for task in agent_tasks:
            await self.queue_manager.submit_task(task)

        # æ›´æ–°å…¨å±€æŒ‡æ ‡
        self.metrics["total_executions"] += 1
        self.metrics["total_tasks_processed"] += len(agent_tasks)

        return execution_id

    async def get_execution_status(self, execution_id: str) -> Dict:
        """è·å–æ‰§è¡ŒçŠ¶æ€

        Args:
            execution_id: æ‰§è¡ŒID

        Returns:
            Dict: æ‰§è¡ŒçŠ¶æ€ä¿¡æ¯
        """
        if execution_id not in self.executions:
            return {"error": "æ‰§è¡ŒIDä¸å­˜åœ¨"}

        summary = self.executions[execution_id]
        queue_status = await self.queue_manager.get_queue_status()

        return {
            "execution_id": execution_id,
            "overall_status": summary.overall_status,
            "submission_timestamp": summary.submission_timestamp,
            "task_queue": {
                **summary.task_queue,
                **queue_status
            },
            "performance_metrics": summary.performance_metrics,
            "error_management": summary.error_management
        }

    async def get_execution_results(self, execution_id: str) -> Dict:
        """è·å–æ‰§è¡Œç»“æœ

        Args:
            execution_id: æ‰§è¡ŒID

        Returns:
            Dict: èšåˆçš„æ‰§è¡Œç»“æœ
        """
        if execution_id not in self.executions:
            return {"error": "æ‰§è¡ŒIDä¸å­˜åœ¨"}

        summary = self.executions[execution_id]

        return {
            "execution_id": execution_id,
            "status": summary.overall_status,
            "agent_execution_sessions": [asdict(session) for session in summary.agent_execution_sessions],
            "performance_metrics": summary.performance_metrics,
            "result_aggregation": summary.result_aggregation,
            "error_management": summary.error_management
        }

    async def cancel_execution(self, execution_id: str) -> bool:
        """å–æ¶ˆæ‰§è¡Œ

        Args:
            execution_id: æ‰§è¡ŒID

        Returns:
            bool: å–æ¶ˆæ˜¯å¦æˆåŠŸ
        """
        if execution_id not in self.executions:
            return False

        # æ›´æ–°æ‰§è¡ŒçŠ¶æ€
        summary = self.executions[execution_id]
        summary.overall_status = "cancelled"

        # å–æ¶ˆæ‰€æœ‰ç›¸å…³ä»»åŠ¡
        # è¿™é‡Œéœ€è¦å®ç°å…·ä½“çš„ä»»åŠ¡å–æ¶ˆé€»è¾‘

        return True

    def get_performance_metrics(self, execution_id: str) -> Dict:
        """è·å–æ€§èƒ½æŒ‡æ ‡

        Args:
            execution_id: æ‰§è¡ŒID

        Returns:
            Dict: æ€§èƒ½æŒ‡æ ‡æ•°æ®
        """
        if execution_id not in self.executions:
            return {"error": "æ‰§è¡ŒIDä¸å­˜åœ¨"}

        summary = self.executions[execution_id]

        # è®¡ç®—å¹¶è¡Œæ•ˆç‡
        parallel_efficiency = self._calculate_parallel_efficiency(summary)

        return {
            "execution_id": execution_id,
            "parallel_efficiency": parallel_efficiency,
            "resource_usage": summary.performance_metrics.get("resource_usage", {}),
            "throughput": summary.performance_metrics.get("throughput", {}),
            "global_metrics": self.metrics.copy()
        }

    def configure_parallel_settings(self, settings: Dict) -> bool:
        """é…ç½®å¹¶è¡Œå¤„ç†è®¾ç½®

        Args:
            settings: å¹¶è¡Œè®¾ç½®é…ç½®

        Returns:
            bool: é…ç½®æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ›´æ–°é…ç½®
            for key, value in settings.items():
                if key in self.config:
                    self.config[key].update(value)

            # é‡æ–°åˆå§‹åŒ–ç›¸å…³ç»„ä»¶
            self.queue_manager = TaskQueueManager(
                self.config.get("task_queue", {})
            )

            return True
        except Exception as e:
            print(f"é…ç½®æ›´æ–°å¤±è´¥: {e}")
            return False

    async def _worker_scheduler(self) -> None:
        """å·¥ä½œè°ƒåº¦å™¨åç¨‹

        æŒç»­ä»é˜Ÿåˆ—ä¸­è·å–ä»»åŠ¡å¹¶åˆ†é…ç»™å·¥ä½œè¿›ç¨‹æ‰§è¡Œã€‚
        """
        while not self._shutdown_event.is_set():
            try:
                # è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡
                task = await self.queue_manager.get_next_task()
                if task:
                    # åˆ›å»ºå·¥ä½œè¿›ç¨‹æ‰§è¡Œä»»åŠ¡
                    await self._execute_task(task)
                else:
                    # æ²¡æœ‰ä»»åŠ¡æ—¶çŸ­æš‚ç­‰å¾…
                    await asyncio.sleep(0.1)
            except Exception as e:
                print(f"å·¥ä½œè°ƒåº¦å™¨é”™è¯¯: {e}")
                await asyncio.sleep(1)

    async def _execute_task(self, task: AgentTask) -> None:
        """æ‰§è¡Œå•ä¸ªAgentä»»åŠ¡

        Args:
            task: Agentä»»åŠ¡
        """
        session = ExecutionSession(
            task_id=task.task_id,
            execution_id=task.execution_id,
            agent_name=task.agent_name,
            status=TaskStatus.RUNNING,
            input_data=task.input_data,
            start_time=time.time()
        )

        # åˆ›å»ºéš”ç¦»ä¸Šä¸‹æ–‡
        context = await self.context_manager.create_isolated_context(task)
        session.execution_context = context

        try:
            # æ‰§è¡ŒAgentä»»åŠ¡
            result = await self._run_agent_in_process(task, context)

            # æ›´æ–°ä¼šè¯ç»“æœ
            session.result = result
            session.status = TaskStatus.COMPLETED
            session.completion_time = time.time()

            # æ ‡è®°ä»»åŠ¡å®Œæˆ
            await self.queue_manager.complete_task(task.task_id, success=True)

        except asyncio.TimeoutError:
            session.status = TaskStatus.TIMEOUT
            session.error_handling = {
                "error_message": f"ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ ({task.timeout_seconds}s)",
                "retry_count": 0,
                "max_retries": task.retry_attempts
            }
            await self.queue_manager.complete_task(task.task_id, success=False)

        except Exception as e:
            session.status = TaskStatus.FAILED
            session.error_handling = {
                "error_message": str(e),
                "traceback": traceback.format_exc(),
                "retry_count": 0,
                "max_retries": task.retry_attempts
            }
            await self.queue_manager.complete_task(task.task_id, success=False)

        # æ›´æ–°æ‰§è¡Œæ€»ç»“
        if task.execution_id in self.executions:
            self.executions[task.execution_id].agent_execution_sessions.append(session)

        # æ¸…ç†ä¸Šä¸‹æ–‡
        await self.context_manager.cleanup_context(context["context_id"])

    async def _run_agent_in_process(self, task: AgentTask, context: Dict[str, Any]) -> Dict[str, Any]:
        """åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­è¿è¡ŒAgent

        Args:
            task: Agentä»»åŠ¡
            context: éš”ç¦»ä¸Šä¸‹æ–‡

        Returns:
            Dict: Agentæ‰§è¡Œç»“æœ
        """
        # è¿™é‡Œä½¿ç”¨è¶…æ—¶åŒ…è£…å™¨æ‰§è¡Œä»»åŠ¡
        try:
            # ä½¿ç”¨asyncio.wait_forå®ç°è¶…æ—¶æ§åˆ¶
            result = await asyncio.wait_for(
                self._execute_agent_logic(task, context),
                timeout=task.timeout_seconds
            )
            return result
        except asyncio.TimeoutError:
            raise
        except Exception as e:
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾›ä¸Šå±‚å¤„ç†
            raise e

    async def _execute_agent_logic(self, task: AgentTask, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå…·ä½“çš„Agenté€»è¾‘

        Args:
            task: Agentä»»åŠ¡
            context: éš”ç¦»ä¸Šä¸‹æ–‡

        Returns:
            Dict: æ‰§è¡Œç»“æœ
        """
        # æ ¹æ®agent_nameè°ƒç”¨ç›¸åº”çš„Agenté€»è¾‘
        if task.agent_name == "basic-decomposition":
            return await self._execute_basic_decomposition(task)
        elif task.agent_name == "oral-explanation":
            return await self._execute_oral_explanation(task)
        elif task.agent_name == "scoring-agent":
            return await self._execute_scoring_agent(task)
        # å…¶ä»–Agentç±»å‹çš„å®ç°...
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„Agentç±»å‹: {task.agent_name}")

    async def _execute_basic_decomposition(self, task: AgentTask) -> Dict[str, Any]:
        """æ‰§è¡ŒåŸºç¡€æ‹†è§£Agent

        Args:
            task: Agentä»»åŠ¡

        Returns:
            Dict: æ‰§è¡Œç»“æœ
        """
        # æ¨¡æ‹ŸAgentæ‰§è¡Œ
        await asyncio.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„basic-decomposition Agent
        # ä¸ºäº†æ¼”ç¤ºï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ
        return {
            "status": "success",
            "output_data": {
                "sub_questions": [
                    {
                        "text": f"åŸºç¡€æ‹†è§£é—®é¢˜1 - {task.input_data.get('material_text', '')[:20]}...",
                        "type": "definition_type",
                        "difficulty": "basic",
                        "guidance": "ğŸ’¡ æç¤ºï¼šä»å®šä¹‰å¼€å§‹æ€è€ƒ"
                    }
                ],
                "total_count": 3,
                "has_guidance": True
            },
            "performance_metrics": {
                "generation_time_ms": 1500,
                "token_usage": {
                    "input_tokens": 256,
                    "output_tokens": 189,
                    "total_tokens": 445
                }
            }
        }

    async def _execute_oral_explanation(self, task: AgentTask) -> Dict[str, Any]:
        """æ‰§è¡Œå£è¯­åŒ–è§£é‡ŠAgent

        Args:
            task: Agentä»»åŠ¡

        Returns:
            Dict: æ‰§è¡Œç»“æœ
        """
        # æ¨¡æ‹ŸAgentæ‰§è¡Œ
        await asyncio.sleep(2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

        return {
            "status": "success",
            "output_data": {
                "explanation_text": f"è¿™æ˜¯å…³äº{task.input_data.get('concept', '')}çš„å£è¯­åŒ–è§£é‡Š...",
                "word_count": 1200,
                "structure_complete": True
            },
            "performance_metrics": {
                "generation_time_ms": 2000,
                "token_usage": {
                    "input_tokens": 300,
                    "output_tokens": 800,
                    "total_tokens": 1100
                }
            }
        }

    async def _execute_scoring_agent(self, task: AgentTask) -> Dict[str, Any]:
        """æ‰§è¡Œè¯„åˆ†Agent

        Args:
            task: Agentä»»åŠ¡

        Returns:
            Dict: æ‰§è¡Œç»“æœ
        """
        # æ¨¡æ‹ŸAgentæ‰§è¡Œ
        await asyncio.sleep(0.8)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

        return {
            "status": "success",
            "output_data": {
                "score_breakdown": {
                    "accuracy": 22,
                    "imagery": 18,
                    "completeness": 20,
                    "originality": 15
                },
                "total_score": 75,
                "color_transition": "purple",
                "recommendations": ["clarification-path", "oral-explanation"]
            },
            "performance_metrics": {
                "generation_time_ms": 800,
                "token_usage": {
                    "input_tokens": 150,
                    "output_tokens": 100,
                    "total_tokens": 250
                }
            }
        }

    def _calculate_parallel_efficiency(self, summary: ParallelExecutionSummary) -> Dict[str, Any]:
        """è®¡ç®—å¹¶è¡Œæ•ˆç‡æŒ‡æ ‡

        Args:
            summary: æ‰§è¡Œæ€»ç»“

        Returns:
            Dict: å¹¶è¡Œæ•ˆç‡æŒ‡æ ‡
        """
        sessions = summary.agent_execution_sessions

        if not sessions:
            return {
                "total_execution_time_ms": 0,
                "estimated_serial_time_ms": 0,
                "efficiency_ratio": 0,
                "concurrency_utilization": 0
            }

        # è®¡ç®—æ€»æ‰§è¡Œæ—¶é—´
        start_times = [s.start_time for s in sessions if s.start_time]
        end_times = [s.completion_time for s in sessions if s.completion_time]

        if not start_times or not end_times:
            return {
                "total_execution_time_ms": 0,
                "estimated_serial_time_ms": 0,
                "efficiency_ratio": 0,
                "concurrency_utilization": 0
            }

        total_execution_time = (max(end_times) - min(start_times)) * 1000

        # ä¼°ç®—ä¸²è¡Œæ‰§è¡Œæ—¶é—´
        total_processing_time = sum(
            (s.completion_time - s.start_time) * 1000
            for s in sessions
            if s.start_time and s.completion_time
        )

        # è®¡ç®—æ•ˆç‡æ¯”ç‡
        efficiency_ratio = total_processing_time / total_execution_time if total_execution_time > 0 else 0

        # è®¡ç®—å¹¶å‘åˆ©ç”¨ç‡
        max_concurrent = summary.max_concurrent_agents
        concurrency_utilization = min(1.0, len(sessions) / max_concurrent) if max_concurrent > 0 else 0

        return {
            "total_execution_time_ms": total_execution_time,
            "estimated_serial_time_ms": total_processing_time,
            "efficiency_ratio": round(efficiency_ratio, 2),
            "concurrency_utilization": round(concurrency_utilization, 2)
        }

    async def shutdown(self) -> None:
        """å…³é—­æ‰§è¡Œå™¨

        æ¸…ç†èµ„æºå¹¶ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚
        """
        # è®¾ç½®å…³é—­æ ‡å¿—
        self._shutdown_event.set()

        # ç­‰å¾…è¿›ç¨‹æ± å…³é—­
        if self.process_pool:
            self.process_pool.close()
            await self.process_pool.join()

        # æ¸…ç†æ‰€æœ‰æ´»è·ƒä¸Šä¸‹æ–‡
        for context_id in list(self.context_manager.active_contexts.keys()):
            await self.context_manager.cleanup_context(context_id)