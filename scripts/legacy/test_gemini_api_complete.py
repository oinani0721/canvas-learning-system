#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„Gemini APIæµ‹è¯•è„šæœ¬

æµ‹è¯•Gemini APIçš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. APIè¿æ¥æµ‹è¯•
2. æ–‡æœ¬ç”ŸæˆåŠŸèƒ½
3. æ¦‚å¿µåˆ†æåŠŸèƒ½
4. æˆæœ¬æ•ˆç›ŠéªŒè¯
5. ä¸GraphitiçŸ¥è¯†å›¾è°±é›†æˆ

Author: Canvas Learning System Team
Version: 1.0
Created: 2025-10-26
"""

import asyncio
import json
import sys
import time
from pathlib import Path
from typing import Dict, List, Any
import httpx
from datetime import datetime

# Gemini APIé…ç½®
GEMINI_CONFIG = {
    "api_key": "sk-Bu198hR8AgONygQQnVfWeZ2cS4lzryBgN0pSRubmSurAK4IF",
    "base_url": "https://binapi.shop/v1",
    "model": "gemini-2.5-flash",
    "temperature": 0.7,
    "max_tokens": 4096
}

class GeminiAPITester:
    """Gemini APIå®Œæ•´æµ‹è¯•å™¨"""

    def __init__(self):
        self.config = GEMINI_CONFIG
        self.client = None
        self.test_results = []

    async def setup_client(self):
        """è®¾ç½®HTTPå®¢æˆ·ç«¯"""
        self.client = httpx.AsyncClient(
            base_url=self.config["base_url"],
            timeout=60.0,
            headers={
                "Authorization": f"Bearer {self.config['api_key']}",
                "Content-Type": "application/json",
                "Accept": "application/json"
            }
        )

    async def cleanup_client(self):
        """æ¸…ç†HTTPå®¢æˆ·ç«¯"""
        if self.client:
            await self.client.aclose()

    def log_test(self, test_name: str, success: bool, details: str = ""):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        self.test_results.append({
            "test": test_name,
            "success": success,
            "details": details,
            "timestamp": datetime.now().isoformat()
        })
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} {test_name}")
        if details:
            print(f"    {details}")

    async def test_1_api_connection(self) -> bool:
        """æµ‹è¯•1: APIè¿æ¥æµ‹è¯•"""
        print("\n=== Test 1: API Connection ===")
        try:
            await self.setup_client()

            # ç®€å•çš„å¥åº·æ£€æŸ¥
            response = await self.client.get("/models")

            if response.status_code == 200:
                self.log_test("API Connection", True, f"Status: {response.status_code}")
                return True
            else:
                self.log_test("API Connection", False, f"HTTP {response.status_code}: {response.text[:100]}")
                return False

        except Exception as e:
            self.log_test("API Connection", False, f"Exception: {str(e)}")
            return False

    async def test_2_text_generation(self) -> bool:
        """æµ‹è¯•2: æ–‡æœ¬ç”ŸæˆåŠŸèƒ½"""
        print("\n=== Test 2: Text Generation ===")
        try:
            payload = {
                "model": self.config["model"],
                "messages": [
                    {
                        "role": "user",
                        "content": "è¯·ç®€å•å›ç­”ï¼šä»€ä¹ˆæ˜¯ç¦»æ•£æ•°å­¦ï¼Ÿè¯·ç”¨ä¸€å¥è¯æ¦‚æ‹¬ã€‚"
                    }
                ],
                "temperature": self.config["temperature"],
                "max_tokens": 200
            }

            start_time = time.time()
            response = await self.client.post("/chat/completions", json=payload)
            end_time = time.time()

            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                duration = end_time - start_time

                self.log_test("Text Generation", True,
                            f"Response: {len(content)} chars, Time: {duration:.2f}s")
                print(f"    Content preview: {content[:100]}...")
                return True
            else:
                self.log_test("Text Generation", False, f"HTTP {response.status_code}")
                return False

        except Exception as e:
            self.log_test("Text Generation", False, f"Exception: {str(e)}")
            return False

    async def test_3_concept_analysis(self) -> bool:
        """æµ‹è¯•3: æ¦‚å¿µåˆ†æåŠŸèƒ½"""
        print("\n=== Test 3: Concept Analysis ===")
        try:
            test_text = """
            CS70ç¦»æ•£æ•°å­¦æ ¸å¿ƒæ¦‚å¿µï¼š

            1. å‘½é¢˜é€»è¾‘ (Propositional Logic)
            - å®šä¹‰ï¼šç ”ç©¶å‘½é¢˜çœŸå‡æ€§çš„æ•°å­¦åˆ†æ”¯
            - åŸºæœ¬è¿æ¥è¯ï¼šä¸(AND)ã€æˆ–(OR)ã€é(NOT)ã€è•´å«(IMPLIES)
            - é‡è¦æ€§è´¨ï¼šäº¤æ¢å¾‹ã€ç»“åˆå¾‹ã€åˆ†é…å¾‹

            2. é€†å¦å‘½é¢˜ (Contrapositive)
            - å®šä¹‰ï¼šå‘½é¢˜Pâ†’Qçš„é€†å¦å‘½é¢˜æ˜¯Â¬Qâ†’Â¬P
            - æ€§è´¨ï¼šåŸå‘½é¢˜ä¸é€†å¦å‘½é¢˜é€»è¾‘ç­‰ä»·
            - åº”ç”¨ï¼šè¯æ˜ä¸­çš„é—´æ¥è¯æ˜æ³•

            3. é¸½ç¬¼åŸç† (Pigeonhole Principle)
            - å®šä¹‰ï¼šnä¸ªç‰©å“æ”¾å…¥mä¸ªå®¹å™¨ï¼Œå¦‚æœn>mï¼Œåˆ™è‡³å°‘ä¸€ä¸ªå®¹å™¨æœ‰å¤šä¸ªç‰©å“
            - åº”ç”¨ï¼šå­˜åœ¨æ€§è¯æ˜
            """

            analysis_prompt = f"""
            è¯·åˆ†æä»¥ä¸‹å­¦ä¹ å†…å®¹ï¼Œæå–å…³é”®æ¦‚å¿µå’Œå…³ç³»ï¼š

            {test_text}

            è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
            {{
                "concepts": [
                    {{"name": "æ¦‚å¿µå", "definition": "å®šä¹‰", "importance": 1-5}}
                ],
                "relationships": [
                    {{"source": "æ¦‚å¿µ1", "target": "æ¦‚å¿µ2", "type": "å…³ç³»ç±»å‹"}}
                ]
            }}
            """

            payload = {
                "model": self.config["model"],
                "messages": [
                    {
                        "role": "user",
                        "content": analysis_prompt
                    }
                ],
                "temperature": 0.3,
                "max_tokens": 1000
            }

            start_time = time.time()
            response = await self.client.post("/chat/completions", json=payload)
            end_time = time.time()

            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                duration = end_time - start_time

                # å°è¯•è§£æJSON
                try:
                    analysis_result = json.loads(content)
                    concepts_count = len(analysis_result.get("concepts", []))
                    relationships_count = len(analysis_result.get("relationships", []))

                    self.log_test("Concept Analysis", True,
                                f"Concepts: {concepts_count}, Relationships: {relationships_count}, Time: {duration:.2f}s")

                    # æ˜¾ç¤ºæå–çš„æ¦‚å¿µ
                    concepts = analysis_result.get("concepts", [])
                    for i, concept in enumerate(concepts[:3]):
                        print(f"    Concept {i+1}: {concept.get('name', 'Unknown')}")

                    return True

                except json.JSONDecodeError:
                    self.log_test("Concept Analysis", False, "Failed to parse JSON response")
                    return False

            else:
                self.log_test("Concept Analysis", False, f"HTTP {response.status_code}")
                return False

        except Exception as e:
            self.log_test("Concept Analysis", False, f"Exception: {str(e)}")
            return False

    async def test_4_cost_analysis(self) -> bool:
        """æµ‹è¯•4: æˆæœ¬æ•ˆç›Šåˆ†æ"""
        print("\n=== Test 4: Cost Effectiveness Analysis ===")
        try:
            test_prompts = [
                "ç®€å•é—®é¢˜ï¼š1+1ç­‰äºå‡ ï¼Ÿ",
                "ä¸­ç­‰é—®é¢˜ï¼šè§£é‡Šä»€ä¹ˆæ˜¯å‡½æ•°ï¼Ÿ",
                "å¤æ‚é—®é¢˜ï¼šåˆ†æå‘½é¢˜é€»è¾‘ä¸å¸ƒå°”ä»£æ•°çš„å…³ç³»åŠå…¶åœ¨è®¡ç®—æœºç§‘å­¦ä¸­çš„åº”ç”¨"
            ]

            total_time = 0
            total_tokens = 0

            for i, prompt in enumerate(test_prompts):
                payload = {
                    "model": self.config["model"],
                    "messages": [
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "temperature": 0.7,
                    "max_tokens": 500
                }

                start_time = time.time()
                response = await self.client.post("/chat/completions", json=payload)
                end_time = time.time()

                if response.status_code == 200:
                    result = response.json()
                    content = result["choices"][0]["message"]["content"]
                    duration = end_time - start_time

                    total_time += duration
                    total_tokens += len(content.split())

                    print(f"    Test {i+1}: {len(content)} chars, {duration:.2f}s")

            # è®¡ç®—æˆæœ¬æ•ˆç›ŠæŒ‡æ ‡
            avg_time = total_time / len(test_prompts)

            # ä¼°ç®—æˆæœ¬ï¼ˆå‡è®¾ä»·æ ¼ï¼‰
            estimated_cost = total_tokens * 0.00001  # å‡è®¾æ¯token $0.00001

            self.log_test("Cost Analysis", True,
                        f"Avg time: {avg_time:.2f}s, Est. cost: ${estimated_cost:.6f}")
            return True

        except Exception as e:
            self.log_test("Cost Analysis", False, f"Exception: {str(e)}")
            return False

    async def test_5_error_handling(self) -> bool:
        """æµ‹è¯•5: é”™è¯¯å¤„ç†"""
        print("\n=== Test 5: Error Handling ===")
        try:
            # æµ‹è¯•æ— æ•ˆè¯·æ±‚
            invalid_payload = {
                "model": "invalid-model-name",
                "messages": []
            }

            response = await self.client.post("/chat/completions", json=invalid_payload)

            if response.status_code >= 400:
                self.log_test("Error Handling", True, f"Properly handles invalid requests (HTTP {response.status_code})")
                return True
            else:
                self.log_test("Error Handling", False, "Should have rejected invalid request")
                return False

        except Exception as e:
            self.log_test("Error Handling", True, f"Properly throws exceptions: {str(e)}")
            return True

    async def test_6_performance_benchmark(self) -> bool:
        """æµ‹è¯•6: æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("\n=== Test 6: Performance Benchmark ===")
        try:
            # å¹¶å‘è¯·æ±‚æµ‹è¯•
            concurrent_requests = 3
            tasks = []

            for i in range(concurrent_requests):
                payload = {
                    "model": self.config["model"],
                    "messages": [
                        {
                            "role": "user",
                            "content": f"è¯·ç”Ÿæˆç¬¬{i+1}ä¸ªCS70ç»ƒä¹ é¢˜ï¼šå…³äºå‘½é¢˜é€»è¾‘"
                        }
                    ],
                    "temperature": 0.7,
                    "max_tokens": 300
                }

                task = self.client.post("/chat/completions", json=payload)
                tasks.append(task)

            start_time = time.time()
            responses = await asyncio.gather(*tasks, return_exceptions=True)
            end_time = time.time()

            successful_responses = sum(1 for r in responses if hasattr(r, 'status_code') and r.status_code == 200)
            total_duration = end_time - start_time

            if successful_responses == concurrent_requests:
                self.log_test("Performance Benchmark", True,
                            f"{concurrent_requests} concurrent requests in {total_duration:.2f}s")
                return True
            else:
                self.log_test("Performance Benchmark", False,
                            f"Only {successful_responses}/{concurrent_requests} succeeded")
                return False

        except Exception as e:
            self.log_test("Performance Benchmark", False, f"Exception: {str(e)}")
            return False

    async def run_all_tests(self) -> bool:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ Starting Complete Gemini API Test Suite")
        print(f"ğŸ“… Test Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ”— API Endpoint: {self.config['base_url']}")
        print(f"ğŸ¤– Model: {self.config['model']}")
        print("=" * 60)

        tests = [
            ("API Connection", self.test_1_api_connection),
            ("Text Generation", self.test_2_text_generation),
            ("Concept Analysis", self.test_3_concept_analysis),
            ("Cost Analysis", self.test_4_cost_analysis),
            ("Error Handling", self.test_5_error_handling),
            ("Performance Benchmark", self.test_6_performance_benchmark)
        ]

        for test_name, test_func in tests:
            try:
                await test_func()
            except Exception as e:
                self.log_test(test_name, False, f"Test crashed: {str(e)}")

        # è¾“å‡ºæµ‹è¯•æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ“Š TEST RESULTS SUMMARY")
        print("=" * 60)

        passed_count = sum(1 for r in self.test_results if r["success"])
        total_count = len(self.test_results)

        for result in self.test_results:
            status = "âœ… PASS" if result["success"] else "âŒ FAIL"
            print(f"{status} {result['test']}")
            if result["details"]:
                print(f"      {result['details']}")

        print(f"\nğŸ“ˆ OVERALL: {passed_count}/{total_count} tests passed")

        if passed_count == total_count:
            print("\nğŸ‰ ALL TESTS PASSED!")
            print("âœ¨ Gemini API is fully functional and ready for use!")
            print("\nğŸ’¡ Key Features Verified:")
            print("   â€¢ API connectivity and authentication")
            print("   â€¢ Text generation with high quality responses")
            print("   â€¢ Concept analysis and knowledge extraction")
            print("   â€¢ Cost-effective performance")
            print("   â€¢ Robust error handling")
            print("   â€¢ Concurrent request capability")

            print("\nğŸš€ Ready for integration with:")
            print("   â€¢ Canvas Learning System")
            print("   â€¢ Graphiti Knowledge Graph")
            print("   â€¢ CS70 Learning Analytics")

        else:
            failed_count = total_count - passed_count
            print(f"\nâš ï¸ {failed_count} tests failed")
            print("ğŸ”§ Please check:")
            print("   â€¢ API key validity")
            print("   â€¢ Network connectivity")
            print("   â€¢ Model availability")
            print("   â€¢ Rate limits")

        return passed_count == total_count

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    tester = GeminiAPITester()

    try:
        success = await tester.run_all_tests()

        # ä¿å­˜æµ‹è¯•ç»“æœ
        results_file = "gemini_api_test_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump({
                "test_date": datetime.now().isoformat(),
                "total_tests": len(tester.test_results),
                "passed_tests": sum(1 for r in tester.test_results if r["success"]),
                "results": tester.test_results
            }, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“„ Test results saved to: {results_file}")

        return success

    finally:
        await tester.cleanup_client()

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)