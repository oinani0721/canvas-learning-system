"""
åŠ¨æ€æ£€éªŒç™½æ¿ç”Ÿæˆå™¨ - Story 8.16æ ¸å¿ƒå®ç°

é›†æˆæ‰€æœ‰ç»„ä»¶ï¼Œå®ç°å®Œæ•´çš„åŠ¨æ€æ£€éªŒç™½æ¿ç”Ÿæˆå’Œç®¡ç†åŠŸèƒ½ã€‚

Author: Canvas Learning System Team
Version: 1.0 (Story 8.16)
Created: 2025-01-22
"""

import json
import os
import uuid
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path

# å¯¼å…¥æ‰€æœ‰ç»„ä»¶
try:
    from canvas_utils import CanvasJSONOperator, CanvasBusinessLogic, COLOR_CODE_YELLOW, COLOR_CODE_BLUE
    from critical_nodes_extractor import CriticalNodesExtractor, CriticalNode, SourceAnalysis
    from knowledge_graph_integration import KnowledgeGraphIntegration, KnowledgeGraphContext
    from learning_cycle_manager import LearningCycleManager, LearningStep
    from intelligent_question_generator import IntelligentQuestionGenerator, GeneratedQuestion, QuestionGenerationConfig
except ImportError as e:
    print(f"Warning: Failed to import components: {e}")
    # ç®€åŒ–çš„æœ¬åœ°å¯¼å…¥
    from critical_nodes_extractor import CriticalNodesExtractor, CriticalNode, SourceAnalysis

# å°è¯•å¯¼å…¥loguru
try:
    from loguru import logger
    LOGURU_ENABLED = True
except ImportError:
    import logging
    logger = logging.getLogger(__name__)
    LOGURU_ENABLED = False


@dataclass
class DynamicReviewCanvas:
    """åŠ¨æ€æ£€éªŒç™½æ¿æ•°æ®ç»“æ„"""
    canvas_id: str
    source_canvas: str
    generation_timestamp: str
    iteration_count: int
    learning_cycle_step: str

    source_analysis: SourceAnalysis
    review_questions: List[GeneratedQuestion]
    dynamic_learning_cycle: Dict[str, Any]
    knowledge_network_expansion: Dict[str, Any]
    progress_tracking: Dict[str, Any]
    quality_metrics: Dict[str, Any]
    user_interaction_data: Dict[str, Any]
    ai_analysis_insights: Dict[str, Any]

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "canvas_id": self.canvas_id,
            "source_canvas": self.source_canvas,
            "generation_timestamp": self.generation_timestamp,
            "iteration_count": self.iteration_count,
            "learning_cycle_step": self.learning_cycle_step,
            "source_analysis": self._serialize_source_analysis(),
            "review_questions": [self._serialize_question(q) for q in self.review_questions],
            "dynamic_learning_cycle": self.dynamic_learning_cycle,
            "knowledge_network_expansion": self.knowledge_network_expansion,
            "progress_tracking": self.progress_tracking,
            "quality_metrics": self.quality_metrics,
            "user_interaction_data": self.user_interaction_data,
            "ai_analysis_insights": self.ai_analysis_insights
        }

    def _serialize_source_analysis(self) -> Dict[str, Any]:
        """åºåˆ—åŒ–æºåˆ†æ"""
        return {
            "canvas_id": self.source_analysis.canvas_id,
            "extraction_algorithm": self.source_analysis.extraction_algorithm,
            "total_source_nodes": self.source_analysis.total_source_nodes,
            "critical_nodes_extracted": [
                {
                    "node_id": node.node_id,
                    "color": node.color,
                    "concept_name": node.concept_name,
                    "confidence_score": node.confidence_score,
                    "mastery_estimation": node.mastery_estimation,
                    "reason_for_critical": node.reason_for_critical,
                    "text_content": node.text_content
                }
                for node in self.source_analysis.critical_nodes_extracted
            ],
            "knowledge_graph_context": self.source_analysis.knowledge_graph_context
        }

    def _serialize_question(self, question: GeneratedQuestion) -> Dict[str, Any]:
        """åºåˆ—åŒ–é—®é¢˜"""
        # Handle both enum and string cases for question_type and difficulty_level
        question_type_value = question.question_type.value if hasattr(question.question_type, 'value') else question.question_type
        difficulty_value = question.difficulty_level.value if hasattr(question.difficulty_level, 'value') else question.difficulty_level

        return {
            "question_id": question.question_id,
            "source_node_id": question.source_node_id,
            "question_type": question_type_value,
            "difficulty_level": difficulty_value,
            "question_text": question.question_text,
            "expected_answer_type": question.expected_answer_type,
            "estimated_time_minutes": question.estimated_time_minutes,
            "hint_available": question.hint_available,
            "hint_text": question.hint_text,
            "learning_objectives": question.learning_objectives,
            "intelligent_generation": question.intelligent_generation,
            "quality_score": question.quality_score,
            "generation_timestamp": question.generation_timestamp
        }


class DynamicReviewCanvasGenerator:
    """
    åŠ¨æ€æ£€éªŒç™½æ¿ç”Ÿæˆå™¨

    è¿™æ˜¯Story 8.16çš„æ ¸å¿ƒç»„ä»¶ï¼Œæ•´åˆäº†æ‰€æœ‰å­æ¨¡å—ï¼š
    1. æ™ºèƒ½èŠ‚ç‚¹æå– (CriticalNodesExtractor)
    2. çŸ¥è¯†å›¾è°±åˆ†æ (KnowledgeGraphIntegration)
    3. æ™ºèƒ½é—®é¢˜ç”Ÿæˆ (IntelligentQuestionGenerator)
    4. å­¦ä¹ å¾ªç¯ç®¡ç† (LearningCycleManager)
    5. Canvaså¸ƒå±€å’Œç”Ÿæˆ
    """

    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–åŠ¨æ€æ£€éªŒç™½æ¿ç”Ÿæˆå™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)

        # åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
        self.nodes_extractor = CriticalNodesExtractor(self.config.get("node_extraction", {}))
        self.kg_integration = KnowledgeGraphIntegration(self.config.get("knowledge_graph", {}))
        self.question_generator = IntelligentQuestionGenerator(
            config=QuestionGenerationConfig(**self.config.get("question_generation", {})),
            kg_integration=self.kg_integration
        )

        # Canvaså¸ƒå±€å‚æ•°
        self.layout_params = self.config.get("layout", {
            "canvas_width": 2000,
            "canvas_height": 1500,
            "question_spacing_x": 500,
            "question_spacing_y": 400,
            "starting_x": 100,
            "starting_y": 100
        })

        if LOGURU_ENABLED:
            logger.info("DynamicReviewCanvasGenerator initialized")

    def _load_config(self, config_path: Optional[str]) -> Dict:
        """åŠ è½½é…ç½®"""
        default_config = {
            "node_extraction": {
                "critical_colors": ["4", "3"],  # çº¢è‰²å’Œç´«è‰²
                "confidence_threshold": 0.7,
                "mastery_threshold": 0.7
            },
            "question_generation": {
                "max_questions_per_node": 3,
                "difficulty_adaptation": True,
                "context_informed_generation": True,
                "include_hints": True,
                "quality_threshold": 0.7
            },
            "knowledge_graph": {
                "enable_mcp": True,
                "context_analysis": True,
                "max_related_concepts": 5,
                "similarity_threshold": 0.3,
                "mcp_timeout": 30
            },
            "learning_cycle": {
                "auto_advance": False,
                "max_iterations": 10,
                "progress_tracking": True
            },
            "layout": {
                "canvas_width": 2000,
                "canvas_height": 1500,
                "question_spacing_x": 500,
                "question_spacing_y": 400,
                "starting_x": 100,
                "starting_y": 100
            },
            "progress_tracking": {
                "green_node_threshold": 80.0,
                "iteration_limit": 10,
                "time_limit_hours": 24
            }
        }

        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                # åˆå¹¶é…ç½®
                default_config.update(user_config)
                if LOGURU_ENABLED:
                    logger.info(f"Loaded configuration from {config_path}")
            except Exception as e:
                if LOGURU_ENABLED:
                    logger.warning(f"Failed to load config from {config_path}: {e}")

        return default_config

    def create_review_canvas(self, source_canvas: str, iteration: int = 1, user_profile: Optional[Dict] = None) -> str:
        """
        åˆ›å»ºæ£€éªŒç™½æ¿ - ä¸»è¦å…¥å£å‡½æ•°

        Args:
            source_canvas: æºCanvasæ–‡ä»¶è·¯å¾„
            iteration: è¿­ä»£æ¬¡æ•°
            user_profile: ç”¨æˆ·å­¦ä¹ æ¡£æ¡ˆ

        Returns:
            str: åˆ›å»ºçš„æ£€éªŒç™½æ¿æ–‡ä»¶è·¯å¾„
        """
        try:
            if LOGURU_ENABLED:
                logger.info(f"Creating review canvas from {source_canvas}, iteration {iteration}")

            # 1. æå–å…³é”®èŠ‚ç‚¹
            source_analysis = self.nodes_extractor.extract_critical_nodes(source_canvas)

            if not source_analysis.critical_nodes_extracted:
                raise ValueError("No critical nodes found in source canvas")

            # 2. ç”Ÿæˆæ£€éªŒé—®é¢˜
            review_questions = self.question_generator.generate_review_questions(
                source_analysis.critical_nodes_extracted, user_profile
            )

            # 3. åˆ†æçŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡
            concepts = [node.concept_name for node in source_analysis.critical_nodes_extracted]
            canvas_data = CanvasJSONOperator.read_canvas(source_canvas)
            kg_context = self.kg_integration.analyze_concept_context(concepts, canvas_data)

            # 4. åˆ›å»ºåŠ¨æ€æ£€éªŒç™½æ¿å¯¹è±¡
            dynamic_canvas = DynamicReviewCanvas(
                canvas_id=f"canvas-{uuid.uuid4().hex[:16]}",
                source_canvas=source_canvas,
                generation_timestamp=datetime.now().isoformat(),
                iteration_count=iteration,
                learning_cycle_step="step_1_understanding",
                source_analysis=source_analysis,
                review_questions=review_questions,
                dynamic_learning_cycle=self._create_learning_cycle_info(),
                knowledge_network_expansion=self._create_network_expansion_info(),
                progress_tracking=self._create_progress_tracking_info(),
                quality_metrics=self._calculate_quality_metrics(review_questions, source_analysis),
                user_interaction_data=self._create_user_interaction_data(),
                ai_analysis_insights=self._generate_ai_insights(source_analysis, kg_context)
            )

            # 5. ç”ŸæˆCanvasæ–‡ä»¶
            canvas_file_path = self._generate_canvas_file(dynamic_canvas, source_canvas, iteration)

            # 6. ä¿å­˜å…ƒæ•°æ®
            self._save_canvas_metadata(dynamic_canvas, canvas_file_path)

            if LOGURU_ENABLED:
                logger.info(f"Review canvas created successfully: {canvas_file_path}")

            return canvas_file_path

        except Exception as e:
            error_msg = f"Failed to create review canvas: {str(e)}"
            if LOGURU_ENABLED:
                logger.error(error_msg, exc_info=True)
            raise ValueError(error_msg) from e

    def process_learning_cycle_step(self, canvas_path: str, step: int, user_input: Dict) -> Dict:
        """
        å¤„ç†å­¦ä¹ å¾ªç¯æ­¥éª¤

        Args:
            canvas_path: Canvasæ–‡ä»¶è·¯å¾„
            step: å½“å‰æ­¥éª¤
            user_input: ç”¨æˆ·è¾“å…¥æ•°æ®

        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        try:
            # åˆå§‹åŒ–å­¦ä¹ å¾ªç¯ç®¡ç†å™¨
            cycle_manager = LearningCycleManager(canvas_path, self.config.get("learning_cycle", {}))

            # å¤„ç†ç”¨æˆ·è¾“å…¥
            step_result = cycle_manager.process_user_input(user_input)

            # å¦‚æœæ­¥éª¤å®Œæˆï¼Œå°è¯•æ¨è¿›åˆ°ä¸‹ä¸€æ­¥
            if step_result.success and step_result.output_data.get("can_advance", False):
                advance_result = cycle_manager.advance_to_next_step(step_result.output_data)
                step_result.output_data["advance_result"] = advance_result.__dict__

            # è·å–å½“å‰è¿›åº¦
            progress = cycle_manager.get_cycle_progress()

            return {
                "step_result": step_result.__dict__,
                "cycle_progress": progress,
                "next_instructions": cycle_manager.get_step_instructions()
            }

        except Exception as e:
            error_msg = f"Failed to process learning cycle step: {str(e)}"
            if LOGURU_ENABLED:
                logger.error(error_msg)
            return {"error": error_msg, "success": False}

    def evaluate_progress(self, canvas_path: str) -> Dict:
        """
        è¯„ä¼°å­¦ä¹ è¿›åº¦

        Args:
            canvas_path: Canvasæ–‡ä»¶è·¯å¾„

        Returns:
            Dict: è¿›åº¦è¯„ä¼°ç»“æœ
        """
        try:
            # è¯»å–Canvasæ–‡ä»¶
            canvas_data = CanvasJSONOperator.read_canvas(canvas_path)

            # åˆ†æèŠ‚ç‚¹é¢œè‰²åˆ†å¸ƒ
            nodes = canvas_data.get("nodes", [])
            color_counts = {"1": 0, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0}
            for node in nodes:
                color = node.get("color")
                if color in color_counts:
                    color_counts[color] += 1

            total_nodes = len(nodes)
            if total_nodes == 0:
                return {"error": "No nodes found in canvas", "success": False}

            # è®¡ç®—è¿›åº¦æŒ‡æ ‡
            green_nodes = color_counts.get("2", 0)  # ç»¿è‰²ï¼ˆå®Œå…¨ç†è§£ï¼‰
            yellow_nodes = color_counts.get("6", 0)  # é»„è‰²ï¼ˆç”¨æˆ·ç†è§£ï¼‰
            red_nodes = color_counts.get("4", 0)    # çº¢è‰²ï¼ˆä¸ç†è§£ï¼‰
            purple_nodes = color_counts.get("3", 0) # ç´«è‰²ï¼ˆä¼¼æ‡‚éæ‡‚ï¼‰

            # è®¡ç®—å®Œæˆç™¾åˆ†æ¯”ï¼ˆç»¿è‰²+é»„è‰²å æ€»æ•°çš„æ¯”ä¾‹ï¼‰
            completion_percentage = ((green_nodes + yellow_nodes) / total_nodes) * 100

            # è®¡ç®—è´¨é‡æŒ‡æ ‡
            quality_metrics = {
                "node_distribution": color_counts,
                "completion_percentage": completion_percentage,
                "mastery_level": (green_nodes / total_nodes) * 100 if total_nodes > 0 else 0,
                "needs_attention": (red_nodes + purple_nodes) / total_nodes * 100 if total_nodes > 0 else 0
            }

            # ç”Ÿæˆè¯„ä¼°ç»“æœ
            progress_result = {
                "overall_progress": {
                    "total_nodes": total_nodes,
                    "green_nodes": green_nodes,
                    "yellow_nodes": yellow_nodes,
                    "red_nodes": red_nodes,
                    "purple_nodes": purple_nodes,
                    "completion_percentage": completion_percentage
                },
                "quality_metrics": quality_metrics,
                "stopping_conditions": self._check_stopping_conditions(quality_metrics),
                "recommendations": self._generate_recommendations(quality_metrics)
            }

            return progress_result

        except Exception as e:
            error_msg = f"Failed to evaluate progress: {str(e)}"
            if LOGURU_ENABLED:
                logger.error(error_msg)
            return {"error": error_msg, "success": False}

    def should_continue_iteration(self, progress_data: Dict) -> Dict:
        """
        åˆ¤æ–­æ˜¯å¦ç»§ç»­è¿­ä»£

        Args:
            progress_data: è¿›åº¦æ•°æ®

        Returns:
            Dict: ç»§ç»­è¿­ä»£å†³ç­–
        """
        try:
            quality_metrics = progress_data.get("quality_metrics", {})
            completion_percentage = quality_metrics.get("completion_percentage", 0)
            mastery_level = quality_metrics.get("mastery_level", 0)

            # è·å–åœæ­¢æ¡ä»¶é…ç½®
            stopping_config = self.config.get("progress_tracking", {})
            green_threshold = stopping_config.get("green_node_threshold", 80.0)
            iteration_limit = stopping_config.get("iteration_limit", 10)

            # æ£€æŸ¥åœæ­¢æ¡ä»¶
            should_stop = False
            stop_reason = ""

            if completion_percentage >= green_threshold:
                should_stop = True
                stop_reason = "è¾¾åˆ°å®Œæˆåº¦é˜ˆå€¼"
            elif mastery_level >= 90:
                should_stop = True
                stop_reason = "æŒæ¡åº¦è¾¾åˆ°ä¼˜ç§€æ°´å¹³"

            # ä¼°ç®—è¿˜éœ€è¦çš„è¿­ä»£æ¬¡æ•°
            estimated_iterations = max(1, int((green_threshold - completion_percentage) / 20))

            decision = {
                "should_continue": not should_stop,
                "recommended_action": "continue_iteration" if not should_stop else "complete_learning",
                "estimated_completion_iterations": estimated_iterations,
                "stop_reason": stop_reason if should_stop else None,
                "confidence_score": min(completion_percentage / green_threshold, 1.0)
            }

            return decision

        except Exception as e:
            error_msg = f"Failed to evaluate continuation: {str(e)}"
            if LOGURU_ENABLED:
                logger.error(error_msg)
            return {"error": error_msg, "should_continue": False}

    def expand_knowledge_network(self, canvas_path: str, user_additions: List[Dict]) -> Dict:
        """
        æ‰©å±•çŸ¥è¯†ç½‘ç»œ

        Args:
            canvas_path: Canvasæ–‡ä»¶è·¯å¾„
            user_additions: ç”¨æˆ·æ·»åŠ çš„å†…å®¹

        Returns:
            Dict: æ‰©å±•ç»“æœ
        """
        try:
            # è¯»å–ç°æœ‰Canvas
            canvas_data = CanvasJSONOperator.read_canvas(canvas_path)

            # è®°å½•æ·»åŠ å‰çŠ¶æ€
            original_nodes = len(canvas_data.get("nodes", []))
            original_edges = len(canvas_data.get("edges", []))

            # å¤„ç†ç”¨æˆ·æ·»åŠ 
            added_nodes = []
            added_edges = []
            relationships_established = []

            for addition in user_additions:
                if addition.get("type") == "node":
                    # æ·»åŠ æ–°èŠ‚ç‚¹
                    node_id = self._add_user_node(canvas_data, addition)
                    added_nodes.append(node_id)
                elif addition.get("type") == "edge":
                    # æ·»åŠ æ–°è¿æ¥
                    edge_id = self._add_user_edge(canvas_data, addition)
                    added_edges.append(edge_id)
                elif addition.get("type") == "relationship":
                    # å»ºç«‹å…³ç³»
                    relationships_established.append(addition)

            # ä¿å­˜æ›´æ–°åçš„Canvas
            CanvasJSONOperator.write_canvas(canvas_path, canvas_data)

            # ç”Ÿæˆæ‰©å±•ç»“æœ
            expansion_result = {
                "network_expansion": {
                    "new_nodes_added": len(added_nodes),
                    "new_edges_added": len(added_edges),
                    "relationships_established": len(relationships_established),
                    "total_nodes": len(canvas_data.get("nodes", [])),
                    "total_edges": len(canvas_data.get("edges", []))
                },
                "added_nodes": added_nodes,
                "added_edges": added_edges,
                "relationships": relationships_established,
                "expansion_quality": self._evaluate_expansion_quality(canvas_data, user_additions)
            }

            if LOGURU_ENABLED:
                logger.info(f"Knowledge network expanded: {len(added_nodes)} nodes, {len(added_edges)} edges")

            return expansion_result

        except Exception as e:
            error_msg = f"Failed to expand knowledge network: {str(e)}"
            if LOGURU_ENABLED:
                logger.error(error_msg)
            return {"error": error_msg, "success": False}

    # ç§æœ‰è¾…åŠ©æ–¹æ³•

    def _create_learning_cycle_info(self) -> Dict[str, Any]:
        """åˆ›å»ºå­¦ä¹ å¾ªç¯ä¿¡æ¯"""
        return {
            "current_step": "step_1_understanding",
            "step_name": "å¡«å†™ç†è§£",
            "step_description": "ç”¨æˆ·å¡«å†™é»„è‰²ç†è§£èŠ‚ç‚¹ï¼Œè¡¨è¾¾å¯¹æ¦‚å¿µçš„ç†è§£",
            "step_instructions": "è¯·ä»”ç»†é˜…è¯»æ¯ä¸ªé—®é¢˜ï¼Œç”¨æ‚¨è‡ªå·±çš„è¯è®¤çœŸå›ç­”ã€‚",
            "estimated_time_minutes": 15,
            "required_inputs": ["yellow_node_understanding"],
            "success_criteria": [
                "ç­”æ¡ˆå†…å®¹ç›¸å…³æ€§>80%",
                "å›ç­”é•¿åº¦ç¬¦åˆè¦æ±‚",
                "é€»è¾‘æ¸…æ™°è¡¨è¾¾"
            ]
        }

    def _create_network_expansion_info(self) -> Dict[str, Any]:
        """åˆ›å»ºçŸ¥è¯†ç½‘ç»œæ‰©å±•ä¿¡æ¯"""
        return {
            "new_nodes_added_in_iteration": [],
            "relationships_established": [],
            "expansion_timestamp": datetime.now().isoformat()
        }

    def _create_progress_tracking_info(self) -> Dict[str, Any]:
        """åˆ›å»ºè¿›åº¦è·Ÿè¸ªä¿¡æ¯"""
        return {
            "overall_progress": {
                "total_nodes": 0,
                "green_nodes": 0,
                "yellow_nodes": 0,
                "red_nodes": 0,
                "purple_nodes": 0,
                "completion_percentage": 0.0
            },
            "stopping_conditions": {
                "green_node_threshold": self.config["progress_tracking"]["green_node_threshold"],
                "iteration_limit": self.config["progress_tracking"]["iteration_limit"],
                "time_limit_hours": self.config["progress_tracking"]["time_limit_hours"],
                "user_satisfaction_threshold": 8.0
            },
            "current_status": {
                "meets_stopping_conditions": False,
                "recommended_action": "continue_iteration",
                "estimated_completion_iterations": 3
            },
            "learning_trends": {
                "mastery_improvement_rate": 0.15,
                "knowledge_expansion_rate": 0.25,
                "user_engagement_score": 8.5
            }
        }

    def _calculate_quality_metrics(self, questions: List[GeneratedQuestion], analysis: SourceAnalysis) -> Dict[str, float]:
        """è®¡ç®—è´¨é‡æŒ‡æ ‡"""
        if not questions:
            return {
                "question_relevance": 0.0,
                "difficulty_appropriateness": 0.0,
                "learning_effectiveness": 0.0,
                "user_satisfaction": 0.0,
                "knowledge_retention": 0.0
            }

        # è®¡ç®—é—®é¢˜è´¨é‡æŒ‡æ ‡
        question_relevance = sum(q.quality_score for q in questions) / len(questions)
        difficulty_appropriateness = self._calculate_difficulty_appropriateness(questions, analysis)
        learning_effectiveness = self._calculate_learning_effectiveness(questions, analysis)

        # æ¨¡æ‹Ÿç”¨æˆ·æ»¡æ„åº¦ï¼ˆå®é™…ä½¿ç”¨æ—¶åº”è¯¥ä»ç”¨æˆ·åé¦ˆæ”¶é›†ï¼‰
        user_satisfaction = min(question_relevance * 10, 10.0)
        knowledge_retention = learning_effectiveness * 0.9  # å‡è®¾ç•™å­˜ç‡ç•¥ä½äºæ•ˆæœ

        return {
            "question_relevance": round(question_relevance, 2),
            "difficulty_appropriateness": round(difficulty_appropriateness, 2),
            "learning_effectiveness": round(learning_effectiveness, 2),
            "user_satisfaction": round(user_satisfaction, 1),
            "knowledge_retention": round(knowledge_retention, 2)
        }

    def _calculate_difficulty_appropriateness(self, questions: List[GeneratedQuestion], analysis: SourceAnalysis) -> float:
        """è®¡ç®—éš¾åº¦é€‚å®œæ€§"""
        if not questions or not analysis.critical_nodes_extracted:
            return 0.0

        # è®¡ç®—å¹³å‡æŒæ¡åº¦
        avg_mastery = sum(node.mastery_estimation for node in analysis.critical_nodes_extracted) / len(analysis.critical_nodes_extracted)

        # è®¡ç®—é—®é¢˜éš¾åº¦åˆ†å¸ƒ
        difficulty_scores = {"basic": 0.25, "intermediate": 0.5, "advanced": 0.75, "expert": 1.0}
        total_difficulty = 0.0
        for q in questions:
            # Handle both enum and string cases
            if hasattr(q.difficulty_level, 'value'):
                difficulty_value = q.difficulty_level.value
            else:
                difficulty_value = q.difficulty_level
            total_difficulty += difficulty_scores.get(difficulty_value, 0.5)

        avg_difficulty = total_difficulty / len(questions)

        # ç†æƒ³æƒ…å†µä¸‹ï¼Œé—®é¢˜éš¾åº¦åº”è¯¥ç•¥é«˜äºå¹³å‡æŒæ¡åº¦
        ideal_difficulty = min(avg_mastery + 0.1, 1.0)
        appropriateness = 1.0 - abs(avg_difficulty - ideal_difficulty)

        return max(0.0, appropriateness)

    def _calculate_learning_effectiveness(self, questions: List[GeneratedQuestion], analysis: SourceAnalysis) -> float:
        """è®¡ç®—å­¦ä¹ æ•ˆæœ"""
        if not questions:
            return 0.0

        # åŸºäºé—®é¢˜è´¨é‡ã€æ•°é‡å’Œå¤šæ ·æ€§è®¡ç®—
        quality_score = sum(q.quality_score for q in questions) / len(questions)
        quantity_score = min(len(questions) / 10, 1.0)  # 10ä¸ªé—®é¢˜ä¸ºæ»¡åˆ†

        # è®¡ç®—ç±»å‹å¤šæ ·æ€§ - handle both enum and string cases
        question_types = set()
        for q in questions:
            if hasattr(q.question_type, 'value'):
                question_types.add(q.question_type.value)
            else:
                question_types.add(q.question_type)

        diversity_score = min(len(question_types) / 5, 1.0)  # 5ç§ç±»å‹ä¸ºæ»¡åˆ†

        # åŠ æƒå¹³å‡
        effectiveness = (quality_score * 0.5 + quantity_score * 0.2 + diversity_score * 0.3)

        return effectiveness

    def _create_user_interaction_data(self) -> Dict[str, Any]:
        """åˆ›å»ºç”¨æˆ·äº¤äº’æ•°æ®"""
        return {
            "time_spent_minutes": 0,
            "questions_answered": 0,
            "questions_skipped": 0,
            "hints_used": 0,
            "feedback_provided": False,
            "user_rating": 0.0
        }

    def _generate_ai_insights(self, analysis: SourceAnalysis, kg_context: KnowledgeGraphContext) -> Dict[str, Any]:
        """ç”ŸæˆAIåˆ†ææ´å¯Ÿ"""
        return {
            "knowledge_gaps_identified": [
                {
                    "concept": node.concept_name,
                    "gap_severity": "high" if node.mastery_estimation < 0.3 else "medium",
                    "recommendation": "éœ€è¦é‡ç‚¹å­¦ä¹ å’Œç»ƒä¹ "
                }
                for node in analysis.critical_nodes_extracted if node.mastery_estimation < 0.6
            ],
            "learning_pattern_analysis": {
                "preferred_approach": "visual_examples",
                "optimal_difficulty": "gradual_increase",
                "learning_pace": "steady_progress"
            },
            "next_recommendations": [
                "ç»§ç»­å®Œæˆå½“å‰è¿­ä»£çš„å­¦ä¹ å¾ªç¯",
                "é‡ç‚¹å…³æ³¨ç†è§£ä¸è¶³çš„æ¦‚å¿µ",
                "é€‚å½“å¢åŠ ç»ƒä¹ å’Œåº”ç”¨"
            ]
        }

    def _generate_canvas_file(self, dynamic_canvas: DynamicReviewCanvas, source_canvas: str, iteration: int) -> str:
        """ç”ŸæˆCanvasæ–‡ä»¶"""
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        source_path = Path(source_canvas)
        output_dir = source_path.parent / "review_canvases"

        # å¤„ç†Windowsè·¯å¾„åˆ›å»ºé—®é¢˜
        try:
            output_dir.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            # å¦‚æœæ— æ³•åˆ›å»ºå­ç›®å½•ï¼Œä½¿ç”¨å½“å‰ç›®å½•
            output_dir = source_path.parent
            if LOGURU_ENABLED:
                logger.warning(f"Could not create review_canvases directory, using parent: {e}")

        timestamp = datetime.now().strftime("%Y%m%d")
        canvas_filename = f"{source_path.stem}-æ£€éªŒç™½æ¿-{timestamp}-iteration{iteration}.canvas"
        canvas_file_path = output_dir / canvas_filename

        # åˆ›å»ºCanvasæ•°æ®ç»“æ„
        canvas_data = {
            "nodes": [],
            "edges": []
        }

        # æ·»åŠ æ ‡é¢˜èŠ‚ç‚¹
        title_node = self._create_title_node(dynamic_canvas, iteration)
        canvas_data["nodes"].append(title_node)

        # æ·»åŠ é—®é¢˜èŠ‚ç‚¹å’Œå¯¹åº”çš„é»„è‰²ç†è§£èŠ‚ç‚¹
        current_x = self.layout_params["starting_x"]
        current_y = self.layout_params["starting_y"]

        for i, question in enumerate(dynamic_canvas.review_questions):
            # é—®é¢˜èŠ‚ç‚¹
            question_node = self._create_question_node(question, current_x, current_y)
            canvas_data["nodes"].append(question_node)

            # é»„è‰²ç†è§£èŠ‚ç‚¹ï¼ˆåœ¨é—®é¢˜ä¸‹æ–¹ï¼‰
            yellow_node = self._create_yellow_node(question, current_x, current_y + 180)
            canvas_data["nodes"].append(yellow_node)

            # è¿æ¥é—®é¢˜èŠ‚ç‚¹å’Œé»„è‰²èŠ‚ç‚¹
            edge = self._create_edge(question_node["id"], yellow_node["id"])
            canvas_data["edges"].append(edge)

            # æ›´æ–°ä½ç½®
            current_x += self.layout_params["question_spacing_x"]
            if (i + 1) % 3 == 0:  # æ¯3ä¸ªé—®é¢˜æ¢è¡Œ
                current_x = self.layout_params["starting_x"]
                current_y += self.layout_params["question_spacing_y"]

        # ä¿å­˜Canvasæ–‡ä»¶
        with open(canvas_file_path, 'w', encoding='utf-8') as f:
            json.dump(canvas_data, f, ensure_ascii=False, indent=2)

        return str(canvas_file_path)

    def _create_title_node(self, dynamic_canvas: DynamicReviewCanvas, iteration: int) -> Dict[str, Any]:
        """åˆ›å»ºæ ‡é¢˜èŠ‚ç‚¹"""
        source_name = Path(dynamic_canvas.source_canvas).stem
        return {
            "id": f"title-{uuid.uuid4().hex[:16]}",
            "type": "text",
            "text": f"# {source_name} - æ£€éªŒç™½æ¿ (ç¬¬{iteration}è½®è¿­ä»£)\n\n"
                   f"ç”Ÿæˆæ—¶é—´: {dynamic_canvas.generation_timestamp[:19]}\n"
                   f"å…³é”®èŠ‚ç‚¹æ•°é‡: {len(dynamic_canvas.review_questions)}\n"
                   f"å½“å‰æ­¥éª¤: {dynamic_canvas.learning_cycle_step}",
            "x": self.layout_params["starting_x"],
            "y": 50,
            "width": 600,
            "height": 120,
            "color": "5"  # è“è‰²
        }

    def _create_question_node(self, question: GeneratedQuestion, x: int, y: int) -> Dict[str, Any]:
        """åˆ›å»ºé—®é¢˜èŠ‚ç‚¹"""
        hint_text = f"\n\nğŸ’¡ æç¤º: {question.hint_text}" if question.hint_available else ""

        # Handle both enum and string cases for question_type and difficulty_level
        question_type_value = question.question_type.value if hasattr(question.question_type, 'value') else question.question_type
        difficulty_value = question.difficulty_level.value if hasattr(question.difficulty_level, 'value') else question.difficulty_level

        return {
            "id": question.question_id,
            "type": "text",
            "text": f"## é—®é¢˜ {question.question_id[-4:]}\n\n"
                   f"{question.question_text}\n\n"
                   f"**ç±»å‹**: {question_type_value}\n"
                   f"**éš¾åº¦**: {difficulty_value}\n"
                   f"**é¢„è®¡æ—¶é—´**: {question.estimated_time_minutes}åˆ†é’Ÿ\n"
                   f"**è´¨é‡åˆ†æ•°**: {question.quality_score:.2f}"
                   f"{hint_text}",
            "x": x,
            "y": y,
            "width": 400,
            "height": 160,
            "color": "1"  # çº¢è‰²ï¼ˆéœ€è¦é‡ç‚¹å…³æ³¨ï¼‰
        }

    def _create_yellow_node(self, question: GeneratedQuestion, x: int, y: int) -> Dict[str, Any]:
        """åˆ›å»ºé»„è‰²ç†è§£èŠ‚ç‚¹"""
        return {
            "id": f"yellow-{question.question_id[-16:]}",
            "type": "text",
            "text": f"## æˆ‘çš„ç†è§£\n\n"
                   f"è¯·åœ¨æ­¤å¤„å¡«å†™æ‚¨å¯¹ä¸Šè¿°é—®é¢˜çš„ç†è§£...\n\n"
                   f"**å‚è€ƒè¦æ±‚**:\n"
                   f"- ç”¨è‡ªå·±çš„è¯è§£é‡Š\n"
                   f"- å¯ä»¥ä¸¾ä¾‹å­è¯´æ˜\n"
                   f"- æ³¨æ˜ä¸ç¡®å®šçš„åœ°æ–¹",
            "x": x + 50,
            "y": y,
            "width": 350,
            "height": 120,
            "color": "6"  # é»„è‰²ï¼ˆç”¨æˆ·ç†è§£è¾“å‡ºåŒºï¼‰
        }

    def _create_edge(self, from_node: str, to_node: str) -> Dict[str, Any]:
        """åˆ›å»ºè¿æ¥è¾¹"""
        return {
            "id": f"edge-{uuid.uuid4().hex[:16]}",
            "fromNode": from_node,
            "toNode": to_node,
            "fromSide": "bottom",
            "toSide": "top",
            "label": "ç†è§£è¾“å‡º"
        }

    def _save_canvas_metadata(self, dynamic_canvas: DynamicReviewCanvas, canvas_file_path: str):
        """ä¿å­˜Canvaså…ƒæ•°æ®"""
        metadata_file = canvas_file_path.replace('.canvas', '_metadata.json')

        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(dynamic_canvas.to_dict(), f, ensure_ascii=False, indent=2)

        if LOGURU_ENABLED:
            logger.info(f"Canvas metadata saved to {metadata_file}")

    def _check_stopping_conditions(self, quality_metrics: Dict) -> Dict[str, Any]:
        """æ£€æŸ¥åœæ­¢æ¡ä»¶"""
        completion_percentage = quality_metrics.get("completion_percentage", 0)
        mastery_level = quality_metrics.get("mastery_level", 0)
        needs_attention = quality_metrics.get("needs_attention", 100)

        threshold = self.config["progress_tracking"]["green_node_threshold"]

        return {
            "meets_threshold": completion_percentage >= threshold,
            "meets_mastery": mastery_level >= 90,
            "minimal_attention_needed": needs_attention <= 10,
            "overall_ready": completion_percentage >= threshold and mastery_level >= 80
        }

    def _generate_recommendations(self, quality_metrics: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        completion_percentage = quality_metrics.get("completion_percentage", 0)
        mastery_level = quality_metrics.get("mastery_level", 0)

        if completion_percentage < 60:
            recommendations.append("å»ºè®®é‡ç‚¹å®Œæˆé»„è‰²ç†è§£èŠ‚ç‚¹çš„å¡«å†™")
        elif completion_percentage < 80:
            recommendations.append("ç»§ç»­å®Œå–„ç†è§£ï¼Œäº‰å–æ›´å¤šèŠ‚ç‚¹è¾¾åˆ°ç»¿è‰²çŠ¶æ€")

        if mastery_level < 50:
            recommendations.append("éœ€è¦é‡æ–°å­¦ä¹ åŸºç¡€æ¦‚å¿µï¼Œå»ºè®®è¡¥å……ç›¸å…³è§£é‡Š")
        elif mastery_level < 80:
            recommendations.append("ç†è§£åŸºæœ¬åˆ°ä½ï¼Œå¯ä»¥é€šè¿‡ç»ƒä¹ å·©å›º")

        if not recommendations:
            recommendations.append("å­¦ä¹ è¿›å±•è‰¯å¥½ï¼Œå¯ä»¥ç»§ç»­ä¸‹ä¸€é˜¶æ®µå­¦ä¹ ")

        return recommendations

    def _add_user_node(self, canvas_data: Dict, addition: Dict) -> str:
        """æ·»åŠ ç”¨æˆ·èŠ‚ç‚¹"""
        node_id = f"user-node-{uuid.uuid4().hex[:16]}"
        node = {
            "id": node_id,
            "type": "text",
            "text": addition.get("content", ""),
            "x": addition.get("x", 100),
            "y": addition.get("y", 100),
            "width": addition.get("width", 400),
            "height": addition.get("height", 300),
            "color": addition.get("color", "6")  # é»˜è®¤é»„è‰²
        }

        canvas_data.setdefault("nodes", []).append(node)
        return node_id

    def _add_user_edge(self, canvas_data: Dict, addition: Dict) -> str:
        """æ·»åŠ ç”¨æˆ·è¿æ¥"""
        edge_id = f"user-edge-{uuid.uuid4().hex[:16]}"
        edge = {
            "id": edge_id,
            "fromNode": addition.get("from_node"),
            "toNode": addition.get("to_node"),
            "fromSide": addition.get("from_side", "right"),
            "toSide": addition.get("to_side", "left")
        }

        if addition.get("label"):
            edge["label"] = addition["label"]

        canvas_data.setdefault("edges", []).append(edge)
        return edge_id

    def _evaluate_expansion_quality(self, canvas_data: Dict, user_additions: List[Dict]) -> float:
        """è¯„ä¼°æ‰©å±•è´¨é‡"""
        # ç®€åŒ–çš„è´¨é‡è¯„ä¼°
        nodes = canvas_data.get("nodes", [])
        edges = canvas_data.get("edges", [])

        # è®¡ç®—è¿æ¥å¯†åº¦
        if len(nodes) > 1:
            density = len(edges) / (len(nodes) * (len(nodes) - 1) / 2)
        else:
            density = 0

        # è®¡ç®—å†…å®¹è´¨é‡ï¼ˆåŸºäºèŠ‚ç‚¹æ–‡æœ¬é•¿åº¦ï¼‰
        avg_content_length = sum(len(node.get("text", "")) for node in nodes) / len(nodes) if nodes else 0
        content_quality = min(avg_content_length / 100, 1.0)

        # ç»¼åˆè´¨é‡åˆ†æ•°
        quality_score = (density * 0.4 + content_quality * 0.6)

        return round(quality_score, 2)


# ä¾¿åˆ©å‡½æ•°
def create_dynamic_review_canvas(source_canvas: str, iteration: int = 1, user_profile: Optional[Dict] = None,
                               config_path: Optional[str] = None) -> str:
    """
    ä¾¿åˆ©å‡½æ•°ï¼šåˆ›å»ºåŠ¨æ€æ£€éªŒç™½æ¿

    Args:
        source_canvas: æºCanvasæ–‡ä»¶è·¯å¾„
        iteration: è¿­ä»£æ¬¡æ•°
        user_profile: ç”¨æˆ·æ¡£æ¡ˆ
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        str: åˆ›å»ºçš„æ£€éªŒç™½æ¿æ–‡ä»¶è·¯å¾„
    """
    generator = DynamicReviewCanvasGenerator(config_path)
    return generator.create_review_canvas(source_canvas, iteration, user_profile)


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    import sys
    if len(sys.argv) > 1:
        source_canvas = sys.argv[1]
        if os.path.exists(source_canvas):
            try:
                result = create_dynamic_review_canvas(source_canvas)
                print(f"Review canvas created: {result}")
            except Exception as e:
                print(f"Error: {e}")
        else:
            print(f"Source canvas not found: {source_canvas}")
    else:
        print("Usage: python dynamic_review_canvas_generator.py <source_canvas>")