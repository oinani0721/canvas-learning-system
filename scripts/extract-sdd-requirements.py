"""
SDD Requirements Extraction Script
ä»PRDå’ŒArchitectureæ–‡æ¡£ä¸­æå–æ‰€æœ‰APIç«¯ç‚¹å’Œæ•°æ®æ¨¡å‹ï¼Œç”ŸæˆSDDéœ€æ±‚ç´¢å¼•ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/extract-sdd-requirements.py

è¾“å‡º:
    docs/specs/sdd-requirements-index.md
"""

import re
import os
import sys
import io
from pathlib import Path
from typing import List, Dict, Tuple
from datetime import datetime

# Force UTF-8 encoding for Windows console output
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


class SDDRequirementsExtractor:
    """SDDéœ€æ±‚æå–å™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.prd_dir = self.project_root / "docs" / "prd"
        self.arch_dir = self.project_root / "docs" / "architecture"
        self.specs_dir = self.project_root / "specs"

        # APIç«¯ç‚¹æ¸…å•
        self.api_endpoints: List[Dict] = []
        # æ•°æ®æ¨¡å‹æ¸…å•
        self.data_models: List[Dict] = []

    def extract_api_endpoints_from_epic(self, epic_file: Path) -> List[Dict]:
        """ä»Epicæ–‡ä»¶ä¸­æå–APIç«¯ç‚¹å®šä¹‰"""
        endpoints = []

        with open(epic_file, 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.split('\n')

            # æŸ¥æ‰¾API Endpointsç« èŠ‚
            in_api_section = False
            current_category = None
            line_number = 0

            for line_num, line in enumerate(lines, 1):
                # æ£€æµ‹APIç« èŠ‚å¼€å§‹
                if re.search(r'## API Endpoints', line, re.IGNORECASE):
                    in_api_section = True
                    continue

                # æ£€æµ‹ç« èŠ‚ç»“æŸ (åªæ£€æµ‹äºŒçº§æ ‡é¢˜ ##ï¼Œä¸åŒ…æ‹¬ ### ä¸‰çº§æ ‡é¢˜)
                if in_api_section and line.startswith('## ') and 'API' not in line:
                    break

                if in_api_section:
                    # æ£€æµ‹åˆ†ç±»ï¼ˆå¦‚ ### Canvasæ“ä½œï¼‰
                    category_match = re.search(r'###\s+(.+)\s+\((\d+)\s+endpoints?\)', line)
                    if category_match:
                        current_category = category_match.group(1).strip()
                        continue

                    # æå–ç«¯ç‚¹å®šä¹‰
                    # æ ¼å¼: - `METHOD /path` - æè¿°
                    endpoint_match = re.search(r'-\s+`(GET|POST|PUT|DELETE|PATCH)\s+([^`]+)`\s*-\s*(.+)', line)
                    if endpoint_match and current_category:
                        method = endpoint_match.group(1)
                        path = endpoint_match.group(2)
                        description = endpoint_match.group(3).strip()

                        endpoints.append({
                            'method': method,
                            'path': path,
                            'description': description,
                            'category': current_category,
                            'prd_file': epic_file.name,
                            'prd_line': line_num,
                            'openapi_status': 'â³å¾…æ£€æŸ¥',
                            'coverage': 0
                        })

        return endpoints

    def extract_data_models_from_epic(self, epic_file: Path) -> List[Dict]:
        """ä»Epicæ–‡ä»¶ä¸­æå–æ•°æ®æ¨¡å‹å®šä¹‰"""
        models = []

        with open(epic_file, 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.split('\n')

            # æŸ¥æ‰¾æ•°æ®æ¨¡å‹ç« èŠ‚
            in_model_section = False
            current_category = None

            for line_num, line in enumerate(lines, 1):
                # æ£€æµ‹æ•°æ®æ¨¡å‹ç« èŠ‚å¼€å§‹
                if re.search(r'## æ•°æ®æ¨¡å‹', line, re.IGNORECASE) or re.search(r'## Data Models', line, re.IGNORECASE):
                    in_model_section = True
                    continue

                # æ£€æµ‹ç« èŠ‚ç»“æŸ (åªæ£€æµ‹äºŒçº§æ ‡é¢˜ ##ï¼Œä¸åŒ…æ‹¬ ### ä¸‰çº§æ ‡é¢˜)
                if in_model_section and line.startswith('## ') and 'æ¨¡å‹' not in line and 'Model' not in line:
                    break

                if in_model_section:
                    # æ£€æµ‹åˆ†ç±»
                    category_match = re.search(r'\d+\.\s+\*\*(.+æ¨¡å‹)\*\*\s+\((\d+)ä¸ª\)', line)
                    if category_match:
                        current_category = category_match.group(1).strip()
                        # ä¸è¦continueï¼Œç»§ç»­æ£€æŸ¥åŒä¸€è¡Œæ˜¯å¦æœ‰æ¨¡å‹åç§°

                    # æå–æ¨¡å‹åç§°
                    # æ ¼å¼: `ModelName`, `ModelBase`, `ModelCreate`
                    # æ³¨æ„ï¼šæ¨¡å‹åç§°å’Œåˆ†ç±»å¯èƒ½åœ¨åŒä¸€è¡Œ
                    if current_category and '`' in line:
                        model_names = re.findall(r'`([A-Z][a-zA-Z]+)`', line)
                        for model_name in model_names:
                            models.append({
                                'name': model_name,
                                'category': current_category,
                                'prd_file': epic_file.name,
                                'prd_line': line_num,
                                'schema_status': 'â³å¾…æ£€æŸ¥',
                                'coverage': 0
                            })

        return models

    def check_openapi_coverage(self):
        """æ£€æŸ¥OpenAPIè§„èŒƒè¦†ç›–ç‡"""
        openapi_file = self.specs_dir / "api" / "fastapi-backend-api.openapi.yml"

        if not openapi_file.exists():
            print(f"âš ï¸ OpenAPIæ–‡ä»¶ä¸å­˜åœ¨: {openapi_file}")
            return

        with open(openapi_file, 'r', encoding='utf-8') as f:
            openapi_content = f.read()

        for endpoint in self.api_endpoints:
            path = endpoint['path']
            method = endpoint['method'].lower()

            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if path in openapi_content:
                # æ£€æŸ¥æ–¹æ³•æ˜¯å¦å®šä¹‰
                # ç®€å•æ£€æŸ¥ï¼šåœ¨è·¯å¾„å®šä¹‰åæŸ¥æ‰¾æ–¹æ³•
                path_index = openapi_content.find(path)
                if path_index != -1:
                    section = openapi_content[path_index:path_index + 1000]
                    if f"  {method}:" in section or f"    {method}:" in section:
                        endpoint['openapi_status'] = 'âœ…å·²å®šä¹‰'
                        endpoint['coverage'] = 100
                    else:
                        endpoint['openapi_status'] = 'âš ï¸è·¯å¾„å­˜åœ¨ï¼Œæ–¹æ³•ç¼ºå¤±'
                        endpoint['coverage'] = 50
            else:
                endpoint['openapi_status'] = 'âŒæœªå®šä¹‰'
                endpoint['coverage'] = 0

    def check_schema_coverage(self):
        """æ£€æŸ¥JSON Schemaè¦†ç›–ç‡"""
        schema_dir = self.specs_dir / "data"

        if not schema_dir.exists():
            print(f"âš ï¸ Schemaç›®å½•ä¸å­˜åœ¨: {schema_dir}")
            return

        # è¯»å–æ‰€æœ‰schemaæ–‡ä»¶
        schema_files = list(schema_dir.glob("*.schema.json"))

        for model in self.data_models:
            model_name = model['name']

            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„schemaæ–‡ä»¶
            # è½¬æ¢é©¼å³°åˆ°kebab-case
            # ä¾‹å¦‚: NodeCreate â†’ node-create.schema.json
            kebab_name = re.sub(r'(?<!^)(?=[A-Z])', '-', model_name).lower()

            matched = False
            for schema_file in schema_files:
                if kebab_name in schema_file.stem:
                    model['schema_status'] = f'âœ…{schema_file.name}'
                    model['coverage'] = 100
                    matched = True
                    break

            if not matched:
                model['schema_status'] = 'âŒæœªå®šä¹‰'
                model['coverage'] = 0

    def generate_index_markdown(self) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„SDDéœ€æ±‚ç´¢å¼•"""

        # ç»Ÿè®¡è¦†ç›–ç‡
        total_endpoints = len(self.api_endpoints)
        covered_endpoints = sum(1 for e in self.api_endpoints if e['coverage'] == 100)
        endpoint_coverage_pct = (covered_endpoints / total_endpoints * 100) if total_endpoints > 0 else 0

        total_models = len(self.data_models)
        covered_models = sum(1 for m in self.data_models if m['coverage'] == 100)
        model_coverage_pct = (covered_models / total_models * 100) if total_models > 0 else 0

        overall_coverage = (covered_endpoints + covered_models) / (total_endpoints + total_models) * 100 if (total_endpoints + total_models) > 0 else 0

        md = f"""# SDDéœ€æ±‚ç´¢å¼• (SDD Requirements Index)

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ç”Ÿæˆè„šæœ¬**: scripts/extract-sdd-requirements.py

---

## ğŸ“Š è¦†ç›–ç‡æ€»è§ˆ

| ç±»åˆ« | æ€»æ•° | å·²è¦†ç›– | è¦†ç›–ç‡ | çŠ¶æ€ |
|------|------|--------|--------|------|
| APIç«¯ç‚¹ | {total_endpoints} | {covered_endpoints} | {endpoint_coverage_pct:.1f}% | {'âœ…' if endpoint_coverage_pct >= 80 else 'âš ï¸' if endpoint_coverage_pct >= 50 else 'âŒ'} |
| æ•°æ®æ¨¡å‹ | {total_models} | {covered_models} | {model_coverage_pct:.1f}% | {'âœ…' if model_coverage_pct >= 80 else 'âš ï¸' if model_coverage_pct >= 50 else 'âŒ'} |
| **æ€»ä½“** | {total_endpoints + total_models} | {covered_endpoints + covered_models} | {overall_coverage:.1f}% | {'âœ…' if overall_coverage >= 80 else 'âš ï¸' if overall_coverage >= 50 else 'âŒ'} |

**è´¨é‡é—¨ç¦**: è¦†ç›–ç‡éœ€è¾¾åˆ° â‰¥80% æ‰èƒ½é€šè¿‡Planning Finalize

---

## ğŸ”— APIç«¯ç‚¹æ¸…å• (æ¥è‡ªPRD Epic 15)

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° | PRDä½ç½® | OpenAPIçŠ¶æ€ | è¦†ç›–ç‡ |
|------|------|------|---------|-------------|--------|
"""

        # æŒ‰åˆ†ç±»ç»„ç»‡ç«¯ç‚¹
        categories = {}
        for endpoint in self.api_endpoints:
            cat = endpoint['category']
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(endpoint)

        for category, eps in categories.items():
            md += f"\n### {category}\n\n"
            for ep in eps:
                md += f"| {ep['path']} | `{ep['method']}` | {ep['description']} | {ep['prd_file']}:L{ep['prd_line']} | {ep['openapi_status']} | {ep['coverage']}% |\n"

        md += f"""
---

## ğŸ“¦ æ•°æ®æ¨¡å‹æ¸…å• (æ¥è‡ªPRD Epic 15)

| æ¨¡å‹åç§° | åˆ†ç±» | PRDä½ç½® | SchemaçŠ¶æ€ | è¦†ç›–ç‡ |
|----------|------|---------|------------|--------|
"""

        # æŒ‰åˆ†ç±»ç»„ç»‡æ¨¡å‹
        model_categories = {}
        for model in self.data_models:
            cat = model['category']
            if cat not in model_categories:
                model_categories[cat] = []
            model_categories[cat].append(model)

        for category, models in model_categories.items():
            md += f"\n### {category}\n\n"
            for model in models:
                md += f"| `{model['name']}` | {model['category']} | {model['prd_file']}:L{model['prd_line']} | {model['schema_status']} | {model['coverage']}% |\n"

        md += """
---

## ğŸ” è¿½æº¯çŸ©é˜µ

### PRDéœ€æ±‚ â†’ OpenAPIç«¯ç‚¹ â†’ JSON Schema â†’ Story

| PRDéœ€æ±‚ | OpenAPIè·¯å¾„ | ç›¸å…³Schema | Storyå¼•ç”¨ |
|---------|-------------|-----------|----------|
"""

        # ç®€å•è¿½æº¯çŸ©é˜µï¼ˆéœ€è¦åç»­å®Œå–„ï¼‰
        for endpoint in self.api_endpoints[:5]:  # ç¤ºä¾‹å‰5ä¸ª
            path = endpoint['path']
            method = endpoint['method']
            # çŒœæµ‹ç›¸å…³Schemaï¼ˆå®é™…éœ€è¦æ›´æ™ºèƒ½çš„æ˜ å°„ï¼‰
            related_schemas = []
            for model in self.data_models:
                if 'Request' in model['name'] or 'Response' in model['name']:
                    if any(keyword in path for keyword in ['node', 'edge', 'canvas', 'agent', 'review']):
                        related_schemas.append(f"`{model['name']}`")

            schemas_str = ", ".join(related_schemas[:2]) if related_schemas else "_TBD_"
            md += f"| {endpoint['description']} | `{method} {path}` | {schemas_str} | _å¾…å…³è”_ |\n"

        md += """
_(è¿½æº¯çŸ©é˜µæŒç»­æ›´æ–°ä¸­...)_

---

## ğŸ“‹ å¾…åˆ›å»ºSDDæ¸…å•

### ç¼ºå¤±çš„OpenAPIç«¯ç‚¹
"""

        missing_endpoints = [e for e in self.api_endpoints if e['coverage'] < 100]
        if missing_endpoints:
            for ep in missing_endpoints:
                md += f"- [ ] `{ep['method']} {ep['path']}` - {ep['description']} ({ep['openapi_status']})\n"
        else:
            md += "_âœ… æ‰€æœ‰APIç«¯ç‚¹å·²å®šä¹‰_\n"

        md += """
### ç¼ºå¤±çš„JSON Schema
"""

        missing_models = [m for m in self.data_models if m['coverage'] < 100]
        if missing_models:
            for model in missing_models:
                kebab_name = re.sub(r'(?<!^)(?=[A-Z])', '-', model['name']).lower()
                md += f"- [ ] `{model['name']}` â†’ `specs/data/{kebab_name}.schema.json`\n"
        else:
            md += "_âœ… æ‰€æœ‰æ•°æ®æ¨¡å‹å·²å®šä¹‰Schema_\n"

        md += """
---

## ğŸ› ï¸ ä½¿ç”¨æŒ‡å—

### Architectåˆ›å»ºOpenAPIç«¯ç‚¹

```bash
# 1. è¯»å–æœ¬Indexï¼Œç¡®è®¤å¾…åˆ›å»ºç«¯ç‚¹
# 2. æ‰§è¡Œåˆ›å»ºå‘½ä»¤ï¼ˆå«Context7éªŒè¯ï¼‰
@architect *create-openapi "/api/v1/canvas/{canvas_name}"

# 3. Indexä¼šè‡ªåŠ¨æ›´æ–°è¦†ç›–ç‡
```

### Architectåˆ›å»ºJSON Schema

```bash
# 1. è¯»å–æœ¬Indexï¼Œç¡®è®¤å¾…åˆ›å»ºSchema
# 2. æ‰§è¡Œåˆ›å»ºå‘½ä»¤ï¼ˆå«Context7éªŒè¯ï¼‰
@architect *create-schemas "NodeCreate"

# 3. Indexä¼šè‡ªåŠ¨æ›´æ–°è¦†ç›–ç‡
```

### SMåˆ›å»ºStoryæ—¶æ£€æŸ¥

```bash
# SM Agentè‡ªåŠ¨æ‰§è¡Œï¼š
# 1. è¯»å–SDD Index
# 2. æ£€æŸ¥Storyæ¶‰åŠçš„ç«¯ç‚¹/æ¨¡å‹æ˜¯å¦å·²æœ‰SDD
# 3. ç¼ºå¤±åˆ™HALTï¼Œé€šçŸ¥Architectè¡¥å……
```

---

## ğŸ“Œ æ³¨æ„äº‹é¡¹

1. **æœ¬æ–‡ä»¶è‡ªåŠ¨ç”Ÿæˆ** - è¯·å‹¿æ‰‹åŠ¨ç¼–è¾‘ç»Ÿè®¡æ•°æ®
2. **æ›´æ–°é¢‘ç‡** - æ¯æ¬¡è¿è¡Œ`scripts/extract-sdd-requirements.py`è‡ªåŠ¨æ›´æ–°
3. **è´¨é‡é—¨ç¦** - Planning Finalizeæ—¶æ£€æŸ¥è¦†ç›–ç‡ â‰¥80%
4. **è¿½æº¯å®Œæ•´æ€§** - ç¡®ä¿æ¯ä¸ªSDDéƒ½èƒ½è¿½æº¯åˆ°PRDéœ€æ±‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: {datetime.now().strftime('%Y-%m-%d')}
"""

        return md

    def save_index(self, output_file: Path):
        """ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_file.parent.mkdir(parents=True, exist_ok=True)

        md_content = self.generate_index_markdown()

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(md_content)

        print(f"âœ… SDDéœ€æ±‚ç´¢å¼•å·²ç”Ÿæˆ: {output_file}")
        print(f"ğŸ“Š APIç«¯ç‚¹: {len(self.api_endpoints)} ä¸ª")
        print(f"ğŸ“¦ æ•°æ®æ¨¡å‹: {len(self.data_models)} ä¸ª")

    def run(self):
        """æ‰§è¡Œæå–æµç¨‹"""
        print("ğŸ” å¼€å§‹æå–SDDéœ€æ±‚...")

        # 1. æå–APIç«¯ç‚¹
        print("\nğŸ“¡ æå–APIç«¯ç‚¹...")
        epic15_file = self.prd_dir / "epics" / "EPIC-15-FastAPI.md"
        if epic15_file.exists():
            self.api_endpoints = self.extract_api_endpoints_from_epic(epic15_file)
            print(f"   âœ… ä»{epic15_file.name}æå– {len(self.api_endpoints)} ä¸ªAPIç«¯ç‚¹")
        else:
            print(f"   âš ï¸ {epic15_file} ä¸å­˜åœ¨")

        # 2. æå–æ•°æ®æ¨¡å‹
        print("\nğŸ“¦ æå–æ•°æ®æ¨¡å‹...")
        if epic15_file.exists():
            self.data_models = self.extract_data_models_from_epic(epic15_file)
            print(f"   âœ… ä»{epic15_file.name}æå– {len(self.data_models)} ä¸ªæ•°æ®æ¨¡å‹")

        # 3. æ£€æŸ¥OpenAPIè¦†ç›–ç‡
        print("\nğŸ” æ£€æŸ¥OpenAPIè¦†ç›–ç‡...")
        if self.api_endpoints:
            self.check_openapi_coverage()
            covered = sum(1 for e in self.api_endpoints if e['coverage'] == 100)
            print(f"   âœ… OpenAPIè¦†ç›–: {covered}/{len(self.api_endpoints)} ({covered/len(self.api_endpoints)*100:.1f}%)")
        else:
            print("   âš ï¸ æ²¡æœ‰æ‰¾åˆ°APIç«¯ç‚¹")

        # 4. æ£€æŸ¥Schemaè¦†ç›–ç‡
        print("\nğŸ” æ£€æŸ¥Schemaè¦†ç›–ç‡...")
        if self.data_models:
            self.check_schema_coverage()
            covered_models = sum(1 for m in self.data_models if m['coverage'] == 100)
            print(f"   âœ… Schemaè¦†ç›–: {covered_models}/{len(self.data_models)} ({covered_models/len(self.data_models)*100:.1f}%)")
        else:
            print("   âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ¨¡å‹")

        # 5. ç”Ÿæˆç´¢å¼•
        print("\nğŸ“ ç”ŸæˆSDDéœ€æ±‚ç´¢å¼•...")
        output_file = self.project_root / "docs" / "specs" / "sdd-requirements-index.md"
        self.save_index(output_file)

        print("\nâœ¨ æå–å®Œæˆï¼")


def main():
    # é¡¹ç›®æ ¹ç›®å½•
    project_root = Path(__file__).parent.parent

    extractor = SDDRequirementsExtractor(str(project_root))
    extractor.run()


if __name__ == "__main__":
    main()
