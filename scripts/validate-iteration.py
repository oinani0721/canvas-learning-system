#!/usr/bin/env python3
"""
Planning Phase Iteration Validator
éªŒè¯ä¸¤æ¬¡Planningè¿­ä»£é—´çš„ä¸€è‡´æ€§ï¼Œæ£€æµ‹Breaking Changes
"""

import sys
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional

# æ·»åŠ libç›®å½•åˆ°path
sys.path.insert(0, str(Path(__file__).parent / "lib"))

from planning_utils import (
    init_utf8_encoding,
    load_snapshot,
    load_validation_rules,
    generate_markdown_report,
    compare_versions,
    print_status,
    get_project_root
)

# ========================================
# éªŒè¯ç»“æœç±»
# ========================================

class ValidationResult:
    """éªŒè¯ç»“æœ"""
    def __init__(self):
        self.breaking_changes: List[Dict] = []
        self.warnings: List[Dict] = []
        self.info: List[Dict] = []

    def add_breaking_change(self, type: str, details: Any, recommendation: str):
        self.breaking_changes.append({
            "type": type,
            "details": details,
            "severity": "HIGH",
            "recommendation": recommendation
        })

    def add_warning(self, type: str, details: Any, recommendation: str = ""):
        self.warnings.append({
            "type": type,
            "details": details,
            "severity": "MEDIUM",
            "recommendation": recommendation
        })

    def add_info(self, type: str, details: Any):
        self.info.append({
            "type": type,
            "details": details,
            "severity": "LOW"
        })

    def has_breaking_changes(self) -> bool:
        return len(self.breaking_changes) > 0

    def has_warnings(self) -> bool:
        return len(self.warnings) > 0

# ========================================
# PRDéªŒè¯é€»è¾‘
# ========================================

def validate_prd_changes(prev: Dict, curr: Dict, rules: Dict) -> ValidationResult:
    """éªŒè¯PRDæ–‡ä»¶çš„å˜æ›´"""
    result = ValidationResult()

    prev_files = {f['path']: f for f in prev.get("files", {}).get("prd", [])}
    curr_files = {f['path']: f for f in curr.get("files", {}).get("prd", [])}

    # æ£€æŸ¥æ–‡ä»¶åˆ é™¤
    deleted_files = set(prev_files.keys()) - set(curr_files.keys())
    if deleted_files and not rules.get("prd_validation", {}).get("can_delete", True):
        result.add_breaking_change(
            "PRD File Deletion",
            list(deleted_files),
            "æ¢å¤è¢«åˆ é™¤çš„PRDæ–‡ä»¶æˆ–æ˜ç¡®æ ‡è®°ä¸ºdeprecated"
        )

    # æ£€æŸ¥ç‰ˆæœ¬å·é€’å¢
    for path in curr_files:
        if path in prev_files:
            prev_version = prev_files[path].get("version", "unknown")
            curr_version = curr_files[path].get("version", "unknown")

            if prev_version != "unknown" and curr_version != "unknown":
                if compare_versions(curr_version, prev_version) <= 0:
                    if rules.get("prd_validation", {}).get("version_must_increment", True):
                        result.add_warning(
                            "PRD Version Not Incremented",
                            f"{path}: {prev_version} â†’ {curr_version}",
                            "é€’å¢ç‰ˆæœ¬å·ä»¥åæ˜ å˜æ›´"
                        )

            # æ£€æŸ¥hashå˜åŒ–
            if prev_files[path]["hash"] != curr_files[path]["hash"]:
                result.add_info(
                    "PRD File Modified",
                    f"{path}: Version {curr_version}"
                )

    # æ£€æŸ¥æ–°å¢æ–‡ä»¶
    added_files = set(curr_files.keys()) - set(prev_files.keys())
    for path in added_files:
        result.add_info(
            "New PRD File Added",
            path
        )

    return result

# ========================================
# ArchitectureéªŒè¯é€»è¾‘
# ========================================

def validate_architecture_changes(prev: Dict, curr: Dict, rules: Dict) -> ValidationResult:
    """éªŒè¯Architectureæ–‡ä»¶çš„å˜æ›´"""
    result = ValidationResult()

    prev_files = {f['path']: f for f in prev.get("files", {}).get("architecture", [])}
    curr_files = {f['path']: f for f in curr.get("files", {}).get("architecture", [])}

    # æ£€æŸ¥æ–‡ä»¶åˆ é™¤
    deleted_files = set(prev_files.keys()) - set(curr_files.keys())
    if deleted_files:
        result.add_breaking_change(
            "Architecture File Deletion",
            list(deleted_files),
            "Architectureæ–‡ä»¶ä¸èƒ½åˆ é™¤ï¼Œåªèƒ½æ ‡è®°ä¸ºdeprecated"
        )

    # æ£€æŸ¥ç‰ˆæœ¬å·é€’å¢
    for path in curr_files:
        if path in prev_files:
            prev_version = prev_files[path].get("version", "unknown")
            curr_version = curr_files[path].get("version", "unknown")

            if prev_version != "unknown" and curr_version != "unknown":
                if compare_versions(curr_version, prev_version) <= 0:
                    result.add_warning(
                        "Architecture Version Not Incremented",
                        f"{path}: {prev_version} â†’ {curr_version}",
                        "é€’å¢ç‰ˆæœ¬å·ä»¥åæ˜ å˜æ›´"
                    )

            # æ£€æŸ¥hashå˜åŒ–
            if prev_files[path]["hash"] != curr_files[path]["hash"]:
                result.add_info(
                    "Architecture File Modified",
                    f"{path}: Version {curr_version}"
                )

    return result

# ========================================
# OpenAPIéªŒè¯é€»è¾‘
# ========================================

def validate_openapi_changes(prev: Dict, curr: Dict, rules: Dict) -> ValidationResult:
    """éªŒè¯OpenAPI Specçš„å˜æ›´"""
    result = ValidationResult()

    prev_specs = {f['path']: f for f in prev.get("files", {}).get("api_specs", [])}
    curr_specs = {f['path']: f for f in curr.get("files", {}).get("api_specs", [])}

    # æ£€æŸ¥OpenAPI specåˆ é™¤
    deleted_specs = set(prev_specs.keys()) - set(curr_specs.keys())
    if deleted_specs:
        result.add_breaking_change(
            "OpenAPI Spec File Deleted",
            list(deleted_specs),
            "ä¸èƒ½åˆ é™¤OpenAPI specæ–‡ä»¶"
        )

    # æ£€æŸ¥ç‰ˆæœ¬å’Œhashå˜åŒ–
    for path in curr_specs:
        if path in prev_specs:
            prev_version = prev_specs[path].get("version", "unknown")
            curr_version = curr_specs[path].get("version", "unknown")
            prev_hash = prev_specs[path]["hash"]
            curr_hash = curr_specs[path]["hash"]

            # Hashå˜åŒ–ä½†ç‰ˆæœ¬æœªå˜
            if prev_hash != curr_hash:
                if prev_version == curr_version:
                    result.add_warning(
                        "OpenAPI Spec Modified Without Version Change",
                        f"{path}: Content changed but version unchanged ({curr_version})",
                        "æ›´æ–°OpenAPI specçš„versionå­—æ®µ"
                    )
                else:
                    result.add_info(
                        "OpenAPI Spec Modified",
                        f"{path}: {prev_version} â†’ {curr_version}"
                    )

    return result

# ========================================
# EpicéªŒè¯é€»è¾‘
# ========================================

def validate_epic_changes(prev: Dict, curr: Dict, rules: Dict) -> ValidationResult:
    """éªŒè¯Epicæ–‡ä»¶çš„å˜æ›´"""
    result = ValidationResult()

    prev_epics = {f['path']: f for f in prev.get("files", {}).get("epics", [])}
    curr_epics = {f['path']: f for f in curr.get("files", {}).get("epics", [])}

    # æ£€æŸ¥Epicåˆ é™¤
    deleted_epics = set(prev_epics.keys()) - set(curr_epics.keys())
    if deleted_epics and not rules.get("prd_validation", {}).get("epics", {}).get("can_delete", False):
        result.add_breaking_change(
            "Epic Deleted",
            list(deleted_epics),
            "Epicä¸èƒ½åˆ é™¤ï¼Œå¦‚éœ€åˆå¹¶è¯·æ˜ç¡®è®°å½•"
        )

    # æ£€æŸ¥Epicæ•°é‡å‡å°‘
    prev_count = len(prev_epics)
    curr_count = len(curr_epics)
    if curr_count < prev_count:
        result.add_warning(
            "Epic Count Decreased",
            f"ä»{prev_count}å‡å°‘åˆ°{curr_count}",
            "ç¡®è®¤Epicåˆå¹¶æˆ–åˆ é™¤æ˜¯æœ‰æ„çš„"
        )

    # æ£€æŸ¥æ–°å¢Epic
    added_epics = set(curr_epics.keys()) - set(prev_epics.keys())
    for path in added_epics:
        result.add_info(
            "New Epic Added",
            path
        )

    return result

# ========================================
# è™šæ‹Ÿæ•°æ®æ£€æµ‹
# ========================================

def detect_mock_data(prev: Dict, curr: Dict, rules: Dict) -> ValidationResult:
    """æ£€æµ‹è™šæ‹Ÿæ•°æ®å¼•å…¥"""
    result = ValidationResult()

    custom_rules = rules.get("custom_rules", {})
    mock_detection = custom_rules.get("detect_mock_data_introduction", {})

    if not mock_detection.get("enabled", False):
        return result

    patterns = mock_detection.get("patterns", [])

    # æ£€æŸ¥æ‰€æœ‰æ–°å¢æˆ–ä¿®æ”¹çš„æ–‡ä»¶
    all_curr_files = []
    for category in curr.get("files", {}).values():
        all_curr_files.extend(category)

    all_prev_files = {f['path']: f for files in prev.get("files", {}).values() for f in files}

    for file in all_curr_files:
        path = file['path']
        curr_hash = file['hash']

        # æ–°å¢æˆ–ä¿®æ”¹çš„æ–‡ä»¶
        if path not in all_prev_files or all_prev_files[path]['hash'] != curr_hash:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«mock data patterns
            # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦è¯»å–æ–‡ä»¶å†…å®¹æ£€æŸ¥
            for pattern in patterns:
                if pattern.lower() in path.lower():
                    result.add_warning(
                        "Potential Mock Data Detected",
                        f"{path} contains pattern '{pattern}'",
                        "ç¡®è®¤è¿™æ˜¯çœŸå®æ•°æ®è€Œéè™šæ‹Ÿæ•°æ®"
                    )
                    break

    return result

# ========================================
# ä¸»éªŒè¯é€»è¾‘
# ========================================

def validate_iterations(prev_iteration: int, curr_iteration: int, rules: Dict) -> ValidationResult:
    """éªŒè¯ä¸¤æ¬¡è¿­ä»£é—´çš„ä¸€è‡´æ€§"""
    print_status(f"Loading snapshots...", "progress")

    prev_snapshot = load_snapshot(prev_iteration)
    curr_snapshot = load_snapshot(curr_iteration)

    if prev_snapshot is None:
        raise FileNotFoundError(f"Previous snapshot not found: iteration-{prev_iteration:03d}.json")

    if curr_snapshot is None:
        raise FileNotFoundError(f"Current snapshot not found: iteration-{curr_iteration:03d}.json")

    print_status(f"Validating Iteration {prev_iteration} â†’ {curr_iteration}...", "progress")

    combined_result = ValidationResult()

    # PRDéªŒè¯
    print_status("  Validating PRD changes...", "progress")
    prd_result = validate_prd_changes(prev_snapshot, curr_snapshot, rules)
    combined_result.breaking_changes.extend(prd_result.breaking_changes)
    combined_result.warnings.extend(prd_result.warnings)
    combined_result.info.extend(prd_result.info)

    # ArchitectureéªŒè¯
    print_status("  Validating Architecture changes...", "progress")
    arch_result = validate_architecture_changes(prev_snapshot, curr_snapshot, rules)
    combined_result.breaking_changes.extend(arch_result.breaking_changes)
    combined_result.warnings.extend(arch_result.warnings)
    combined_result.info.extend(arch_result.info)

    # OpenAPIéªŒè¯
    print_status("  Validating OpenAPI Spec changes...", "progress")
    api_result = validate_openapi_changes(prev_snapshot, curr_snapshot, rules)
    combined_result.breaking_changes.extend(api_result.breaking_changes)
    combined_result.warnings.extend(api_result.warnings)
    combined_result.info.extend(api_result.info)

    # EpicéªŒè¯
    print_status("  Validating Epic changes...", "progress")
    epic_result = validate_epic_changes(prev_snapshot, curr_snapshot, rules)
    combined_result.breaking_changes.extend(epic_result.breaking_changes)
    combined_result.warnings.extend(epic_result.warnings)
    combined_result.info.extend(epic_result.info)

    # è™šæ‹Ÿæ•°æ®æ£€æµ‹
    print_status("  Detecting mock data introduction...", "progress")
    mock_result = detect_mock_data(prev_snapshot, curr_snapshot, rules)
    combined_result.breaking_changes.extend(mock_result.breaking_changes)
    combined_result.warnings.extend(mock_result.warnings)
    combined_result.info.extend(mock_result.info)

    return combined_result, prev_snapshot, curr_snapshot

# ========================================
# æŠ¥å‘Šç”Ÿæˆ
# ========================================

def generate_validation_report(
    result: ValidationResult,
    prev_snapshot: Dict,
    curr_snapshot: Dict,
    output_path: Path
):
    """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
    sections = []

    # Summary
    summary_content = f"""
**Previous Iteration**: {prev_snapshot['iteration']}
**Current Iteration**: {curr_snapshot['iteration']}
**Previous Git Commit**: `{prev_snapshot['git_commit'][:8]}...`
**Current Git Commit**: `{curr_snapshot['git_commit'][:8]}...`

**Validation Results**:
- ğŸ”´ Breaking Changes: {len(result.breaking_changes)}
- ğŸŸ¡ Warnings: {len(result.warnings)}
- ğŸŸ¢ Info: {len(result.info)}
"""
    sections.append({"title": "Summary", "content": summary_content})

    # Breaking Changes
    if result.breaking_changes:
        bc_content = ""
        for i, change in enumerate(result.breaking_changes, 1):
            bc_content += f"### {i}. âŒ {change['type']}\n\n"
            bc_content += f"**Details**: {change['details']}\n\n"
            bc_content += f"**Severity**: {change['severity']}\n\n"
            bc_content += f"**Recommendation**: {change['recommendation']}\n\n"
            bc_content += "---\n\n"
        sections.append({"title": "ğŸ”´ Breaking Changes", "content": bc_content})

    # Warnings
    if result.warnings:
        warn_content = ""
        for i, warning in enumerate(result.warnings, 1):
            warn_content += f"### {i}. âš ï¸ {warning['type']}\n\n"
            warn_content += f"**Details**: {warning['details']}\n\n"
            warn_content += f"**Recommendation**: {warning.get('recommendation', 'Review manually')}\n\n"
            warn_content += "---\n\n"
        sections.append({"title": "ğŸŸ¡ Warnings", "content": warn_content})

    # Info
    if result.info:
        info_content = ""
        for i, info in enumerate(result.info, 1):
            info_content += f"{i}. âœ… **{info['type']}**: {info['details']}\n\n"
        sections.append({"title": "ğŸŸ¢ Info", "content": info_content})

    # Version Matrix
    version_matrix = f"""
| Category | Previous | Current | Change |
|----------|----------|---------|--------|
| PRD Files | {prev_snapshot['statistics']['prd_count']} | {curr_snapshot['statistics']['prd_count']} | {curr_snapshot['statistics']['prd_count'] - prev_snapshot['statistics']['prd_count']:+d} |
| Architecture Files | {prev_snapshot['statistics']['architecture_count']} | {curr_snapshot['statistics']['architecture_count']} | {curr_snapshot['statistics']['architecture_count'] - prev_snapshot['statistics']['architecture_count']:+d} |
| Epic Files | {prev_snapshot['statistics']['epic_count']} | {curr_snapshot['statistics']['epic_count']} | {curr_snapshot['statistics']['epic_count'] - prev_snapshot['statistics']['epic_count']:+d} |
| API Specs | {prev_snapshot['statistics']['api_spec_count']} | {curr_snapshot['statistics']['api_spec_count']} | {curr_snapshot['statistics']['api_spec_count'] - prev_snapshot['statistics']['api_spec_count']:+d} |
"""
    sections.append({"title": "Version Matrix", "content": version_matrix})

    # Recommendations
    if result.has_breaking_changes():
        rec_content = """
ğŸ”´ **Critical**: This iteration contains Breaking Changes.

**Required Actions**:
1. Review all Breaking Changes listed above
2. For each Breaking Change, decide:
   - **Accept**: Update OpenAPI spec version (Major increment) and document in CHANGELOG
   - **Reject**: Revert changes to avoid breaking change
   - **Modify**: Adjust implementation to avoid breaking change
3. DO NOT proceed until all Breaking Changes are resolved
4. Run validation again after fixes

**How to Fix**:
```bash
# If accepting breaking changes
python scripts/finalize-iteration.py --breaking

# If reverting
git checkout docs/prd.md  # Example: revert specific file
python scripts/validate-iteration.py  # Re-validate
```
"""
        sections.append({"title": "Recommendations", "content": rec_content})
    elif result.has_warnings():
        rec_content = """
ğŸŸ¡ **Warnings Found**: Review recommended, but not blocking.

**Suggested Actions**:
1. Review all warnings
2. Address concerns or document reasons for ignoring
3. Proceed with caution

**You can proceed with**:
```bash
python scripts/finalize-iteration.py
```
"""
        sections.append({"title": "Recommendations", "content": rec_content})
    else:
        rec_content = """
âœ… **All Checks Passed**: No issues detected.

**Next Steps**:
```bash
python scripts/finalize-iteration.py
git commit -m "Planning Iteration {curr_snapshot['iteration']} Complete"
```
"""
        sections.append({"title": "Recommendations", "content": rec_content})

    # ç”ŸæˆæŠ¥å‘Š
    report = generate_markdown_report(
        f"Planning Iteration {curr_snapshot['iteration']} Validation Report",
        sections
    )

    # ä¿å­˜æŠ¥å‘Š
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print_status(f"Validation report saved: {output_path}", "success")

# ========================================
# CLIæ¥å£
# ========================================

def main():
    import argparse

    parser = argparse.ArgumentParser(
        description="Validate consistency between Planning Phase iterations"
    )
    parser.add_argument(
        '--iteration',
        type=int,
        required=True,
        help='Current iteration number to validate'
    )
    parser.add_argument(
        '--final',
        action='store_true',
        help='Run final validation before finalize (stricter checks)'
    )
    parser.add_argument(
        '--output',
        type=str,
        help='Output report path (default: iteration-{iteration}-validation-report.md)'
    )

    args = parser.parse_args()

    # Auto-detect previous iteration
    previous_iteration = args.iteration - 1 if args.iteration > 1 else 1
    current_iteration = args.iteration

    # Initialize UTF-8 encoding for Windows
    init_utf8_encoding()

    # åŠ è½½éªŒè¯è§„åˆ™
    try:
        rules = load_validation_rules()
    except FileNotFoundError as e:
        print_status(f"Error: {e}", "error")
        return 1

    # æ‰§è¡ŒéªŒè¯
    try:
        result, prev_snapshot, curr_snapshot = validate_iterations(
            previous_iteration,
            current_iteration,
            rules
        )
    except FileNotFoundError as e:
        print_status(f"Error: {e}", "error")
        return 1

    # ç”ŸæˆæŠ¥å‘Š
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = get_project_root() / f"iteration-{current_iteration:03d}-validation-report.md"

    # Final validation stricter mode
    if args.final:
        print_status("Running FINAL validation (stricter checks)...", "warning")

    generate_validation_report(result, prev_snapshot, curr_snapshot, output_path)

    # æ‰“å°æ‘˜è¦
    print("\n" + "="*60)
    print("ğŸ“Š Validation Summary")
    print("="*60)
    print(f"ğŸ”´ Breaking Changes: {len(result.breaking_changes)}")
    print(f"ğŸŸ¡ Warnings: {len(result.warnings)}")
    print(f"ğŸŸ¢ Info: {len(result.info)}")
    print("="*60)

    if result.has_breaking_changes():
        print("\nâŒ VALIDATION FAILED: Breaking changes detected!")
        print(f"Review the report: {output_path}")
        return 1
    elif result.has_warnings():
        print("\nâš ï¸ VALIDATION PASSED WITH WARNINGS")
        print(f"Review the report: {output_path}")
        return 0
    else:
        print("\nâœ… VALIDATION PASSED: No issues detected!")
        return 0

if __name__ == "__main__":
    sys.exit(main())
