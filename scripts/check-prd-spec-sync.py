#!/usr/bin/env python3
"""
PRD-Spec Drift Detection Script
æ£€æµ‹PRDä¸SDDè§„èŒƒä¹‹é—´çš„ä¸ä¸€è‡´

åŠŸèƒ½:
1. æ£€æŸ¥PRDä¸­å®šä¹‰çš„APIç«¯ç‚¹æ˜¯å¦åœ¨OpenAPIè§„èŒƒä¸­å­˜åœ¨
2. æ£€æŸ¥PRDä¸­å®šä¹‰çš„æ•°æ®æ¨¡å‹æ˜¯å¦æœ‰å¯¹åº”çš„JSON Schema
3. æ£€æŸ¥Epic/Storyæ˜¯å¦æœ‰å¯¹åº”çš„Gherkinè¡Œä¸ºè§„èŒƒ
4. æŠ¥å‘Šorphaned specs (è§„èŒƒå­˜åœ¨ä½†PRDä¸­æ²¡æœ‰å¼•ç”¨)

ç”¨æ³•:
  python scripts/check-prd-spec-sync.py

è¿”å›ç :
  0 - åŒæ­¥æ­£å¸¸
  1 - æ£€æµ‹åˆ°drift (éœ€è¦ä¿®å¤)
"""

import sys
import re
from pathlib import Path
from typing import List, Dict, Set, Tuple


def get_project_root() -> Path:
    """è·å–é¡¹ç›®æ ¹ç›®å½•"""
    return Path(__file__).parent.parent


def extract_api_endpoints_from_prd(prd_content: str) -> Set[str]:
    """ä»PRDå†…å®¹ä¸­æå–APIç«¯ç‚¹å®šä¹‰"""
    endpoints = set()

    # åŒ¹é…å¸¸è§çš„APIç«¯ç‚¹æ¨¡å¼
    # ä¾‹å¦‚: GET /api/canvas/nodes, POST /api/scoring
    patterns = [
        r'(GET|POST|PUT|DELETE|PATCH)\s+(/api/[a-zA-Z0-9/_\-{}]+)',
        r'`(GET|POST|PUT|DELETE|PATCH)\s+(/api/[a-zA-Z0-9/_\-{}]+)`',
        r'endpoint[:\s]+[`"]?(/api/[a-zA-Z0-9/_\-{}]+)[`"]?',
    ]

    for pattern in patterns:
        matches = re.findall(pattern, prd_content, re.IGNORECASE)
        for match in matches:
            if isinstance(match, tuple):
                endpoint = match[1] if len(match) > 1 else match[0]
            else:
                endpoint = match
            # æ ‡å‡†åŒ–ç«¯ç‚¹æ ¼å¼
            endpoint = endpoint.strip().lower()
            endpoints.add(endpoint)

    return endpoints


def extract_endpoints_from_openapi(openapi_path: Path) -> Set[str]:
    """ä»OpenAPIè§„èŒƒä¸­æå–å·²å®šä¹‰çš„ç«¯ç‚¹"""
    endpoints = set()

    if not openapi_path.exists():
        return endpoints

    content = openapi_path.read_text(encoding='utf-8')

    # ç®€å•çš„YAMLè·¯å¾„è§£æ
    # åŒ¹é… paths: ä¸‹çš„ç«¯ç‚¹å®šä¹‰
    in_paths = False
    for line in content.split('\n'):
        if line.strip() == 'paths:':
            in_paths = True
            continue

        if in_paths:
            # æ£€æµ‹æ–°çš„é¡¶çº§é”®
            if line and not line.startswith(' ') and not line.startswith('\t'):
                in_paths = False
                continue

            # æå–è·¯å¾„
            match = re.match(r'^  ["\']?(/[a-zA-Z0-9/_\-{}]+)["\']?:', line)
            if match:
                endpoint = match.group(1).lower()
                endpoints.add(endpoint)

    return endpoints


def extract_data_models_from_prd(prd_content: str) -> Set[str]:
    """ä»PRDä¸­æå–æ•°æ®æ¨¡å‹åç§°"""
    models = set()

    # åŒ¹é…æ¨¡å¼å¦‚: "Canvas Node Schema", "User Model", etc.
    patterns = [
        r'(?:schema|model)[:\s]+[`"]?([A-Z][a-zA-Z0-9]+)[`"]?',
        r'[`"]([A-Z][a-zA-Z0-9]+)(?:Schema|Model)[`"]',
        r'æ•°æ®æ¨¡å‹[:\s]+[`"]?([A-Z][a-zA-Z0-9]+)[`"]?',
    ]

    for pattern in patterns:
        matches = re.findall(pattern, prd_content, re.IGNORECASE)
        for match in matches:
            models.add(match.lower())

    return models


def extract_schemas_from_specs(specs_dir: Path) -> Set[str]:
    """ä»specs/data/ç›®å½•æå–å·²å®šä¹‰çš„Schema"""
    schemas = set()

    data_dir = specs_dir / 'data'
    if not data_dir.exists():
        return schemas

    for schema_file in data_dir.glob('*.json'):
        # ä»æ–‡ä»¶åæå–schemaå
        name = schema_file.stem.replace('.schema', '').replace('-', '').lower()
        schemas.add(name)

    return schemas


def extract_epics_from_prd(prd_dir: Path) -> Set[str]:
    """æå–PRDä¸­å®šä¹‰çš„Epicç¼–å·"""
    epics = set()

    for prd_file in prd_dir.glob('**/*.md'):
        content = prd_file.read_text(encoding='utf-8')
        # åŒ¹é… Epic N, Epic-N, epic N ç­‰æ ¼å¼
        matches = re.findall(r'epic[- ]?(\d+)', content, re.IGNORECASE)
        epics.update(matches)

    return epics


def extract_epics_from_features(behavior_dir: Path) -> Set[str]:
    """ä»Gherkinè§„èŒƒçš„@epicæ ‡ç­¾ä¸­æå–Epicç¼–å·"""
    epics = set()

    if not behavior_dir.exists():
        return epics

    for feature_file in behavior_dir.glob('*.feature'):
        content = feature_file.read_text(encoding='utf-8')
        # åŒ¹é… @epic-N æ ‡ç­¾
        matches = re.findall(r'@epic-(\d+)', content)
        epics.update(matches)

    return epics


def check_sync() -> Tuple[List[str], List[str], List[str]]:
    """
    æ‰§è¡ŒåŒæ­¥æ£€æŸ¥

    è¿”å›:
        (errors, warnings, info) - ä¸‰ä¸ªæ¶ˆæ¯åˆ—è¡¨
    """
    root = get_project_root()
    prd_dir = root / 'docs' / 'prd'
    specs_dir = root / 'specs'

    errors = []
    warnings = []
    info = []

    # 1. è¯»å–æ‰€æœ‰PRDå†…å®¹
    prd_content = ""
    if prd_dir.exists():
        for prd_file in prd_dir.glob('**/*.md'):
            prd_content += prd_file.read_text(encoding='utf-8') + "\n"

    # 2. æ£€æŸ¥APIç«¯ç‚¹åŒæ­¥
    prd_endpoints = extract_api_endpoints_from_prd(prd_content)

    openapi_files = list((specs_dir / 'api').glob('*.yml')) if (specs_dir / 'api').exists() else []
    openapi_files += list((specs_dir / 'api').glob('*.yaml')) if (specs_dir / 'api').exists() else []

    spec_endpoints = set()
    for openapi_file in openapi_files:
        spec_endpoints.update(extract_endpoints_from_openapi(openapi_file))

    # PRDä¸­æœ‰ä½†OpenAPIä¸­æ²¡æœ‰çš„ç«¯ç‚¹
    missing_in_spec = prd_endpoints - spec_endpoints
    if missing_in_spec:
        warnings.append(f"API endpoints in PRD but not in OpenAPI specs: {missing_in_spec}")

    # OpenAPIä¸­æœ‰ä½†PRDä¸­æ²¡æœ‰çš„ç«¯ç‚¹ (orphaned)
    orphaned_endpoints = spec_endpoints - prd_endpoints
    if orphaned_endpoints:
        info.append(f"API endpoints in specs but not referenced in PRD: {orphaned_endpoints}")

    # 3. æ£€æŸ¥æ•°æ®æ¨¡å‹åŒæ­¥
    prd_models = extract_data_models_from_prd(prd_content)
    spec_schemas = extract_schemas_from_specs(specs_dir)

    # PRDä¸­æœ‰ä½†Schemaä¸­æ²¡æœ‰çš„æ¨¡å‹
    missing_schemas = prd_models - spec_schemas
    if missing_schemas:
        warnings.append(f"Data models in PRD but no JSON Schema: {missing_schemas}")

    # 4. æ£€æŸ¥Epic-FeatureåŒæ­¥
    prd_epics = extract_epics_from_prd(prd_dir)
    feature_epics = extract_epics_from_features(specs_dir / 'behavior')

    # PRDä¸­çš„Epicæ²¡æœ‰å¯¹åº”çš„Featureæ–‡ä»¶
    missing_features = prd_epics - feature_epics
    if missing_features:
        info.append(f"Epics without Gherkin behavior specs: {missing_features}")

    # 5. æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    required_dirs = [
        specs_dir / 'api',
        specs_dir / 'data',
        specs_dir / 'behavior',
    ]

    for dir_path in required_dirs:
        if not dir_path.exists():
            warnings.append(f"Missing specs directory: {dir_path}")

    return errors, warnings, info


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ” PRD-Spec Drift Detection")
    print("=" * 60)

    errors, warnings, info = check_sync()

    # æ‰“å°ç»“æœ
    if errors:
        print("\nâŒ ERRORS (must fix before commit):")
        for error in errors:
            print(f"  â€¢ {error}")

    if warnings:
        print("\nâš ï¸ WARNINGS (recommended to fix):")
        for warning in warnings:
            print(f"  â€¢ {warning}")

    if info:
        print("\nâ„¹ï¸ INFO:")
        for item in info:
            print(f"  â€¢ {item}")

    if not errors and not warnings and not info:
        print("\nâœ… PRD and Specs are in sync!")

    print("=" * 60)

    # è¿”å›ç : åªæœ‰errorsæ‰å¤±è´¥
    if errors:
        return 1
    return 0


if __name__ == "__main__":
    sys.exit(main())
