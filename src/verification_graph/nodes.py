"""
Verification Graph Node Functions - Socratic Q&A Flow

Epic 24: Verification Canvas Redesign (æ™ºèƒ½å¼•å¯¼æ¨¡å¼)
Story 24.2: Socratic Q&A Flow
Story 24.4: Dynamic Agent Selection (integration)
Story 24.5: RAG Context Injection

å®ç°StateGraphçš„å®Œæ•´èŠ‚ç‚¹å‡½æ•°ï¼ŒåŒ…å«:
- é—®é¢˜ç”Ÿæˆ (Socratic templates + RAG context)
- å›ç­”è¯„ä¼° (scoring integration)
- æç¤ºç”Ÿæˆ (dynamic agent selection)
- æ¦‚å¿µå®Œæˆå’Œè¿›åº¦æ›´æ–°

âœ… Verified from LangGraph Context7 (topic: StateGraph nodes):
- Node function receives state and returns dict of updates
- Async functions supported
- Partial state updates

Story 24.2 AC:
- âœ… AC 1: å®ç°é—®é¢˜ç”Ÿæˆé€»è¾‘
- âœ… AC 2: å®ç°å›ç­”è¯„ä¼°
- âœ… AC 3: å®ç°æç¤ºå¼•å¯¼
- âœ… AC 4: å®ç°æ¦‚å¿µå®Œæˆ

Story 24.5 AC:
- âœ… AC 1: RAGæœåŠ¡é›†æˆ
- âœ… AC 2: ä¸Šä¸‹æ–‡æ³¨å…¥åˆ°é—®é¢˜ç”Ÿæˆ
- âœ… AC 3: ä¼˜é›…é™çº§ (graceful fallback)

Author: Canvas Learning System Team
Version: 1.1.0
Created: 2025-12-13
Updated: 2025-12-13 (Story 24.5 RAG integration)
"""

import logging
import sys
from datetime import datetime
from typing import Any, Dict, Optional

from verification_graph.state import VerificationState

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RAG Service Integration (Story 24.5)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Lazy import RAG service to avoid circular imports
_rag_service = None
_rag_available = None


def _get_rag_service():
    """
    è·å–RAGæœåŠ¡å®ä¾‹ (å»¶è¿Ÿå¯¼å…¥)

    Story 24.5: RAGæœåŠ¡é›†æˆï¼Œæ”¯æŒä¼˜é›…é™çº§
    """
    global _rag_service, _rag_available

    if _rag_available is not None:
        return _rag_service if _rag_available else None

    try:
        # Add backend to path if needed
        if "C:/Users/ROG/æ‰˜ç¦/Canvas/backend" not in sys.path:
            sys.path.insert(0, "C:/Users/ROG/æ‰˜ç¦/Canvas/backend")

        from app.services.rag_service import RAGService

        _rag_service = RAGService()
        _rag_available = _rag_service.is_available

        if _rag_available:
            logger.info("[RAG] RAG service available for context injection")
        else:
            logger.warning(f"[RAG] RAG service not available: {_rag_service.import_error}")

        return _rag_service if _rag_available else None

    except ImportError as e:
        logger.warning(f"[RAG] Could not import RAG service: {e}")
        _rag_available = False
        return None
    except Exception as e:
        logger.error(f"[RAG] Unexpected error initializing RAG service: {e}")
        _rag_available = False
        return None


async def fetch_rag_context(
    concept: str,
    source_canvas: str,
    max_results: int = 3
) -> Optional[str]:
    """
    è·å–RAGä¸Šä¸‹æ–‡

    Story 24.5: ä»RAGæœåŠ¡è·å–ä¸å½“å‰æ¦‚å¿µç›¸å…³çš„å­¦ä¹ å†å²å’Œä¸Šä¸‹æ–‡ã€‚

    Args:
        concept: å½“å‰æ¦‚å¿µæ–‡æœ¬
        source_canvas: æºCanvasæ–‡ä»¶è·¯å¾„
        max_results: æœ€å¤§ç»“æœæ•°

    Returns:
        RAGä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼Œå¦‚æœä¸å¯ç”¨åˆ™è¿”å›None
    """
    rag_service = _get_rag_service()

    if rag_service is None:
        logger.debug("[RAG] Skipping context fetch - service not available")
        return None

    try:
        # æ„å»ºæŸ¥è¯¢
        query = f"å…³äºã€Œ{concept}ã€çš„å­¦ä¹ å†å²å’Œç›¸å…³çŸ¥è¯†"

        # æ‰§è¡ŒæŸ¥è¯¢ (ä½¿ç”¨ä¼˜é›…é™çº§ç‰ˆæœ¬)
        result = await rag_service.query_with_fallback(
            query=query,
            canvas_file=source_canvas
        )

        # æå–ä¸Šä¸‹æ–‡
        if result and result.get("reranked_results"):
            contexts = []
            for r in result["reranked_results"][:max_results]:
                if isinstance(r, dict) and r.get("content"):
                    contexts.append(r["content"][:200])  # æˆªæ–­é•¿å†…å®¹
                elif isinstance(r, str):
                    contexts.append(r[:200])

            if contexts:
                context = "\n".join(contexts)
                logger.debug(f"[RAG] Retrieved {len(contexts)} context items for concept: {concept}")
                return context

        logger.debug(f"[RAG] No context found for concept: {concept}")
        return None

    except Exception as e:
        logger.warning(f"[RAG] Error fetching context: {e}")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Question Templates (Socratic Style)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

QUESTION_TEMPLATES = {
    "definition": [
        "è¯·è§£é‡Šä»€ä¹ˆæ˜¯ã€Œ{concept}ã€ï¼Ÿ",
        "ç”¨ä½ è‡ªå·±çš„è¯æè¿°ã€Œ{concept}ã€çš„å«ä¹‰ã€‚",
        "å¦‚æœè¦å‘ä¸€ä¸ªåˆå­¦è€…è§£é‡Šã€Œ{concept}ã€ï¼Œä½ ä¼šæ€ä¹ˆè¯´ï¼Ÿ",
    ],
    "application": [
        "ã€Œ{concept}ã€åœ¨ä»€ä¹ˆåœºæ™¯ä¸‹ä¼šç”¨åˆ°ï¼Ÿ",
        "è¯·ä¸¾ä¸€ä¸ªã€Œ{concept}ã€çš„å®é™…åº”ç”¨ä¾‹å­ã€‚",
        "å¦‚ä½•å°†ã€Œ{concept}ã€åº”ç”¨åˆ°å®é™…é—®é¢˜ä¸­ï¼Ÿ",
    ],
    "comparison": [
        "ã€Œ{concept}ã€å’Œç›¸å…³æ¦‚å¿µæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
        "è¯·å¯¹æ¯”ã€Œ{concept}ã€ä¸å…¶ç›¸ä¼¼æ¦‚å¿µçš„å¼‚åŒã€‚",
        "ã€Œ{concept}ã€çš„ç‹¬ç‰¹ä¹‹å¤„æ˜¯ä»€ä¹ˆï¼Ÿ",
    ],
    "example": [
        "è¯·ä¸¾ä¸€ä¸ªå…³äºã€Œ{concept}ã€çš„å…·ä½“ä¾‹å­ã€‚",
        "èƒ½å¦ç”¨ä¸€ä¸ªä¾‹å­è¯´æ˜ã€Œ{concept}ã€ï¼Ÿ",
        "æè¿°ä¸€ä¸ªèƒ½ä½“ç°ã€Œ{concept}ã€çš„åœºæ™¯ã€‚",
    ],
    "derivation": [
        "ã€Œ{concept}ã€æ˜¯å¦‚ä½•å¾—å‡ºçš„ï¼Ÿ",
        "è¯·è§£é‡Šã€Œ{concept}ã€èƒŒåçš„æ¨å¯¼è¿‡ç¨‹ã€‚",
        "ã€Œ{concept}ã€çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
    ],
}

# æç¤ºæ¨¡æ¿ (é€’è¿›å¼å¼•å¯¼)
HINT_TEMPLATES = {
    "level_1": [
        "æç¤º1: æƒ³æƒ³ã€Œ{concept}ã€çš„åŸºæœ¬å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ",
        "æç¤º1: å›å¿†ä¸€ä¸‹ã€Œ{concept}ã€çš„æ ¸å¿ƒç‰¹ç‚¹ã€‚",
    ],
    "level_2": [
        "æç¤º2: ã€Œ{concept}ã€é€šå¸¸å’Œä»€ä¹ˆæ¦‚å¿µä¸€èµ·å‡ºç°ï¼Ÿ",
        "æç¤º2: æ€è€ƒã€Œ{concept}ã€è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ",
    ],
    "level_3": [
        "æç¤º3: ã€Œ{concept}ã€çš„å…³é”®è¦ç´ åŒ…æ‹¬: {key_points}",
        "æç¤º3: è¿™ä¸ªæ¦‚å¿µçš„æ ¸å¿ƒåœ¨äº: {key_points}",
    ],
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Node Functions
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def generate_question(state: VerificationState) -> Dict[str, Any]:
    """
    ç”Ÿæˆå¼•å¯¼é—®é¢˜èŠ‚ç‚¹

    åŸºäºå½“å‰æ¦‚å¿µå’Œä¸Šä¸‹æ–‡ç”ŸæˆSocraticå¼å¼•å¯¼é—®é¢˜ã€‚
    Story 24.5: ä¸»åŠ¨è·å–RAGä¸Šä¸‹æ–‡å¹¶æ³¨å…¥é—®é¢˜ã€‚

    âœ… Verified from LangGraph Context7:
    - Node function receives state and returns dict of updates
    - Async functions supported for I/O operations

    Returns:
        State updates:
        - current_question: ç”Ÿæˆçš„é—®é¢˜
        - question_type: é—®é¢˜ç±»å‹
        - rag_context: è·å–çš„RAGä¸Šä¸‹æ–‡ (å¯é€‰)
        - rag_available: RAGæœåŠ¡æ˜¯å¦å¯ç”¨
    """
    current_concept = state.get("current_concept", "")
    current_concept_idx = state.get("current_concept_idx", 0)
    total_concepts = state.get("total_concepts", 0)
    source_canvas = state.get("source_canvas", "")

    logger.debug(f"[generate_question] START - concept {current_concept_idx + 1}/{total_concepts}: {current_concept}")

    # Story 24.5: ä¸»åŠ¨è·å–RAGä¸Šä¸‹æ–‡
    rag_context = None
    rag_available = False
    if current_concept and source_canvas:
        try:
            rag_context = await fetch_rag_context(
                concept=current_concept,
                source_canvas=source_canvas,
                max_results=3
            )
            rag_available = rag_context is not None
            if rag_available:
                logger.debug(f"[generate_question] RAG context fetched: {len(rag_context)} chars")
        except Exception as e:
            logger.warning(f"[generate_question] RAG fetch failed (graceful degradation): {e}")
            rag_context = None
            rag_available = False

    # é€‰æ‹©é—®é¢˜ç±»å‹ (è½®æ¢ä¸åŒç±»å‹å¢åŠ å¤šæ ·æ€§)
    question_types = list(QUESTION_TEMPLATES.keys())
    question_type = question_types[current_concept_idx % len(question_types)]

    # è·å–é—®é¢˜æ¨¡æ¿
    templates = QUESTION_TEMPLATES.get(question_type, QUESTION_TEMPLATES["definition"])
    template_idx = current_concept_idx % len(templates)
    template = templates[template_idx]

    # ç”Ÿæˆé—®é¢˜
    question = template.format(concept=current_concept)

    # Story 24.5: RAGä¸Šä¸‹æ–‡å¢å¼º
    if rag_available and rag_context:
        # å°†RAGä¸Šä¸‹æ–‡èå…¥é—®é¢˜ï¼Œæä¾›å­¦ä¹ å†å²èƒŒæ™¯
        context_preview = rag_context[:300] if len(rag_context) > 300 else rag_context
        question = f"ğŸ“š åŸºäºä½ ä¹‹å‰çš„å­¦ä¹ :\n{context_preview}\n\n{question}"
        logger.debug("[generate_question] RAG context injected into question")

    logger.debug(f"[generate_question] END - type: {question_type}, rag: {rag_available}")

    return {
        "current_question": question,
        "question_type": question_type,
        "rag_context": rag_context,  # Store for potential reuse
        "rag_available": rag_available,
    }


async def wait_for_answer(state: VerificationState) -> Dict[str, Any]:
    """
    ç­‰å¾…ç”¨æˆ·å›ç­”èŠ‚ç‚¹

    æ­¤èŠ‚ç‚¹è¡¨ç¤ºç­‰å¾…ç”¨æˆ·è¾“å…¥å›ç­”ã€‚
    å®é™…çš„ç­‰å¾…ç”±å¤–éƒ¨æ§åˆ¶å™¨(VerificationService)å¤„ç†ã€‚
    æ­¤èŠ‚ç‚¹ä»…ä½œä¸ºçŠ¶æ€æ£€æŸ¥ç‚¹ã€‚

    Returns:
        Empty dict (checkpoint only)
    """
    current_concept = state.get("current_concept", "")
    current_question = state.get("current_question", "")

    logger.debug(f"[wait_for_answer] Waiting for answer on: {current_concept}")
    logger.debug(f"[wait_for_answer] Question: {current_question[:50]}...")

    # å®é™…ç­‰å¾…ç”±VerificationService.process_answer()å¤„ç†
    # Graphåœ¨æ­¤æš‚åœï¼Œç­‰å¾…å¤–éƒ¨è¾“å…¥
    return {}


async def evaluate_answer(state: VerificationState) -> Dict[str, Any]:
    """
    è¯„ä¼°ç”¨æˆ·å›ç­”èŠ‚ç‚¹

    è¯„ä¼°ç”¨æˆ·å›ç­”è´¨é‡å¹¶ç»™å‡ºè¯„åˆ†ã€‚
    Story 24.2 å®ç°åŸºç¡€è¯„ä¼°é€»è¾‘ã€‚
    æœªæ¥å¯é›†æˆscoring-agentè¿›è¡Œæ·±åº¦è¯„ä¼°ã€‚

    âœ… Verified from project scoring pattern:
    - 4ç»´åº¦è¯„åˆ†: å‡†ç¡®æ€§ã€å½¢è±¡æ€§ã€å®Œæ•´æ€§ã€ç‹¬åˆ›æ€§

    Returns:
        State updates:
        - answer_quality: å›ç­”è´¨é‡è¯„çº§
        - answer_score: å›ç­”è¯„åˆ† (0-100)
    """
    user_answer = state.get("user_answer", "")
    current_concept = state.get("current_concept", "")
    hints_given = state.get("hints_given", 0)

    logger.debug(f"[evaluate_answer] START - concept: {current_concept}, "
                f"answer length: {len(user_answer)}, hints: {hints_given}")

    # åŸºç¡€è¯„ä¼°é€»è¾‘ (å¯æ‰©å±•ä¸ºscoring-agentè°ƒç”¨)
    score, quality = _evaluate_answer_basic(user_answer, current_concept, hints_given)

    logger.debug(f"[evaluate_answer] END - quality: {quality}, score: {score}")

    return {
        "answer_quality": quality,
        "answer_score": score,
    }


def _evaluate_answer_basic(
    answer: str,
    concept: str,
    hints_given: int
) -> tuple[float, str]:
    """
    åŸºç¡€å›ç­”è¯„ä¼°

    æ ¹æ®å›ç­”é•¿åº¦ã€å…³é”®è¯åŒ¹é…ç­‰è¿›è¡Œåˆæ­¥è¯„ä¼°ã€‚

    Args:
        answer: ç”¨æˆ·å›ç­”
        concept: å½“å‰æ¦‚å¿µ
        hints_given: å·²ç»™æç¤ºæ•°

    Returns:
        (score, quality) tuple
    """
    if not answer or not answer.strip():
        return 0.0, "wrong"

    answer_lower = answer.lower()
    concept_lower = concept.lower()

    # åŸºç¡€åˆ†æ•° (æ ¹æ®é•¿åº¦)
    base_score = min(len(answer) / 3, 40)  # æœ€å¤š40åˆ†

    # å…³é”®è¯åŒ¹é…åŠ åˆ†
    keyword_bonus = 0
    if concept_lower in answer_lower:
        keyword_bonus += 20

    # ç»“æ„åŒ–è¡¨è¾¾åŠ åˆ† (åŒ…å«å¸¸è§è§£é‡Šæ¨¡å¼)
    structure_patterns = ["æ˜¯æŒ‡", "å®šä¹‰", "ç‰¹ç‚¹", "åŒ…æ‹¬", "ä¾‹å¦‚", "å› æ­¤", "æ‰€ä»¥"]
    for pattern in structure_patterns:
        if pattern in answer:
            keyword_bonus += 5

    # æç¤ºæƒ©ç½š (æ¯ä¸ªæç¤º-5åˆ†)
    hint_penalty = hints_given * 5

    # è®¡ç®—æœ€ç»ˆåˆ†æ•°
    raw_score = base_score + keyword_bonus - hint_penalty
    score = max(0, min(100, raw_score))

    # ç¡®å®šè´¨é‡ç­‰çº§
    if score >= 85:
        quality = "excellent"
    elif score >= 70:
        quality = "good"
    elif score >= 50:
        quality = "partial"
    elif score >= 30:
        quality = "wrong"
    else:
        if hints_given >= 2:
            quality = "no_idea"
        else:
            quality = "wrong"

    return score, quality


async def provide_hint(state: VerificationState) -> Dict[str, Any]:
    """
    æä¾›æç¤ºå¼•å¯¼èŠ‚ç‚¹

    æ ¹æ®å›ç­”è´¨é‡å’Œæ¦‚å¿µç±»å‹ï¼Œä½¿ç”¨åŠ¨æ€é€‰æ‹©çš„Agentæä¾›æç¤ºã€‚
    é›†æˆStory 24.4çš„AgentSelectorã€‚

    Returns:
        State updates:
        - current_hints: æ›´æ–°çš„æç¤ºåˆ—è¡¨
        - hints_given: å·²ç»™å‡ºæç¤ºæ•°+1
        - selected_agent: ä½¿ç”¨çš„Agent
    """
    current_concept = state.get("current_concept", "")
    hints_given = state.get("hints_given", 0)
    current_hints = list(state.get("current_hints", []))
    answer_quality = state.get("answer_quality", "wrong")
    answer_score = state.get("answer_score", 0.0)

    logger.debug(f"[provide_hint] START - concept: {current_concept}, "
                f"hints_given: {hints_given}, quality: {answer_quality}")

    # åŠ¨æ€é€‰æ‹©Agent (é›†æˆStory 24.4)
    selected_agent = await _select_guidance_agent(answer_quality, answer_score, hints_given)

    # ç”Ÿæˆæç¤º (æ ¹æ®æç¤ºçº§åˆ«)
    hint_level = f"level_{min(hints_given + 1, 3)}"
    new_hint = _generate_hint(current_concept, hint_level, selected_agent)

    updated_hints = current_hints + [new_hint]

    logger.debug(f"[provide_hint] END - agent: {selected_agent}, hint: {new_hint[:50]}...")

    return {
        "current_hints": updated_hints,
        "hints_given": hints_given + 1,
        "selected_agent": selected_agent,
    }


async def _select_guidance_agent(
    answer_quality: str,
    answer_score: float,
    hints_given: int
) -> str:
    """
    é€‰æ‹©å¼•å¯¼Agent

    é›†æˆStory 24.4çš„AgentSelectoré€»è¾‘ã€‚

    Args:
        answer_quality: å›ç­”è´¨é‡
        answer_score: å›ç­”è¯„åˆ†
        hints_given: å·²ç»™æç¤ºæ•°

    Returns:
        é€‰ä¸­çš„Agentåç§°
    """
    # å°è¯•å¯¼å…¥AgentSelector (Story 24.4)
    try:
        import sys
        if "C:/Users/ROG/æ‰˜ç¦/Canvas/backend" not in sys.path:
            sys.path.insert(0, "C:/Users/ROG/æ‰˜ç¦/Canvas/backend")

        from app.services.agent_selector import (
            AgentSelector,
            AnswerQuality,
            SelectionContext,
            get_agent_selector,
        )

        selector = get_agent_selector()

        # æ˜ å°„è´¨é‡å­—ç¬¦ä¸²åˆ°æšä¸¾
        quality_map = {
            "excellent": AnswerQuality.EXCELLENT,
            "good": AnswerQuality.GOOD,
            "partial": AnswerQuality.PARTIAL,
            "wrong": AnswerQuality.WRONG,
            "confused": AnswerQuality.CONFUSED,
            "no_idea": AnswerQuality.NO_IDEA,
            "reasoning_error": AnswerQuality.REASONING_ERROR,
            "skipped": AnswerQuality.SKIPPED,
        }

        aq = quality_map.get(answer_quality, AnswerQuality.WRONG)

        context = SelectionContext(
            answer_quality=aq,
            answer_score=answer_score,
            concept_text="",  # Will be enhanced in Story 24.5
            hints_given=hints_given,
        )

        result = await selector.select_agent(context)
        logger.debug(f"[_select_guidance_agent] AgentSelector chose: {result.agent.value}")
        return result.agent.value

    except ImportError as e:
        logger.warning(f"[_select_guidance_agent] AgentSelector not available: {e}")
        # Fallback to simple logic
        if answer_score < 30:
            return "basic-decomposition"
        elif answer_score < 50:
            return "example-teaching"
        elif answer_score < 70:
            return "memory-anchor"
        else:
            return "clarification-path"


def _generate_hint(concept: str, hint_level: str, agent: str) -> str:
    """
    ç”Ÿæˆæç¤ºå†…å®¹

    æ ¹æ®æç¤ºçº§åˆ«å’Œé€‰ä¸­çš„Agentç”Ÿæˆæç¤ºã€‚

    Args:
        concept: å½“å‰æ¦‚å¿µ
        hint_level: æç¤ºçº§åˆ« (level_1, level_2, level_3)
        agent: é€‰ä¸­çš„Agent

    Returns:
        æç¤ºæ–‡æœ¬
    """
    # Agent-specific hint prefixes
    agent_prefixes = {
        "memory-anchor": "è®°å¿†æç¤º: ",
        "example-teaching": "ä¾‹é¢˜æç¤º: ",
        "comparison-table": "å¯¹æ¯”æç¤º: ",
        "basic-decomposition": "æ‹†è§£æç¤º: ",
        "clarification-path": "æ¾„æ¸…æç¤º: ",
    }

    prefix = agent_prefixes.get(agent, "æç¤º: ")

    # è·å–æ¨¡æ¿
    templates = HINT_TEMPLATES.get(hint_level, HINT_TEMPLATES["level_1"])
    template = templates[0]  # Use first template

    # ç”Ÿæˆæç¤º
    hint = template.format(
        concept=concept,
        key_points="[æ ¸å¿ƒè¦ç‚¹å°†æ ¹æ®æ¦‚å¿µå†…å®¹ç”Ÿæˆ]"
    )

    return f"{prefix}{hint}"


async def finalize_concept(state: VerificationState) -> Dict[str, Any]:
    """
    å®Œæˆå½“å‰æ¦‚å¿µéªŒè¯èŠ‚ç‚¹

    è®°å½•æ¦‚å¿µéªŒè¯ç»“æœï¼Œæ›´æ–°è¿›åº¦ç»Ÿè®¡ã€‚

    Returns:
        State updates including color counts and concept results
    """
    current_concept = state.get("current_concept", "")
    current_concept_idx = state.get("current_concept_idx", 0)
    answer_quality = state.get("answer_quality", "wrong")
    answer_score = state.get("answer_score", 0.0)
    user_answer = state.get("user_answer", "")
    completed_concepts = state.get("completed_concepts", 0)
    concept_results = list(state.get("concept_results", []))
    hints_given = state.get("hints_given", 0)
    current_hints = state.get("current_hints", [])
    selected_agent = state.get("selected_agent")

    logger.debug(f"[finalize_concept] START - concept: {current_concept}, "
                f"quality: {answer_quality}, score: {answer_score}")

    # ç¡®å®šæœ€ç»ˆé¢œè‰²
    final_color, color_deltas = _determine_final_color(answer_quality, answer_score)

    # åˆ›å»ºå°è¯•è®°å½•
    attempt_record = {
        "attempt_number": 1,  # ç®€åŒ–ç‰ˆæœ¬ï¼Œæœªæ¥å¯æ”¯æŒå¤šæ¬¡å°è¯•
        "user_answer": user_answer,
        "score": answer_score,
        "quality": answer_quality,
        "hints_provided": list(current_hints),
        "agent_used": selected_agent,
        "timestamp": datetime.now().isoformat(),
    }

    # åˆ›å»ºæ¦‚å¿µç»“æœè®°å½•
    concept_result = {
        "concept_id": f"concept-{current_concept_idx}",
        "concept_text": current_concept,
        "final_color": final_color,
        "final_score": answer_score,
        "attempts": [attempt_record],
        "mastered": final_color == "green",
    }

    logger.debug(f"[finalize_concept] END - color: {final_color}")

    return {
        "completed_concepts": completed_concepts + 1,
        "green_count": state.get("green_count", 0) + color_deltas["green"],
        "yellow_count": state.get("yellow_count", 0) + color_deltas["yellow"],
        "purple_count": state.get("purple_count", 0) + color_deltas["purple"],
        "red_count": state.get("red_count", 0) + color_deltas["red"],
        "concept_results": concept_results + [concept_result],
        # é‡ç½®å½“å‰æ¦‚å¿µçŠ¶æ€
        "hints_given": 0,
        "current_hints": [],
        "user_answer": "",
        "selected_agent": None,
    }


def _determine_final_color(
    quality: str,
    score: float
) -> tuple[str, Dict[str, int]]:
    """
    ç¡®å®šæ¦‚å¿µæœ€ç»ˆé¢œè‰²

    Args:
        quality: å›ç­”è´¨é‡
        score: å›ç­”è¯„åˆ†

    Returns:
        (color, delta_dict) tuple
    """
    deltas = {"green": 0, "yellow": 0, "purple": 0, "red": 0}

    if quality == "excellent" or score >= 85:
        color = "green"
        deltas["green"] = 1
    elif quality == "good" or score >= 60:
        color = "yellow"
        deltas["yellow"] = 1
    elif quality == "skipped":
        color = "purple"
        deltas["purple"] = 1
    else:
        color = "red"
        deltas["red"] = 1

    return color, deltas


async def advance_to_next_concept(state: VerificationState) -> Dict[str, Any]:
    """
    å‰è¿›åˆ°ä¸‹ä¸€ä¸ªæ¦‚å¿µèŠ‚ç‚¹

    Updates current_concept and current_concept_idx.

    Returns:
        State updates for next concept
    """
    concept_queue = state.get("concept_queue", [])
    current_concept_idx = state.get("current_concept_idx", 0)

    next_idx = current_concept_idx + 1

    if next_idx < len(concept_queue):
        next_concept = concept_queue[next_idx]
        logger.debug(f"[advance_to_next_concept] Moving to concept {next_idx + 1}/{len(concept_queue)}: {next_concept}")
    else:
        next_concept = ""
        logger.debug("[advance_to_next_concept] No more concepts")

    return {
        "current_concept_idx": next_idx,
        "current_concept": next_concept,
    }


async def complete_verification(state: VerificationState) -> Dict[str, Any]:
    """
    å®ŒæˆéªŒè¯ä¼šè¯èŠ‚ç‚¹

    æ ‡è®°éªŒè¯ä¼šè¯å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆç»Ÿè®¡ã€‚

    Returns:
        State updates marking completion
    """
    green_count = state.get("green_count", 0)
    yellow_count = state.get("yellow_count", 0)
    purple_count = state.get("purple_count", 0)
    red_count = state.get("red_count", 0)
    total = state.get("total_concepts", 1)

    mastery_rate = (green_count / total * 100) if total > 0 else 0

    logger.info("[complete_verification] Session completed!")
    logger.info(f"[complete_verification] Results: "
               f"Green={green_count}, Yellow={yellow_count}, "
               f"Purple={purple_count}, Red={red_count}")
    logger.info(f"[complete_verification] Mastery rate: {mastery_rate:.1f}%")

    return {
        "is_completed": True,
    }


__all__ = [
    "generate_question",
    "wait_for_answer",
    "evaluate_answer",
    "provide_hint",
    "finalize_concept",
    "advance_to_next_concept",
    "complete_verification",
    "QUESTION_TEMPLATES",
    "HINT_TEMPLATES",
]
