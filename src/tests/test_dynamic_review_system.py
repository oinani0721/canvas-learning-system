"""
åŠ¨æ€æ£€éªŒç™½æ¿ç³»ç»Ÿæµ‹è¯•
Story 8.16 - å®Œå–„åŠ¨æ€æ£€éªŒç™½æ¿ç”ŸæˆåŠŸèƒ½

Author: Canvas Learning System Team
Version: 1.0 (Story 8.16)
Created: 2025-01-22
"""

import os

# å¯¼å…¥è¦æµ‹è¯•çš„æ¨¡å—
import sys
import unittest
from pathlib import Path
from unittest.mock import Mock, patch

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from critical_nodes_extractor import CriticalNode, CriticalNodesExtractor, SourceAnalysis
from dynamic_review_canvas_generator import DynamicReviewCanvasGenerator
from intelligent_question_generator import GeneratedQuestion, IntelligentQuestionGenerator, QuestionGenerationConfig
from knowledge_graph_integration import KnowledgeGraphContext, KnowledgeGraphIntegration
from learning_cycle_manager import LearningCycleManager, LearningStep


class TestCriticalNodesExtractor(unittest.TestCase):
    """æµ‹è¯•å…³é”®èŠ‚ç‚¹æå–å™¨"""

    def setUp(self):
        self.extractor = CriticalNodesExtractor()
        self.test_canvas_data = {
            "nodes": [
                {
                    "id": "node-001",
                    "type": "text",
                    "text": "é€»è¾‘ç­‰ä»·æ€§æ˜¯å‘½é¢˜é€»è¾‘ä¸­çš„é‡è¦æ¦‚å¿µ",
                    "color": "4",  # çº¢è‰²
                    "x": 100,
                    "y": 100,
                    "width": 400,
                    "height": 300
                },
                {
                    "id": "node-002",
                    "type": "text",
                    "text": "é›†åˆè¿ç®—åŒ…æ‹¬å¹¶é›†ã€äº¤é›†ç­‰åŸºæœ¬æ“ä½œ",
                    "color": "3",  # ç´«è‰²
                    "x": 200,
                    "y": 200,
                    "width": 400,
                    "height": 300
                },
                {
                    "id": "node-003",
                    "type": "text",
                    "text": "ç®€çŸ­",
                    "color": "4",
                    "x": 300,
                    "y": 300,
                    "width": 200,
                    "height": 100
                }
            ],
            "edges": []
        }

    @patch('os.path.exists')
    def test_extract_critical_nodes_success(self, mock_exists):
        """æµ‹è¯•æˆåŠŸæå–å…³é”®èŠ‚ç‚¹"""
        mock_exists.return_value = True  # Mock file existence check

        # Mock the local CanvasJSONOperator.read_canvas method
        with patch('critical_nodes_extractor.CanvasJSONOperator.read_canvas') as mock_read:
            mock_read.return_value = self.test_canvas_data

            analysis = self.extractor.extract_critical_nodes("test_canvas.canvas")

            self.assertIsInstance(analysis, SourceAnalysis)
            self.assertEqual(len(analysis.critical_nodes_extracted), 2)  # åº”è¯¥æå–2ä¸ªèŠ‚ç‚¹ï¼ˆæ’é™¤å¤ªçŸ­çš„ï¼‰
            self.assertEqual(analysis.total_source_nodes, 3)

    def test_calculate_color_score(self):
        """æµ‹è¯•é¢œè‰²è¯„åˆ†è®¡ç®—"""
        red_node = {"color": "4"}
        purple_node = {"color": "3"}
        other_node = {"color": "2"}

        red_score = self.extractor._calculate_color_score(red_node)
        purple_score = self.extractor._calculate_color_score(purple_node)
        other_score = self.extractor._calculate_color_score(other_node)

        self.assertEqual(red_score, 1.0)
        self.assertEqual(purple_score, 0.8)
        self.assertEqual(other_score, 0.3)


class TestKnowledgeGraphIntegration(unittest.TestCase):
    """æµ‹è¯•çŸ¥è¯†å›¾è°±é›†æˆ"""

    def setUp(self):
        self.integration = KnowledgeGraphIntegration()

    def test_analyze_concept_context_fallback(self):
        """æµ‹è¯•fallbackåˆ†æ"""
        concepts = ["é€»è¾‘ç­‰ä»·æ€§", "é›†åˆè¿ç®—"]
        canvas_data = {"nodes": [], "edges": []}

        context = self.integration.analyze_concept_context(concepts, canvas_data)

        self.assertIsInstance(context, KnowledgeGraphContext)
        self.assertEqual(len(context.related_concepts), 2)
        self.assertIn("é€»è¾‘ç­‰ä»·æ€§", context.related_concepts)
        self.assertIn("é›†åˆè¿ç®—", context.related_concepts)

    def test_calculate_text_similarity(self):
        """æµ‹è¯•æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—"""
        text1 = "hello world test"
        text2 = "hello world example"
        text3 = "completely different text"

        similarity_1_2 = self.integration._calculate_text_similarity(text1, text2)
        similarity_1_3 = self.integration._calculate_text_similarity(text1, text3)

        self.assertGreater(similarity_1_2, 0.0)  # Should have some similarity due to common words
        self.assertEqual(similarity_1_3, 0.0)  # Should have no similarity


class TestIntelligentQuestionGenerator(unittest.TestCase):
    """æµ‹è¯•æ™ºèƒ½é—®é¢˜ç”Ÿæˆå™¨"""

    def setUp(self):
        self.config = QuestionGenerationConfig(max_questions_per_node=2)
        self.generator = IntelligentQuestionGenerator(config=self.config)

    def test_generate_review_questions(self):
        """æµ‹è¯•ç”Ÿæˆæ£€éªŒé—®é¢˜"""
        test_nodes = [
            CriticalNode(
                node_id="test-001",
                color="4",
                concept_name="é€»è¾‘ç­‰ä»·æ€§",
                confidence_score=0.8,
                mastery_estimation=0.3,
                reason_for_critical="æµ‹è¯•èŠ‚ç‚¹",
                text_content="é€»è¾‘ç­‰ä»·æ€§æ˜¯å‘½é¢˜é€»è¾‘ä¸­çš„é‡è¦æ¦‚å¿µ"
            )
        ]

        questions = self.generator.generate_review_questions(test_nodes)

        self.assertIsInstance(questions, list)
        self.assertGreater(len(questions), 0)
        self.assertLessEqual(len(questions), 2)  # ä¸åº”è¶…è¿‡max_questions_per_node

        for question in questions:
            self.assertIsInstance(question, GeneratedQuestion)
            self.assertIn("é€»è¾‘ç­‰ä»·æ€§", question.question_text)
            self.assertGreater(question.quality_score, 0)

    def test_determine_base_difficulty(self):
        """æµ‹è¯•åŸºç¡€éš¾åº¦ç¡®å®š"""
        low_mastery_node = CriticalNode("test", "4", "æ¦‚å¿µ", 0.8, 0.2, "æµ‹è¯•")
        high_mastery_node = CriticalNode("test", "4", "æ¦‚å¿µ", 0.8, 0.9, "æµ‹è¯•")

        low_difficulty = self.generator._determine_base_difficulty(low_mastery_node, None)
        high_difficulty = self.generator._determine_base_difficulty(high_mastery_node, None)

        self.assertEqual(low_difficulty.value, "basic")
        self.assertEqual(high_difficulty.value, "expert")

    def test_estimate_time(self):
        """æµ‹è¯•æ—¶é—´ä¼°ç®—"""
        from intelligent_question_generator import DifficultyLevel, QuestionType

        basic_time = self.generator._estimate_time(DifficultyLevel.BASIC, QuestionType.CONCEPTUAL_UNDERSTANDING)
        advanced_time = self.generator._estimate_time(DifficultyLevel.ADVANCED, QuestionType.PROBLEM_SOLVING)

        self.assertGreater(advanced_time, basic_time)
        self.assertGreater(basic_time, 0)


class TestLearningCycleManager(unittest.TestCase):
    """æµ‹è¯•å­¦ä¹ å¾ªç¯ç®¡ç†å™¨"""

    def setUp(self):
        self.test_canvas = "test_canvas.canvas"
        self.manager = LearningCycleManager(self.test_canvas)

    def test_step_definitions_initialization(self):
        """æµ‹è¯•æ­¥éª¤å®šä¹‰åˆå§‹åŒ–"""
        self.assertIn(LearningStep.STEP_1_UNDERSTANDING, self.manager.step_definitions)
        self.assertIn(LearningStep.STEP_8_SUMMARY, self.manager.step_definitions)

        step_1_def = self.manager.step_definitions[LearningStep.STEP_1_UNDERSTANDING]
        self.assertEqual(step_1_def.name, "å¡«å†™ç†è§£")
        self.assertIn("å¡«å†™é»„è‰²ç†è§£èŠ‚ç‚¹", step_1_def.description)

    def test_get_next_step(self):
        """æµ‹è¯•è·å–ä¸‹ä¸€æ­¥"""
        next_step = self.manager._get_next_step(LearningStep.STEP_1_UNDERSTANDING)
        self.assertEqual(next_step, LearningStep.STEP_2_SCORING)

        last_step_next = self.manager._get_next_step(LearningStep.STEP_8_SUMMARY)
        self.assertIsNone(last_step_next)

    def test_validate_user_input(self):
        """æµ‹è¯•ç”¨æˆ·è¾“å…¥éªŒè¯"""
        valid_input = {"yellow_node_understanding": "è¿™æ˜¯æˆ‘çš„è¯¦ç»†ç†è§£ï¼ŒåŒ…å«è¶³å¤Ÿçš„é•¿åº¦æ¥æ»¡è¶³éªŒè¯è¦æ±‚", "node_id": "test-001"}
        invalid_input = {"yellow_node_understanding": "å¤ªçŸ­"}

        valid_result = self.manager._validate_user_input(LearningStep.STEP_1_UNDERSTANDING, valid_input)
        invalid_result = self.manager._validate_user_input(LearningStep.STEP_1_UNDERSTANDING, invalid_input)

        self.assertTrue(valid_result["valid"])
        self.assertFalse(invalid_result["valid"])


class TestDynamicReviewCanvasGenerator(unittest.TestCase):
    """æµ‹è¯•åŠ¨æ€æ£€éªŒç™½æ¿ç”Ÿæˆå™¨"""

    def setUp(self):
        self.generator = DynamicReviewCanvasGenerator()

    @patch('dynamic_review_canvas_generator.CanvasJSONOperator.read_canvas')
    @patch('dynamic_review_canvas_generator.Path')
    @patch('os.path.exists')
    def test_create_review_canvas_success(self, mock_exists, mock_path, mock_read):
        """æµ‹è¯•æˆåŠŸåˆ›å»ºæ£€éªŒç™½æ¿"""
        # è®¾ç½®mock
        mock_exists.return_value = True  # Mock file existence check
        mock_path.return_value.parent = Path("/tmp")
        mock_path.return_value.stem = "test_canvas"

        # Mockå…³é”®èŠ‚ç‚¹æå–
        mock_analysis = SourceAnalysis(
            canvas_id="test-canvas",
            extraction_algorithm="test",
            total_source_nodes=5,
            critical_nodes_extracted=[
                CriticalNode("node-001", "4", "æµ‹è¯•æ¦‚å¿µ", 0.8, 0.3, "æµ‹è¯•")
            ],
            knowledge_graph_context={}
        )

        # Mocké—®é¢˜ç”Ÿæˆ
        mock_questions = [
            GeneratedQuestion(
                question_id="q-001",
                source_node_id="node-001",
                question_type="conceptual_understanding",
                difficulty_level="basic",
                question_text="è¯·è§£é‡Šæµ‹è¯•æ¦‚å¿µ",
                expected_answer_type="explanation",
                estimated_time_minutes=10,
                hint_available=True
            )
        ]

        # Mock Canvasè¯»å–
        mock_read.return_value = {"nodes": [], "edges": []}

        # ç›´æ¥mock generatorå®ä¾‹çš„ç»„ä»¶
        self.generator.nodes_extractor.extract_critical_nodes = Mock(return_value=mock_analysis)
        self.generator.question_generator.generate_review_questions = Mock(return_value=mock_questions)

        with patch('builtins.open', create=True) as mock_open:
            mock_open.return_value.__enter__.return_value.write = Mock()

            result = self.generator.create_review_canvas("test_canvas.canvas", iteration=1)

            self.assertIsInstance(result, str)
            self.assertTrue(result.endswith(".canvas"))

    def test_load_config_default(self):
        """æµ‹è¯•åŠ è½½é»˜è®¤é…ç½®"""
        config = self.generator._load_config(None)

        self.assertIn("node_extraction", config)
        self.assertIn("question_generation", config)
        self.assertIn("knowledge_graph", config)
        self.assertIn("learning_cycle", config)

        # æ£€æŸ¥é»˜è®¤å€¼
        self.assertEqual(config["node_extraction"]["confidence_threshold"], 0.7)
        self.assertEqual(config["question_generation"]["max_questions_per_node"], 3)

    def test_calculate_quality_metrics(self):
        """æµ‹è¯•è´¨é‡æŒ‡æ ‡è®¡ç®—"""
        from intelligent_question_generator import DifficultyLevel, GeneratedQuestion, QuestionType

        test_questions = [
            GeneratedQuestion(
                question_id="q-001",
                source_node_id="node-001",
                question_type=QuestionType.CONCEPTUAL_UNDERSTANDING,
                difficulty_level=DifficultyLevel.BASIC,
                question_text="æµ‹è¯•é—®é¢˜",
                expected_answer_type="explanation",
                estimated_time_minutes=10,
                hint_available=False,
                quality_score=0.8
            )
        ]

        test_analysis = SourceAnalysis(
            canvas_id="test",
            extraction_algorithm="test",
            total_source_nodes=1,
            critical_nodes_extracted=[
                CriticalNode("node-001", "4", "æµ‹è¯•", 0.8, 0.5, "æµ‹è¯•")
            ],
            knowledge_graph_context={}
        )

        metrics = self.generator._calculate_quality_metrics(test_questions, test_analysis)

        self.assertIn("question_relevance", metrics)
        self.assertIn("difficulty_appropriateness", metrics)
        self.assertIn("learning_effectiveness", metrics)
        self.assertGreater(metrics["question_relevance"], 0)
        self.assertLessEqual(metrics["question_relevance"], 1.0)


class TestIntegrationWorkflow(unittest.TestCase):
    """æµ‹è¯•é›†æˆå·¥ä½œæµ"""

    @patch('dynamic_review_canvas_generator.CanvasJSONOperator.read_canvas')
    @patch('dynamic_review_canvas_generator.Path')
    @patch('os.path.exists')
    def test_complete_workflow(self, mock_exists, mock_path, mock_read):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
        # è®¾ç½®mock
        mock_exists.return_value = True  # Mock file existence check
        mock_path.return_value.parent = Path("/tmp")
        mock_path.return_value.stem = "test_canvas"

        # å‡†å¤‡æµ‹è¯•æ•°æ®
        mock_analysis = SourceAnalysis(
            canvas_id="test",
            extraction_algorithm="test",
            total_source_nodes=3,
            critical_nodes_extracted=[
                CriticalNode("node-001", "4", "æ¦‚å¿µ1", 0.8, 0.3, "æµ‹è¯•"),
                CriticalNode("node-002", "3", "æ¦‚å¿µ2", 0.7, 0.6, "æµ‹è¯•")
            ],
            knowledge_graph_context={}
        )

        mock_questions = [
            GeneratedQuestion(
                question_id="q-001",
                source_node_id="node-001",
                question_type="conceptual_understanding",
                difficulty_level="basic",
                question_text="é—®é¢˜1",
                expected_answer_type="explanation",
                estimated_time_minutes=10,
                hint_available=True,
                quality_score=0.85
            ),
            GeneratedQuestion(
                question_id="q-002",
                source_node_id="node-002",
                question_type="application_scenario",
                difficulty_level="intermediate",
                question_text="é—®é¢˜2",
                expected_answer_type="example",
                estimated_time_minutes=15,
                hint_available=False,
                quality_score=0.75
            )
        ]

        mock_read.return_value = {"nodes": [], "edges": []}

        # åˆ›å»ºç”Ÿæˆå™¨
        generator = DynamicReviewCanvasGenerator()

        # ç›´æ¥mock generatorå®ä¾‹çš„ç»„ä»¶
        generator.nodes_extractor.extract_critical_nodes = Mock(return_value=mock_analysis)
        generator.question_generator.generate_review_questions = Mock(return_value=mock_questions)

        with patch('builtins.open', create=True) as mock_open:
            mock_open.return_value.__enter__.return_value.write = Mock()

            # æ‰§è¡Œå·¥ä½œæµ
            result = generator.create_review_canvas("test_canvas.canvas", iteration=1)

            # éªŒè¯ç»“æœ
            self.assertIsInstance(result, str)
            self.assertTrue(result.endswith(".canvas"))


def run_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()

    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestCriticalNodesExtractor,
        TestKnowledgeGraphIntegration,
        TestIntelligentQuestionGenerator,
        TestLearningCycleManager,
        TestDynamicReviewCanvasGenerator,
        TestIntegrationWorkflow
    ]

    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)

    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)

    # è¿”å›æµ‹è¯•ç»“æœ
    return result.wasSuccessful()


if __name__ == "__main__":
    print("è¿è¡ŒåŠ¨æ€æ£€éªŒç™½æ¿ç³»ç»Ÿæµ‹è¯•...")
    success = run_tests()

    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
        sys.exit(1)
