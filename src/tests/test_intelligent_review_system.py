"""
æ™ºèƒ½å¤ä¹ ç³»ç»Ÿå®Œæ•´æµ‹è¯•å¥—ä»¶

æœ¬æ¨¡å—åŒ…å«Story 8.9: å»ºç«‹æ™ºèƒ½å¤ä¹ è®¡åˆ’ç”Ÿæˆçš„å®Œæ•´æµ‹è¯•ï¼Œ
éªŒè¯æ‰€æœ‰åŠŸèƒ½ç»„ä»¶çš„æ­£ç¡®æ€§ã€é›†æˆæ€§å’Œæ€§èƒ½ã€‚

Author: Canvas Learning System Team
Version: 1.0
Created: 2025-01-23
"""

import unittest
import json
import os
import tempfile
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock

# å¯¼å…¥å¾…æµ‹è¯•çš„æ¨¡å—
import sys
sys.path.append('..')

try:
    from learning_analyzer import LearningAnalyzer
    from intelligent_review_generator import IntelligentReviewGenerator, ReviewPlanConfig
    from review_canvas_builder import ReviewCanvasBuilder
    from personalization_engine import PersonalizationEngine
    from intelligent_review_cli import IntelligentReviewCLI
except ImportError as e:
    print(f"Warning: æ— æ³•å¯¼å…¥æµ‹è¯•æ¨¡å—: {e}")


class TestLearningAnalyzer(unittest.TestCase):
    """å­¦ä¹ åˆ†æå™¨æµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        self.analyzer = LearningAnalyzer()

    def test_analyze_learning_history_basic(self):
        """æµ‹è¯•åŸºç¡€å­¦ä¹ å†å²åˆ†æ"""
        # æ¨¡æ‹Ÿå­¦ä¹ æ•°æ®
        canvas_path = "test_canvas.canvas"

        # è¿™é‡Œç®€åŒ–æµ‹è¯•ï¼Œå› ä¸ºä¾èµ–å®é™…çš„Canvasæ–‡ä»¶
        with self.assertRaises(Exception):
            result = self.analyzer.analyze_learning_history(
                user_id="test_user",
                canvas_path=canvas_path
            )

    def test_collect_learning_data(self):
        """æµ‹è¯•å­¦ä¹ æ•°æ®æ”¶é›†"""
        # æµ‹è¯•æ–‡ä»¶æŸ¥æ‰¾åŠŸèƒ½
        canvas_files = self.analyzer._find_canvas_files()
        self.assertIsInstance(canvas_files, list)

    def test_identify_weak_concepts(self):
        """æµ‹è¯•è–„å¼±ç¯èŠ‚è¯†åˆ«"""
        # æ¨¡æ‹Ÿæ¦‚å¿µæ•°æ®
        concepts = [
            {
                "concept_name": "æµ‹è¯•æ¦‚å¿µ1",
                "mastery_score": 3.0,
                "weakness_score": 0.7,
                "weakness_type": "insufficient_exposure"
            },
            {
                "concept_name": "æµ‹è¯•æ¦‚å¿µ2",
                "mastery_score": 8.5,
                "weakness_score": 0.2,
                "weakness_type": "general_weakness"
            }
        ]

        weak_concepts = self.analyzer._identify_weak_concepts(concepts, {})

        self.assertEqual(len(weak_concepts), 1)
        self.assertEqual(weak_concepts[0]["concept_name"], "æµ‹è¯•æ¦‚å¿µ1")

    def test_calculate_mastery_score(self):
        """æµ‹è¯•æŒæ¡åˆ†æ•°è®¡ç®—"""
        concept_data = {
            "mastery_level": "mastered",
            "encounters": 5,
            "understanding_records": [
                {"quality_score": 8.0},
                {"quality_score": 9.0}
            ],
            "performance_scores": [
                {"score": 8.5},
                {"score": 9.0}
            ]
        }

        score = self.analyzer._calculate_mastery_score(concept_data)
        self.assertGreater(score, 7.0)
        self.assertLessEqual(score, 10.0)

    def test_analyze_learning_trends(self):
        """æµ‹è¯•å­¦ä¹ è¶‹åŠ¿åˆ†æ"""
        learning_data = {
            "scoring_records": [
                {"score": 6.0, "timestamp": 1000},
                {"score": 7.5, "timestamp": 2000},
                {"score": 8.0, "timestamp": 3000}
            ]
        }

        trends = self.analyzer._analyze_learning_trends(learning_data)

        self.assertIn("overall_performance_trend", trends)
        self.assertIn("study_frequency_trend", trends)


class TestIntelligentReviewGenerator(unittest.TestCase):
    """æ™ºèƒ½å¤ä¹ è®¡åˆ’ç”Ÿæˆå™¨æµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        self.generator = IntelligentReviewGenerator()

    def test_generate_review_plan_basic(self):
        """æµ‹è¯•åŸºç¡€å¤ä¹ è®¡åˆ’ç”Ÿæˆ"""
        config = ReviewPlanConfig(
            user_id="test_user",
            target_canvas="test_canvas.canvas",
            plan_type="weakness_focused"
        )

        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®é¿å…æ–‡ä»¶ä¾èµ–
        with patch.object(self.generator.learning_analyzer, 'analyze_learning_history') as mock_analyze:
            mock_analyze.return_value = {
                "analysis_summary": {
                    "total_concepts_analyzed": 5,
                    "concepts_mastered": 2,
                    "concepts_needing_review": 3,
                    "critical_weaknesses": 1
                },
                "identified_weak_concepts": [
                    {
                        "concept_name": "æµ‹è¯•æ¦‚å¿µ",
                        "weakness_score": 0.7,
                        "mastery_score": 4.0,
                        "weakness_type": "conceptual_misunderstanding",
                        "recommended_focus_areas": ["åŸºç¡€æ¦‚å¿µå¤ä¹ "]
                    }
                ]
            }

            result = self.generator.generate_review_plan(
                user_id="test_user",
                target_canvas="test_canvas.canvas",
                plan_type="weakness_focused",
                config=config
            )

            self.assertIn("plan_id", result)
            self.assertIn("review_sessions", result)
            self.assertEqual(result["user_id"], "test_user")

    def test_select_concepts_by_strategy(self):
        """æµ‹è¯•åŸºäºç­–ç•¥çš„æ¦‚å¿µé€‰æ‹©"""
        weak_concepts = [
            {"concept_name": "æ¦‚å¿µ1", "weakness_score": 0.8},
            {"concept_name": "æ¦‚å¿µ2", "weakness_score": 0.6},
            {"concept_name": "æ¦‚å¿µ3", "weakness_score": 0.9}
        ]

        config = ReviewPlanConfig(plan_type="weakness_focused")

        selected = self.generator._select_concepts_by_strategy(
            weak_concepts, {}, config
        )

        self.assertLessEqual(len(selected), 5)  # æœ€å¤š5ä¸ªæ¦‚å¿µ
        # åº”è¯¥æŒ‰è–„å¼±ç¨‹åº¦æ’åº
        if len(selected) > 1:
            self.assertGreaterEqual(
                selected[0]["weakness_score"],
                selected[1]["weakness_score"]
            )

    def test_generate_review_questions(self):
        """æµ‹è¯•å¤ä¹ é—®é¢˜ç”Ÿæˆ"""
        concept_data = {
            "concept_name": "æµ‹è¯•æ¦‚å¿µ",
            "weakness_type": "insufficient_exposure",
            "mastery_score": 4.0
        }
        config = ReviewPlanConfig()

        questions = self.generator._generate_review_questions(concept_data, config)

        self.assertGreater(len(questions), 0)
        self.assertIn("question_text", questions[0])
        self.assertIn("question_type", questions[0])

    def test_determine_concept_difficulty(self):
        """æµ‹è¯•æ¦‚å¿µéš¾åº¦ç¡®å®š"""
        concept_data = {"mastery_score": 3.0}
        config = ReviewPlanConfig(difficulty_level="adaptive")

        difficulty = self.generator._determine_concept_difficulty(concept_data, config)

        self.assertIn(difficulty, ["easy", "medium", "hard", "expert"])

    def test_create_review_sessions(self):
        """æµ‹è¯•å¤ä¹ ä¼šè¯åˆ›å»º"""
        from intelligent_review_generator import ReviewConcept

        concepts = [
            ReviewConcept(
                concept_name="æ¦‚å¿µ1",
                weakness_score=0.7,
                mastery_score=4.0,
                difficulty="medium",
                urgency_level="high",
                recommended_focus_areas=["åŸºç¡€å¤ä¹ "],
                review_questions=[],
                supporting_materials=[],
                estimated_time_minutes=15
            ),
            ReviewConcept(
                concept_name="æ¦‚å¿µ2",
                weakness_score=0.5,
                mastery_score=6.0,
                difficulty="medium",
                urgency_level="medium",
                recommended_focus_areas=["åº”ç”¨ç»ƒä¹ "],
                review_questions=[],
                supporting_materials=[],
                estimated_time_minutes=12
            )
        ]

        config = ReviewPlanConfig(estimated_duration=30)

        sessions = self.generator._create_review_sessions(concepts, config)

        self.assertGreater(len(sessions), 0)
        # ç”±äºæ€»æ—¶é—´30åˆ†é’Ÿï¼Œåº”è¯¥åˆ†æˆå¤šä¸ªä¼šè¯æˆ–å•ä¸ªä¼šè¯


class TestReviewCanvasBuilder(unittest.TestCase):
    """å¤ä¹ Canvasæ„å»ºå™¨æµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        self.builder = ReviewCanvasBuilder()
        self.temp_dir = tempfile.mkdtemp()

    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        shutil.rmtree(self.temp_dir)

    def test_create_review_canvas_basic(self):
        """æµ‹è¯•åŸºç¡€Canvasåˆ›å»º"""
        review_plan = {
            "plan_id": "test-plan-123",
            "user_id": "test_user",
            "target_canvas": "test_canvas.canvas",
            "plan_type": "weakness_focused",
            "review_sessions": [
                {
                    "session_id": "session-1",
                    "difficulty_level": "medium",
                    "estimated_duration": 30,
                    "learning_objectives": ["æŒæ¡åŸºç¡€æ¦‚å¿µ"],
                    "concepts": [
                        {
                            "concept_name": "æµ‹è¯•æ¦‚å¿µ",
                            "difficulty": "medium",
                            "estimated_time_minutes": 15,
                            "recommended_focus_areas": ["åŸºç¡€å¤ä¹ "],
                            "review_questions": [
                                {
                                    "question_text": "è¯·è§£é‡Šæµ‹è¯•æ¦‚å¿µ",
                                    "suggested_approach": "ä»å®šä¹‰å¼€å§‹"
                                }
                            ]
                        }
                    ]
                }
            ],
            "personalization_features": {
                "learning_style_adaptation": {
                    "preferred_approach": "self_explanation_focused"
                }
            },
            "next_review_date": datetime.now().isoformat()
        }

        output_path = os.path.join(self.temp_dir, "test_review.canvas")

        result_path = self.builder.create_review_canvas(
            review_plan=review_plan,
            output_path=output_path
        )

        self.assertEqual(result_path, output_path)
        self.assertTrue(os.path.exists(output_path))

        # éªŒè¯Canvasæ–‡ä»¶ç»“æ„
        with open(output_path, 'r', encoding='utf-8') as f:
            canvas_data = json.load(f)

        self.assertIn("nodes", canvas_data)
        self.assertIn("edges", canvas_data)
        self.assertGreater(len(canvas_data["nodes"]), 0)

    def test_generate_canvas_name(self):
        """æµ‹è¯•Canvasæ–‡ä»¶åç”Ÿæˆ"""
        target_canvas = "ç¦»æ•£æ•°å­¦.canvas"

        canvas_name = self.builder._generate_canvas_name(target_canvas)

        self.assertIn("ç¦»æ•£æ•°å­¦", canvas_name)
        self.assertIn("æ™ºèƒ½å¤ä¹ ", canvas_name)
        self.assertIn(datetime.now().strftime("%Y%m%d"), canvas_name)

    def test_add_intro_node(self):
        """æµ‹è¯•ä»‹ç»èŠ‚ç‚¹æ·»åŠ """
        canvas_data = {"nodes": [], "edges": []}
        review_plan = {
            "plan_type": "weakness_focused",
            "target_canvas": "test.canvas",
            "generation_timestamp": datetime.now().isoformat()
        }

        node, new_y = self.builder._add_intro_node(
            canvas_data, review_plan, 100, 100
        )

        self.assertEqual(len(canvas_data["nodes"]), 1)
        self.assertEqual(canvas_data["nodes"][0]["id"], node["id"])
        self.assertEqual(node["color"], "5")  # è“è‰²

    def test_add_concept_node(self):
        """æµ‹è¯•æ¦‚å¿µèŠ‚ç‚¹æ·»åŠ """
        canvas_data = {"nodes": [], "edges": []}
        concept = {
            "concept_name": "æµ‹è¯•æ¦‚å¿µ",
            "difficulty": "medium",
            "estimated_time_minutes": 15,
            "recommended_focus_areas": ["åŸºç¡€å¤ä¹ "],
            "review_questions": [
                {
                    "question_text": "è¯·è§£é‡Šæµ‹è¯•æ¦‚å¿µ",
                    "suggested_approach": "ä»å®šä¹‰å¼€å§‹"
                }
            ]
        }

        concept_node, new_x, new_y = self.builder._add_concept_node(
            canvas_data, concept, 100, 100
        )

        # åº”è¯¥æ·»åŠ 3ä¸ªèŠ‚ç‚¹ï¼šæ¦‚å¿µã€é—®é¢˜ã€é»„è‰²ç†è§£åŒº
        self.assertEqual(len(canvas_data["nodes"]), 3)
        self.assertEqual(len(canvas_data["edges"]), 2)  # æ¦‚å¿µ->é—®é¢˜, é—®é¢˜->é»„è‰²


class TestPersonalizationEngine(unittest.TestCase):
    """ä¸ªæ€§åŒ–å¼•æ“æµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        self.engine = PersonalizationEngine(user_id="test_user")

    def test_analyze_learning_style(self):
        """æµ‹è¯•å­¦ä¹ é£æ ¼åˆ†æ"""
        # æ¨¡æ‹Ÿå­¦ä¹ å†å²æ•°æ®
        learning_history = {
            "canvas_files": [
                {
                    "questions": [{"text": "é—®é¢˜1"}, {"text": "é—®é¢˜2"}],
                    "understanding_records": [
                        {"quality_score": 8.0},
                        {"quality_score": 7.5}
                    ],
                    "explanations": [
                        {"explanation_type": "definition"},
                        {"explanation_type": "example"}
                    ]
                }
            ]
        }

        result = self.engine.analyze_learning_style(learning_history)

        self.assertIn("primary_style", result)
        self.assertIn("style_confidence", result)
        self.assertIn("recommendations", result)
        self.assertGreater(result.style_confidence, 0)

    def test_optimize_time_management(self):
        """æµ‹è¯•æ—¶é—´ç®¡ç†ä¼˜åŒ–"""
        result = self.engine.optimize_time_management()

        self.assertIn("optimal_session_duration", result)
        self.assertIn("recommended_break_intervals", result)
        self.assertIn("peak_performance_periods", result)
        self.assertIn("optimal_study_times", result)
        self.assertGreater(result.optimal_session_duration, 20)
        self.assertLessEqual(result.optimal_session_duration, 120)

    def test_generate_motivation_profile(self):
        """æµ‹è¯•åŠ¨æœºæ¡£æ¡ˆç”Ÿæˆ"""
        result = self.engine.generate_motivation_profile()

        self.assertIn("primary_motivators", result)
        self.assertIn("achievement_preferences", result)
        self.assertIn("incentive_types", result)
        self.assertIn("personalized_encouragements", result)
        self.assertGreater(len(result.primary_motivators), 0)

    def test_update_user_preferences(self):
        """æµ‹è¯•ç”¨æˆ·åå¥½æ›´æ–°"""
        user_feedback = {
            "satisfaction": 0.8,
            "preferred_difficulty": "gradual",
            "content_preferences": {"visual": 0.8, "text": 0.6},
            "time_preferences": {"preferred_duration": 50},
            "complexity_tolerance": "moderate"
        }

        result = self.engine.update_user_preferences(user_feedback)

        self.assertEqual(result.user_id, "test_user")
        self.assertIn("updated_at", result)
        self.assertIn("created_at", result)

    def test_get_personalized_recommendations(self):
        """æµ‹è¯•ä¸ªæ€§åŒ–æ¨è"""
        from personalization_engine import UserProfile

        user_profile = UserProfile(
            user_id="test_user",
            learning_style="visual",
            preferred_difficulty_progression="gradual",
            optimal_study_duration=45,
            peak_performance_times=["morning", "evening"],
            feedback_preferences=["immediate"],
            motivation_factors=["achievement", "mastery"],
            interaction_patterns={},
            complexity_tolerance="moderate",
            content_preferences={},
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat()
        )

        current_context = {"current_time": "morning"}

        result = self.engine.get_personalized_recommendations(user_profile, current_context)

        self.assertIn("learning_approach", result)
        self.assertIn("content_format", result)
        self.assertIn("time_suggestions", result)
        self.assertIn("motivation_strategies", result)


class TestIntelligentReviewCLI(unittest.TestCase):
    """æ™ºèƒ½å¤ä¹ CLIæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        self.cli = IntelligentReviewCLI()
        self.temp_dir = tempfile.mkdtemp()

    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        shutil.rmtree(self.temp_dir)

    def test_cli_initialization(self):
        """æµ‹è¯•CLIåˆå§‹åŒ–"""
        self.assertIsNotNone(self.cli.learning_analyzer)
        self.assertIsNotNone(self.cli.review_generator)
        self.assertIsNotNone(self.cli.canvas_builder)
        self.assertIsNotNone(self.cli.personalization_engine)
        self.assertTrue(self.cli.data_dir.exists())

    @patch('intelligent_review_cli.IntelligentReviewGenerator.generate_review_plan')
    def test_generate_review_plan_command(self, mock_generate):
        """æµ‹è¯•ç”Ÿæˆå¤ä¹ è®¡åˆ’å‘½ä»¤"""
        # æ¨¡æ‹Ÿè¿”å›æ•°æ®
        mock_generate.return_value = {
            "plan_id": "test-plan-123",
            "user_id": "test_user",
            "target_canvas": "test.canvas",
            "analysis_summary": {
                "total_concepts_analyzed": 5,
                "concepts_mastered": 2,
                "concepts_needing_review": 3
            },
            "review_sessions": [
                {
                    "session_id": "session-1",
                    "estimated_duration": 30,
                    "difficulty_level": "medium",
                    "concepts": []
                }
            ],
            "estimated_completion_time": {
                "total_estimated_minutes": 30
            }
        }

        # åˆ›å»ºæ¨¡æ‹Ÿå‚æ•°
        class MockArgs:
            canvas_path = "test.canvas"
            plan_type = "weakness_focused"
            difficulty = "adaptive"
            duration = 45
            max_concepts = 5
            user_id = "test_user"
            output = None
            include_explanations = True
            include_examples = True

        args = MockArgs()

        # æ‰§è¡Œå‘½ä»¤
        with patch('intelligent_review_cli.ReviewCanvasBuilder.create_review_canvas') as mock_canvas:
            mock_canvas.return_value = "test_output.canvas"

            with patch('builtins.open', create=True) as mock_file:
                mock_file.return_value.__enter__.return_value.write.return_value = None

                self.cli.generate_review_plan(args)

        # éªŒè¯è°ƒç”¨
        mock_generate.assert_called_once()

    def test_analyze_canvas_progress(self):
        """æµ‹è¯•Canvasè¿›åº¦åˆ†æ"""
        review_plan = {
            "plan_id": "test-plan",
            "review_sessions": [
                {
                    "concepts": [
                        {"concept_name": "æ¦‚å¿µ1"},
                        {"concept_name": "æ¦‚å¿µ2"}
                    ]
                }
            ]
        }

        progress = self.cli._analyze_canvas_progress(review_plan)

        self.assertIn("total_concepts", progress)
        self.assertIn("completed_concepts", progress)
        self.assertIn("completion_rate", progress)


class TestSystemIntegration(unittest.TestCase):
    """ç³»ç»Ÿé›†æˆæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        self.temp_dir = tempfile.mkdtemp()

    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        shutil.rmtree(self.temp_dir)

    def test_end_to_end_workflow(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµ"""
        # 1. åˆ›å»ºå­¦ä¹ åˆ†æå™¨
        analyzer = LearningAnalyzer()

        # 2. åˆ›å»ºå¤ä¹ è®¡åˆ’ç”Ÿæˆå™¨
        generator = IntelligentReviewGenerator(learning_analyzer=analyzer)

        # 3. åˆ›å»ºCanvasæ„å»ºå™¨
        builder = ReviewCanvasBuilder()

        # 4. åˆ›å»ºä¸ªæ€§åŒ–å¼•æ“
        personalization = PersonalizationEngine()

        # 5. åˆ›å»ºCLI
        cli = IntelligentReviewCLI()

        # éªŒè¯æ‰€æœ‰ç»„ä»¶éƒ½èƒ½æ­£å¸¸åˆå§‹åŒ–
        self.assertIsNotNone(analyzer)
        self.assertIsNotNone(generator)
        self.assertIsNotNone(builder)
        self.assertIsNotNone(personalization)
        self.assertIsNotNone(cli)

    def test_configuration_compatibility(self):
        """æµ‹è¯•é…ç½®å…¼å®¹æ€§"""
        from intelligent_review_generator import ReviewPlanConfig

        # æµ‹è¯•å„ç§é…ç½®ç»„åˆ
        configs = [
            ReviewPlanConfig(plan_type="weakness_focused"),
            ReviewPlanConfig(plan_type="comprehensive"),
            ReviewPlanConfig(plan_type="targeted"),
            ReviewPlanConfig(difficulty_level="easy"),
            ReviewPlanConfig(difficulty_level="adaptive"),
            ReviewPlanConfig(estimated_duration=30),
            ReviewPlanConfig(max_concepts_per_session=3)
        ]

        for config in configs:
            self.assertIsInstance(config.user_id, str)
            self.assertIsInstance(config.target_canvas, str)
            self.assertIn(config.plan_type, ["weakness_focused", "comprehensive", "targeted"])

    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        # æµ‹è¯•ä¸å­˜åœ¨çš„æ–‡ä»¶
        analyzer = LearningAnalyzer()

        with self.assertRaises(Exception):
            analyzer.analyze_learning_history(canvas_path="nonexistent.canvas")

    def test_performance_requirements(self):
        """æµ‹è¯•æ€§èƒ½è¦æ±‚"""
        import time

        # æµ‹è¯•å­¦ä¹ åˆ†ææ€§èƒ½
        start_time = time.time()
        analyzer = LearningAnalyzer()
        canvas_files = analyzer._find_canvas_files()
        analysis_time = time.time() - start_time

        # åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆï¼ˆ<5ç§’ï¼‰
        self.assertLess(analysis_time, 5.0)

        # æµ‹è¯•å¤ä¹ è®¡åˆ’ç”Ÿæˆæ€§èƒ½
        start_time = time.time()
        generator = IntelligentReviewGenerator()

        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®é¿å…æ–‡ä»¶ä¾èµ–
        with patch.object(generator.learning_analyzer, 'analyze_learning_history') as mock_analyze:
            mock_analyze.return_value = {
                "analysis_summary": {},
                "identified_weak_concepts": []
            }

            config = ReviewPlanConfig()
            try:
                generator.generate_review_plan("test", "test", "weakness_focused", config)
            except:
                pass  # é¢„æœŸå¯èƒ½å¤±è´¥ï¼Œå› ä¸ºå…¶ä»–ä¾èµ–

        generation_time = time.time() - start_time
        self.assertLess(generation_time, 10.0)


class TestAccuracyValidation(unittest.TestCase):
    """å‡†ç¡®æ€§éªŒè¯æµ‹è¯•"""

    def test_weakness_identification_accuracy(self):
        """æµ‹è¯•è–„å¼±ç¯èŠ‚è¯†åˆ«å‡†ç¡®æ€§"""
        generator = IntelligentReviewGenerator()

        # æµ‹è¯•æ•°æ®ï¼šå·²çŸ¥æŒæ¡ç¨‹åº¦çš„æ¦‚å¿µ
        test_concepts = [
            {"name": "å®Œå…¨æŒæ¡", "score": 9.5, "expected_weakness": 0.1},
            {"name": "éƒ¨åˆ†æŒæ¡", "score": 6.0, "expected_weakness": 0.4},
            {"name": "æœªæŒæ¡", "score": 3.0, "expected_weakness": 0.7},
            {"name": "éå¸¸è–„å¼±", "score": 1.0, "expected_weakness": 0.9}
        ]

        for concept in test_concepts:
            # éªŒè¯è–„å¼±åˆ†æ•°è®¡ç®—é€»è¾‘
            expected_weakness = concept["expected_weakness"]
            actual_weakness = max(0, (10 - concept["score"]) / 10)

            self.assertAlmostEqual(
                actual_weakness, expected_weakness, 0.1,
                f"æ¦‚å¿µ {concept['name']} çš„è–„å¼±åˆ†æ•°è®¡ç®—ä¸å‡†ç¡®"
            )

    def test_difficulty_classification_accuracy(self):
        """æµ‹è¯•éš¾åº¦åˆ†ç±»å‡†ç¡®æ€§"""
        generator = IntelligentReviewGenerator()

        # æµ‹è¯•ä¸åŒæŒæ¡ç¨‹åº¦çš„éš¾åº¦åˆ†ç±»
        test_cases = [
            {"score": 9.0, "expected_difficulties": ["hard", "expert"]},
            {"score": 6.0, "expected_difficulties": ["medium", "hard"]},
            {"score": 4.0, "expected_difficulties": ["easy", "medium"]},
            {"score": 2.0, "expected_difficulties": ["easy"]}
        ]

        config = ReviewPlanConfig(difficulty_level="adaptive")

        for case in test_cases:
            concept_data = {"mastery_score": case["score"]}
            difficulty = generator._determine_concept_difficulty(concept_data, config)

            # éªŒè¯éš¾åº¦åˆ†ç±»åˆç†æ€§
            self.assertIn(difficulty, ["easy", "medium", "hard", "expert"])

            # é«˜åˆ†åº”è¯¥å¯¹åº”é«˜éš¾åº¦ï¼Œä½åˆ†åº”è¯¥å¯¹åº”ä½éš¾åº¦
            if case["score"] >= 8:
                self.assertIn(difficulty, ["hard", "expert"])
            elif case["score"] <= 4:
                self.assertEqual(difficulty, "easy")

    def test_time_estimation_accuracy(self):
        """æµ‹è¯•æ—¶é—´ä¼°ç®—å‡†ç¡®æ€§"""
        builder = ReviewCanvasBuilder()

        # æµ‹è¯•ä¸åŒå¤æ‚åº¦æ¦‚å¿µçš„æ—¶é—´ä¼°ç®—
        test_concepts = [
            {
                "mastery_score": 9.0,
                "weakness_score": 0.1,
                "estimated_time": 8
            },
            {
                "mastery_score": 5.0,
                "weakness_score": 0.5,
                "estimated_time": 12
            },
            {
                "mastery_score": 2.0,
                "weakness_score": 0.8,
                "estimated_time": 20
            }
        ]

        for concept in test_concepts:
            config = ReviewPlanConfig()
            estimated_time = builder._estimate_concept_review_time(concept, config)

            # éªŒè¯æ—¶é—´ä¼°ç®—åœ¨åˆç†èŒƒå›´å†…ï¼ˆ5-30åˆ†é’Ÿï¼‰
            self.assertGreaterEqual(estimated_time, 5)
            self.assertLessEqual(estimated_time, 30)

            # éªŒè¯æ—¶é—´ä¼°ç®—é€»è¾‘ï¼šæŒæ¡åº¦è¶Šä½ï¼Œæ—¶é—´è¶Šé•¿
            if concept["mastery_score"] < 5:
                self.assertGreater(estimated_time, 10)
            elif concept["mastery_score"] > 8:
                self.assertLessEqual(estimated_time, 15)


def run_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹è¿è¡Œæ™ºèƒ½å¤ä¹ ç³»ç»Ÿæµ‹è¯•å¥—ä»¶...")
    print("="*60)

    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()

    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestLearningAnalyzer,
        TestIntelligentReviewGenerator,
        TestReviewCanvasBuilder,
        TestPersonalizationEngine,
        TestIntelligentReviewCLI,
        TestSystemIntegration,
        TestAccuracyValidation
    ]

    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)

    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)

    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡:")
    print(f"  æ€»æµ‹è¯•æ•°: {result.testsRun}")
    print(f"  æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"  å¤±è´¥: {len(result.failures)}")
    print(f"  é”™è¯¯: {len(result.errors)}")
    print(f"  è·³è¿‡: {len(result.skipped)}")

    if result.failures:
        print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback.split('AssertionError:')[-1].strip()}")

    if result.errors:
        print(f"\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback.split('Error:')[-1].strip()}")

    success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100
    print(f"\nâœ… æµ‹è¯•é€šè¿‡ç‡: {success_rate:.1f}%")

    if success_rate >= 90:
        print("ğŸ‰ æµ‹è¯•é€šè¿‡ï¼æ™ºèƒ½å¤ä¹ ç³»ç»ŸåŠŸèƒ½æ­£å¸¸ã€‚")
    elif success_rate >= 70:
        print("âš ï¸ æµ‹è¯•åŸºæœ¬é€šè¿‡ï¼Œå»ºè®®æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•ã€‚")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥è¾ƒå¤šï¼Œéœ€è¦ä¿®å¤é—®é¢˜ã€‚")

    return result.wasSuccessful()


if __name__ == "__main__":
    run_tests()