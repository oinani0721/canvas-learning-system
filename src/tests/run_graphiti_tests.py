#!/usr/bin/env python3
"""
Graphitiæµ‹è¯•è¿è¡Œå™¨

è¿è¡Œæ‰€æœ‰Graphitiç›¸å…³çš„æµ‹è¯•å¹¶ç”ŸæˆæŠ¥å‘Šã€‚

Author: Canvas Learning System Team
Version: 1.0
Created: 2025-01-22
"""

import sys
import time
import unittest
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰Graphitiæµ‹è¯•"""
    print("ğŸš€ å¼€å§‹è¿è¡ŒGraphitiçŸ¥è¯†å›¾è°±ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)

    # æµ‹è¯•å¥—ä»¶
    test_modules = [
        'test_concept_extractor',
        'test_graphiti_integration',
        'test_graphiti_integration_comprehensive'
    ]

    total_tests = 0
    total_failures = 0
    total_errors = 0
    total_skipped = 0

    start_time = time.time()

    for module_name in test_modules:
        print(f"\nğŸ“‹ è¿è¡Œæµ‹è¯•æ¨¡å—: {module_name}")
        print("-" * 40)

        try:
            # å¯¼å…¥æµ‹è¯•æ¨¡å—
            module = __import__(module_name)

            # åˆ›å»ºæµ‹è¯•å¥—ä»¶
            loader = unittest.TestLoader()
            suite = loader.loadTestsFromModule(module)

            # è¿è¡Œæµ‹è¯•
            runner = unittest.TextTestRunner(verbosity=2)
            result = runner.run(suite)

            # ç»Ÿè®¡ç»“æœ
            total_tests += result.testsRun
            total_failures += len(result.failures)
            total_errors += len(result.errors)
            total_skipped += len(result.skipped)

            # æ‰“å°ç»“æœæ‘˜è¦
            print(f"\nğŸ“Š {module_name} æµ‹è¯•ç»“æœ:")
            print(f"   è¿è¡Œ: {result.testsRun}")
            print(f"   å¤±è´¥: {len(result.failures)}")
            print(f"   é”™è¯¯: {len(result.errors)}")
            print(f"   è·³è¿‡: {len(result.skipped)}")

            if result.failures:
                print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
                for test, traceback in result.failures:
                    print(f"   - {test}: {traceback.split('AssertionError:')[-1].strip() if 'AssertionError:' in traceback else 'Unknown'}")

            if result.errors:
                print("\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
                for test, traceback in result.errors:
                    print(f"   - {test}: {traceback.split('Exception:')[-1].strip() if 'Exception:' in traceback else 'Unknown'}")

        except Exception as e:
            print(f"âŒ è¿è¡Œæµ‹è¯•æ¨¡å— {module_name} æ—¶å‡ºé”™: {e}")
            total_errors += 1

    end_time = time.time()
    duration = end_time - start_time

    # æ€»ä½“ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ€»ä½“æµ‹è¯•ç»“æœ")
    print("=" * 60)
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"æˆåŠŸ: {total_tests - total_failures - total_errors - total_skipped}")
    print(f"å¤±è´¥: {total_failures}")
    print(f"é”™è¯¯: {total_errors}")
    print(f"è·³è¿‡: {total_skipped}")
    print(f"è¿è¡Œæ—¶é—´: {duration:.2f}ç§’")

    success_rate = ((total_tests - total_failures - total_errors) / total_tests * 100) if total_tests > 0 else 0
    print(f"æˆåŠŸç‡: {success_rate:.1f}%")

    if total_failures == 0 and total_errors == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print(f"\nâš ï¸  æœ‰ {total_failures + total_errors} ä¸ªæµ‹è¯•æœªé€šè¿‡")
        return False


def run_specific_test(test_name):
    """è¿è¡Œç‰¹å®šçš„æµ‹è¯•"""
    print(f"ğŸ” è¿è¡Œç‰¹å®šæµ‹è¯•: {test_name}")
    print("-" * 40)

    try:
        # å°è¯•ä½œä¸ºæ¨¡å—è¿è¡Œ
        if test_name.startswith('test_'):
            module = __import__(test_name)
            loader = unittest.TestLoader()
            suite = loader.loadTestsFromModule(module)
        else:
            # å°è¯•ä½œä¸ºæµ‹è¯•ç±»è¿è¡Œ
            loader = unittest.TestLoader()
            suite = loader.loadTestsFromName(test_name)

        runner = unittest.TextTestRunner(verbosity=2)
        result = runner.run(suite)

        return result.wasSuccessful()

    except Exception as e:
        print(f"âŒ è¿è¡Œæµ‹è¯•å¤±è´¥: {e}")
        return False


def generate_test_report():
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    report = {
        "timestamp": datetime.now().isoformat(),
        "system": "Canvas Learning System - Graphiti Knowledge Graph",
        "version": "1.0",
        "test_categories": [
            {
                "name": "æ¦‚å¿µæå–æµ‹è¯•",
                "module": "test_concept_extractor",
                "description": "æµ‹è¯•æ¦‚å¿µæå–å™¨çš„å„ç§åŠŸèƒ½ï¼ŒåŒ…æ‹¬ä¸­æ–‡åˆ†è¯ã€å…³ç³»è¯†åˆ«ã€ç½®ä¿¡åº¦è®¡ç®—ç­‰"
            },
            {
                "name": "Graphitié›†æˆæµ‹è¯•",
                "module": "test_graphiti_integration",
                "description": "æµ‹è¯•GraphitiçŸ¥è¯†å›¾è°±ç®¡ç†å™¨çš„æ ¸å¿ƒåŠŸèƒ½"
            },
            {
                "name": "ç»¼åˆé›†æˆæµ‹è¯•",
                "module": "test_graphiti_integration_comprehensive",
                "description": "ç«¯åˆ°ç«¯æµ‹è¯•ï¼ŒéªŒè¯æ•´ä¸ªç³»ç»Ÿçš„é›†æˆå’Œæ€§èƒ½"
            }
        ],
        "coverage_areas": [
            "æ¦‚å¿µæå–å’Œå…³ç³»è¯†åˆ«",
            "çŸ¥è¯†å›¾è°±å­˜å‚¨å’Œæ£€ç´¢",
            "å‘½ä»¤è¡Œæ¥å£",
            "å¯è§†åŒ–ç”Ÿæˆ",
            "æ•°æ®å¤‡ä»½å’Œæ¢å¤",
            "æ€§èƒ½å’Œå¯æ‰©å±•æ€§",
            "é”™è¯¯å¤„ç†å’Œå¥å£®æ€§"
        ]
    }

    report_path = Path(__file__).parent / "test_report.json"
    import json
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1:
        # è¿è¡Œç‰¹å®šæµ‹è¯•
        test_name = sys.argv[1]
        success = run_specific_test(test_name)
    else:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        success = run_all_tests()
        generate_test_report()

    # é€€å‡ºç 
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
