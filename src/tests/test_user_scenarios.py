"""
ç”¨æˆ·åœºæ™¯éªŒè¯æµ‹è¯• - Canvaså­¦ä¹ ç³»ç»Ÿ

æœ¬æ¨¡å—åŒ…å«å„ç§çœŸå®ç”¨æˆ·ä½¿ç”¨åœºæ™¯çš„éªŒè¯æµ‹è¯•ï¼Œç¡®ä¿æ™ºèƒ½å¤ä¹ è®¡åˆ’ç”Ÿæˆç³»ç»Ÿ
åœ¨å®é™…ä½¿ç”¨åœºæ™¯ä¸­çš„å¯é æ€§å’Œå®ç”¨æ€§ã€‚

Author: Canvas Learning System Team
Version: 1.0
Created: 2025-01-23
"""

import json
import os
import shutil

# å¯¼å…¥å¾…æµ‹è¯•çš„æ¨¡å—
import sys
import tempfile
import unittest
from datetime import datetime, timedelta
from pathlib import Path
from unittest.mock import patch

sys.path.append('..')

try:
    from intelligent_review_cli import IntelligentReviewCLI
    from intelligent_review_generator import IntelligentReviewGenerator, ReviewPlanConfig
    from learning_analyzer import LearningAnalyzer
    from personalization_engine import PersonalizationEngine
    from review_canvas_builder import ReviewCanvasBuilder
except ImportError as e:
    print(f"Warning: æ— æ³•å¯¼å…¥æµ‹è¯•æ¨¡å—: {e}")


class TestUserScenarioValidation(unittest.TestCase):
    """ç”¨æˆ·åœºæ™¯éªŒè¯æµ‹è¯•åŸºç±»"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        self.temp_dir = tempfile.mkdtemp()
        self.create_test_data()

    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        shutil.rmtree(self.temp_dir)

    def create_test_data(self):
        """åˆ›å»ºæµ‹è¯•æ•°æ®"""
        # åˆ›å»ºæµ‹è¯•Canvasæ–‡ä»¶
        self.test_canvas_path = os.path.join(self.temp_dir, "test_discrete_math.canvas")
        test_canvas_data = {
            "nodes": [
                {
                    "id": "node-1",
                    "type": "text",
                    "text": "é€»è¾‘ç­‰ä»·æ€§",
                    "x": 100,
                    "y": 100,
                    "width": 200,
                    "height": 100,
                    "color": "1"  # çº¢è‰² - éœ€è¦å¤ä¹ 
                },
                {
                    "id": "node-2",
                    "type": "text",
                    "text": "å·²æŒæ¡çš„æ¦‚å¿µ",
                    "x": 300,
                    "y": 100,
                    "width": 200,
                    "height": 100,
                    "color": "2"  # ç»¿è‰² - å·²æŒæ¡
                },
                {
                    "id": "node-3",
                    "type": "text",
                    "text": "æˆ‘ç†è§£é€»è¾‘ç­‰ä»·æ€§æ˜¯...",
                    "x": 200,
                    "y": 250,
                    "width": 250,
                    "height": 100,
                    "color": "6"  # é»„è‰² - ä¸ªäººç†è§£
                }
            ],
            "edges": []
        }

        with open(self.test_canvas_path, 'w', encoding='utf-8') as f:
            json.dump(test_canvas_data, f, ensure_ascii=False, indent=2)

        # åˆ›å»ºæ•°æ®ç›®å½•
        self.data_dir = Path(self.temp_dir) / "data" / "review_plans"
        self.data_dir.mkdir(parents=True, exist_ok=True)


class TestNewUserScenario(TestUserScenarioValidation):
    """æ–°ç”¨æˆ·é¦–æ¬¡ä½¿ç”¨åœºæ™¯æµ‹è¯•"""

    def test_new_user_first_review_plan(self):
        """æµ‹è¯•æ–°ç”¨æˆ·é¦–æ¬¡ç”Ÿæˆå¤ä¹ è®¡åˆ’"""
        print("\nğŸ¯ æµ‹è¯•åœºæ™¯: æ–°ç”¨æˆ·é¦–æ¬¡ä½¿ç”¨")

        # 1. æ–°ç”¨æˆ·ç”Ÿæˆå¤ä¹ è®¡åˆ’
        generator = IntelligentReviewGenerator()
        builder = ReviewCanvasBuilder()

        # åˆ›å»ºæ–°ç”¨æˆ·é…ç½®
        config = ReviewPlanConfig(
            user_id="new_user",
            target_canvas="test_discrete_math.canvas",
            plan_type="weakness_focused",
            difficulty_level="easy",
            estimated_duration=30,
            max_concepts_per_session=3
        )

        # æ¨¡æ‹Ÿå­¦ä¹ åˆ†æç»“æœ
        mock_analysis_result = {
            "analysis_summary": {
                "total_concepts_analyzed": 2,
                "concepts_mastered": 1,
                "concepts_needing_review": 1,
                "critical_weaknesses": 0
            },
            "identified_weak_concepts": [
                {
                    "concept_name": "é€»è¾‘ç­‰ä»·æ€§",
                    "weakness_score": 0.6,
                    "mastery_score": 4.0,
                    "weakness_type": "conceptual_misunderstanding",
                    "recommended_focus_areas": [
                        "æ¦‚å¿µå®šä¹‰å¤ä¹ ",
                        "åŸºç¡€ç»ƒä¹ åŠ å¼º"
                    ],
                    "supporting_evidence": {
                        "last_review_score": 4,
                        "review_frequency": "insufficient",
                        "graphiti_related_concepts": ["é€»è¾‘è•´å«", "çœŸå€¼è¡¨"],
                        "mcp_semantic_gaps": ["æ¦‚å¿µæ··æ·†"]
                    }
                }
            ],
            "learning_trends": {
                "overall_performance_trend": "stable",
                "study_frequency_trend": "increasing",
                "retention_analysis": {
                    "short_term_retention": 0.8,
                    "optimal_review_interval": 7
                }
            }
        }

        with patch.object(generator.learning_analyzer, 'analyze_learning_history') as mock_analyze:
            mock_analyze.return_value = mock_analysis_result

            # ç”Ÿæˆå¤ä¹ è®¡åˆ’
            review_plan = generator.generate_review_plan(
                user_id="new_user",
                target_canvas="test_discrete_math.canvas",
                plan_type="weakness_focused",
                config=config
            )

        # éªŒè¯ç”Ÿæˆç»“æœ
        self.assertIn("plan_id", review_plan)
        self.assertEqual(review_plan["user_id"], "new_user")
        self.assertEqual(review_plan["plan_type"], "weakness_focused")

        # éªŒè¯ä¼šè¯é€‚åˆæ–°ç”¨æˆ·
        sessions = review_plan.get("review_sessions", [])
        self.assertEqual(len(sessions), 1)  # æ–°ç”¨æˆ·åº”è¯¥åªæœ‰ä¸€ä¸ªä¼šè¯
        self.assertLessEqual(sessions[0]["estimated_duration"], 30)

        # éªŒè¯éš¾åº¦é€‚åˆæ–°ç”¨æˆ·
        self.assertEqual(sessions[0]["difficulty_level"], "easy" or "medium")

        # 2. åˆ›å»ºå¤ä¹ Canvas
        canvas_path = builder.create_review_canvas(
            review_plan=review_plan,
            output_path=os.path.join(self.temp_dir, "new_user_review.canvas")
        )

        self.assertTrue(os.path.exists(canvas_path))

        # éªŒè¯Canvaså†…å®¹é€‚åˆæ–°ç”¨æˆ·
        with open(canvas_path, 'r', encoding='utf-8') as f:
            canvas_data = json.load(f)

        nodes = canvas_data.get("nodes", [])

        # åº”è¯¥åŒ…å«ä»‹ç»èŠ‚ç‚¹
        intro_nodes = [n for n in nodes if "å¤ä¹ æ¦‚è§ˆ" in n.get("text", "")]
        self.assertGreater(len(intro_nodes), 0)

        # åº”è¯¥åŒ…å«è¿›åº¦è·Ÿè¸ª
        progress_nodes = [n for n in nodes if "è¿›åº¦è·Ÿè¸ª" in n.get("text", "")]
        self.assertGreater(len(progress_nodes), 0)

        # åº”è¯¥åŒ…å«å­¦ä¹ å»ºè®®
        suggestion_nodes = [n for n in nodes if "å­¦ä¹ å»ºè®®" in n.get("text", "")]
        self.assertGreater(len(suggestion_nodes), 0)

        print("âœ… æ–°ç”¨æˆ·åœºæ™¯æµ‹è¯•é€šè¿‡")

    def test_new_user_personalization(self):
        """æµ‹è¯•æ–°ç”¨æˆ·ä¸ªæ€§åŒ–åŠŸèƒ½"""
        print("ğŸ¯ æµ‹è¯•: æ–°ç”¨æˆ·ä¸ªæ€§åŒ–")

        engine = PersonalizationEngine(user_id="new_user")

        # æ–°ç”¨æˆ·æ²¡æœ‰å†å²æ•°æ®ï¼Œåº”è¯¥è¿”å›é»˜è®¤åˆ†æ
        learning_style = engine.analyze_learning_learning_style()

        self.assertIn("primary_style", learning_style)
        self.assertIn("style_confidence", learning_style)
        self.assertIn("recommendations", learning_style)

        # å¯¹äºæ–°ç”¨æˆ·ï¼Œç½®ä¿¡åº¦åº”è¯¥è¾ƒä½
        self.assertLessEqual(learning_style.style_confidence, 0.7)

        # æ—¶é—´ä¼˜åŒ–åº”è¯¥æä¾›åˆç†çš„é»˜è®¤å€¼
        time_optimization = engine.optimize_time_management()

        self.assertIn("optimal_session_duration", time_optimization)
        self.assertGreater(time_optimization.optimal_session_duration, 20)
        self.assertLessEqual(time_optimization.optimal_session_duration, 60)

        # åŠ¨æœºæ¡£æ¡ˆåº”è¯¥åŒ…å«åŸºæœ¬è¦ç´ 
        motivation_profile = engine.generate_motivation_profile()

        self.assertIn("primary_motivators", motivation_profile)
        self.assertIn("personalized_encouragements", motivation_profile)
        self.assertGreater(len(motivation_profile.personalized_encouragements), 0)

        print("âœ… æ–°ç”¨æˆ·ä¸ªæ€§åŒ–æµ‹è¯•é€šè¿‡")


class TestRegularUserScenario(TestUserScenarioValidation):
    """è€ç”¨æˆ·å¸¸è§„ä½¿ç”¨åœºæ™¯æµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        super().setUp()
        self.create_user_history()

    def create_user_history(self):
        """åˆ›å»ºç”¨æˆ·å†å²æ•°æ®"""
        # æ¨¡æ‹Ÿå¤šæ¬¡å­¦ä¹ è®°å½•
        history_data = []
        base_time = datetime.now() - timedelta(days=30)

        for i in range(20):
            learning_time = base_time + timedelta(days=i)
            score = 5.0 + (i * 0.2)  # é€æ¸æå‡

            record = {
                "timestamp": learning_time.isoformat(),
                "concept": f"æ¦‚å¿µ{i % 5 + 1}",
                "score": min(10.0, score),
                "time_spent": 20 + (i % 3) * 10,
                "user_feedback": "good" if score > 7 else "need_more_practice"
            }
            history_data.append(record)

        self.user_history_file = os.path.join(self.temp_dir, "user_history.json")
        with open(self.user_history_file, 'w', encoding='utf-8') as f:
            json.dump(history_data, f, ensure_ascii=False, indent=2)

    def test_regular_user_advanced_plan(self):
        """æµ‹è¯•è€ç”¨æˆ·é«˜çº§å¤ä¹ è®¡åˆ’"""
        print("\nğŸ¯ æµ‹è¯•åœºæ™¯: è€ç”¨æˆ·é«˜çº§å¤ä¹ ")

        generator = IntelligentReviewGenerator()
        builder = ReviewCanvasBuilder()

        # è€ç”¨æˆ·é…ç½®ï¼šæ›´é«˜éš¾åº¦ï¼Œæ›´å¤šæ¦‚å¿µ
        config = ReviewPlanConfig(
            user_id="regular_user",
            target_canvas="test_discrete_math.canvas",
            plan_type="comprehensive",
            difficulty_level="adaptive",
            estimated_duration=60,
            max_concepts_per_session=6
        )

        # æ¨¡æ‹Ÿè€ç”¨æˆ·çš„å­¦ä¹ åˆ†æç»“æœ
        mock_analysis_result = {
            "analysis_summary": {
                "total_concepts_analyzed": 10,
                "concepts_mastered": 7,
                "concepts_needing_review": 3,
                "critical_weaknesses": 1
            },
            "identified_weak_concepts": [
                {
                    "concept_name": "å¤æ‚æ¦‚å¿µ1",
                    "weakness_score": 0.4,
                    "mastery_score": 6.0,
                    "weakness_type": "procedural_error",
                    "recommended_focus_areas": [
                        "é«˜çº§åº”ç”¨ç»ƒä¹ ",
                        "å¤æ‚æ¡ˆä¾‹åˆ†æ"
                    ]
                },
                {
                    "concept_name": "å¤æ‚æ¦‚å¿µ2",
                    "weakness_score": 0.3,
                    "mastery_score": 7.5,
                    "weakness_type": "recall_failure",
                    "recommended_focus_areas": [
                        "å¤ä¹ é¢‘ç‡è°ƒæ•´",
                        "è®°å¿†æŠ€å·§åº”ç”¨"
                    ]
                }
            ],
            "learning_trends": {
                "overall_performance_trend": "improving",
                "study_frequency_trend": "stable",
                "concept_mastery_trend": "improving",
                "weakness_improvement_rate": 0.25,
                "retention_analysis": {
                    "short_term_retention": 0.85,
                    "long_term_retention": 0.75,
                    "optimal_review_interval": 14
                }
            }
        }

        with patch.object(generator.learning_analyzer, 'analyze_learning_history') as mock_analyze:
            mock_analyze.return_value = mock_analysis_result

            # ç”Ÿæˆå¤ä¹ è®¡åˆ’
            review_plan = generator.generate_review_plan(
                user_id="regular_user",
                target_canvas="test_discrete_math.canvas",
                plan_type="comprehensive",
                config=config
            )

        # éªŒè¯è€ç”¨æˆ·è®¡åˆ’ç‰¹ç‚¹
        self.assertEqual(review_plan["plan_type"], "comprehensive")

        sessions = review_plan.get("review_sessions", [])
        self.assertGreaterEqual(len(sessions), 1)  # å¯èƒ½éœ€è¦å¤šä¸ªä¼šè¯

        total_duration = sum(s["estimated_duration"] for s in sessions)
        self.assertGreaterEqual(total_duration, 45)  # åº”è¯¥æ¥è¿‘60åˆ†é’Ÿ

        # éªŒè¯åŒ…å«å·²æŒæ¡æ¦‚å¿µçš„å¤ä¹ 
        summary = review_plan.get("analysis_summary", {})
        self.assertGreater(summary.get("concepts_mastered", 0), 3)

        # 2. åˆ›å»ºé€‚åˆè€ç”¨æˆ·çš„Canvas
        canvas_path = builder.create_review_canvas(
            review_plan=review_plan,
            output_path=os.path.join(self.temp_dir, "advanced_review.canvas")
        )

        self.assertTrue(os.path.exists(canvas_path))

        # éªŒè¯Canvaså†…å®¹æ›´æ·±å…¥
        with open(canvas_path, 'r', encoding='utf-8') as f:
            canvas_data = json.load(f)

        nodes = canvas_data.get("nodes", [])

        # åº”è¯¥åŒ…å«æ›´å¤æ‚çš„å­¦ä¹ ç›®æ ‡
        objective_nodes = [n for n in nodes if "å­¦ä¹ ç›®æ ‡" in n.get("text", "")]
        self.assertGreater(len(objective_nodes), 0)

        print("âœ… è€ç”¨æˆ·é«˜çº§è®¡åˆ’æµ‹è¯•é€šè¿‡")

    def test_regular_user_progress_tracking(self):
        """æµ‹è¯•è€ç”¨æˆ·è¿›åº¦è·Ÿè¸ª"""
        print("ğŸ¯ æµ‹è¯•: è€ç”¨æˆ·è¿›åº¦è·Ÿè¸ª")

        cli = IntelligentReviewCLI()

        # æ¨¡æ‹Ÿæœ‰å†å²è®¡åˆ’çš„ç”¨æˆ·
        plan_data = {
            "plan_id": "regular-user-plan-123",
            "user_id": "regular_user",
            "generation_timestamp": (datetime.now() - timedelta(days=7)).isoformat(),
            "review_sessions": [
                {
                    "session_id": "session-1",
                    "concepts": [
                        {"concept_name": "æ¦‚å¿µ1", "estimated_time_minutes": 15},
                        {"concept_name": "æ¦‚å¿µ2", "estimated_time_minutes": 12}
                    ]
                }
            ]
        }

        plan_file = self.data_dir / f"{plan_data['plan_id']}.json"
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan_data, f, ensure_ascii=False, indent=2)

        # æ¨¡æ‹Ÿè¿›åº¦åˆ†æ
        progress = cli._analyze_canvas_progress(plan_data)

        self.assertIn("completed_concepts", progress)
        self.assertIn("total_concepts", progress)
        self.assertIn("completion_rate", progress)
        self.assertIn("average_score", progress)

        # è€ç”¨æˆ·åº”è¯¥æœ‰ä¸€å®šçš„å®Œæˆåº¦
        # è¿™é‡Œæ¨¡æ‹Ÿå®Œæˆåº¦ï¼Œå®é™…åº”è¯¥ä»Canvasæ–‡ä»¶è¯»å–
        progress["completed_concepts"] = 1
        progress["total_concepts"] = 2
        progress["completion_rate"] = 0.5
        progress["average_score"] = 7.5

        self.assertEqual(progress["completion_rate"], 0.5)
        self.assertEqual(progress["average_score"], 7.5)

        print("âœ… è€ç”¨æˆ·è¿›åº¦è·Ÿè¸ªæµ‹è¯•é€šè¿‡")


class TestPerformanceScenario(TestUserScenarioValidation):
    """æ€§èƒ½å‹åŠ›æµ‹è¯•åœºæ™¯"""

    def test_large_dataset_processing(self):
        """æµ‹è¯•å¤§æ•°æ®é›†å¤„ç†æ€§èƒ½"""
        print("\nğŸ¯ æµ‹è¯•åœºæ™¯: å¤§æ•°æ®é›†å¤„ç†æ€§èƒ½")

        import time

        # åˆ›å»ºå¤§å‹Canvasæ•°æ®
        large_canvas_path = os.path.join(self.temp_dir, "large_canvas.canvas")

        large_canvas_data = {
            "nodes": [],
            "edges": []
        }

        # åˆ›å»º100ä¸ªèŠ‚ç‚¹
        for i in range(100):
            node = {
                "id": f"node-{i}",
                "type": "text",
                "text": f"æ¦‚å¿µ{i}",
                "x": (i % 10) * 150,
                "y": (i // 10) * 120,
                "width": 140,
                "height": 100,
                "color": "1" if i % 3 == 0 else "2"  # 1/3çº¢è‰²ï¼Œ2/3ç»¿è‰²
            }
            large_canvas_data["nodes"].append(node)

        with open(large_canvas_path, 'w', encoding='utf-8') as f:
            json.dump(large_canvas_data, f, ensure_ascii=False, indent=2)

        # æµ‹è¯•å­¦ä¹ åˆ†ææ€§èƒ½
        analyzer = LearningAnalyzer()
        start_time = time.time()

        canvas_files = analyzer._find_canvas_files(large_canvas_path)
        search_time = time.time() - start_time

        self.assertLess(search_time, 1.0)  # æ–‡ä»¶æŸ¥æ‰¾åº”è¯¥å¾ˆå¿«
        self.assertEqual(len(canvas_files), 1)

        # æµ‹è¯•Canvasæ•°æ®å¤„ç†
        start_time = time.time()
        canvas_data = analyzer._load_canvas_data(large_canvas_path)
        load_time = time.time() - start_time

        self.assertLess(load_time, 0.5)  # 100ä¸ªèŠ‚ç‚¹åŠ è½½åº”è¯¥å¾ˆå¿«
        self.assertEqual(len(canvas_data["nodes"]), 100)

        print(f"âœ… å¤§æ•°æ®é›†æµ‹è¯•é€šè¿‡ (æœç´¢: {search_time:.3f}s, åŠ è½½: {load_time:.3f}s)")

    def test_multiple_plan_generation(self):
        """æµ‹è¯•å¤šè®¡åˆ’ç”Ÿæˆæ€§èƒ½"""
        print("ğŸ¯ æµ‹è¯•åœºæ™¯: æ‰¹é‡è®¡åˆ’ç”Ÿæˆ")

        import time

        generator = IntelligentReviewGenerator()

        # æµ‹è¯•ç”Ÿæˆå¤šä¸ªè®¡åˆ’çš„æ€§èƒ½
        start_time = time.time()

        plans = []
        for i in range(5):  # ç”Ÿæˆ5ä¸ªè®¡åˆ’
            config = ReviewPlanConfig(
                user_id=f"user_{i}",
                target_canvas=f"test_canvas_{i}.canvas",
                plan_type="weakness_focused"
            )

            with patch.object(generator.learning_analyzer, 'analyze_learning_history') as mock_analyze:
                mock_analyze.return_value = {
                    "analysis_summary": {"total_concepts_analyzed": 3},
                    "identified_weak_concepts": []
                }

                plan = generator.generate_review_plan(
                    user_id=f"user_{i}",
                    target_canvas=f"test_canvas_{i}.canvas",
                    plan_type="weakness_focused",
                    config=config
                )
                plans.append(plan)

        generation_time = time.time() - start_time

        self.assertEqual(len(plans), 5)
        self.assertLess(generation_time, 15.0)  # 5ä¸ªè®¡åˆ’åº”è¯¥åœ¨15ç§’å†…å®Œæˆ

        print(f"âœ… æ‰¹é‡ç”Ÿæˆæµ‹è¯•é€šè¿‡ (5ä¸ªè®¡åˆ’: {generation_time:.3f}s)")

    def test_concurrent_access(self):
        """æµ‹è¯•å¹¶å‘è®¿é—®"""
        print("ğŸ¯ æµ‹è¯•åœºæ™¯: å¹¶å‘è®¿é—®")

        import threading
        import time

        def generate_plan(user_id_suffix):
            """ç”Ÿæˆè®¡åˆ’çš„çº¿ç¨‹å‡½æ•°"""
            generator = IntelligentReviewGenerator()
            config = ReviewPlanConfig(
                user_id=f"concurrent_user_{user_id_suffix}",
                target_canvas=f"concurrent_canvas_{user_id_suffix}.canvas",
                plan_type="weakness_focused"
            )

            with patch.object(generator.learning_analyzer, 'analyze_learning_history') as mock_analyze:
                mock_analyze.return_value = {
                    "analysis_summary": {"total_concepts_analyzed": 2},
                    "identified_weak_concepts": []
                }

                try:
                    plan = generator.generate_review_plan(
                        user_id=f"concurrent_user_{user_id_suffix}",
                        target_canvas=f"concurrent_canvas_{user_id_suffix}.canvas",
                        plan_type="weakness_focused",
                        config=config
                    )
                    return f"success_{user_id_suffix}"
                except Exception as e:
                    return f"error_{user_id_suffix}: {e}"

        # åˆ›å»ºå¤šä¸ªçº¿ç¨‹
        threads = []
        start_time = time.time()

        for i in range(3):  # 3ä¸ªå¹¶å‘ç”¨æˆ·
            thread = threading.Thread(target=generate_plan, args=(i,))
            threads.append(thread)
            thread.start()

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()

        concurrent_time = time.time() - start_time

        # å¹¶å‘è®¿é—®åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        self.assertLess(concurrent_time, 20.0)

        print(f"âœ… å¹¶å‘è®¿é—®æµ‹è¯•é€šè¿‡ (3ä¸ªçº¿ç¨‹: {concurrent_time:.3f}s)")


class TestEdgeCaseScenarios(TestUserScenarioValidation):
    """è¾¹ç•Œæƒ…å†µæµ‹è¯•åœºæ™¯"""

    def test_empty_canvas_scenario(self):
        """æµ‹è¯•ç©ºCanvasåœºæ™¯"""
        print("\nğŸ¯ æµ‹è¯•åœºæ™¯: ç©ºCanvaså¤„ç†")

        # åˆ›å»ºç©ºCanvas
        empty_canvas_path = os.path.join(self.temp_dir, "empty_canvas.canvas")
        empty_canvas_data = {"nodes": [], "edges": []}

        with open(empty_canvas_path, 'w', encoding='utf-8') as f:
            json.dump(empty_canvas_data, f, ensure_ascii=False)

        analyzer = LearningAnalyzer()

        # åº”è¯¥èƒ½æ­£å¸¸å¤„ç†ç©ºCanvas
        canvas_files = analyzer._find_canvas_files(empty_canvas_path)
        self.assertEqual(len(canvas_files), 1)

        canvas_data = analyzer._load_canvas_data(empty_canvas_path)
        self.assertEqual(len(canvas_data["nodes"]), 0)

        print("âœ… ç©ºCanvasåœºæ™¯æµ‹è¯•é€šè¿‡")

    def test_very_long_content_scenario(self):
        """æµ‹è¯•è¶…é•¿å†…å®¹åœºæ™¯"""
        print("ğŸ¯ æµ‹è¯•åœºæ™¯: è¶…é•¿å†…å®¹å¤„ç†")

        # åˆ›å»ºåŒ…å«è¶…é•¿æ–‡æœ¬çš„Canvas
        long_canvas_path = os.path.join(self.temp_dir, "long_content_canvas.canvas")

        long_text = "è¿™æ˜¯ä¸€ä¸ªéå¸¸é•¿çš„æ¦‚å¿µæè¿°ï¼Œ" * 100  # çº¦1000å­—

        long_canvas_data = {
            "nodes": [
                {
                    "id": "long-concept",
                    "type": "text",
                    "text": long_text,
                    "x": 100,
                    "y": 100,
                    "width": 500,
                    "height": 300,
                    "color": "1"
                }
            ],
            "edges": []
        }

        with open(long_canvas_path, 'w', encoding='utf-8') as f:
            json.dump(long_canvas_data, f, ensure_ascii=False, indent=2)

        # æµ‹è¯•å†…å®¹åˆ†æ
        analyzer = LearningAnalyzer()

        node_analysis = analyzer._analyze_node_content(long_text, "1")

        self.assertEqual(node_analysis["type"], "concept")
        self.assertGreater(len(node_analysis["keywords"]), 0)

        # æµ‹è¯•å…³é”®è¯æå–
        keywords = analyzer._extract_keywords(long_text)
        self.assertGreater(len(keywords), 0)
        self.assertLessEqual(len(keywords), 10)  # æœ€å¤š10ä¸ªå…³é”®è¯

        print("âœ… è¶…é•¿å†…å®¹åœºæ™¯æµ‹è¯•é€šè¿‡")

    def test_special_characters_scenario(self):
        """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦åœºæ™¯"""
        print("ğŸ¯ æµ‹è¯•åœºæ™¯: ç‰¹æ®Šå­—ç¬¦å¤„ç†")

        # åˆ›å»ºåŒ…å«ç‰¹æ®Šå­—ç¬¦çš„Canvas
        special_canvas_path = os.path.join(self.temp_dir, "special_chars_canvas.canvas")

        special_text = "æ•°å­¦å…¬å¼: âˆ«âˆ«âˆ‘ f(x)dx = F(b) - F(a) ğŸ§® ç¬¦å·: âˆ€xâˆˆS, P(x) ğŸ“Š"

        special_canvas_data = {
            "nodes": [
                {
                    "id": "special-concept",
                    "type": "text",
                    "text": special_text,
                    "x": 100,
                    "y": 100,
                    "width": 400,
                    "height": 200,
                    "color": "1"
                }
            ],
            "edges": []
        }

        with open(special_canvas_path, 'w', encoding='utf-8') as f:
            json.dump(special_canvas_data, f, ensure_ascii=False, indent=2)

        # æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å¤„ç†
        analyzer = LearningAnalyzer()

        # åº”è¯¥èƒ½æ­£å¸¸å¤„ç†ç‰¹æ®Šå­—ç¬¦
        canvas_data = analyzer._load_canvas_data(special_canvas_path)
        self.assertEqual(len(canvas_data["nodes"]), 1)
        self.assertEqual(canvas_data["nodes"][0]["text"], special_text)

        print("âœ… ç‰¹æ®Šå­—ç¬¦åœºæ™¯æµ‹è¯•é€šè¿‡")

    def test_malformed_canvas_scenario(self):
        """æµ‹è¯•æŸåCanvasåœºæ™¯"""
        print("ğŸ¯ æµ‹è¯•åœºæ™¯: æŸåCanvaså¤„ç†")

        # åˆ›å»ºæŸåçš„Canvasæ–‡ä»¶
        malformed_canvas_path = os.path.join(self.temp_dir, "malformed_canvas.canvas")

        with open(malformed_canvas_path, 'w', encoding='utf-8') as f:
            f.write('{"nodes": [{"id": "test", "type": "text"')  # ç¼ºå°‘é—­åˆæ‹¬å·

        analyzer = LearningAnalyzer()

        # åº”è¯¥èƒ½æ£€æµ‹åˆ°æ ¼å¼é”™è¯¯
        try:
            canvas_data = analyzer._load_canvas_data(malformed_canvas_path)
            self.fail("åº”è¯¥æ£€æµ‹åˆ°JSONæ ¼å¼é”™è¯¯")
        except Exception as e:
            self.assertIsInstance(e, (ValueError, json.JSONDecodeError))

        print("âœ… æŸåCanvasåœºæ™¯æµ‹è¯•é€šè¿‡")


def run_scenario_tests():
    """è¿è¡Œæ‰€æœ‰åœºæ™¯æµ‹è¯•"""
    print("ğŸ­ å¼€å§‹è¿è¡Œç”¨æˆ·åœºæ™¯éªŒè¯æµ‹è¯•...")
    print("="*60)

    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()

    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestNewUserScenario,
        TestRegularUserScenario,
        TestPerformanceScenario,
        TestEdgeCaseScenarios
    ]

    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)

    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)

    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š åœºæ™¯æµ‹è¯•ç»“æœç»Ÿè®¡:")
    print(f"  æ€»æµ‹è¯•æ•°: {result.testsRun}")
    print(f"  æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"  å¤±è´¥: {len(result.failures)}")
    print(f"  é”™è¯¯: {len(result.errors)}")
    print(f"  è·³è¿‡: {len(result.skipped)}")

    success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100
    print(f"\nâœ… åœºæ™¯æµ‹è¯•é€šè¿‡ç‡: {success_rate:.1f}%")

    if result.wasSuccessful():
        print("ğŸ‰ æ‰€æœ‰ç”¨æˆ·åœºæ™¯éªŒè¯æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ’¡ æ™ºèƒ½å¤ä¹ ç³»ç»Ÿå·²å‡†å¤‡å¥½å¤„ç†å„ç§çœŸå®ç”¨æˆ·åœºæ™¯ã€‚")
    else:
        print("âš ï¸ éƒ¨åˆ†åœºæ™¯æµ‹è¯•å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥å’Œä¿®å¤ã€‚")

    return result.wasSuccessful()


if __name__ == "__main__":
    run_scenario_tests()
