"""
BMad Orchestrator CLI - å…¨è‡ªåŠ¨åŒ–å¼€å‘å‘½ä»¤è¡Œæ¥å£

æä¾›å‘½ä»¤:
- epic-develop: å¯åŠ¨ Epic å…¨è‡ªåŠ¨åŒ–å·¥ä½œæµ
- epic-status: æŸ¥çœ‹å·¥ä½œæµçŠ¶æ€
- epic-resume: æ¢å¤ä¸­æ–­çš„å·¥ä½œæµ
- epic-stop: åœæ­¢è¿è¡Œä¸­çš„å·¥ä½œæµ

ä½¿ç”¨æ–¹å¼:
    python -m bmad_orchestrator epic-develop 15 --stories 15.1 15.2 15.3
    python -m bmad_orchestrator epic-status epic-15
    python -m bmad_orchestrator epic-resume epic-15
    python -m bmad_orchestrator epic-stop epic-15

ğŸ”’ é›¶å¹»è§‰å¼€å‘åŸåˆ™:
    - é»˜è®¤å¯ç”¨ --enforce-gateï¼Œå¼ºåˆ¶æ‰§è¡Œ Commit Gate éªŒè¯
    - --skip-dev å’Œ --fast-mode éœ€è¦æ˜¾å¼ --no-enforce-gate æ‰èƒ½ç”Ÿæ•ˆ
    - æ‰€æœ‰è·³è¿‡æ“ä½œéƒ½ä¼šè®°å½•åˆ°å®¡è®¡æ—¥å¿—

Author: Canvas Learning System Team
Version: 2.0.0 (Commit Gate å¼ºåˆ¶æ‰§è¡Œ)
Created: 2025-11-30
Updated: 2025-12-11 (æ·»åŠ  Commit Gate å¼ºåˆ¶ä¿æŠ¤)
"""

import argparse
import asyncio
import io
import json
import sys

# Fix Windows encoding issue for emoji output
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
from datetime import datetime
from pathlib import Path
from typing import List, Literal, Optional

from .audit import create_audit_log
from .graph import compile_graph, resume_workflow, run_epic_workflow

# ============================================================================
# Git æ ¹ç›®å½•æ£€æµ‹
# ============================================================================

def get_git_root() -> str:
    """
    è‡ªåŠ¨æ£€æµ‹ Git ä»“åº“æ ¹ç›®å½•

    ä¼˜å…ˆçº§:
    1. å½“å‰ç›®å½•æ˜¯ Git æ ¹ç›®å½• â†’ è¿”å›å½“å‰ç›®å½•
    2. å‘ä¸Šéå†æŸ¥æ‰¾ .git ç›®å½•
    3. æ‰¾ä¸åˆ° â†’ è¿”å›å½“å‰ç›®å½• "."

    Returns:
        Git ä»“åº“æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œæˆ– "." ä½œä¸ºå›é€€
    """
    import subprocess

    try:
        result = subprocess.run(
            ['git', 'rev-parse', '--show-toplevel'],
            capture_output=True,
            text=True,
            cwd='.'
        )
        if result.returncode == 0:
            return result.stdout.strip()
    except Exception:
        pass

    # å›é€€: å‘ä¸Šéå†æŸ¥æ‰¾ .git
    current = Path.cwd()
    while current != current.parent:
        if (current / '.git').exists():
            return str(current)
        current = current.parent

    return "."


# ============================================================================
# å®¡è®¡æ—¥å¿— - è®°å½•æ‰€æœ‰è·³è¿‡æ“ä½œ
# ============================================================================

def log_skip_audit(event: str, details: dict, log_path: Optional[Path] = None):
    """
    è®°å½•è·³è¿‡æ“ä½œåˆ°å®¡è®¡æ—¥å¿—

    âš ï¸ é›¶å¹»è§‰å¼€å‘åŸåˆ™: æ‰€æœ‰è·³è¿‡æ“ä½œå¿…é¡»æœ‰å®Œæ•´è¿½æº¯
    """
    if log_path is None:
        log_path = Path(__file__).parent.parent.parent / "logs" / "bmad-audit-trail.jsonl"

    log_path.parent.mkdir(parents=True, exist_ok=True)

    entry = {
        "timestamp": datetime.now().isoformat(),
        "event": event,
        "story_id": "CLI",
        "data": details,
    }

    try:
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")
    except Exception as e:
        print(f"[WARNING] Failed to write audit log: {e}")

# ============================================================================
# CLI å‘½ä»¤å®ç°
# ============================================================================

async def cmd_epic_develop(
    epic_id: str,
    story_ids: List[str],
    base_path: str,
    worktree_base: Optional[str],
    max_turns: int,
    mode: Optional[Literal["parallel", "linear", "hybrid"]],
    ultrathink: bool,
    dry_run: bool,
    yes: bool = False,
    skip_sm: bool = False,
    skip_po: bool = False,
    skip_analysis: bool = False,
    skip_dev: bool = False,
    skip_qa: bool = False,
    skip_sdd: bool = False,
    resume_from: Optional[str] = None,
    timeout: int = 3600,
    fast_mode: bool = False,
    enforce_gate: bool = True,  # ğŸ”’ é»˜è®¤å¯ç”¨ Commit Gate å¼ºåˆ¶æ‰§è¡Œ
) -> int:
    """
    å¯åŠ¨ Epic å…¨è‡ªåŠ¨åŒ–å·¥ä½œæµ

    Args:
        epic_id: Epic ID
        story_ids: Story IDs
        base_path: é¡¹ç›®æ ¹ç›®å½•
        worktree_base: Worktree çˆ¶ç›®å½•
        max_turns: æœ€å¤§è½®æ•°
        mode: æ‰§è¡Œæ¨¡å¼
        ultrathink: å¯ç”¨ UltraThink
        dry_run: é¢„è§ˆæ¨¡å¼
        skip_sm: è·³è¿‡SMé˜¶æ®µï¼Œç›´æ¥ä»POå¼€å§‹
        skip_po: è·³è¿‡POéªŒè¯é˜¶æ®µ
        skip_analysis: è·³è¿‡ä¾èµ–åˆ†æé˜¶æ®µ
        skip_dev: è·³è¿‡DEVé˜¶æ®µï¼Œç›´æ¥ä»QAå¼€å§‹ (ç”¨äºre-QAåœºæ™¯)
        skip_qa: è·³è¿‡QAå®¡æŸ¥é˜¶æ®µ
        skip_sdd: è·³è¿‡SDDéªŒè¯é˜¶æ®µ
        resume_from: ä»æŒ‡å®šé˜¶æ®µæ¢å¤
        timeout: ä¼šè¯è¶…æ—¶æ—¶é—´(ç§’)
        fast_mode: å¿«é€Ÿæ¨¡å¼ (è·³è¿‡PO/QA/SDD)
        enforce_gate: ğŸ”’ å¼ºåˆ¶æ‰§è¡Œ Commit Gate (é»˜è®¤Trueï¼Œä¸å…è®¸è·³è¿‡DEV/QA)

    Returns:
        é€€å‡ºç  (0=æˆåŠŸ, 1=å¤±è´¥)
    """
    # ========================================================================
    # ğŸ”’ Commit Gate å¼ºåˆ¶ä¿æŠ¤æœºåˆ¶ (é›¶å¹»è§‰å¼€å‘åŸåˆ™)
    # ========================================================================
    if enforce_gate:
        dangerous_skips = []

        if skip_dev:
            dangerous_skips.append("--skip-dev")
        if skip_qa:
            dangerous_skips.append("--skip-qa")
        if fast_mode:
            dangerous_skips.append("--fast-mode")

        if dangerous_skips:
            print("\n" + "=" * 70)
            print("ğŸ”’ COMMIT GATE PROTECTION ACTIVE")
            print("=" * 70)
            print("\nâŒ ERROR: ä»¥ä¸‹å‚æ•°ä¸ --enforce-gate å†²çª:")
            for skip in dangerous_skips:
                print(f"     â€¢ {skip}")
            print("\nâš ï¸  é›¶å¹»è§‰å¼€å‘åŸåˆ™è¦æ±‚:")
            print("     â€¢ DEV é˜¶æ®µå¿…é¡»çœŸå®æ‰§è¡Œ")
            print("     â€¢ QA é˜¶æ®µå¿…é¡»çœŸå®æ‰§è¡Œ")
            print("     â€¢ Commit Gate (G1-G10) å¿…é¡»å…¨éƒ¨é€šè¿‡")
            print("\nğŸ’¡ å¦‚æœç¡®å®éœ€è¦è·³è¿‡è¿™äº›é˜¶æ®µï¼Œè¯·æ·»åŠ  --no-enforce-gate å‚æ•°")
            print("   ä½†è¯·æ³¨æ„ï¼šè¿™å°†è®°å½•åˆ°å®¡è®¡æ—¥å¿—ï¼Œä¸”è¿åé›¶å¹»è§‰å¼€å‘åŸåˆ™")
            print("=" * 70)

            # è®°å½•å®¡è®¡æ—¥å¿—
            log_skip_audit("ENFORCE_GATE_BLOCKED", {
                "epic_id": epic_id,
                "stories": story_ids,
                "blocked_params": dangerous_skips,
                "reason": "Commit Gate protection active",
            })

            return 1

    # å¦‚æœç¦ç”¨äº† enforce_gateï¼Œè®°å½•è­¦å‘Š
    if not enforce_gate:
        print("\n" + "âš ï¸" * 35)
        print("âš ï¸  WARNING: --no-enforce-gate å·²å¯ç”¨")
        print("âš ï¸  Commit Gate ä¿æŠ¤å·²ç¦ç”¨ï¼Œè¿™è¿åé›¶å¹»è§‰å¼€å‘åŸåˆ™")
        print("âš ï¸  æ­¤æ“ä½œå·²è®°å½•åˆ°å®¡è®¡æ—¥å¿—")
        print("âš ï¸" * 35 + "\n")

        log_skip_audit("ENFORCE_GATE_DISABLED", {
            "epic_id": epic_id,
            "stories": story_ids,
            "skip_dev": skip_dev,
            "skip_qa": skip_qa,
            "fast_mode": fast_mode,
            "warning": "Zero-hallucination principle violated",
        })

    # ========================================================================
    # å¤„ç† --resume-from å‚æ•°
    # ========================================================================
    if resume_from:
        phase_order = ["sm", "po", "analysis", "dev", "qa", "sdd", "merge", "commit"]
        try:
            resume_index = phase_order.index(resume_from)
            skip_sm = resume_index > 0
            skip_po = resume_index > 1
            skip_analysis = resume_index > 2

            # ğŸ”’ å³ä½¿ resume-from ä¹Ÿä¸èƒ½è·³è¿‡ DEV (é™¤é enforce_gate=False)
            if resume_index > 3 and enforce_gate:
                print(f"\nâŒ ERROR: --resume-from {resume_from} ä¼šè·³è¿‡ DEV é˜¶æ®µ")
                print("   è¿™ä¸ --enforce-gate å†²çªï¼Œè¯·æ·»åŠ  --no-enforce-gate")
                log_skip_audit("RESUME_FROM_BLOCKED", {
                    "epic_id": epic_id,
                    "resume_from": resume_from,
                    "reason": "Would skip DEV phase",
                })
                return 1

            skip_dev = resume_index > 3  # dev=3, qa=4, sdd=5, merge=6, commit=7
            print(f"[INFO] Resuming from '{resume_from}' - skipping previous phases")
        except ValueError:
            print(f"[ERROR] Invalid resume-from phase: {resume_from}")
            return 1

    # ========================================================================
    # å¤„ç† --fast-mode å‚æ•°
    # ========================================================================
    if fast_mode:
        skip_po = True
        skip_qa = True
        skip_sdd = True
        print("[INFO] Fast mode enabled - skipping PO/QA/SDD validation")

        # è®°å½•åˆ°å®¡è®¡æ—¥å¿—
        log_skip_audit("FAST_MODE_ENABLED", {
            "epic_id": epic_id,
            "stories": story_ids,
            "skipped_phases": ["PO", "QA", "SDD"],
        })

    print("=" * 70)
    print("BMad Orchestrator - Epic Development Workflow")
    print("=" * 70)
    print(f"Epic ID: {epic_id}")
    print(f"Stories: {', '.join(story_ids)}")
    print(f"Base Path: {base_path}")
    print(f"Worktree Base: {worktree_base or 'Auto (parent of base_path)'}")
    print(f"Max Turns: {max_turns}")
    print(f"Mode: {mode or 'Auto-detect'}")
    print(f"UltraThink: {ultrathink}")
    print(f"Timeout: {timeout}s")
    print(f"Dry Run: {dry_run}")
    print("\nPhase Skip Settings:")
    print(f"  Skip SM: {skip_sm}")
    print(f"  Skip PO: {skip_po}")
    print(f"  Skip Analysis: {skip_analysis}")
    print(f"  Skip DEV: {skip_dev}")
    print(f"  Skip QA: {skip_qa}")
    print(f"  Skip SDD: {skip_sdd}")
    if any([skip_sm, skip_po, skip_analysis, skip_dev, skip_qa, skip_sdd]):
        entry_point = "SM"
        if skip_sm:
            entry_point = "PO"
        if skip_sm and skip_po:
            entry_point = "Analysis"
        if skip_sm and skip_po and skip_analysis:
            entry_point = "DEV"
        if skip_sm and skip_po and skip_analysis and skip_dev:
            entry_point = "QA"
        print(f"  ** Entry Point: {entry_point} **")
    print("=" * 70)

    if dry_run:
        print("\n[DRY RUN] Would execute workflow with above settings")
        print("[DRY RUN] No actual changes will be made")

        # é¢„è§ˆæ¨¡å¼: åˆ†æä¾èµ–
        from .dependency_analyzer import analyze_dependencies, print_analysis_report

        result = await analyze_dependencies(
            story_ids=story_ids,
            base_path=Path(base_path),
        )
        print("\n" + print_analysis_report(result))
        return 0

    # ç¡®è®¤æ‰§è¡Œ (skip if --yes flag is provided)
    if not yes:
        print("\n[WARNING] This will start an automated 24/7 development workflow.")
        print("          The workflow will run unattended until completion.")
        print("\n          Press Enter to continue, or Ctrl+C to cancel...")
        print("          (Use --yes to skip this prompt)")

        try:
            input()
        except KeyboardInterrupt:
            print("\nCancelled.")
            return 1
    else:
        print("\n[OK] Auto-confirmed with --yes flag. Starting workflow...")

    # æ‰§è¡Œå·¥ä½œæµ
    try:
        result = await run_epic_workflow(
            epic_id=epic_id,
            story_ids=story_ids,
            base_path=base_path,
            worktree_base=worktree_base,
            max_turns=max_turns,
            mode_override=mode,
            skip_sm=skip_sm,
            skip_po=skip_po,
            skip_analysis=skip_analysis,
            skip_dev=skip_dev,
            skip_qa=skip_qa,
            skip_sdd=skip_sdd,
            timeout=timeout,
        )

        # è¾“å‡ºç»“æœ
        print("\n" + "=" * 70)
        print("WORKFLOW COMPLETE")
        print("=" * 70)
        print(f"Final Status: {result.get('final_status', 'unknown')}")
        print(f"Summary: {result.get('completion_summary', 'N/A')}")

        # ====================================================================
        # ç”Ÿæˆæ‰§è¡Œå®¡è®¡æŠ¥å‘Š
        # ====================================================================
        audit = create_audit_log(epic_id=epic_id, story_ids=story_ids, project_root=Path(base_path))

        # ä» result ä¸­æå–æ‰§è¡Œè®°å½•
        executed_nodes = result.get("executed_nodes", [])
        for node_entry in executed_nodes:
            node_name = node_entry.get("node", "unknown")
            status = node_entry.get("status", "unknown")
            if status == "completed":
                audit.log_execution(node_name, [], metadata=node_entry)
            elif status == "failed":
                audit.log_failure(node_name, node_entry.get("error", "Unknown error"))
            elif status == "skipped":
                audit.log_skip(node_name, node_entry.get("reason", "Skipped"))

        # è®°å½•è·³è¿‡çš„é˜¶æ®µ
        if skip_sm:
            audit.log_skip("sm_node", "CLI flag: --skip-sm")
        if skip_po:
            audit.log_skip("po_node", "CLI flag: --skip-po")
        if skip_analysis:
            audit.log_skip("analysis_node", "CLI flag: --skip-analysis")
        if skip_dev:
            audit.log_skip("dev_node", "CLI flag: --skip-dev")
        if skip_qa:
            audit.log_skip("qa_node", "CLI flag: --skip-qa")
        if skip_sdd:
            audit.log_skip("sdd_validation_node", "CLI flag: --skip-sdd")

        audit.finalize()

        # ä¿å­˜å®¡è®¡æŠ¥å‘Š
        logs_dir = Path(base_path) / "logs" / "audit"
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        audit.save(logs_dir / f"epic-{epic_id}-{timestamp}.json")
        audit.save_markdown(logs_dir / f"epic-{epic_id}-{timestamp}.md")

        # æ£€æŸ¥å·¥ä½œæµåˆè§„æ€§
        compliance = audit.check_workflow_compliance()
        if compliance["compliant"]:
            print("\nâœ… å·¥ä½œæµåˆè§„æ€§: é€šè¿‡")
        else:
            print("\nâš ï¸ å·¥ä½œæµåˆè§„æ€§: å­˜åœ¨é—®é¢˜")
            if compliance["missing_required"]:
                print(f"   ç¼ºå¤±å¿…è¦èŠ‚ç‚¹: {', '.join(compliance['missing_required'])}")
            if compliance["order_violations"]:
                print(f"   æ‰§è¡Œé¡ºåºé—®é¢˜: {len(compliance['order_violations'])} ä¸ª")

        print(f"\nğŸ“‹ å®¡è®¡æŠ¥å‘Šå·²ä¿å­˜: {logs_dir / f'epic-{epic_id}-{timestamp}.md'}")

        # è¯¦ç»†ç»Ÿè®¡
        dev_outcomes = result.get("dev_outcomes", [])
        qa_outcomes = result.get("qa_outcomes", [])
        blockers = result.get("blockers", [])
        commits = result.get("commit_shas", [])

        print("\nStatistics:")
        print(f"  Stories Processed: {len(dev_outcomes)}")
        print(f"  Dev Success: {sum(1 for o in dev_outcomes if o.get('outcome') == 'SUCCESS')}")
        print(f"  QA Passed: {sum(1 for o in qa_outcomes if o.get('qa_gate') in ('PASS', 'WAIVED'))}")
        print(f"  Commits: {len(commits)}")
        print(f"  Blockers: {len(blockers)}")

        if blockers:
            print("\nBlockers:")
            for b in blockers[:5]:
                print(f"  - {b.get('story_id')}: {b.get('blocker_type')} - {b.get('description', '')[:50]}")

        return 0 if result.get("final_status") == "success" else 1

    except Exception as e:
        print(f"\n[ERROR] Workflow failed with error: {e}")
        return 1


async def cmd_epic_status(thread_id: str, checkpointer_path: str) -> int:
    """
    æŸ¥çœ‹å·¥ä½œæµçŠ¶æ€

    Args:
        thread_id: å·¥ä½œæµçº¿ç¨‹ ID
        checkpointer_path: æ£€æŸ¥ç‚¹æ•°æ®åº“è·¯å¾„

    Returns:
        é€€å‡ºç 
    """
    print(f"Checking status for: {thread_id}")

    try:
        compiled = compile_graph(checkpointer_path)
        config = {"configurable": {"thread_id": thread_id}}

        state = await compiled.aget_state(config)

        if not state.values:
            print(f"\n[ERROR] No workflow found for thread: {thread_id}")
            return 1

        values = state.values
        print("\n" + "=" * 70)
        print(f"WORKFLOW STATUS: {thread_id}")
        print("=" * 70)
        print(f"Session ID: {values.get('session_id', 'N/A')}")
        print(f"Epic ID: {values.get('epic_id', 'N/A')}")
        print(f"Current Phase: {values.get('current_phase', 'N/A')}")
        print(f"Final Status: {values.get('final_status', 'in_progress')}")
        print(f"Started At: {values.get('started_at', 'N/A')}")

        # è¿›åº¦è¯¦æƒ…
        story_drafts = values.get("story_drafts", [])
        approved_stories = values.get("approved_stories", [])
        dev_outcomes = values.get("dev_outcomes", [])
        qa_outcomes = values.get("qa_outcomes", [])

        print("\nProgress:")
        print(f"  SM: {len(story_drafts)} drafts created")
        print(f"  PO: {len(approved_stories)} stories approved")
        print(f"  DEV: {len(dev_outcomes)} stories developed")
        print(f"  QA: {len(qa_outcomes)} stories reviewed")

        # é˜¶æ®µçŠ¶æ€
        print("\nPhase Status:")
        print(f"  SM: {values.get('sm_status', 'pending')}")
        print(f"  PO: {values.get('po_status', 'pending')}")
        print(f"  DEV: {values.get('dev_status', 'pending')}")
        print(f"  QA: {values.get('qa_status', 'pending')}")
        print(f"  MERGE: {values.get('merge_status', 'pending')}")

        # æ‰§è¡Œæ¨¡å¼
        print("\nExecution:")
        print(f"  Mode: {values.get('execution_mode', 'N/A')}")
        print(f"  Current Batch: {values.get('current_batch_index', 0) + 1}/{len(values.get('parallel_batches', []))}")

        return 0

    except Exception as e:
        print(f"\n[ERROR] Failed to get status: {e}")
        return 1


async def cmd_epic_resume(thread_id: str, checkpointer_path: str) -> int:
    """
    æ¢å¤ä¸­æ–­çš„å·¥ä½œæµ

    Args:
        thread_id: å·¥ä½œæµçº¿ç¨‹ ID
        checkpointer_path: æ£€æŸ¥ç‚¹æ•°æ®åº“è·¯å¾„

    Returns:
        é€€å‡ºç 
    """
    print(f"Resuming workflow: {thread_id}")

    try:
        result = await resume_workflow(thread_id, checkpointer_path)

        if not result:
            print(f"\n[ERROR] No workflow found to resume: {thread_id}")
            return 1

        print("\n" + "=" * 70)
        print("WORKFLOW RESUMED AND COMPLETED")
        print("=" * 70)
        print(f"Final Status: {result.get('final_status', 'unknown')}")
        print(f"Summary: {result.get('completion_summary', 'N/A')}")

        return 0 if result.get("final_status") == "success" else 1

    except Exception as e:
        print(f"\n[ERROR] Failed to resume: {e}")
        return 1


async def cmd_epic_stop(thread_id: str) -> int:
    """
    åœæ­¢è¿è¡Œä¸­çš„å·¥ä½œæµ

    Args:
        thread_id: å·¥ä½œæµçº¿ç¨‹ ID

    Returns:
        é€€å‡ºç 
    """
    print(f"Stopping workflow: {thread_id}")
    # TODO: å®ç°åœæ­¢é€»è¾‘ (éœ€è¦è¿½è¸ªè¿è¡Œä¸­çš„è¿›ç¨‹)
    print("[WARNING] Stop functionality is not yet implemented")
    print("          Please manually terminate Claude processes")
    return 1


# ============================================================================
# CLI ä¸»å…¥å£
# ============================================================================

def main():
    """CLI ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="BMad Orchestrator - å…¨è‡ªåŠ¨åŒ– 24/7 å¼€å‘ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¯åŠ¨ Epic 15 å…¨è‡ªåŠ¨å¼€å‘
  python -m bmad_orchestrator epic-develop 15 --stories 15.1 15.2 15.3

  # é¢„è§ˆæ¨¡å¼ (ä¸æ‰§è¡Œ)
  python -m bmad_orchestrator epic-develop 15 --stories 15.1 15.2 --dry-run

  # æŒ‡å®šå¹¶è¡Œæ¨¡å¼
  python -m bmad_orchestrator epic-develop 15 --stories 15.1 15.2 --mode parallel

  # æŸ¥çœ‹çŠ¶æ€
  python -m bmad_orchestrator epic-status epic-15

  # æ¢å¤ä¸­æ–­çš„å·¥ä½œæµ
  python -m bmad_orchestrator epic-resume epic-15
        """
    )

    subparsers = parser.add_subparsers(dest="command", help="å‘½ä»¤")

    # epic-develop å‘½ä»¤
    develop_parser = subparsers.add_parser(
        "epic-develop",
        help="å¯åŠ¨ Epic å…¨è‡ªåŠ¨åŒ–å·¥ä½œæµ"
    )
    develop_parser.add_argument("epic_id", help="Epic ID")
    develop_parser.add_argument("--stories", nargs="+", required=True, help="Story IDs")
    develop_parser.add_argument("--base-path", default=get_git_root(), help="é¡¹ç›®æ ¹ç›®å½• (è‡ªåŠ¨æ£€æµ‹ Git æ ¹ç›®å½•)")
    develop_parser.add_argument("--worktree-base", help="Worktree çˆ¶ç›®å½•")
    develop_parser.add_argument("--max-turns", type=int, default=200, help="æ¯ä¸ªä¼šè¯æœ€å¤§è½®æ•°")
    develop_parser.add_argument(
        "--mode",
        choices=["parallel", "linear", "hybrid"],
        help="æ‰§è¡Œæ¨¡å¼ (é»˜è®¤: è‡ªåŠ¨æ£€æµ‹)"
    )
    develop_parser.add_argument("--no-ultrathink", action="store_true", help="ç¦ç”¨ UltraThink")
    develop_parser.add_argument("--dry-run", action="store_true", help="é¢„è§ˆæ¨¡å¼")
    develop_parser.add_argument("--yes", "-y", action="store_true", help="è·³è¿‡ç¡®è®¤æç¤º (ç”¨äºæ— äººå€¼å®ˆè¿è¡Œ)")
    develop_parser.add_argument("--skip-sm", action="store_true", help="è·³è¿‡SMé˜¶æ®µï¼Œç›´æ¥ä»POéªŒè¯å¼€å§‹ (Storyæ–‡ä»¶å·²å­˜åœ¨æ—¶ä½¿ç”¨)")
    develop_parser.add_argument("--skip-po", action="store_true", help="è·³è¿‡POéªŒè¯é˜¶æ®µï¼Œç›´æ¥ä»åˆ†æå¼€å§‹ (Storyå·²éªŒè¯æ—¶ä½¿ç”¨)")
    develop_parser.add_argument("--skip-analysis", action="store_true", help="è·³è¿‡ä¾èµ–åˆ†æï¼Œä½¿ç”¨--modeæŒ‡å®šçš„æ¨¡å¼")
    develop_parser.add_argument("--skip-dev", action="store_true", help="è·³è¿‡DEVé˜¶æ®µï¼Œä»mainåˆ›å»ºworktreeså¹¶ç›´æ¥è¿è¡ŒQA (ç”¨äºre-QAåœºæ™¯)")
    develop_parser.add_argument("--skip-qa", action="store_true", help="è·³è¿‡QAå®¡æŸ¥é˜¶æ®µ (å¿«é€Ÿè¿­ä»£æ¨¡å¼)")
    develop_parser.add_argument("--skip-sdd", action="store_true", help="è·³è¿‡SDDéªŒè¯é˜¶æ®µ")
    develop_parser.add_argument(
        "--resume-from",
        type=str,
        choices=["sm", "po", "analysis", "dev", "qa", "sdd", "merge", "commit"],
        help="ä»æŒ‡å®šé˜¶æ®µæ¢å¤ (è‡ªåŠ¨è·³è¿‡ä¹‹å‰é˜¶æ®µ)"
    )
    develop_parser.add_argument("--timeout", type=int, default=3600, help="ä¼šè¯è¶…æ—¶æ—¶é—´(ç§’)ï¼Œé»˜è®¤3600")
    develop_parser.add_argument("--fast-mode", action="store_true", help="å¿«é€Ÿæ¨¡å¼: è·³è¿‡PO/QA/SDDéªŒè¯")

    # ğŸ”’ Commit Gate å¼ºåˆ¶æ‰§è¡Œå‚æ•° (é›¶å¹»è§‰å¼€å‘åŸåˆ™)
    gate_group = develop_parser.add_mutually_exclusive_group()
    gate_group.add_argument(
        "--enforce-gate",
        action="store_true",
        dest="enforce_gate",
        default=True,
        help="ğŸ”’ å¼ºåˆ¶æ‰§è¡Œ Commit Gate (é»˜è®¤å¯ç”¨) - ç¦æ­¢ --skip-dev/--skip-qa/--fast-mode"
    )
    gate_group.add_argument(
        "--no-enforce-gate",
        action="store_false",
        dest="enforce_gate",
        help="âš ï¸ ç¦ç”¨ Commit Gate ä¿æŠ¤ (è¿åé›¶å¹»è§‰å¼€å‘åŸåˆ™ï¼Œå°†è®°å½•å®¡è®¡æ—¥å¿—)"
    )

    # epic-status å‘½ä»¤
    status_parser = subparsers.add_parser(
        "epic-status",
        help="æŸ¥çœ‹å·¥ä½œæµçŠ¶æ€"
    )
    status_parser.add_argument("thread_id", help="å·¥ä½œæµçº¿ç¨‹ ID (å¦‚ epic-15)")
    status_parser.add_argument("--db", default="bmad_orchestrator.db", help="æ£€æŸ¥ç‚¹æ•°æ®åº“")

    # epic-resume å‘½ä»¤
    resume_parser = subparsers.add_parser(
        "epic-resume",
        help="æ¢å¤ä¸­æ–­çš„å·¥ä½œæµ"
    )
    resume_parser.add_argument("thread_id", help="å·¥ä½œæµçº¿ç¨‹ ID")
    resume_parser.add_argument("--db", default="bmad_orchestrator.db", help="æ£€æŸ¥ç‚¹æ•°æ®åº“")

    # epic-stop å‘½ä»¤
    stop_parser = subparsers.add_parser(
        "epic-stop",
        help="åœæ­¢è¿è¡Œä¸­çš„å·¥ä½œæµ"
    )
    stop_parser.add_argument("thread_id", help="å·¥ä½œæµçº¿ç¨‹ ID")

    # è§£æå‚æ•°
    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    # æ‰§è¡Œå‘½ä»¤
    if args.command == "epic-develop":
        # Parse comma-separated story IDs (support both "16.1,16.2" and "16.1 16.2" formats)
        parsed_stories = []
        for story in args.stories:
            # Split by comma and strip whitespace
            parsed_stories.extend([s.strip() for s in story.split(",") if s.strip()])

        return asyncio.run(cmd_epic_develop(
            epic_id=args.epic_id,
            story_ids=parsed_stories,
            base_path=args.base_path,
            worktree_base=args.worktree_base,
            max_turns=args.max_turns,
            mode=args.mode,
            ultrathink=not args.no_ultrathink,
            dry_run=args.dry_run,
            yes=args.yes,
            skip_sm=args.skip_sm,
            skip_po=args.skip_po,
            skip_analysis=args.skip_analysis,
            skip_dev=args.skip_dev,
            skip_qa=args.skip_qa,
            skip_sdd=args.skip_sdd,
            resume_from=args.resume_from,
            timeout=args.timeout,
            fast_mode=args.fast_mode,
            enforce_gate=args.enforce_gate,  # ğŸ”’ ä¼ é€’ Commit Gate å¼ºåˆ¶å‚æ•°
        ))
    elif args.command == "epic-status":
        return asyncio.run(cmd_epic_status(args.thread_id, args.db))
    elif args.command == "epic-resume":
        return asyncio.run(cmd_epic_resume(args.thread_id, args.db))
    elif args.command == "epic-stop":
        return asyncio.run(cmd_epic_stop(args.thread_id))

    return 1


if __name__ == "__main__":
    sys.exit(main())
